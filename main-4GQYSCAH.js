import{$ as l,$a as tc,$b as Ni,A as Cs,Aa as ai,Ab as ie,B as Et,Ba as Si,Bb as Q,C as xt,Ca as En,Cb as ne,D as Lt,Da as Ss,Db as it,E as ks,Ea as Os,Eb as qi,F as Ke,Fa as si,Fb as Fi,G as Ds,Ga as Oi,Gb as ke,H as Es,Ha as Ul,Hb as Ie,I as oi,Ia as Hl,Ib as Rn,J as Gt,Ja as Yl,Jb as he,K as xs,Ka as Zl,Kb as sc,L as Ml,La as Xl,Lb as k,M as Nl,Ma as Jl,Mb as Y,N as Ll,Na as $l,Nb as T,O as Io,Oa as Ue,Ob as se,P as tt,Pa as Co,Pb as xe,Q as Ae,Qa as Ql,Qb as B,R as pe,Ra as f,Rb as j,S as fe,Sa as xn,Sb as Rt,T as U,Ta as Pe,Tb as Be,U as _o,Ua as qe,Ub as N,V as Ti,Va as Ce,Vb as Me,W as g,Wa as He,Wb as m,X as E,Xa as Pi,Xb as St,Y as Gl,Ya as Fe,Yb as mt,Z as A,Za as Tn,Zb as Mi,_ as O,_a as ec,_b as de,a as b,aa as Ri,ab as ko,ac as Ns,b as ge,ba as Kl,bb as y,bc as rc,ca as ze,cb as x,cc as lc,d as De,da as We,db as _,dc as ft,e as Ol,ea as re,eb as H,ec as ri,f as kt,fa as le,fb as st,fc as Ls,g as ws,ga as Tt,gb as ic,gc as Vt,h as In,ha as Cn,hb as nc,hc as cc,i as S,ia as zl,ib as Z,ic as me,j as Ee,ja as V,jb as F,jc as Wt,k as Dt,ka as D,kb as ve,kc as dc,l as Oe,la as kn,lb as Ps,lc as K,m as I,ma as Kt,mb as qs,mc as Ye,n as ni,na as wo,nb as Fs,nc as Do,o as _n,oa as Ts,ob as Ms,oc as uc,p as Pl,pa as te,pb as pt,q,qa as Bl,qb as X,r as xi,ra as jl,rb as oc,s as Ge,sa as we,sb as ac,t as wn,ta as ce,tb as J,u as vo,ua as Rs,ub as $,v as Ao,va as R,vb as Bt,w as ql,wa as zt,wb as jt,x as Fl,xa as Vl,xb as M,y as Nt,ya as Dn,yb as u,z as ue,za as Wl,zb as h}from"./chunk-Z45WTGF5.js";var mc=null;function Ot(){return mc}function Gs(i){mc??=i}var Sn=class{},On=(()=>{class i{historyGo(e){throw new Error("")}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:()=>l(fc),providedIn:"platform"})}return i})(),Ks=new A(""),fc=(()=>{class i extends On{_location;_history;_doc=l(D);constructor(){super(),this._location=window.location,this._history=window.history}getBaseHrefFromDOM(){return Ot().getBaseHref(this._doc)}onPopState(e){let t=Ot().getGlobalEventTarget(this._doc,"window");return t.addEventListener("popstate",e,!1),()=>t.removeEventListener("popstate",e)}onHashChange(e){let t=Ot().getGlobalEventTarget(this._doc,"window");return t.addEventListener("hashchange",e,!1),()=>t.removeEventListener("hashchange",e)}get href(){return this._location.href}get protocol(){return this._location.protocol}get hostname(){return this._location.hostname}get port(){return this._location.port}get pathname(){return this._location.pathname}get search(){return this._location.search}get hash(){return this._location.hash}set pathname(e){this._location.pathname=e}pushState(e,t,o){this._history.pushState(e,t,o)}replaceState(e,t,o){this._history.replaceState(e,t,o)}forward(){this._history.forward()}back(){this._history.back()}historyGo(e=0){this._history.go(e)}getState(){return this._history.state}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:()=>new i,providedIn:"platform"})}return i})();function Eo(i,n){return i?n?i.endsWith("/")?n.startsWith("/")?i+n.slice(1):i+n:n.startsWith("/")?i+n:`${i}/${n}`:i:n}function hc(i){let n=i.search(/#|\?|$/);return i[n-1]==="/"?i.slice(0,n-1)+i.slice(n):i}function rt(i){return i&&i[0]!=="?"?`?${i}`:i}var lt=(()=>{class i{historyGo(e){throw new Error("")}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:()=>l(To),providedIn:"root"})}return i})(),xo=new A(""),To=(()=>{class i extends lt{_platformLocation;_baseHref;_removeListenerFns=[];constructor(e,t){super(),this._platformLocation=e,this._baseHref=t??this._platformLocation.getBaseHrefFromDOM()??l(D).location?.origin??""}ngOnDestroy(){for(;this._removeListenerFns.length;)this._removeListenerFns.pop()()}onPopState(e){this._removeListenerFns.push(this._platformLocation.onPopState(e),this._platformLocation.onHashChange(e))}getBaseHref(){return this._baseHref}prepareExternalUrl(e){return Eo(this._baseHref,e)}path(e=!1){let t=this._platformLocation.pathname+rt(this._platformLocation.search),o=this._platformLocation.hash;return o&&e?`${t}${o}`:t}pushState(e,t,o,a){let s=this.prepareExternalUrl(o+rt(a));this._platformLocation.pushState(e,t,s)}replaceState(e,t,o,a){let s=this.prepareExternalUrl(o+rt(a));this._platformLocation.replaceState(e,t,s)}forward(){this._platformLocation.forward()}back(){this._platformLocation.back()}getState(){return this._platformLocation.getState()}historyGo(e=0){this._platformLocation.historyGo?.(e)}static \u0275fac=function(t){return new(t||i)(O(On),O(xo,8))};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),yt=(()=>{class i{_subject=new S;_basePath;_locationStrategy;_urlChangeListeners=[];_urlChangeSubscription=null;constructor(e){this._locationStrategy=e;let t=this._locationStrategy.getBaseHref();this._basePath=Th(hc(pc(t))),this._locationStrategy.onPopState(o=>{this._subject.next({url:this.path(!0),pop:!0,state:o.state,type:o.type})})}ngOnDestroy(){this._urlChangeSubscription?.unsubscribe(),this._urlChangeListeners=[]}path(e=!1){return this.normalize(this._locationStrategy.path(e))}getState(){return this._locationStrategy.getState()}isCurrentPathEqualTo(e,t=""){return this.path()==this.normalize(e+rt(t))}normalize(e){return i.stripTrailingSlash(xh(this._basePath,pc(e)))}prepareExternalUrl(e){return e&&e[0]!=="/"&&(e="/"+e),this._locationStrategy.prepareExternalUrl(e)}go(e,t="",o=null){this._locationStrategy.pushState(o,"",e,t),this._notifyUrlChangeListeners(this.prepareExternalUrl(e+rt(t)),o)}replaceState(e,t="",o=null){this._locationStrategy.replaceState(o,"",e,t),this._notifyUrlChangeListeners(this.prepareExternalUrl(e+rt(t)),o)}forward(){this._locationStrategy.forward()}back(){this._locationStrategy.back()}historyGo(e=0){this._locationStrategy.historyGo?.(e)}onUrlChange(e){return this._urlChangeListeners.push(e),this._urlChangeSubscription??=this.subscribe(t=>{this._notifyUrlChangeListeners(t.url,t.state)}),()=>{let t=this._urlChangeListeners.indexOf(e);this._urlChangeListeners.splice(t,1),this._urlChangeListeners.length===0&&(this._urlChangeSubscription?.unsubscribe(),this._urlChangeSubscription=null)}}_notifyUrlChangeListeners(e="",t){this._urlChangeListeners.forEach(o=>o(e,t))}subscribe(e,t,o){return this._subject.subscribe({next:e,error:t??void 0,complete:o??void 0})}static normalizeQueryParams=rt;static joinWithSlash=Eo;static stripTrailingSlash=hc;static \u0275fac=function(t){return new(t||i)(O(lt))};static \u0275prov=g({token:i,factory:()=>Eh(),providedIn:"root"})}return i})();function Eh(){return new yt(O(lt))}function xh(i,n){if(!i||!n.startsWith(i))return n;let e=n.substring(i.length);return e===""||["/",";","?","#"].includes(e[0])?e:n}function pc(i){return i.replace(/\/index.html$/,"")}function Th(i){if(new RegExp("^(https?:)?//").test(i)){let[,e]=i.split(/\/\/[^\/]+/);return e}return i}var zs=(()=>{class i extends lt{_platformLocation;_baseHref="";_removeListenerFns=[];constructor(e,t){super(),this._platformLocation=e,t!=null&&(this._baseHref=t)}ngOnDestroy(){for(;this._removeListenerFns.length;)this._removeListenerFns.pop()()}onPopState(e){this._removeListenerFns.push(this._platformLocation.onPopState(e),this._platformLocation.onHashChange(e))}getBaseHref(){return this._baseHref}path(e=!1){let t=this._platformLocation.hash??"#";return t.length>0?t.substring(1):t}prepareExternalUrl(e){let t=Eo(this._baseHref,e);return t.length>0?"#"+t:t}pushState(e,t,o,a){let s=this.prepareExternalUrl(o+rt(a))||this._platformLocation.pathname;this._platformLocation.pushState(e,t,s)}replaceState(e,t,o,a){let s=this.prepareExternalUrl(o+rt(a))||this._platformLocation.pathname;this._platformLocation.replaceState(e,t,s)}forward(){this._platformLocation.forward()}back(){this._platformLocation.back()}getState(){return this._platformLocation.getState()}historyGo(e=0){this._platformLocation.historyGo?.(e)}static \u0275fac=function(t){return new(t||i)(O(On),O(xo,8))};static \u0275prov=g({token:i,factory:i.\u0275fac})}return i})();var Bs=(()=>{class i{_viewContainerRef;_viewRef=null;ngTemplateOutletContext=null;ngTemplateOutlet=null;ngTemplateOutletInjector=null;constructor(e){this._viewContainerRef=e}ngOnChanges(e){if(this._shouldRecreateView(e)){let t=this._viewContainerRef;if(this._viewRef&&t.remove(t.indexOf(this._viewRef)),!this.ngTemplateOutlet){this._viewRef=null;return}let o=this._createContextForwardProxy();this._viewRef=t.createEmbeddedView(this.ngTemplateOutlet,o,{injector:this.ngTemplateOutletInjector??void 0})}}_shouldRecreateView(e){return!!e.ngTemplateOutlet||!!e.ngTemplateOutletInjector}_createContextForwardProxy(){return new Proxy({},{set:(e,t,o)=>this.ngTemplateOutletContext?Reflect.set(this.ngTemplateOutletContext,t,o):!1,get:(e,t,o)=>{if(this.ngTemplateOutletContext)return Reflect.get(this.ngTemplateOutletContext,t,o)}})}static \u0275fac=function(t){return new(t||i)(He(Fe))};static \u0275dir=_({type:i,selectors:[["","ngTemplateOutlet",""]],inputs:{ngTemplateOutletContext:"ngTemplateOutletContext",ngTemplateOutlet:"ngTemplateOutlet",ngTemplateOutletInjector:"ngTemplateOutletInjector"},features:[we]})}return i})();var je=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({})}return i})();function js(i,n){n=encodeURIComponent(n);for(let e of i.split(";")){let t=e.indexOf("="),[o,a]=t==-1?[e,""]:[e.slice(0,t),e.slice(t+1)];if(o.trim()===n)return decodeURIComponent(a)}return null}var Pn=class{};var Ws="browser";function gc(i){return i===Ws}var bc=(()=>{class i{static \u0275prov=g({token:i,providedIn:"root",factory:()=>new Vs(l(D),window)})}return i})(),Vs=class{document;window;offset=()=>[0,0];constructor(n,e){this.document=n,this.window=e}setOffset(n){Array.isArray(n)?this.offset=()=>n:this.offset=n}getScrollPosition(){return[this.window.scrollX,this.window.scrollY]}scrollToPosition(n,e){this.window.scrollTo(ge(b({},e),{left:n[0],top:n[1]}))}scrollToAnchor(n,e){let t=Oh(this.document,n);t&&(this.scrollToElement(t,e),t.focus())}setHistoryScrollRestoration(n){try{this.window.history.scrollRestoration=n}catch{console.warn(_o(2400,!1))}}scrollToElement(n,e){let t=n.getBoundingClientRect(),o=t.left+this.window.pageXOffset,a=t.top+this.window.pageYOffset,s=this.offset();this.window.scrollTo(ge(b({},e),{left:o-s[0],top:a-s[1]}))}};function Oh(i,n){let e=i.getElementById(n)||i.getElementsByName(n)[0];if(e)return e;if(typeof i.createTreeWalker=="function"&&i.body&&typeof i.body.attachShadow=="function"){let t=i.createTreeWalker(i.body,NodeFilter.SHOW_ELEMENT),o=t.currentNode;for(;o;){let a=o.shadowRoot;if(a){let s=a.getElementById(n)||a.querySelector(`[name="${n}"]`);if(s)return s}o=t.nextNode()}}return null}var So=new A(""),Xs=(()=>{class i{_zone;_plugins;_eventNameToPlugin=new Map;constructor(e,t){this._zone=t,e.forEach(o=>{o.manager=this}),this._plugins=e.slice().reverse()}addEventListener(e,t,o,a){return this._findPluginFor(t).addEventListener(e,t,o,a)}getZone(){return this._zone}_findPluginFor(e){let t=this._eventNameToPlugin.get(e);if(t)return t;if(t=this._plugins.find(a=>a.supports(e)),!t)throw new U(5101,!1);return this._eventNameToPlugin.set(e,t),t}static \u0275fac=function(t){return new(t||i)(O(So),O(F))};static \u0275prov=g({token:i,factory:i.\u0275fac})}return i})(),qn=class{_doc;constructor(n){this._doc=n}manager},Us="ng-app-id";function vc(i){for(let n of i)n.remove()}function Ac(i,n){let e=n.createElement("style");return e.textContent=i,e}function qh(i,n,e,t){let o=i.head?.querySelectorAll(`style[${Us}="${n}"],link[${Us}="${n}"]`);if(o)for(let a of o)a.removeAttribute(Us),a instanceof HTMLLinkElement?t.set(a.href.slice(a.href.lastIndexOf("/")+1),{usage:0,elements:[a]}):a.textContent&&e.set(a.textContent,{usage:0,elements:[a]})}function Ys(i,n){let e=n.createElement("link");return e.setAttribute("rel","stylesheet"),e.setAttribute("href",i),e}var Js=(()=>{class i{doc;appId;nonce;inline=new Map;external=new Map;hosts=new Set;constructor(e,t,o,a={}){this.doc=e,this.appId=t,this.nonce=o,qh(e,t,this.inline,this.external),this.hosts.add(e.head)}addStyles(e,t){for(let o of e)this.addUsage(o,this.inline,Ac);t?.forEach(o=>this.addUsage(o,this.external,Ys))}removeStyles(e,t){for(let o of e)this.removeUsage(o,this.inline);t?.forEach(o=>this.removeUsage(o,this.external))}addUsage(e,t,o){let a=t.get(e);a?a.usage++:t.set(e,{usage:1,elements:[...this.hosts].map(s=>this.addElement(s,o(e,this.doc)))})}removeUsage(e,t){let o=t.get(e);o&&(o.usage--,o.usage<=0&&(vc(o.elements),t.delete(e)))}ngOnDestroy(){for(let[,{elements:e}]of[...this.inline,...this.external])vc(e);this.hosts.clear()}addHost(e){this.hosts.add(e);for(let[t,{elements:o}]of this.inline)o.push(this.addElement(e,Ac(t,this.doc)));for(let[t,{elements:o}]of this.external)o.push(this.addElement(e,Ys(t,this.doc)))}removeHost(e){this.hosts.delete(e)}addElement(e,t){return this.nonce&&t.setAttribute("nonce",this.nonce),e.appendChild(t)}static \u0275fac=function(t){return new(t||i)(O(D),O(Dn),O(En,8),O(ai))};static \u0275prov=g({token:i,factory:i.\u0275fac})}return i})(),Hs={svg:"http://www.w3.org/2000/svg",xhtml:"http://www.w3.org/1999/xhtml",xlink:"http://www.w3.org/1999/xlink",xml:"http://www.w3.org/XML/1998/namespace",xmlns:"http://www.w3.org/2000/xmlns/",math:"http://www.w3.org/1998/Math/MathML"},$s=/%COMP%/g;var _c="%COMP%",Fh=`_nghost-${_c}`,Mh=`_ngcontent-${_c}`,Nh=!0,Lh=new A("",{providedIn:"root",factory:()=>Nh});function Gh(i){return Mh.replace($s,i)}function Kh(i){return Fh.replace($s,i)}function wc(i,n){return n.map(e=>e.replace($s,i))}var Nn=(()=>{class i{eventManager;sharedStylesHost;appId;removeStylesOnCompDestroy;doc;platformId;ngZone;nonce;animationDisabled;maxAnimationTimeout;tracingService;rendererByCompId=new Map;defaultRenderer;platformIsServer;registry;constructor(e,t,o,a,s,r,c,d=null,p,v,C=null){this.eventManager=e,this.sharedStylesHost=t,this.appId=o,this.removeStylesOnCompDestroy=a,this.doc=s,this.platformId=r,this.ngZone=c,this.nonce=d,this.animationDisabled=p,this.maxAnimationTimeout=v,this.tracingService=C,this.platformIsServer=!1,this.defaultRenderer=new Fn(e,s,c,this.platformIsServer,this.tracingService,this.registry=zl(),this.maxAnimationTimeout)}createRenderer(e,t){if(!e||!t)return this.defaultRenderer;let o=this.getOrCreateRenderer(e,t);return o instanceof Ro?o.applyToHost(e):o instanceof Mn&&o.applyStyles(),o}getOrCreateRenderer(e,t){let o=this.rendererByCompId,a=o.get(t.id);if(!a){let s=this.doc,r=this.ngZone,c=this.eventManager,d=this.sharedStylesHost,p=this.removeStylesOnCompDestroy,v=this.platformIsServer,C=this.tracingService;switch(t.encapsulation){case Os.Emulated:a=new Ro(c,d,t,this.appId,p,s,r,v,C,this.registry,this.animationDisabled,this.maxAnimationTimeout);break;case Os.ShadowDom:return new Zs(c,d,e,t,s,r,this.nonce,v,C,this.registry,this.maxAnimationTimeout);default:a=new Mn(c,d,t,p,s,r,v,C,this.registry,this.animationDisabled,this.maxAnimationTimeout);break}o.set(t.id,a)}return a}ngOnDestroy(){this.rendererByCompId.clear()}componentReplaced(e){this.rendererByCompId.delete(e)}static \u0275fac=function(t){return new(t||i)(O(Xs),O(Js),O(Dn),O(Lh),O(D),O(ai),O(F),O(En),O(oc),O(ac),O(nc,8))};static \u0275prov=g({token:i,factory:i.\u0275fac})}return i})(),Fn=class{eventManager;doc;ngZone;platformIsServer;tracingService;registry;maxAnimationTimeout;data=Object.create(null);throwOnSyntheticProps=!0;constructor(n,e,t,o,a,s,r){this.eventManager=n,this.doc=e,this.ngZone=t,this.platformIsServer=o,this.tracingService=a,this.registry=s,this.maxAnimationTimeout=r}destroy(){}destroyNode=null;createElement(n,e){return e?this.doc.createElementNS(Hs[e]||e,n):this.doc.createElement(n)}createComment(n){return this.doc.createComment(n)}createText(n){return this.doc.createTextNode(n)}appendChild(n,e){(Ic(n)?n.content:n).appendChild(e)}insertBefore(n,e,t){n&&(Ic(n)?n.content:n).insertBefore(e,t)}removeChild(n,e){let{elements:t}=this.registry;if(t){t.animate(e,()=>e.remove(),this.maxAnimationTimeout);return}e.remove()}selectRootElement(n,e){let t=typeof n=="string"?this.doc.querySelector(n):n;if(!t)throw new U(-5104,!1);return e||(t.textContent=""),t}parentNode(n){return n.parentNode}nextSibling(n){return n.nextSibling}setAttribute(n,e,t,o){if(o){e=o+":"+e;let a=Hs[o];a?n.setAttributeNS(a,e,t):n.setAttribute(e,t)}else n.setAttribute(e,t)}removeAttribute(n,e,t){if(t){let o=Hs[t];o?n.removeAttributeNS(o,e):n.removeAttribute(`${t}:${e}`)}else n.removeAttribute(e)}addClass(n,e){n.classList.add(e)}removeClass(n,e){n.classList.remove(e)}setStyle(n,e,t,o){o&(xn.DashCase|xn.Important)?n.style.setProperty(e,t,o&xn.Important?"important":""):n.style[e]=t}removeStyle(n,e,t){t&xn.DashCase?n.style.removeProperty(e):n.style[e]=""}setProperty(n,e,t){n!=null&&(n[e]=t)}setValue(n,e){n.nodeValue=e}listen(n,e,t,o){if(typeof n=="string"&&(n=Ot().getGlobalEventTarget(this.doc,n),!n))throw new U(5102,!1);let a=this.decoratePreventDefault(t);return this.tracingService?.wrapEventListener&&(a=this.tracingService.wrapEventListener(n,e,a)),this.eventManager.addEventListener(n,e,a,o)}decoratePreventDefault(n){return e=>{if(e==="__ngUnwrap__")return n;n(e)===!1&&e.preventDefault()}}};function Ic(i){return i.tagName==="TEMPLATE"&&i.content!==void 0}var Zs=class extends Fn{sharedStylesHost;hostEl;shadowRoot;constructor(n,e,t,o,a,s,r,c,d,p,v){super(n,a,s,c,d,p,v),this.sharedStylesHost=e,this.hostEl=t,this.shadowRoot=t.attachShadow({mode:"open"}),this.sharedStylesHost.addHost(this.shadowRoot);let C=o.styles;C=wc(o.id,C);for(let L of C){let W=document.createElement("style");r&&W.setAttribute("nonce",r),W.textContent=L,this.shadowRoot.appendChild(W)}let P=o.getExternalStyles?.();if(P)for(let L of P){let W=Ys(L,a);r&&W.setAttribute("nonce",r),this.shadowRoot.appendChild(W)}}nodeOrShadowRoot(n){return n===this.hostEl?this.shadowRoot:n}appendChild(n,e){return super.appendChild(this.nodeOrShadowRoot(n),e)}insertBefore(n,e,t){return super.insertBefore(this.nodeOrShadowRoot(n),e,t)}removeChild(n,e){return super.removeChild(null,e)}parentNode(n){return this.nodeOrShadowRoot(super.parentNode(this.nodeOrShadowRoot(n)))}destroy(){this.sharedStylesHost.removeHost(this.shadowRoot)}},Mn=class extends Fn{sharedStylesHost;removeStylesOnCompDestroy;styles;styleUrls;_animationDisabled;constructor(n,e,t,o,a,s,r,c,d,p,v,C){super(n,a,s,r,c,d,v),this.sharedStylesHost=e,this.removeStylesOnCompDestroy=o,this._animationDisabled=p;let P=t.styles;this.styles=C?wc(C,P):P,this.styleUrls=t.getExternalStyles?.(C)}applyStyles(){this.sharedStylesHost.addStyles(this.styles,this.styleUrls)}destroy(){if(this.removeStylesOnCompDestroy){if(!this._animationDisabled&&this.registry.elements){this.ngZone.runOutsideAngular(()=>{setTimeout(()=>{this.sharedStylesHost.removeStyles(this.styles,this.styleUrls)},this.maxAnimationTimeout)});return}this.sharedStylesHost.removeStyles(this.styles,this.styleUrls)}}},Ro=class extends Mn{contentAttr;hostAttr;constructor(n,e,t,o,a,s,r,c,d,p,v,C){let P=o+"-"+t.id;super(n,e,t,a,s,r,c,d,p,v,C,P),this.contentAttr=Gh(P),this.hostAttr=Kh(P)}applyToHost(n){this.applyStyles(),this.setAttribute(n,this.hostAttr,"")}createElement(n,e){let t=super.createElement(n,e);return super.setAttribute(t,this.contentAttr,""),t}};var Oo=class i extends Sn{supportsDOMEvents=!0;static makeCurrent(){Gs(new i)}onAndCancel(n,e,t,o){return n.addEventListener(e,t,o),()=>{n.removeEventListener(e,t,o)}}dispatchEvent(n,e){n.dispatchEvent(e)}remove(n){n.remove()}createElement(n,e){return e=e||this.getDefaultDocument(),e.createElement(n)}createHtmlDocument(){return document.implementation.createHTMLDocument("fakeTitle")}getDefaultDocument(){return document}isElementNode(n){return n.nodeType===Node.ELEMENT_NODE}isShadowRoot(n){return n instanceof DocumentFragment}getGlobalEventTarget(n,e){return e==="window"?window:e==="document"?n:e==="body"?n.body:null}getBaseHref(n){let e=Bh();return e==null?null:jh(e)}resetBaseElement(){Ln=null}getUserAgent(){return window.navigator.userAgent}getCookie(n){return js(document.cookie,n)}},Ln=null;function Bh(){return Ln=Ln||document.head.querySelector("base"),Ln?Ln.getAttribute("href"):null}function jh(i){return new URL(i,document.baseURI).pathname}var Vh=(()=>{class i{build(){return new XMLHttpRequest}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac})}return i})(),kc=(()=>{class i extends qn{constructor(e){super(e)}supports(e){return!0}addEventListener(e,t,o,a){return e.addEventListener(t,o,a),()=>this.removeEventListener(e,t,o,a)}removeEventListener(e,t,o,a){return e.removeEventListener(t,o,a)}static \u0275fac=function(t){return new(t||i)(O(D))};static \u0275prov=g({token:i,factory:i.\u0275fac})}return i})(),Cc=["alt","control","meta","shift"],Wh={"\b":"Backspace","	":"Tab","\x7F":"Delete","\x1B":"Escape",Del:"Delete",Esc:"Escape",Left:"ArrowLeft",Right:"ArrowRight",Up:"ArrowUp",Down:"ArrowDown",Menu:"ContextMenu",Scroll:"ScrollLock",Win:"OS"},Uh={alt:i=>i.altKey,control:i=>i.ctrlKey,meta:i=>i.metaKey,shift:i=>i.shiftKey},Dc=(()=>{class i extends qn{constructor(e){super(e)}supports(e){return i.parseEventName(e)!=null}addEventListener(e,t,o,a){let s=i.parseEventName(t),r=i.eventCallback(s.fullKey,o,this.manager.getZone());return this.manager.getZone().runOutsideAngular(()=>Ot().onAndCancel(e,s.domEventName,r,a))}static parseEventName(e){let t=e.toLowerCase().split("."),o=t.shift();if(t.length===0||!(o==="keydown"||o==="keyup"))return null;let a=i._normalizeKey(t.pop()),s="",r=t.indexOf("code");if(r>-1&&(t.splice(r,1),s="code."),Cc.forEach(d=>{let p=t.indexOf(d);p>-1&&(t.splice(p,1),s+=d+".")}),s+=a,t.length!=0||a.length===0)return null;let c={};return c.domEventName=o,c.fullKey=s,c}static matchEventFullKeyCode(e,t){let o=Wh[e.key]||e.key,a="";return t.indexOf("code.")>-1&&(o=e.code,a="code."),o==null||!o?!1:(o=o.toLowerCase(),o===" "?o="space":o==="."&&(o="dot"),Cc.forEach(s=>{if(s!==o){let r=Uh[s];r(e)&&(a+=s+".")}}),a+=o,a===t)}static eventCallback(e,t,o){return a=>{i.matchEventFullKeyCode(a,e)&&o.runGuarded(()=>t(a))}}static _normalizeKey(e){return e==="esc"?"escape":e}static \u0275fac=function(t){return new(t||i)(O(D))};static \u0275prov=g({token:i,factory:i.\u0275fac})}return i})();function Qs(i,n){let e=b({rootComponent:i},Hh(n));return dc(e)}function Hh(i){return{appProviders:[...$h,...i?.providers??[]],platformProviders:Jh}}function Yh(){Oo.makeCurrent()}function Zh(){return new Kt}function Xh(){return Vl(document),document}var Jh=[{provide:ai,useValue:Ws},{provide:Wl,useValue:Yh,multi:!0},{provide:D,useFactory:Xh}];var $h=[{provide:Kl,useValue:"root"},{provide:Kt,useFactory:Zh},{provide:So,useClass:kc,multi:!0,deps:[D]},{provide:So,useClass:Dc,multi:!0,deps:[D]},Nn,Js,Xs,{provide:qe,useExisting:Nn},{provide:Pn,useClass:Vh},[]];var tr=class{};var li=class i{headers;normalizedNames=new Map;lazyInit;lazyUpdate=null;constructor(n){n?typeof n=="string"?this.lazyInit=()=>{this.headers=new Map,n.split(`
`).forEach(e=>{let t=e.indexOf(":");if(t>0){let o=e.slice(0,t),a=e.slice(t+1).trim();this.addHeaderEntry(o,a)}})}:typeof Headers<"u"&&n instanceof Headers?(this.headers=new Map,n.forEach((e,t)=>{this.addHeaderEntry(t,e)})):this.lazyInit=()=>{this.headers=new Map,Object.entries(n).forEach(([e,t])=>{this.setHeaderEntries(e,t)})}:this.headers=new Map}has(n){return this.init(),this.headers.has(n.toLowerCase())}get(n){this.init();let e=this.headers.get(n.toLowerCase());return e&&e.length>0?e[0]:null}keys(){return this.init(),Array.from(this.normalizedNames.values())}getAll(n){return this.init(),this.headers.get(n.toLowerCase())||null}append(n,e){return this.clone({name:n,value:e,op:"a"})}set(n,e){return this.clone({name:n,value:e,op:"s"})}delete(n,e){return this.clone({name:n,value:e,op:"d"})}maybeSetNormalizedName(n,e){this.normalizedNames.has(e)||this.normalizedNames.set(e,n)}init(){this.lazyInit&&(this.lazyInit instanceof i?this.copyFrom(this.lazyInit):this.lazyInit(),this.lazyInit=null,this.lazyUpdate&&(this.lazyUpdate.forEach(n=>this.applyUpdate(n)),this.lazyUpdate=null))}copyFrom(n){n.init(),Array.from(n.headers.keys()).forEach(e=>{this.headers.set(e,n.headers.get(e)),this.normalizedNames.set(e,n.normalizedNames.get(e))})}clone(n){let e=new i;return e.lazyInit=this.lazyInit&&this.lazyInit instanceof i?this.lazyInit:this,e.lazyUpdate=(this.lazyUpdate||[]).concat([n]),e}applyUpdate(n){let e=n.name.toLowerCase();switch(n.op){case"a":case"s":let t=n.value;if(typeof t=="string"&&(t=[t]),t.length===0)return;this.maybeSetNormalizedName(n.name,e);let o=(n.op==="a"?this.headers.get(e):void 0)||[];o.push(...t),this.headers.set(e,o);break;case"d":let a=n.value;if(!a)this.headers.delete(e),this.normalizedNames.delete(e);else{let s=this.headers.get(e);if(!s)return;s=s.filter(r=>a.indexOf(r)===-1),s.length===0?(this.headers.delete(e),this.normalizedNames.delete(e)):this.headers.set(e,s)}break}}addHeaderEntry(n,e){let t=n.toLowerCase();this.maybeSetNormalizedName(n,t),this.headers.has(t)?this.headers.get(t).push(e):this.headers.set(t,[e])}setHeaderEntries(n,e){let t=(Array.isArray(e)?e:[e]).map(a=>a.toString()),o=n.toLowerCase();this.headers.set(o,t),this.maybeSetNormalizedName(n,o)}forEach(n){this.init(),Array.from(this.normalizedNames.keys()).forEach(e=>n(this.normalizedNames.get(e),this.headers.get(e)))}};var ir=class{encodeKey(n){return Ec(n)}encodeValue(n){return Ec(n)}decodeKey(n){return decodeURIComponent(n)}decodeValue(n){return decodeURIComponent(n)}};function Qh(i,n){let e=new Map;return i.length>0&&i.replace(/^\?/,"").split("&").forEach(o=>{let a=o.indexOf("="),[s,r]=a==-1?[n.decodeKey(o),""]:[n.decodeKey(o.slice(0,a)),n.decodeValue(o.slice(a+1))],c=e.get(s)||[];c.push(r),e.set(s,c)}),e}var ep=/%(\d[a-f0-9])/gi,tp={40:"@","3A":":",24:"$","2C":",","3B":";","3D":"=","3F":"?","2F":"/"};function Ec(i){return encodeURIComponent(i).replace(ep,(n,e)=>tp[e]??n)}function Po(i){return`${i}`}var Pt=class i{map;encoder;updates=null;cloneFrom=null;constructor(n={}){if(this.encoder=n.encoder||new ir,n.fromString){if(n.fromObject)throw new U(2805,!1);this.map=Qh(n.fromString,this.encoder)}else n.fromObject?(this.map=new Map,Object.keys(n.fromObject).forEach(e=>{let t=n.fromObject[e],o=Array.isArray(t)?t.map(Po):[Po(t)];this.map.set(e,o)})):this.map=null}has(n){return this.init(),this.map.has(n)}get(n){this.init();let e=this.map.get(n);return e?e[0]:null}getAll(n){return this.init(),this.map.get(n)||null}keys(){return this.init(),Array.from(this.map.keys())}append(n,e){return this.clone({param:n,value:e,op:"a"})}appendAll(n){let e=[];return Object.keys(n).forEach(t=>{let o=n[t];Array.isArray(o)?o.forEach(a=>{e.push({param:t,value:a,op:"a"})}):e.push({param:t,value:o,op:"a"})}),this.clone(e)}set(n,e){return this.clone({param:n,value:e,op:"s"})}delete(n,e){return this.clone({param:n,value:e,op:"d"})}toString(){return this.init(),this.keys().map(n=>{let e=this.encoder.encodeKey(n);return this.map.get(n).map(t=>e+"="+this.encoder.encodeValue(t)).join("&")}).filter(n=>n!=="").join("&")}clone(n){let e=new i({encoder:this.encoder});return e.cloneFrom=this.cloneFrom||this,e.updates=(this.updates||[]).concat(n),e}init(){this.map===null&&(this.map=new Map),this.cloneFrom!==null&&(this.cloneFrom.init(),this.cloneFrom.keys().forEach(n=>this.map.set(n,this.cloneFrom.map.get(n))),this.updates.forEach(n=>{switch(n.op){case"a":case"s":let e=(n.op==="a"?this.map.get(n.param):void 0)||[];e.push(Po(n.value)),this.map.set(n.param,e);break;case"d":if(n.value!==void 0){let t=this.map.get(n.param)||[],o=t.indexOf(Po(n.value));o!==-1&&t.splice(o,1),t.length>0?this.map.set(n.param,t):this.map.delete(n.param)}else{this.map.delete(n.param);break}}}),this.cloneFrom=this.updates=null)}};var nr=class{map=new Map;set(n,e){return this.map.set(n,e),this}get(n){return this.map.has(n)||this.map.set(n,n.defaultValue()),this.map.get(n)}delete(n){return this.map.delete(n),this}has(n){return this.map.has(n)}keys(){return this.map.keys()}};function ip(i){switch(i){case"DELETE":case"GET":case"HEAD":case"OPTIONS":case"JSONP":return!1;default:return!0}}function xc(i){return typeof ArrayBuffer<"u"&&i instanceof ArrayBuffer}function Tc(i){return typeof Blob<"u"&&i instanceof Blob}function Rc(i){return typeof FormData<"u"&&i instanceof FormData}function np(i){return typeof URLSearchParams<"u"&&i instanceof URLSearchParams}var op="X-Request-URL",Sc="text/plain",Oc="application/json",Xv=`${Oc}, ${Sc}, */*`,Li=class i{url;body=null;headers;context;reportProgress=!1;withCredentials=!1;credentials;keepalive=!1;cache;priority;mode;redirect;referrer;integrity;responseType="json";method;params;urlWithParams;transferCache;timeout;constructor(n,e,t,o){this.url=e,this.method=n.toUpperCase();let a;if(ip(this.method)||o?(this.body=t!==void 0?t:null,a=o):a=t,a){if(this.reportProgress=!!a.reportProgress,this.withCredentials=!!a.withCredentials,this.keepalive=!!a.keepalive,a.responseType&&(this.responseType=a.responseType),a.headers&&(this.headers=a.headers),a.context&&(this.context=a.context),a.params&&(this.params=a.params),a.priority&&(this.priority=a.priority),a.cache&&(this.cache=a.cache),a.credentials&&(this.credentials=a.credentials),typeof a.timeout=="number"){if(a.timeout<1||!Number.isInteger(a.timeout))throw new U(2822,"");this.timeout=a.timeout}a.mode&&(this.mode=a.mode),a.redirect&&(this.redirect=a.redirect),a.integrity&&(this.integrity=a.integrity),a.referrer&&(this.referrer=a.referrer),this.transferCache=a.transferCache}if(this.headers??=new li,this.context??=new nr,!this.params)this.params=new Pt,this.urlWithParams=e;else{let s=this.params.toString();if(s.length===0)this.urlWithParams=e;else{let r=e.indexOf("?"),c=r===-1?"?":r<e.length-1?"&":"";this.urlWithParams=e+c+s}}}serializeBody(){return this.body===null?null:typeof this.body=="string"||xc(this.body)||Tc(this.body)||Rc(this.body)||np(this.body)?this.body:this.body instanceof Pt?this.body.toString():typeof this.body=="object"||typeof this.body=="boolean"||Array.isArray(this.body)?JSON.stringify(this.body):this.body.toString()}detectContentTypeHeader(){return this.body===null||Rc(this.body)?null:Tc(this.body)?this.body.type||null:xc(this.body)?null:typeof this.body=="string"?Sc:this.body instanceof Pt?"application/x-www-form-urlencoded;charset=UTF-8":typeof this.body=="object"||typeof this.body=="number"||typeof this.body=="boolean"?Oc:null}clone(n={}){let e=n.method||this.method,t=n.url||this.url,o=n.responseType||this.responseType,a=n.keepalive??this.keepalive,s=n.priority||this.priority,r=n.cache||this.cache,c=n.mode||this.mode,d=n.redirect||this.redirect,p=n.credentials||this.credentials,v=n.referrer||this.referrer,C=n.integrity||this.integrity,P=n.transferCache??this.transferCache,L=n.timeout??this.timeout,W=n.body!==void 0?n.body:this.body,ae=n.withCredentials??this.withCredentials,ye=n.reportProgress??this.reportProgress,et=n.headers||this.headers,at=n.params||this.params,Dh=n.context??this.context;return n.setHeaders!==void 0&&(et=Object.keys(n.setHeaders).reduce((_s,An)=>_s.set(An,n.setHeaders[An]),et)),n.setParams&&(at=Object.keys(n.setParams).reduce((_s,An)=>_s.set(An,n.setParams[An]),at)),new i(e,t,W,{params:at,headers:et,context:Dh,reportProgress:ye,responseType:o,withCredentials:ae,transferCache:P,keepalive:a,cache:r,priority:s,timeout:L,mode:c,redirect:d,credentials:p,referrer:v,integrity:C})}},ar=(function(i){return i[i.Sent=0]="Sent",i[i.UploadProgress=1]="UploadProgress",i[i.ResponseHeader=2]="ResponseHeader",i[i.DownloadProgress=3]="DownloadProgress",i[i.Response=4]="Response",i[i.User=5]="User",i})(ar||{}),or=class{headers;status;statusText;url;ok;type;redirected;constructor(n,e=200,t="OK"){this.headers=n.headers||new li,this.status=n.status!==void 0?n.status:e,this.statusText=n.statusText||t,this.url=n.url||null,this.redirected=n.redirected,this.ok=this.status>=200&&this.status<300}};var qo=class i extends or{body;constructor(n={}){super(n),this.body=n.body!==void 0?n.body:null}type=ar.Response;clone(n={}){return new i({body:n.body!==void 0?n.body:this.body,headers:n.headers||this.headers,status:n.status!==void 0?n.status:this.status,statusText:n.statusText||this.statusText,url:n.url||this.url||void 0,redirected:n.redirected??this.redirected})}};function er(i,n){return{body:n,headers:i.headers,context:i.context,observe:i.observe,params:i.params,reportProgress:i.reportProgress,responseType:i.responseType,withCredentials:i.withCredentials,credentials:i.credentials,transferCache:i.transferCache,timeout:i.timeout,keepalive:i.keepalive,priority:i.priority,cache:i.cache,mode:i.mode,redirect:i.redirect,integrity:i.integrity,referrer:i.referrer}}var sr=(()=>{class i{handler;constructor(e){this.handler=e}request(e,t,o={}){let a;if(e instanceof Li)a=e;else{let c;o.headers instanceof li?c=o.headers:c=new li(o.headers);let d;o.params&&(o.params instanceof Pt?d=o.params:d=new Pt({fromObject:o.params})),a=new Li(e,t,o.body!==void 0?o.body:null,{headers:c,context:o.context,params:d,reportProgress:o.reportProgress,responseType:o.responseType||"json",withCredentials:o.withCredentials,transferCache:o.transferCache,keepalive:o.keepalive,priority:o.priority,cache:o.cache,mode:o.mode,redirect:o.redirect,credentials:o.credentials,referrer:o.referrer,integrity:o.integrity,timeout:o.timeout})}let s=I(a).pipe(xt(c=>this.handler.handle(c)));if(e instanceof Li||o.observe==="events")return s;let r=s.pipe(ue(c=>c instanceof qo));switch(o.observe||"body"){case"body":switch(a.responseType){case"arraybuffer":return r.pipe(q(c=>{if(c.body!==null&&!(c.body instanceof ArrayBuffer))throw new U(2806,!1);return c.body}));case"blob":return r.pipe(q(c=>{if(c.body!==null&&!(c.body instanceof Blob))throw new U(2807,!1);return c.body}));case"text":return r.pipe(q(c=>{if(c.body!==null&&typeof c.body!="string")throw new U(2808,!1);return c.body}));case"json":default:return r.pipe(q(c=>c.body))}case"response":return r;default:throw new U(2809,!1)}}delete(e,t={}){return this.request("DELETE",e,t)}get(e,t={}){return this.request("GET",e,t)}head(e,t={}){return this.request("HEAD",e,t)}jsonp(e,t){return this.request("JSONP",e,{params:new Pt().append(t,"JSONP_CALLBACK"),observe:"body",responseType:"json"})}options(e,t={}){return this.request("OPTIONS",e,t)}patch(e,t,o={}){return this.request("PATCH",e,er(o,t))}post(e,t,o={}){return this.request("POST",e,er(o,t))}put(e,t,o={}){return this.request("PUT",e,er(o,t))}static \u0275fac=function(t){return new(t||i)(O(tr))};static \u0275prov=g({token:i,factory:i.\u0275fac})}return i})();var Jv=RegExp(`^${op}:`,"m");var qc=(()=>{class i{_doc;constructor(e){this._doc=e}getTitle(){return this._doc.title}setTitle(e){this._doc.title=e||""}static \u0275fac=function(t){return new(t||i)(O(D))};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();var rr=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:function(t){let o=null;return t?o=new(t||i):o=O(rp),o},providedIn:"root"})}return i})(),rp=(()=>{class i extends rr{_doc;constructor(e){super(),this._doc=e}sanitize(e,t){if(t==null)return null;switch(e){case Ue.NONE:return t;case Ue.HTML:return Oi(t,"HTML")?si(t):$l(this._doc,String(t)).toString();case Ue.STYLE:return Oi(t,"Style")?si(t):t;case Ue.SCRIPT:if(Oi(t,"Script"))return si(t);throw new U(5200,!1);case Ue.URL:return Oi(t,"URL")?si(t):Jl(String(t));case Ue.RESOURCE_URL:if(Oi(t,"ResourceURL"))return si(t);throw new U(5201,!1);default:throw new U(5202,!1)}}bypassSecurityTrustHtml(e){return Ul(e)}bypassSecurityTrustStyle(e){return Hl(e)}bypassSecurityTrustScript(e){return Yl(e)}bypassSecurityTrustUrl(e){return Zl(e)}bypassSecurityTrustResourceUrl(e){return Xl(e)}static \u0275fac=function(t){return new(t||i)(O(D))};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();var G="primary",Jn=Symbol("RouteTitle"),hr=class{params;constructor(n){this.params=n||{}}has(n){return Object.prototype.hasOwnProperty.call(this.params,n)}get(n){if(this.has(n)){let e=this.params[n];return Array.isArray(e)?e[0]:e}return null}getAll(n){if(this.has(n)){let e=this.params[n];return Array.isArray(e)?e:[e]}return[]}get keys(){return Object.keys(this.params)}};function ui(i){return new hr(i)}function jc(i,n,e){let t=e.path.split("/");if(t.length>i.length||e.pathMatch==="full"&&(n.hasChildren()||t.length<i.length))return null;let o={};for(let a=0;a<t.length;a++){let s=t[a],r=i[a];if(s[0]===":")o[s.substring(1)]=r;else if(s!==r.path)return null}return{consumed:i.slice(0,t.length),posParams:o}}function lp(i,n){if(i.length!==n.length)return!1;for(let e=0;e<i.length;++e)if(!gt(i[e],n[e]))return!1;return!0}function gt(i,n){let e=i?pr(i):void 0,t=n?pr(n):void 0;if(!e||!t||e.length!=t.length)return!1;let o;for(let a=0;a<e.length;a++)if(o=e[a],!Vc(i[o],n[o]))return!1;return!0}function pr(i){return[...Object.keys(i),...Object.getOwnPropertySymbols(i)]}function Vc(i,n){if(Array.isArray(i)&&Array.isArray(n)){if(i.length!==n.length)return!1;let e=[...i].sort(),t=[...n].sort();return e.every((o,a)=>t[a]===o)}else return i===n}function Wc(i){return i.length>0?i[i.length-1]:null}function qt(i){return _n(i)?i:qs(i)?Oe(Promise.resolve(i)):I(i)}var cp={exact:Hc,subset:Yc},Uc={exact:dp,subset:up,ignored:()=>!0};function Mc(i,n,e){return cp[e.paths](i.root,n.root,e.matrixParams)&&Uc[e.queryParams](i.queryParams,n.queryParams)&&!(e.fragment==="exact"&&i.fragment!==n.fragment)}function dp(i,n){return gt(i,n)}function Hc(i,n,e){if(!ci(i.segments,n.segments)||!No(i.segments,n.segments,e)||i.numberOfChildren!==n.numberOfChildren)return!1;for(let t in n.children)if(!i.children[t]||!Hc(i.children[t],n.children[t],e))return!1;return!0}function up(i,n){return Object.keys(n).length<=Object.keys(i).length&&Object.keys(n).every(e=>Vc(i[e],n[e]))}function Yc(i,n,e){return Zc(i,n,n.segments,e)}function Zc(i,n,e,t){if(i.segments.length>e.length){let o=i.segments.slice(0,e.length);return!(!ci(o,e)||n.hasChildren()||!No(o,e,t))}else if(i.segments.length===e.length){if(!ci(i.segments,e)||!No(i.segments,e,t))return!1;for(let o in n.children)if(!i.children[o]||!Yc(i.children[o],n.children[o],t))return!1;return!0}else{let o=e.slice(0,i.segments.length),a=e.slice(i.segments.length);return!ci(i.segments,o)||!No(i.segments,o,t)||!i.children[G]?!1:Zc(i.children[G],n,a,t)}}function No(i,n,e){return n.every((t,o)=>Uc[e](i[o].parameters,t.parameters))}var vt=class{root;queryParams;fragment;_queryParamMap;constructor(n=new ee([],{}),e={},t=null){this.root=n,this.queryParams=e,this.fragment=t}get queryParamMap(){return this._queryParamMap??=ui(this.queryParams),this._queryParamMap}toString(){return mp.serialize(this)}},ee=class{segments;children;parent=null;constructor(n,e){this.segments=n,this.children=e,Object.values(e).forEach(t=>t.parent=this)}hasChildren(){return this.numberOfChildren>0}get numberOfChildren(){return Object.keys(this.children).length}toString(){return Lo(this)}},Ut=class{path;parameters;_parameterMap;constructor(n,e){this.path=n,this.parameters=e}get parameterMap(){return this._parameterMap??=ui(this.parameters),this._parameterMap}toString(){return Jc(this)}};function hp(i,n){return ci(i,n)&&i.every((e,t)=>gt(e.parameters,n[t].parameters))}function ci(i,n){return i.length!==n.length?!1:i.every((e,t)=>e.path===n[t].path)}function pp(i,n){let e=[];return Object.entries(i.children).forEach(([t,o])=>{t===G&&(e=e.concat(n(o,t)))}),Object.entries(i.children).forEach(([t,o])=>{t!==G&&(e=e.concat(n(o,t)))}),e}var hi=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:()=>new Ht,providedIn:"root"})}return i})(),Ht=class{parse(n){let e=new fr(n);return new vt(e.parseRootSegment(),e.parseQueryParams(),e.parseFragment())}serialize(n){let e=`/${Gn(n.root,!0)}`,t=gp(n.queryParams),o=typeof n.fragment=="string"?`#${fp(n.fragment)}`:"";return`${e}${t}${o}`}},mp=new Ht;function Lo(i){return i.segments.map(n=>Jc(n)).join("/")}function Gn(i,n){if(!i.hasChildren())return Lo(i);if(n){let e=i.children[G]?Gn(i.children[G],!1):"",t=[];return Object.entries(i.children).forEach(([o,a])=>{o!==G&&t.push(`${o}:${Gn(a,!1)}`)}),t.length>0?`${e}(${t.join("//")})`:e}else{let e=pp(i,(t,o)=>o===G?[Gn(i.children[G],!1)]:[`${o}:${Gn(t,!1)}`]);return Object.keys(i.children).length===1&&i.children[G]!=null?`${Lo(i)}/${e[0]}`:`${Lo(i)}/(${e.join("//")})`}}function Xc(i){return encodeURIComponent(i).replace(/%40/g,"@").replace(/%3A/gi,":").replace(/%24/g,"$").replace(/%2C/gi,",")}function Fo(i){return Xc(i).replace(/%3B/gi,";")}function fp(i){return encodeURI(i)}function mr(i){return Xc(i).replace(/\(/g,"%28").replace(/\)/g,"%29").replace(/%26/gi,"&")}function Go(i){return decodeURIComponent(i)}function Nc(i){return Go(i.replace(/\+/g,"%20"))}function Jc(i){return`${mr(i.path)}${yp(i.parameters)}`}function yp(i){return Object.entries(i).map(([n,e])=>`;${mr(n)}=${mr(e)}`).join("")}function gp(i){let n=Object.entries(i).map(([e,t])=>Array.isArray(t)?t.map(o=>`${Fo(e)}=${Fo(o)}`).join("&"):`${Fo(e)}=${Fo(t)}`).filter(e=>e);return n.length?`?${n.join("&")}`:""}var bp=/^[^\/()?;#]+/;function lr(i){let n=i.match(bp);return n?n[0]:""}var vp=/^[^\/()?;=#]+/;function Ap(i){let n=i.match(vp);return n?n[0]:""}var Ip=/^[^=?&#]+/;function _p(i){let n=i.match(Ip);return n?n[0]:""}var wp=/^[^&#]+/;function Cp(i){let n=i.match(wp);return n?n[0]:""}var fr=class{url;remaining;constructor(n){this.url=n,this.remaining=n}parseRootSegment(){return this.consumeOptional("/"),this.remaining===""||this.peekStartsWith("?")||this.peekStartsWith("#")?new ee([],{}):new ee([],this.parseChildren())}parseQueryParams(){let n={};if(this.consumeOptional("?"))do this.parseQueryParam(n);while(this.consumeOptional("&"));return n}parseFragment(){return this.consumeOptional("#")?decodeURIComponent(this.remaining):null}parseChildren(){if(this.remaining==="")return{};this.consumeOptional("/");let n=[];for(this.peekStartsWith("(")||n.push(this.parseSegment());this.peekStartsWith("/")&&!this.peekStartsWith("//")&&!this.peekStartsWith("/(");)this.capture("/"),n.push(this.parseSegment());let e={};this.peekStartsWith("/(")&&(this.capture("/"),e=this.parseParens(!0));let t={};return this.peekStartsWith("(")&&(t=this.parseParens(!1)),(n.length>0||Object.keys(e).length>0)&&(t[G]=new ee(n,e)),t}parseSegment(){let n=lr(this.remaining);if(n===""&&this.peekStartsWith(";"))throw new U(4009,!1);return this.capture(n),new Ut(Go(n),this.parseMatrixParams())}parseMatrixParams(){let n={};for(;this.consumeOptional(";");)this.parseParam(n);return n}parseParam(n){let e=Ap(this.remaining);if(!e)return;this.capture(e);let t="";if(this.consumeOptional("=")){let o=lr(this.remaining);o&&(t=o,this.capture(t))}n[Go(e)]=Go(t)}parseQueryParam(n){let e=_p(this.remaining);if(!e)return;this.capture(e);let t="";if(this.consumeOptional("=")){let s=Cp(this.remaining);s&&(t=s,this.capture(t))}let o=Nc(e),a=Nc(t);if(n.hasOwnProperty(o)){let s=n[o];Array.isArray(s)||(s=[s],n[o]=s),s.push(a)}else n[o]=a}parseParens(n){let e={};for(this.capture("(");!this.consumeOptional(")")&&this.remaining.length>0;){let t=lr(this.remaining),o=this.remaining[t.length];if(o!=="/"&&o!==")"&&o!==";")throw new U(4010,!1);let a;t.indexOf(":")>-1?(a=t.slice(0,t.indexOf(":")),this.capture(a),this.capture(":")):n&&(a=G);let s=this.parseChildren();e[a]=Object.keys(s).length===1?s[G]:new ee([],s),this.consumeOptional("//")}return e}peekStartsWith(n){return this.remaining.startsWith(n)}consumeOptional(n){return this.peekStartsWith(n)?(this.remaining=this.remaining.substring(n.length),!0):!1}capture(n){if(!this.consumeOptional(n))throw new U(4011,!1)}};function $c(i){return i.segments.length>0?new ee([],{[G]:i}):i}function Qc(i){let n={};for(let[t,o]of Object.entries(i.children)){let a=Qc(o);if(t===G&&a.segments.length===0&&a.hasChildren())for(let[s,r]of Object.entries(a.children))n[s]=r;else(a.segments.length>0||a.hasChildren())&&(n[t]=a)}let e=new ee(i.segments,n);return kp(e)}function kp(i){if(i.numberOfChildren===1&&i.children[G]){let n=i.children[G];return new ee(i.segments.concat(n.segments),n.children)}return i}function Yt(i){return i instanceof vt}function ed(i,n,e=null,t=null){let o=td(i);return id(o,n,e,t)}function td(i){let n;function e(a){let s={};for(let c of a.children){let d=e(c);s[c.outlet]=d}let r=new ee(a.url,s);return a===i&&(n=r),r}let t=e(i.root),o=$c(t);return n??o}function id(i,n,e,t){let o=i;for(;o.parent;)o=o.parent;if(n.length===0)return cr(o,o,o,e,t);let a=Dp(n);if(a.toRoot())return cr(o,o,new ee([],{}),e,t);let s=Ep(a,o,i),r=s.processChildren?zn(s.segmentGroup,s.index,a.commands):od(s.segmentGroup,s.index,a.commands);return cr(o,s.segmentGroup,r,e,t)}function Ko(i){return typeof i=="object"&&i!=null&&!i.outlets&&!i.segmentPath}function jn(i){return typeof i=="object"&&i!=null&&i.outlets}function cr(i,n,e,t,o){let a={};t&&Object.entries(t).forEach(([c,d])=>{a[c]=Array.isArray(d)?d.map(p=>`${p}`):`${d}`});let s;i===n?s=e:s=nd(i,n,e);let r=$c(Qc(s));return new vt(r,a,o)}function nd(i,n,e){let t={};return Object.entries(i.children).forEach(([o,a])=>{a===n?t[o]=e:t[o]=nd(a,n,e)}),new ee(i.segments,t)}var zo=class{isAbsolute;numberOfDoubleDots;commands;constructor(n,e,t){if(this.isAbsolute=n,this.numberOfDoubleDots=e,this.commands=t,n&&t.length>0&&Ko(t[0]))throw new U(4003,!1);let o=t.find(jn);if(o&&o!==Wc(t))throw new U(4004,!1)}toRoot(){return this.isAbsolute&&this.commands.length===1&&this.commands[0]=="/"}};function Dp(i){if(typeof i[0]=="string"&&i.length===1&&i[0]==="/")return new zo(!0,0,i);let n=0,e=!1,t=i.reduce((o,a,s)=>{if(typeof a=="object"&&a!=null){if(a.outlets){let r={};return Object.entries(a.outlets).forEach(([c,d])=>{r[c]=typeof d=="string"?d.split("/"):d}),[...o,{outlets:r}]}if(a.segmentPath)return[...o,a.segmentPath]}return typeof a!="string"?[...o,a]:s===0?(a.split("/").forEach((r,c)=>{c==0&&r==="."||(c==0&&r===""?e=!0:r===".."?n++:r!=""&&o.push(r))}),o):[...o,a]},[]);return new zo(e,n,t)}var zi=class{segmentGroup;processChildren;index;constructor(n,e,t){this.segmentGroup=n,this.processChildren=e,this.index=t}};function Ep(i,n,e){if(i.isAbsolute)return new zi(n,!0,0);if(!e)return new zi(n,!1,NaN);if(e.parent===null)return new zi(e,!0,0);let t=Ko(i.commands[0])?0:1,o=e.segments.length-1+t;return xp(e,o,i.numberOfDoubleDots)}function xp(i,n,e){let t=i,o=n,a=e;for(;a>o;){if(a-=o,t=t.parent,!t)throw new U(4005,!1);o=t.segments.length}return new zi(t,!1,o-a)}function Tp(i){return jn(i[0])?i[0].outlets:{[G]:i}}function od(i,n,e){if(i??=new ee([],{}),i.segments.length===0&&i.hasChildren())return zn(i,n,e);let t=Rp(i,n,e),o=e.slice(t.commandIndex);if(t.match&&t.pathIndex<i.segments.length){let a=new ee(i.segments.slice(0,t.pathIndex),{});return a.children[G]=new ee(i.segments.slice(t.pathIndex),i.children),zn(a,0,o)}else return t.match&&o.length===0?new ee(i.segments,{}):t.match&&!i.hasChildren()?yr(i,n,e):t.match?zn(i,0,o):yr(i,n,e)}function zn(i,n,e){if(e.length===0)return new ee(i.segments,{});{let t=Tp(e),o={};if(Object.keys(t).some(a=>a!==G)&&i.children[G]&&i.numberOfChildren===1&&i.children[G].segments.length===0){let a=zn(i.children[G],n,e);return new ee(i.segments,a.children)}return Object.entries(t).forEach(([a,s])=>{typeof s=="string"&&(s=[s]),s!==null&&(o[a]=od(i.children[a],n,s))}),Object.entries(i.children).forEach(([a,s])=>{t[a]===void 0&&(o[a]=s)}),new ee(i.segments,o)}}function Rp(i,n,e){let t=0,o=n,a={match:!1,pathIndex:0,commandIndex:0};for(;o<i.segments.length;){if(t>=e.length)return a;let s=i.segments[o],r=e[t];if(jn(r))break;let c=`${r}`,d=t<e.length-1?e[t+1]:null;if(o>0&&c===void 0)break;if(c&&d&&typeof d=="object"&&d.outlets===void 0){if(!Gc(c,d,s))return a;t+=2}else{if(!Gc(c,{},s))return a;t++}o++}return{match:!0,pathIndex:o,commandIndex:t}}function yr(i,n,e){let t=i.segments.slice(0,n),o=0;for(;o<e.length;){let a=e[o];if(jn(a)){let c=Sp(a.outlets);return new ee(t,c)}if(o===0&&Ko(e[0])){let c=i.segments[n];t.push(new Ut(c.path,Lc(e[0]))),o++;continue}let s=jn(a)?a.outlets[G]:`${a}`,r=o<e.length-1?e[o+1]:null;s&&r&&Ko(r)?(t.push(new Ut(s,Lc(r))),o+=2):(t.push(new Ut(s,{})),o++)}return new ee(t,{})}function Sp(i){let n={};return Object.entries(i).forEach(([e,t])=>{typeof t=="string"&&(t=[t]),t!==null&&(n[e]=yr(new ee([],{}),0,t))}),n}function Lc(i){let n={};return Object.entries(i).forEach(([e,t])=>n[e]=`${t}`),n}function Gc(i,n,e){return i==e.path&&gt(n,e.parameters)}var Bi="imperative",_e=(function(i){return i[i.NavigationStart=0]="NavigationStart",i[i.NavigationEnd=1]="NavigationEnd",i[i.NavigationCancel=2]="NavigationCancel",i[i.NavigationError=3]="NavigationError",i[i.RoutesRecognized=4]="RoutesRecognized",i[i.ResolveStart=5]="ResolveStart",i[i.ResolveEnd=6]="ResolveEnd",i[i.GuardsCheckStart=7]="GuardsCheckStart",i[i.GuardsCheckEnd=8]="GuardsCheckEnd",i[i.RouteConfigLoadStart=9]="RouteConfigLoadStart",i[i.RouteConfigLoadEnd=10]="RouteConfigLoadEnd",i[i.ChildActivationStart=11]="ChildActivationStart",i[i.ChildActivationEnd=12]="ChildActivationEnd",i[i.ActivationStart=13]="ActivationStart",i[i.ActivationEnd=14]="ActivationEnd",i[i.Scroll=15]="Scroll",i[i.NavigationSkipped=16]="NavigationSkipped",i})(_e||{}),Xe=class{id;url;constructor(n,e){this.id=n,this.url=e}},Zt=class extends Xe{type=_e.NavigationStart;navigationTrigger;restoredState;constructor(n,e,t="imperative",o=null){super(n,e),this.navigationTrigger=t,this.restoredState=o}toString(){return`NavigationStart(id: ${this.id}, url: '${this.url}')`}},Je=class extends Xe{urlAfterRedirects;type=_e.NavigationEnd;constructor(n,e,t){super(n,e),this.urlAfterRedirects=t}toString(){return`NavigationEnd(id: ${this.id}, url: '${this.url}', urlAfterRedirects: '${this.urlAfterRedirects}')`}},Ne=(function(i){return i[i.Redirect=0]="Redirect",i[i.SupersededByNewNavigation=1]="SupersededByNewNavigation",i[i.NoDataFromResolver=2]="NoDataFromResolver",i[i.GuardRejected=3]="GuardRejected",i[i.Aborted=4]="Aborted",i})(Ne||{}),Vi=(function(i){return i[i.IgnoredSameUrlNavigation=0]="IgnoredSameUrlNavigation",i[i.IgnoredByUrlHandlingStrategy=1]="IgnoredByUrlHandlingStrategy",i})(Vi||{}),bt=class extends Xe{reason;code;type=_e.NavigationCancel;constructor(n,e,t,o){super(n,e),this.reason=t,this.code=o}toString(){return`NavigationCancel(id: ${this.id}, url: '${this.url}')`}},At=class extends Xe{reason;code;type=_e.NavigationSkipped;constructor(n,e,t,o){super(n,e),this.reason=t,this.code=o}},Wi=class extends Xe{error;target;type=_e.NavigationError;constructor(n,e,t,o){super(n,e),this.error=t,this.target=o}toString(){return`NavigationError(id: ${this.id}, url: '${this.url}', error: ${this.error})`}},Vn=class extends Xe{urlAfterRedirects;state;type=_e.RoutesRecognized;constructor(n,e,t,o){super(n,e),this.urlAfterRedirects=t,this.state=o}toString(){return`RoutesRecognized(id: ${this.id}, url: '${this.url}', urlAfterRedirects: '${this.urlAfterRedirects}', state: ${this.state})`}},Bo=class extends Xe{urlAfterRedirects;state;type=_e.GuardsCheckStart;constructor(n,e,t,o){super(n,e),this.urlAfterRedirects=t,this.state=o}toString(){return`GuardsCheckStart(id: ${this.id}, url: '${this.url}', urlAfterRedirects: '${this.urlAfterRedirects}', state: ${this.state})`}},jo=class extends Xe{urlAfterRedirects;state;shouldActivate;type=_e.GuardsCheckEnd;constructor(n,e,t,o,a){super(n,e),this.urlAfterRedirects=t,this.state=o,this.shouldActivate=a}toString(){return`GuardsCheckEnd(id: ${this.id}, url: '${this.url}', urlAfterRedirects: '${this.urlAfterRedirects}', state: ${this.state}, shouldActivate: ${this.shouldActivate})`}},Vo=class extends Xe{urlAfterRedirects;state;type=_e.ResolveStart;constructor(n,e,t,o){super(n,e),this.urlAfterRedirects=t,this.state=o}toString(){return`ResolveStart(id: ${this.id}, url: '${this.url}', urlAfterRedirects: '${this.urlAfterRedirects}', state: ${this.state})`}},Wo=class extends Xe{urlAfterRedirects;state;type=_e.ResolveEnd;constructor(n,e,t,o){super(n,e),this.urlAfterRedirects=t,this.state=o}toString(){return`ResolveEnd(id: ${this.id}, url: '${this.url}', urlAfterRedirects: '${this.urlAfterRedirects}', state: ${this.state})`}},Uo=class{route;type=_e.RouteConfigLoadStart;constructor(n){this.route=n}toString(){return`RouteConfigLoadStart(path: ${this.route.path})`}},Ho=class{route;type=_e.RouteConfigLoadEnd;constructor(n){this.route=n}toString(){return`RouteConfigLoadEnd(path: ${this.route.path})`}},Yo=class{snapshot;type=_e.ChildActivationStart;constructor(n){this.snapshot=n}toString(){return`ChildActivationStart(path: '${this.snapshot.routeConfig&&this.snapshot.routeConfig.path||""}')`}},Zo=class{snapshot;type=_e.ChildActivationEnd;constructor(n){this.snapshot=n}toString(){return`ChildActivationEnd(path: '${this.snapshot.routeConfig&&this.snapshot.routeConfig.path||""}')`}},Xo=class{snapshot;type=_e.ActivationStart;constructor(n){this.snapshot=n}toString(){return`ActivationStart(path: '${this.snapshot.routeConfig&&this.snapshot.routeConfig.path||""}')`}},Jo=class{snapshot;type=_e.ActivationEnd;constructor(n){this.snapshot=n}toString(){return`ActivationEnd(path: '${this.snapshot.routeConfig&&this.snapshot.routeConfig.path||""}')`}},Ui=class{routerEvent;position;anchor;type=_e.Scroll;constructor(n,e,t){this.routerEvent=n,this.position=e,this.anchor=t}toString(){let n=this.position?`${this.position[0]}, ${this.position[1]}`:null;return`Scroll(anchor: '${this.anchor}', position: '${n}')`}},Wn=class{},Hi=class{url;navigationBehaviorOptions;constructor(n,e){this.url=n,this.navigationBehaviorOptions=e}};function Op(i){return!(i instanceof Wn)&&!(i instanceof Hi)}function Pp(i,n){return i.providers&&!i._injector&&(i._injector=ko(i.providers,n,`Route: ${i.path}`)),i._injector??n}function ct(i){return i.outlet||G}function qp(i,n){let e=i.filter(t=>ct(t)===n);return e.push(...i.filter(t=>ct(t)!==n)),e}function Xi(i){if(!i)return null;if(i.routeConfig?._injector)return i.routeConfig._injector;for(let n=i.parent;n;n=n.parent){let e=n.routeConfig;if(e?._loadedInjector)return e._loadedInjector;if(e?._injector)return e._injector}return null}var $o=class{rootInjector;outlet=null;route=null;children;attachRef=null;get injector(){return Xi(this.route?.snapshot)??this.rootInjector}constructor(n){this.rootInjector=n,this.children=new pi(this.rootInjector)}},pi=(()=>{class i{rootInjector;contexts=new Map;constructor(e){this.rootInjector=e}onChildOutletCreated(e,t){let o=this.getOrCreateContext(e);o.outlet=t,this.contexts.set(e,o)}onChildOutletDestroyed(e){let t=this.getContext(e);t&&(t.outlet=null,t.attachRef=null)}onOutletDeactivated(){let e=this.contexts;return this.contexts=new Map,e}onOutletReAttached(e){this.contexts=e}getOrCreateContext(e){let t=this.getContext(e);return t||(t=new $o(this.rootInjector),this.contexts.set(e,t)),t}getContext(e){return this.contexts.get(e)||null}static \u0275fac=function(t){return new(t||i)(O(ze))};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),Qo=class{_root;constructor(n){this._root=n}get root(){return this._root.value}parent(n){let e=this.pathFromRoot(n);return e.length>1?e[e.length-2]:null}children(n){let e=gr(n,this._root);return e?e.children.map(t=>t.value):[]}firstChild(n){let e=gr(n,this._root);return e&&e.children.length>0?e.children[0].value:null}siblings(n){let e=br(n,this._root);return e.length<2?[]:e[e.length-2].children.map(o=>o.value).filter(o=>o!==n)}pathFromRoot(n){return br(n,this._root).map(e=>e.value)}};function gr(i,n){if(i===n.value)return n;for(let e of n.children){let t=gr(i,e);if(t)return t}return null}function br(i,n){if(i===n.value)return[n];for(let e of n.children){let t=br(i,e);if(t.length)return t.unshift(n),t}return[]}var Ze=class{value;children;constructor(n,e){this.value=n,this.children=e}toString(){return`TreeNode(${this.value})`}};function Ki(i){let n={};return i&&i.children.forEach(e=>n[e.value.outlet]=e),n}var Un=class extends Qo{snapshot;constructor(n,e){super(n),this.snapshot=e,Dr(this,n)}toString(){return this.snapshot.toString()}};function ad(i){let n=Fp(i),e=new Ee([new Ut("",{})]),t=new Ee({}),o=new Ee({}),a=new Ee({}),s=new Ee(""),r=new It(e,t,a,s,o,G,i,n.root);return r.snapshot=n.root,new Un(new Ze(r,[]),n)}function Fp(i){let n={},e={},t={},a=new di([],n,t,"",e,G,i,null,{});return new Hn("",new Ze(a,[]))}var It=class{urlSubject;paramsSubject;queryParamsSubject;fragmentSubject;dataSubject;outlet;component;snapshot;_futureSnapshot;_routerState;_paramMap;_queryParamMap;title;url;params;queryParams;fragment;data;constructor(n,e,t,o,a,s,r,c){this.urlSubject=n,this.paramsSubject=e,this.queryParamsSubject=t,this.fragmentSubject=o,this.dataSubject=a,this.outlet=s,this.component=r,this._futureSnapshot=c,this.title=this.dataSubject?.pipe(q(d=>d[Jn]))??I(void 0),this.url=n,this.params=e,this.queryParams=t,this.fragment=o,this.data=a}get routeConfig(){return this._futureSnapshot.routeConfig}get root(){return this._routerState.root}get parent(){return this._routerState.parent(this)}get firstChild(){return this._routerState.firstChild(this)}get children(){return this._routerState.children(this)}get pathFromRoot(){return this._routerState.pathFromRoot(this)}get paramMap(){return this._paramMap??=this.params.pipe(q(n=>ui(n))),this._paramMap}get queryParamMap(){return this._queryParamMap??=this.queryParams.pipe(q(n=>ui(n))),this._queryParamMap}toString(){return this.snapshot?this.snapshot.toString():`Future(${this._futureSnapshot})`}};function ea(i,n,e="emptyOnly"){let t,{routeConfig:o}=i;return n!==null&&(e==="always"||o?.path===""||!n.component&&!n.routeConfig?.loadComponent)?t={params:b(b({},n.params),i.params),data:b(b({},n.data),i.data),resolve:b(b(b(b({},i.data),n.data),o?.data),i._resolvedData)}:t={params:b({},i.params),data:b({},i.data),resolve:b(b({},i.data),i._resolvedData??{})},o&&rd(o)&&(t.resolve[Jn]=o.title),t}var di=class{url;params;queryParams;fragment;data;outlet;component;routeConfig;_resolve;_resolvedData;_routerState;_paramMap;_queryParamMap;get title(){return this.data?.[Jn]}constructor(n,e,t,o,a,s,r,c,d){this.url=n,this.params=e,this.queryParams=t,this.fragment=o,this.data=a,this.outlet=s,this.component=r,this.routeConfig=c,this._resolve=d}get root(){return this._routerState.root}get parent(){return this._routerState.parent(this)}get firstChild(){return this._routerState.firstChild(this)}get children(){return this._routerState.children(this)}get pathFromRoot(){return this._routerState.pathFromRoot(this)}get paramMap(){return this._paramMap??=ui(this.params),this._paramMap}get queryParamMap(){return this._queryParamMap??=ui(this.queryParams),this._queryParamMap}toString(){let n=this.url.map(t=>t.toString()).join("/"),e=this.routeConfig?this.routeConfig.path:"";return`Route(url:'${n}', path:'${e}')`}},Hn=class extends Qo{url;constructor(n,e){super(e),this.url=n,Dr(this,e)}toString(){return sd(this._root)}};function Dr(i,n){n.value._routerState=i,n.children.forEach(e=>Dr(i,e))}function sd(i){let n=i.children.length>0?` { ${i.children.map(sd).join(", ")} } `:"";return`${i.value}${n}`}function dr(i){if(i.snapshot){let n=i.snapshot,e=i._futureSnapshot;i.snapshot=e,gt(n.queryParams,e.queryParams)||i.queryParamsSubject.next(e.queryParams),n.fragment!==e.fragment&&i.fragmentSubject.next(e.fragment),gt(n.params,e.params)||i.paramsSubject.next(e.params),lp(n.url,e.url)||i.urlSubject.next(e.url),gt(n.data,e.data)||i.dataSubject.next(e.data)}else i.snapshot=i._futureSnapshot,i.dataSubject.next(i._futureSnapshot.data)}function vr(i,n){let e=gt(i.params,n.params)&&hp(i.url,n.url),t=!i.parent!=!n.parent;return e&&!t&&(!i.parent||vr(i.parent,n.parent))}function rd(i){return typeof i.title=="string"||i.title===null}var ld=new A(""),mi=(()=>{class i{activated=null;get activatedComponentRef(){return this.activated}_activatedRoute=null;name=G;activateEvents=new Z;deactivateEvents=new Z;attachEvents=new Z;detachEvents=new Z;routerOutletData=cc(void 0);parentContexts=l(pi);location=l(Fe);changeDetector=l(me);inputBinder=l($n,{optional:!0});supportsBindingToComponentInputs=!0;ngOnChanges(e){if(e.name){let{firstChange:t,previousValue:o}=e.name;if(t)return;this.isTrackedInParentContexts(o)&&(this.deactivate(),this.parentContexts.onChildOutletDestroyed(o)),this.initializeOutletWithName()}}ngOnDestroy(){this.isTrackedInParentContexts(this.name)&&this.parentContexts.onChildOutletDestroyed(this.name),this.inputBinder?.unsubscribeFromRouteData(this)}isTrackedInParentContexts(e){return this.parentContexts.getContext(e)?.outlet===this}ngOnInit(){this.initializeOutletWithName()}initializeOutletWithName(){if(this.parentContexts.onChildOutletCreated(this.name,this),this.activated)return;let e=this.parentContexts.getContext(this.name);e?.route&&(e.attachRef?this.attach(e.attachRef,e.route):this.activateWith(e.route,e.injector))}get isActivated(){return!!this.activated}get component(){if(!this.activated)throw new U(4012,!1);return this.activated.instance}get activatedRoute(){if(!this.activated)throw new U(4012,!1);return this._activatedRoute}get activatedRouteData(){return this._activatedRoute?this._activatedRoute.snapshot.data:{}}detach(){if(!this.activated)throw new U(4012,!1);this.location.detach();let e=this.activated;return this.activated=null,this._activatedRoute=null,this.detachEvents.emit(e.instance),e}attach(e,t){this.activated=e,this._activatedRoute=t,this.location.insert(e.hostView),this.inputBinder?.bindActivatedRouteToOutletComponent(this),this.attachEvents.emit(e.instance)}deactivate(){if(this.activated){let e=this.component;this.activated.destroy(),this.activated=null,this._activatedRoute=null,this.deactivateEvents.emit(e)}}activateWith(e,t){if(this.isActivated)throw new U(4013,!1);this._activatedRoute=e;let o=this.location,s=e.snapshot.component,r=this.parentContexts.getOrCreateContext(this.name).children,c=new Ar(e,r,o.injector,this.routerOutletData);this.activated=o.createComponent(s,{index:o.length,injector:c,environmentInjector:t}),this.changeDetector.markForCheck(),this.inputBinder?.bindActivatedRouteToOutletComponent(this),this.activateEvents.emit(this.activated.instance)}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["router-outlet"]],inputs:{name:"name",routerOutletData:[1,"routerOutletData"]},outputs:{activateEvents:"activate",deactivateEvents:"deactivate",attachEvents:"attach",detachEvents:"detach"},exportAs:["outlet"],features:[we]})}return i})(),Ar=class{route;childContexts;parent;outletData;constructor(n,e,t,o){this.route=n,this.childContexts=e,this.parent=t,this.outletData=o}get(n,e){return n===It?this.route:n===pi?this.childContexts:n===ld?this.outletData:this.parent.get(n,e)}},$n=new A(""),Er=(()=>{class i{outletDataSubscriptions=new Map;bindActivatedRouteToOutletComponent(e){this.unsubscribeFromRouteData(e),this.subscribeToRouteData(e)}unsubscribeFromRouteData(e){this.outletDataSubscriptions.get(e)?.unsubscribe(),this.outletDataSubscriptions.delete(e)}subscribeToRouteData(e){let{activatedRoute:t}=e,o=xi([t.queryParams,t.params,t.data]).pipe(Ae(([a,s,r],c)=>(r=b(b(b({},a),s),r),c===0?I(r):Promise.resolve(r)))).subscribe(a=>{if(!e.isActivated||!e.activatedComponentRef||e.activatedRoute!==t||t.component===null){this.unsubscribeFromRouteData(e);return}let s=uc(t.component);if(!s){this.unsubscribeFromRouteData(e);return}for(let{templateName:r}of s.inputs)e.activatedComponentRef.setInput(r,a[r])});this.outletDataSubscriptions.set(e,o)}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac})}return i})(),xr=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["ng-component"]],exportAs:["emptyRouterOutlet"],decls:1,vars:0,template:function(t,o){t&1&&ie(0,"router-outlet")},dependencies:[mi],encapsulation:2})}return i})();function Tr(i){let n=i.children&&i.children.map(Tr),e=n?ge(b({},i),{children:n}):b({},i);return!e.component&&!e.loadComponent&&(n||e.loadChildren)&&e.outlet&&e.outlet!==G&&(e.component=xr),e}function Mp(i,n,e){let t=Yn(i,n._root,e?e._root:void 0);return new Un(t,n)}function Yn(i,n,e){if(e&&i.shouldReuseRoute(n.value,e.value.snapshot)){let t=e.value;t._futureSnapshot=n.value;let o=Np(i,n,e);return new Ze(t,o)}else{if(i.shouldAttach(n.value)){let a=i.retrieve(n.value);if(a!==null){let s=a.route;return s.value._futureSnapshot=n.value,s.children=n.children.map(r=>Yn(i,r)),s}}let t=Lp(n.value),o=n.children.map(a=>Yn(i,a));return new Ze(t,o)}}function Np(i,n,e){return n.children.map(t=>{for(let o of e.children)if(i.shouldReuseRoute(t.value,o.value.snapshot))return Yn(i,t,o);return Yn(i,t)})}function Lp(i){return new It(new Ee(i.url),new Ee(i.params),new Ee(i.queryParams),new Ee(i.fragment),new Ee(i.data),i.outlet,i.component,i)}var Yi=class{redirectTo;navigationBehaviorOptions;constructor(n,e){this.redirectTo=n,this.navigationBehaviorOptions=e}},cd="ngNavigationCancelingError";function ta(i,n){let{redirectTo:e,navigationBehaviorOptions:t}=Yt(n)?{redirectTo:n,navigationBehaviorOptions:void 0}:n,o=dd(!1,Ne.Redirect);return o.url=e,o.navigationBehaviorOptions=t,o}function dd(i,n){let e=new Error(`NavigationCancelingError: ${i||""}`);return e[cd]=!0,e.cancellationCode=n,e}function Gp(i){return ud(i)&&Yt(i.url)}function ud(i){return!!i&&i[cd]}var Kp=(i,n,e,t)=>q(o=>(new Ir(n,o.targetRouterState,o.currentRouterState,e,t).activate(i),o)),Ir=class{routeReuseStrategy;futureState;currState;forwardEvent;inputBindingEnabled;constructor(n,e,t,o,a){this.routeReuseStrategy=n,this.futureState=e,this.currState=t,this.forwardEvent=o,this.inputBindingEnabled=a}activate(n){let e=this.futureState._root,t=this.currState?this.currState._root:null;this.deactivateChildRoutes(e,t,n),dr(this.futureState.root),this.activateChildRoutes(e,t,n)}deactivateChildRoutes(n,e,t){let o=Ki(e);n.children.forEach(a=>{let s=a.value.outlet;this.deactivateRoutes(a,o[s],t),delete o[s]}),Object.values(o).forEach(a=>{this.deactivateRouteAndItsChildren(a,t)})}deactivateRoutes(n,e,t){let o=n.value,a=e?e.value:null;if(o===a)if(o.component){let s=t.getContext(o.outlet);s&&this.deactivateChildRoutes(n,e,s.children)}else this.deactivateChildRoutes(n,e,t);else a&&this.deactivateRouteAndItsChildren(e,t)}deactivateRouteAndItsChildren(n,e){n.value.component&&this.routeReuseStrategy.shouldDetach(n.value.snapshot)?this.detachAndStoreRouteSubtree(n,e):this.deactivateRouteAndOutlet(n,e)}detachAndStoreRouteSubtree(n,e){let t=e.getContext(n.value.outlet),o=t&&n.value.component?t.children:e,a=Ki(n);for(let s of Object.values(a))this.deactivateRouteAndItsChildren(s,o);if(t&&t.outlet){let s=t.outlet.detach(),r=t.children.onOutletDeactivated();this.routeReuseStrategy.store(n.value.snapshot,{componentRef:s,route:n,contexts:r})}}deactivateRouteAndOutlet(n,e){let t=e.getContext(n.value.outlet),o=t&&n.value.component?t.children:e,a=Ki(n);for(let s of Object.values(a))this.deactivateRouteAndItsChildren(s,o);t&&(t.outlet&&(t.outlet.deactivate(),t.children.onOutletDeactivated()),t.attachRef=null,t.route=null)}activateChildRoutes(n,e,t){let o=Ki(e);n.children.forEach(a=>{this.activateRoutes(a,o[a.value.outlet],t),this.forwardEvent(new Jo(a.value.snapshot))}),n.children.length&&this.forwardEvent(new Zo(n.value.snapshot))}activateRoutes(n,e,t){let o=n.value,a=e?e.value:null;if(dr(o),o===a)if(o.component){let s=t.getOrCreateContext(o.outlet);this.activateChildRoutes(n,e,s.children)}else this.activateChildRoutes(n,e,t);else if(o.component){let s=t.getOrCreateContext(o.outlet);if(this.routeReuseStrategy.shouldAttach(o.snapshot)){let r=this.routeReuseStrategy.retrieve(o.snapshot);this.routeReuseStrategy.store(o.snapshot,null),s.children.onOutletReAttached(r.contexts),s.attachRef=r.componentRef,s.route=r.route.value,s.outlet&&s.outlet.attach(r.componentRef,r.route.value),dr(r.route.value),this.activateChildRoutes(n,null,s.children)}else s.attachRef=null,s.route=o,s.outlet&&s.outlet.activateWith(o,s.injector),this.activateChildRoutes(n,null,s.children)}else this.activateChildRoutes(n,null,t)}},ia=class{path;route;constructor(n){this.path=n,this.route=this.path[this.path.length-1]}},ji=class{component;route;constructor(n,e){this.component=n,this.route=e}};function zp(i,n,e){let t=i._root,o=n?n._root:null;return Kn(t,o,e,[t.value])}function Bp(i){let n=i.routeConfig?i.routeConfig.canActivateChild:null;return!n||n.length===0?null:{node:i,guards:n}}function Ji(i,n){let e=Symbol(),t=n.get(i,e);return t===e?typeof i=="function"&&!Gl(i)?i:n.get(i):t}function Kn(i,n,e,t,o={canDeactivateChecks:[],canActivateChecks:[]}){let a=Ki(n);return i.children.forEach(s=>{jp(s,a[s.value.outlet],e,t.concat([s.value]),o),delete a[s.value.outlet]}),Object.entries(a).forEach(([s,r])=>Bn(r,e.getContext(s),o)),o}function jp(i,n,e,t,o={canDeactivateChecks:[],canActivateChecks:[]}){let a=i.value,s=n?n.value:null,r=e?e.getContext(i.value.outlet):null;if(s&&a.routeConfig===s.routeConfig){let c=Vp(s,a,a.routeConfig.runGuardsAndResolvers);c?o.canActivateChecks.push(new ia(t)):(a.data=s.data,a._resolvedData=s._resolvedData),a.component?Kn(i,n,r?r.children:null,t,o):Kn(i,n,e,t,o),c&&r&&r.outlet&&r.outlet.isActivated&&o.canDeactivateChecks.push(new ji(r.outlet.component,s))}else s&&Bn(n,r,o),o.canActivateChecks.push(new ia(t)),a.component?Kn(i,null,r?r.children:null,t,o):Kn(i,null,e,t,o);return o}function Vp(i,n,e){if(typeof e=="function")return e(i,n);switch(e){case"pathParamsChange":return!ci(i.url,n.url);case"pathParamsOrQueryParamsChange":return!ci(i.url,n.url)||!gt(i.queryParams,n.queryParams);case"always":return!0;case"paramsOrQueryParamsChange":return!vr(i,n)||!gt(i.queryParams,n.queryParams);case"paramsChange":default:return!vr(i,n)}}function Bn(i,n,e){let t=Ki(i),o=i.value;Object.entries(t).forEach(([a,s])=>{o.component?n?Bn(s,n.children.getContext(a),e):Bn(s,null,e):Bn(s,n,e)}),o.component?n&&n.outlet&&n.outlet.isActivated?e.canDeactivateChecks.push(new ji(n.outlet.component,o)):e.canDeactivateChecks.push(new ji(null,o)):e.canDeactivateChecks.push(new ji(null,o))}function Qn(i){return typeof i=="function"}function Wp(i){return typeof i=="boolean"}function Up(i){return i&&Qn(i.canLoad)}function Hp(i){return i&&Qn(i.canActivate)}function Yp(i){return i&&Qn(i.canActivateChild)}function Zp(i){return i&&Qn(i.canDeactivate)}function Xp(i){return i&&Qn(i.canMatch)}function hd(i){return i instanceof Pl||i?.name==="EmptyError"}var Mo=Symbol("INITIAL_VALUE");function Zi(){return Ae(i=>xi(i.map(n=>n.pipe(Ke(1),tt(Mo)))).pipe(q(n=>{for(let e of n)if(e!==!0){if(e===Mo)return Mo;if(e===!1||Jp(e))return e}return!0}),ue(n=>n!==Mo),Ke(1)))}function Jp(i){return Yt(i)||i instanceof Yi}function $p(i,n){return Ge(e=>{let{targetSnapshot:t,currentSnapshot:o,guards:{canActivateChecks:a,canDeactivateChecks:s}}=e;return s.length===0&&a.length===0?I(ge(b({},e),{guardsResult:!0})):Qp(s,t,o,i).pipe(Ge(r=>r&&Wp(r)?em(t,a,i,n):I(r)),q(r=>ge(b({},e),{guardsResult:r})))})}function Qp(i,n,e,t){return Oe(i).pipe(Ge(o=>am(o.component,o.route,e,n,t)),Gt(o=>o!==!0,!0))}function em(i,n,e,t){return Oe(n).pipe(xt(o=>vo(im(o.route.parent,t),tm(o.route,t),om(i,o.path,e),nm(i,o.route,e))),Gt(o=>o!==!0,!0))}function tm(i,n){return i!==null&&n&&n(new Xo(i)),I(!0)}function im(i,n){return i!==null&&n&&n(new Yo(i)),I(!0)}function nm(i,n,e){let t=n.routeConfig?n.routeConfig.canActivate:null;if(!t||t.length===0)return I(!0);let o=t.map(a=>Ao(()=>{let s=Xi(n)??e,r=Ji(a,s),c=Hp(r)?r.canActivate(n,i):We(s,()=>r(n,i));return qt(c).pipe(Gt())}));return I(o).pipe(Zi())}function om(i,n,e){let t=n[n.length-1],a=n.slice(0,n.length-1).reverse().map(s=>Bp(s)).filter(s=>s!==null).map(s=>Ao(()=>{let r=s.guards.map(c=>{let d=Xi(s.node)??e,p=Ji(c,d),v=Yp(p)?p.canActivateChild(t,i):We(d,()=>p(t,i));return qt(v).pipe(Gt())});return I(r).pipe(Zi())}));return I(a).pipe(Zi())}function am(i,n,e,t,o){let a=n&&n.routeConfig?n.routeConfig.canDeactivate:null;if(!a||a.length===0)return I(!0);let s=a.map(r=>{let c=Xi(n)??o,d=Ji(r,c),p=Zp(d)?d.canDeactivate(i,n,e,t):We(c,()=>d(i,n,e,t));return qt(p).pipe(Gt())});return I(s).pipe(Zi())}function sm(i,n,e,t){let o=n.canLoad;if(o===void 0||o.length===0)return I(!0);let a=o.map(s=>{let r=Ji(s,i),c=Up(r)?r.canLoad(n,e):We(i,()=>r(n,e));return qt(c)});return I(a).pipe(Zi(),pd(t))}function pd(i){return Ol(fe(n=>{if(typeof n!="boolean")throw ta(i,n)}),q(n=>n===!0))}function rm(i,n,e,t){let o=n.canMatch;if(!o||o.length===0)return I(!0);let a=o.map(s=>{let r=Ji(s,i),c=Xp(r)?r.canMatch(n,e):We(i,()=>r(n,e));return qt(c)});return I(a).pipe(Zi(),pd(t))}var Zn=class{segmentGroup;constructor(n){this.segmentGroup=n||null}},Xn=class extends Error{urlTree;constructor(n){super(),this.urlTree=n}};function Gi(i){return ni(new Zn(i))}function lm(i){return ni(new U(4e3,!1))}function cm(i){return ni(dd(!1,Ne.GuardRejected))}var _r=class{urlSerializer;urlTree;constructor(n,e){this.urlSerializer=n,this.urlTree=e}lineralizeSegments(n,e){let t=[],o=e.root;for(;;){if(t=t.concat(o.segments),o.numberOfChildren===0)return I(t);if(o.numberOfChildren>1||!o.children[G])return lm(`${n.redirectTo}`);o=o.children[G]}}applyRedirectCommands(n,e,t,o,a){return dm(e,o,a).pipe(q(s=>{if(s instanceof vt)throw new Xn(s);let r=this.applyRedirectCreateUrlTree(s,this.urlSerializer.parse(s),n,t);if(s[0]==="/")throw new Xn(r);return r}))}applyRedirectCreateUrlTree(n,e,t,o){let a=this.createSegmentGroup(n,e.root,t,o);return new vt(a,this.createQueryParams(e.queryParams,this.urlTree.queryParams),e.fragment)}createQueryParams(n,e){let t={};return Object.entries(n).forEach(([o,a])=>{if(typeof a=="string"&&a[0]===":"){let r=a.substring(1);t[o]=e[r]}else t[o]=a}),t}createSegmentGroup(n,e,t,o){let a=this.createSegments(n,e.segments,t,o),s={};return Object.entries(e.children).forEach(([r,c])=>{s[r]=this.createSegmentGroup(n,c,t,o)}),new ee(a,s)}createSegments(n,e,t,o){return e.map(a=>a.path[0]===":"?this.findPosParam(n,a,o):this.findOrReturn(a,t))}findPosParam(n,e,t){let o=t[e.path.substring(1)];if(!o)throw new U(4001,!1);return o}findOrReturn(n,e){let t=0;for(let o of e){if(o.path===n.path)return e.splice(t),o;t++}return n}};function dm(i,n,e){if(typeof i=="string")return I(i);let t=i,{queryParams:o,fragment:a,routeConfig:s,url:r,outlet:c,params:d,data:p,title:v}=n;return qt(We(e,()=>t({params:d,data:p,queryParams:o,fragment:a,routeConfig:s,url:r,outlet:c,title:v})))}var wr={matched:!1,consumedSegments:[],remainingSegments:[],parameters:{},positionalParamSegments:{}};function um(i,n,e,t,o){let a=md(i,n,e);return a.matched?(t=Pp(n,t),rm(t,n,e,o).pipe(q(s=>s===!0?a:b({},wr)))):I(a)}function md(i,n,e){if(n.path==="**")return hm(e);if(n.path==="")return n.pathMatch==="full"&&(i.hasChildren()||e.length>0)?b({},wr):{matched:!0,consumedSegments:[],remainingSegments:e,parameters:{},positionalParamSegments:{}};let o=(n.matcher||jc)(e,i,n);if(!o)return b({},wr);let a={};Object.entries(o.posParams??{}).forEach(([r,c])=>{a[r]=c.path});let s=o.consumed.length>0?b(b({},a),o.consumed[o.consumed.length-1].parameters):a;return{matched:!0,consumedSegments:o.consumed,remainingSegments:e.slice(o.consumed.length),parameters:s,positionalParamSegments:o.posParams??{}}}function hm(i){return{matched:!0,parameters:i.length>0?Wc(i).parameters:{},consumedSegments:i,remainingSegments:[],positionalParamSegments:{}}}function Kc(i,n,e,t){return e.length>0&&fm(i,e,t)?{segmentGroup:new ee(n,mm(t,new ee(e,i.children))),slicedSegments:[]}:e.length===0&&ym(i,e,t)?{segmentGroup:new ee(i.segments,pm(i,e,t,i.children)),slicedSegments:e}:{segmentGroup:new ee(i.segments,i.children),slicedSegments:e}}function pm(i,n,e,t){let o={};for(let a of e)if(oa(i,n,a)&&!t[ct(a)]){let s=new ee([],{});o[ct(a)]=s}return b(b({},t),o)}function mm(i,n){let e={};e[G]=n;for(let t of i)if(t.path===""&&ct(t)!==G){let o=new ee([],{});e[ct(t)]=o}return e}function fm(i,n,e){return e.some(t=>oa(i,n,t)&&ct(t)!==G)}function ym(i,n,e){return e.some(t=>oa(i,n,t))}function oa(i,n,e){return(i.hasChildren()||n.length>0)&&e.pathMatch==="full"?!1:e.path===""}function gm(i,n,e){return n.length===0&&!i.children[e]}var Cr=class{};function bm(i,n,e,t,o,a,s="emptyOnly"){return new kr(i,n,e,t,o,s,a).recognize()}var vm=31,kr=class{injector;configLoader;rootComponentType;config;urlTree;paramsInheritanceStrategy;urlSerializer;applyRedirects;absoluteRedirectCount=0;allowRedirects=!0;constructor(n,e,t,o,a,s,r){this.injector=n,this.configLoader=e,this.rootComponentType=t,this.config=o,this.urlTree=a,this.paramsInheritanceStrategy=s,this.urlSerializer=r,this.applyRedirects=new _r(this.urlSerializer,this.urlTree)}noMatchError(n){return new U(4002,`'${n.segmentGroup}'`)}recognize(){let n=Kc(this.urlTree.root,[],[],this.config).segmentGroup;return this.match(n).pipe(q(({children:e,rootSnapshot:t})=>{let o=new Ze(t,e),a=new Hn("",o),s=ed(t,[],this.urlTree.queryParams,this.urlTree.fragment);return s.queryParams=this.urlTree.queryParams,a.url=this.urlSerializer.serialize(s),{state:a,tree:s}}))}match(n){let e=new di([],Object.freeze({}),Object.freeze(b({},this.urlTree.queryParams)),this.urlTree.fragment,Object.freeze({}),G,this.rootComponentType,null,{});return this.processSegmentGroup(this.injector,this.config,n,G,e).pipe(q(t=>({children:t,rootSnapshot:e})),Et(t=>{if(t instanceof Xn)return this.urlTree=t.urlTree,this.match(t.urlTree.root);throw t instanceof Zn?this.noMatchError(t):t}))}processSegmentGroup(n,e,t,o,a){return t.segments.length===0&&t.hasChildren()?this.processChildren(n,e,t,a):this.processSegment(n,e,t,t.segments,o,!0,a).pipe(q(s=>s instanceof Ze?[s]:[]))}processChildren(n,e,t,o){let a=[];for(let s of Object.keys(t.children))s==="primary"?a.unshift(s):a.push(s);return Oe(a).pipe(xt(s=>{let r=t.children[s],c=qp(e,s);return this.processSegmentGroup(n,c,r,s,o)}),Nl((s,r)=>(s.push(...r),s)),ks(null),Ml(),Ge(s=>{if(s===null)return Gi(t);let r=fd(s);return Am(r),I(r)}))}processSegment(n,e,t,o,a,s,r){return Oe(e).pipe(xt(c=>this.processSegmentAgainstRoute(c._injector??n,e,c,t,o,a,s,r).pipe(Et(d=>{if(d instanceof Zn)return I(null);throw d}))),Gt(c=>!!c),Et(c=>{if(hd(c))return gm(t,o,a)?I(new Cr):Gi(t);throw c}))}processSegmentAgainstRoute(n,e,t,o,a,s,r,c){return ct(t)!==s&&(s===G||!oa(o,a,t))?Gi(o):t.redirectTo===void 0?this.matchSegmentAgainstRoute(n,o,t,a,s,c):this.allowRedirects&&r?this.expandSegmentAgainstRouteUsingRedirect(n,o,e,t,a,s,c):Gi(o)}expandSegmentAgainstRouteUsingRedirect(n,e,t,o,a,s,r){let{matched:c,parameters:d,consumedSegments:p,positionalParamSegments:v,remainingSegments:C}=md(e,o,a);if(!c)return Gi(e);typeof o.redirectTo=="string"&&o.redirectTo[0]==="/"&&(this.absoluteRedirectCount++,this.absoluteRedirectCount>vm&&(this.allowRedirects=!1));let P=new di(a,d,Object.freeze(b({},this.urlTree.queryParams)),this.urlTree.fragment,zc(o),ct(o),o.component??o._loadedComponent??null,o,Bc(o)),L=ea(P,r,this.paramsInheritanceStrategy);return P.params=Object.freeze(L.params),P.data=Object.freeze(L.data),this.applyRedirects.applyRedirectCommands(p,o.redirectTo,v,P,n).pipe(Ae(ae=>this.applyRedirects.lineralizeSegments(o,ae)),Ge(ae=>this.processSegment(n,t,e,ae.concat(C),s,!1,r)))}matchSegmentAgainstRoute(n,e,t,o,a,s){let r=um(e,t,o,n,this.urlSerializer);return t.path==="**"&&(e.children={}),r.pipe(Ae(c=>c.matched?(n=t._injector??n,this.getChildConfig(n,t,o).pipe(Ae(({routes:d})=>{let p=t._loadedInjector??n,{parameters:v,consumedSegments:C,remainingSegments:P}=c,L=new di(C,v,Object.freeze(b({},this.urlTree.queryParams)),this.urlTree.fragment,zc(t),ct(t),t.component??t._loadedComponent??null,t,Bc(t)),W=ea(L,s,this.paramsInheritanceStrategy);L.params=Object.freeze(W.params),L.data=Object.freeze(W.data);let{segmentGroup:ae,slicedSegments:ye}=Kc(e,C,P,d);if(ye.length===0&&ae.hasChildren())return this.processChildren(p,d,ae,L).pipe(q(at=>new Ze(L,at)));if(d.length===0&&ye.length===0)return I(new Ze(L,[]));let et=ct(t)===a;return this.processSegment(p,d,ae,ye,et?G:a,!0,L).pipe(q(at=>new Ze(L,at instanceof Ze?[at]:[])))}))):Gi(e)))}getChildConfig(n,e,t){return e.children?I({routes:e.children,injector:n}):e.loadChildren?e._loadedRoutes!==void 0?I({routes:e._loadedRoutes,injector:e._loadedInjector}):sm(n,e,t,this.urlSerializer).pipe(Ge(o=>o?this.configLoader.loadChildren(n,e).pipe(fe(a=>{e._loadedRoutes=a.routes,e._loadedInjector=a.injector})):cm(e))):I({routes:[],injector:n})}};function Am(i){i.sort((n,e)=>n.value.outlet===G?-1:e.value.outlet===G?1:n.value.outlet.localeCompare(e.value.outlet))}function Im(i){let n=i.value.routeConfig;return n&&n.path===""}function fd(i){let n=[],e=new Set;for(let t of i){if(!Im(t)){n.push(t);continue}let o=n.find(a=>t.value.routeConfig===a.value.routeConfig);o!==void 0?(o.children.push(...t.children),e.add(o)):n.push(t)}for(let t of e){let o=fd(t.children);n.push(new Ze(t.value,o))}return n.filter(t=>!e.has(t))}function zc(i){return i.data||{}}function Bc(i){return i.resolve||{}}function _m(i,n,e,t,o,a){return Ge(s=>bm(i,n,e,t,s.extractedUrl,o,a).pipe(q(({state:r,tree:c})=>ge(b({},s),{targetSnapshot:r,urlAfterRedirects:c}))))}function wm(i,n){return Ge(e=>{let{targetSnapshot:t,guards:{canActivateChecks:o}}=e;if(!o.length)return I(e);let a=new Set(o.map(c=>c.route)),s=new Set;for(let c of a)if(!s.has(c))for(let d of yd(c))s.add(d);let r=0;return Oe(s).pipe(xt(c=>a.has(c)?Cm(c,t,i,n):(c.data=ea(c,c.parent,i).resolve,I(void 0))),fe(()=>r++),xs(1),Ge(c=>r===s.size?I(e):Dt))})}function yd(i){let n=i.children.map(e=>yd(e)).flat();return[i,...n]}function Cm(i,n,e,t){let o=i.routeConfig,a=i._resolve;return o?.title!==void 0&&!rd(o)&&(a[Jn]=o.title),Ao(()=>(i.data=ea(i,i.parent,e).resolve,km(a,i,n,t).pipe(q(s=>(i._resolvedData=s,i.data=b(b({},i.data),s),null)))))}function km(i,n,e,t){let o=pr(i);if(o.length===0)return I({});let a={};return Oe(o).pipe(Ge(s=>Dm(i[s],n,e,t).pipe(Gt(),fe(r=>{if(r instanceof Yi)throw ta(new Ht,r);a[s]=r}))),xs(1),q(()=>a),Et(s=>hd(s)?Dt:ni(s)))}function Dm(i,n,e,t){let o=Xi(n)??t,a=Ji(i,o),s=a.resolve?a.resolve(n,e):We(o,()=>a(n,e));return qt(s)}function ur(i){return Ae(n=>{let e=i(n);return e?Oe(e).pipe(q(()=>n)):I(n)})}var Rr=(()=>{class i{buildTitle(e){let t,o=e.root;for(;o!==void 0;)t=this.getResolvedTitleForRoute(o)??t,o=o.children.find(a=>a.outlet===G);return t}getResolvedTitleForRoute(e){return e.data[Jn]}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:()=>l(gd),providedIn:"root"})}return i})(),gd=(()=>{class i extends Rr{title;constructor(e){super(),this.title=e}updateTitle(e){let t=this.buildTitle(e);t!==void 0&&this.title.setTitle(t)}static \u0275fac=function(t){return new(t||i)(O(qc))};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),Xt=new A("",{providedIn:"root",factory:()=>({})}),fi=new A(""),aa=(()=>{class i{componentLoaders=new WeakMap;childrenLoaders=new WeakMap;onLoadStartListener;onLoadEndListener;compiler=l(rc);loadComponent(e,t){if(this.componentLoaders.get(t))return this.componentLoaders.get(t);if(t._loadedComponent)return I(t._loadedComponent);this.onLoadStartListener&&this.onLoadStartListener(t);let o=qt(We(e,()=>t.loadComponent())).pipe(q(vd),Ae(Ad),fe(s=>{this.onLoadEndListener&&this.onLoadEndListener(t),t._loadedComponent=s}),oi(()=>{this.componentLoaders.delete(t)})),a=new In(o,()=>new S).pipe(ws());return this.componentLoaders.set(t,a),a}loadChildren(e,t){if(this.childrenLoaders.get(t))return this.childrenLoaders.get(t);if(t._loadedRoutes)return I({routes:t._loadedRoutes,injector:t._loadedInjector});this.onLoadStartListener&&this.onLoadStartListener(t);let a=bd(t,this.compiler,e,this.onLoadEndListener).pipe(oi(()=>{this.childrenLoaders.delete(t)})),s=new In(a,()=>new S).pipe(ws());return this.childrenLoaders.set(t,s),s}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();function bd(i,n,e,t){return qt(We(e,()=>i.loadChildren())).pipe(q(vd),Ae(Ad),Ge(o=>o instanceof tc||Array.isArray(o)?I(o):Oe(n.compileModuleAsync(o))),q(o=>{t&&t(i);let a,s,r=!1;return Array.isArray(o)?(s=o,r=!0):(a=o.create(e).injector,s=a.get(fi,[],{optional:!0,self:!0}).flat()),{routes:s.map(Tr),injector:a}}))}function Em(i){return i&&typeof i=="object"&&"default"in i}function vd(i){return Em(i)?i.default:i}function Ad(i){return I(i)}var sa=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:()=>l(xm),providedIn:"root"})}return i})(),xm=(()=>{class i{shouldProcessUrl(e){return!0}extract(e){return e}merge(e,t){return e}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),Sr=new A(""),Or=new A("");function Id(i,n,e){let t=i.get(Or),o=i.get(D);if(!o.startViewTransition||t.skipNextTransition)return t.skipNextTransition=!1,new Promise(d=>setTimeout(d));let a,s=new Promise(d=>{a=d}),r=o.startViewTransition(()=>(a(),Tm(i)));r.ready.catch(d=>{});let{onViewTransitionCreated:c}=t;return c&&We(i,()=>c({transition:r,from:n,to:e})),s}function Tm(i){return new Promise(n=>{ve({read:()=>setTimeout(n)},{injector:i})})}var Pr=new A(""),ra=(()=>{class i{currentNavigation=te(null,{equal:()=>!1});currentTransition=null;lastSuccessfulNavigation=null;events=new S;transitionAbortWithErrorSubject=new S;configLoader=l(aa);environmentInjector=l(ze);destroyRef=l(kn);urlSerializer=l(hi);rootContexts=l(pi);location=l(yt);inputBindingEnabled=l($n,{optional:!0})!==null;titleStrategy=l(Rr);options=l(Xt,{optional:!0})||{};paramsInheritanceStrategy=this.options.paramsInheritanceStrategy||"emptyOnly";urlHandlingStrategy=l(sa);createViewTransition=l(Sr,{optional:!0});navigationErrorHandler=l(Pr,{optional:!0});navigationId=0;get hasRequestedNavigation(){return this.navigationId!==0}transitions;afterPreactivation=()=>I(void 0);rootComponentType=null;destroyed=!1;constructor(){let e=o=>this.events.next(new Uo(o)),t=o=>this.events.next(new Ho(o));this.configLoader.onLoadEndListener=t,this.configLoader.onLoadStartListener=e,this.destroyRef.onDestroy(()=>{this.destroyed=!0})}complete(){this.transitions?.complete()}handleNavigationRequest(e){let t=++this.navigationId;ft(()=>{this.transitions?.next(ge(b({},e),{extractedUrl:this.urlHandlingStrategy.extract(e.rawUrl),targetSnapshot:null,targetRouterState:null,guards:{canActivateChecks:[],canDeactivateChecks:[]},guardsResult:null,abortController:new AbortController,id:t}))})}setupNavigations(e){return this.transitions=new Ee(null),this.transitions.pipe(ue(t=>t!==null),Ae(t=>{let o=!1;return I(t).pipe(Ae(a=>{if(this.navigationId>t.id)return this.cancelNavigationTransition(t,"",Ne.SupersededByNewNavigation),Dt;this.currentTransition=t,this.currentNavigation.set({id:a.id,initialUrl:a.rawUrl,extractedUrl:a.extractedUrl,targetBrowserUrl:typeof a.extras.browserUrl=="string"?this.urlSerializer.parse(a.extras.browserUrl):a.extras.browserUrl,trigger:a.source,extras:a.extras,previousNavigation:this.lastSuccessfulNavigation?ge(b({},this.lastSuccessfulNavigation),{previousNavigation:null}):null,abort:()=>a.abortController.abort()});let s=!e.navigated||this.isUpdatingInternalState()||this.isUpdatedBrowserUrl(),r=a.extras.onSameUrlNavigation??e.onSameUrlNavigation;if(!s&&r!=="reload")return this.events.next(new At(a.id,this.urlSerializer.serialize(a.rawUrl),"",Vi.IgnoredSameUrlNavigation)),a.resolve(!1),Dt;if(this.urlHandlingStrategy.shouldProcessUrl(a.rawUrl))return I(a).pipe(Ae(c=>(this.events.next(new Zt(c.id,this.urlSerializer.serialize(c.extractedUrl),c.source,c.restoredState)),c.id!==this.navigationId?Dt:Promise.resolve(c))),_m(this.environmentInjector,this.configLoader,this.rootComponentType,e.config,this.urlSerializer,this.paramsInheritanceStrategy),fe(c=>{t.targetSnapshot=c.targetSnapshot,t.urlAfterRedirects=c.urlAfterRedirects,this.currentNavigation.update(p=>(p.finalUrl=c.urlAfterRedirects,p));let d=new Vn(c.id,this.urlSerializer.serialize(c.extractedUrl),this.urlSerializer.serialize(c.urlAfterRedirects),c.targetSnapshot);this.events.next(d)}));if(s&&this.urlHandlingStrategy.shouldProcessUrl(a.currentRawUrl)){let{id:c,extractedUrl:d,source:p,restoredState:v,extras:C}=a,P=new Zt(c,this.urlSerializer.serialize(d),p,v);this.events.next(P);let L=ad(this.rootComponentType).snapshot;return this.currentTransition=t=ge(b({},a),{targetSnapshot:L,urlAfterRedirects:d,extras:ge(b({},C),{skipLocationChange:!1,replaceUrl:!1})}),this.currentNavigation.update(W=>(W.finalUrl=d,W)),I(t)}else return this.events.next(new At(a.id,this.urlSerializer.serialize(a.extractedUrl),"",Vi.IgnoredByUrlHandlingStrategy)),a.resolve(!1),Dt}),fe(a=>{let s=new Bo(a.id,this.urlSerializer.serialize(a.extractedUrl),this.urlSerializer.serialize(a.urlAfterRedirects),a.targetSnapshot);this.events.next(s)}),q(a=>(this.currentTransition=t=ge(b({},a),{guards:zp(a.targetSnapshot,a.currentSnapshot,this.rootContexts)}),t)),$p(this.environmentInjector,a=>this.events.next(a)),fe(a=>{if(t.guardsResult=a.guardsResult,a.guardsResult&&typeof a.guardsResult!="boolean")throw ta(this.urlSerializer,a.guardsResult);let s=new jo(a.id,this.urlSerializer.serialize(a.extractedUrl),this.urlSerializer.serialize(a.urlAfterRedirects),a.targetSnapshot,!!a.guardsResult);this.events.next(s)}),ue(a=>a.guardsResult?!0:(this.cancelNavigationTransition(a,"",Ne.GuardRejected),!1)),ur(a=>{if(a.guards.canActivateChecks.length!==0)return I(a).pipe(fe(s=>{let r=new Vo(s.id,this.urlSerializer.serialize(s.extractedUrl),this.urlSerializer.serialize(s.urlAfterRedirects),s.targetSnapshot);this.events.next(r)}),Ae(s=>{let r=!1;return I(s).pipe(wm(this.paramsInheritanceStrategy,this.environmentInjector),fe({next:()=>r=!0,complete:()=>{r||this.cancelNavigationTransition(s,"",Ne.NoDataFromResolver)}}))}),fe(s=>{let r=new Wo(s.id,this.urlSerializer.serialize(s.extractedUrl),this.urlSerializer.serialize(s.urlAfterRedirects),s.targetSnapshot);this.events.next(r)}))}),ur(a=>{let s=r=>{let c=[];if(r.routeConfig?.loadComponent){let d=Xi(r)??this.environmentInjector;c.push(this.configLoader.loadComponent(d,r.routeConfig).pipe(fe(p=>{r.component=p}),q(()=>{})))}for(let d of r.children)c.push(...s(d));return c};return xi(s(a.targetSnapshot.root)).pipe(ks(null),Ke(1))}),ur(()=>this.afterPreactivation()),Ae(()=>{let{currentSnapshot:a,targetSnapshot:s}=t,r=this.createViewTransition?.(this.environmentInjector,a.root,s.root);return r?Oe(r).pipe(q(()=>t)):I(t)}),q(a=>{let s=Mp(e.routeReuseStrategy,a.targetSnapshot,a.currentRouterState);return this.currentTransition=t=ge(b({},a),{targetRouterState:s}),this.currentNavigation.update(r=>(r.targetRouterState=s,r)),t}),fe(()=>{this.events.next(new Wn)}),Kp(this.rootContexts,e.routeReuseStrategy,a=>this.events.next(a),this.inputBindingEnabled),Ke(1),pe(new kt(a=>{let s=t.abortController.signal,r=()=>a.next();return s.addEventListener("abort",r),()=>s.removeEventListener("abort",r)}).pipe(ue(()=>!o&&!t.targetRouterState),fe(()=>{this.cancelNavigationTransition(t,t.abortController.signal.reason+"",Ne.Aborted)}))),fe({next:a=>{o=!0,this.lastSuccessfulNavigation=ft(this.currentNavigation),this.events.next(new Je(a.id,this.urlSerializer.serialize(a.extractedUrl),this.urlSerializer.serialize(a.urlAfterRedirects))),this.titleStrategy?.updateTitle(a.targetRouterState.snapshot),a.resolve(!0)},complete:()=>{o=!0}}),pe(this.transitionAbortWithErrorSubject.pipe(fe(a=>{throw a}))),oi(()=>{o||this.cancelNavigationTransition(t,"",Ne.SupersededByNewNavigation),this.currentTransition?.id===t.id&&(this.currentNavigation.set(null),this.currentTransition=null)}),Et(a=>{if(this.destroyed)return t.resolve(!1),Dt;if(o=!0,ud(a))this.events.next(new bt(t.id,this.urlSerializer.serialize(t.extractedUrl),a.message,a.cancellationCode)),Gp(a)?this.events.next(new Hi(a.url,a.navigationBehaviorOptions)):t.resolve(!1);else{let s=new Wi(t.id,this.urlSerializer.serialize(t.extractedUrl),a,t.targetSnapshot??void 0);try{let r=We(this.environmentInjector,()=>this.navigationErrorHandler?.(s));if(r instanceof Yi){let{message:c,cancellationCode:d}=ta(this.urlSerializer,r);this.events.next(new bt(t.id,this.urlSerializer.serialize(t.extractedUrl),c,d)),this.events.next(new Hi(r.redirectTo,r.navigationBehaviorOptions))}else throw this.events.next(s),a}catch(r){this.options.resolveNavigationPromiseOnError?t.resolve(!1):t.reject(r)}}return Dt}))}))}cancelNavigationTransition(e,t,o){let a=new bt(e.id,this.urlSerializer.serialize(e.extractedUrl),t,o);this.events.next(a),e.resolve(!1)}isUpdatingInternalState(){return this.currentTransition?.extractedUrl.toString()!==this.currentTransition?.currentUrlTree.toString()}isUpdatedBrowserUrl(){let e=this.urlHandlingStrategy.extract(this.urlSerializer.parse(this.location.path(!0))),t=ft(this.currentNavigation),o=t?.targetBrowserUrl??t?.extractedUrl;return e.toString()!==o?.toString()&&!t?.extras.skipLocationChange}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();function Rm(i){return i!==Bi}var _d=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:()=>l(Sm),providedIn:"root"})}return i})(),na=class{shouldDetach(n){return!1}store(n,e){}shouldAttach(n){return!1}retrieve(n){return null}shouldReuseRoute(n,e){return n.routeConfig===e.routeConfig}},Sm=(()=>{class i extends na{static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),wd=(()=>{class i{urlSerializer=l(hi);options=l(Xt,{optional:!0})||{};canceledNavigationResolution=this.options.canceledNavigationResolution||"replace";location=l(yt);urlHandlingStrategy=l(sa);urlUpdateStrategy=this.options.urlUpdateStrategy||"deferred";currentUrlTree=new vt;getCurrentUrlTree(){return this.currentUrlTree}rawUrlTree=this.currentUrlTree;getRawUrlTree(){return this.rawUrlTree}createBrowserPath({finalUrl:e,initialUrl:t,targetBrowserUrl:o}){let a=e!==void 0?this.urlHandlingStrategy.merge(e,t):t,s=o??a;return s instanceof vt?this.urlSerializer.serialize(s):s}commitTransition({targetRouterState:e,finalUrl:t,initialUrl:o}){t&&e?(this.currentUrlTree=t,this.rawUrlTree=this.urlHandlingStrategy.merge(t,o),this.routerState=e):this.rawUrlTree=o}routerState=ad(null);getRouterState(){return this.routerState}stateMemento=this.createStateMemento();updateStateMemento(){this.stateMemento=this.createStateMemento()}createStateMemento(){return{rawUrlTree:this.rawUrlTree,currentUrlTree:this.currentUrlTree,routerState:this.routerState}}resetInternalState({finalUrl:e}){this.routerState=this.stateMemento.routerState,this.currentUrlTree=this.stateMemento.currentUrlTree,this.rawUrlTree=this.urlHandlingStrategy.merge(this.currentUrlTree,e??this.rawUrlTree)}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:()=>l(Om),providedIn:"root"})}return i})(),Om=(()=>{class i extends wd{currentPageId=0;lastSuccessfulId=-1;restoredState(){return this.location.getState()}get browserPageId(){return this.canceledNavigationResolution!=="computed"?this.currentPageId:this.restoredState()?.\u0275routerPageId??this.currentPageId}registerNonRouterCurrentEntryChangeListener(e){return this.location.subscribe(t=>{t.type==="popstate"&&setTimeout(()=>{e(t.url,t.state,"popstate")})})}handleRouterEvent(e,t){e instanceof Zt?this.updateStateMemento():e instanceof At?this.commitTransition(t):e instanceof Vn?this.urlUpdateStrategy==="eager"&&(t.extras.skipLocationChange||this.setBrowserUrl(this.createBrowserPath(t),t)):e instanceof Wn?(this.commitTransition(t),this.urlUpdateStrategy==="deferred"&&!t.extras.skipLocationChange&&this.setBrowserUrl(this.createBrowserPath(t),t)):e instanceof bt&&e.code!==Ne.SupersededByNewNavigation&&e.code!==Ne.Redirect?this.restoreHistory(t):e instanceof Wi?this.restoreHistory(t,!0):e instanceof Je&&(this.lastSuccessfulId=e.id,this.currentPageId=this.browserPageId)}setBrowserUrl(e,{extras:t,id:o}){let{replaceUrl:a,state:s}=t;if(this.location.isCurrentPathEqualTo(e)||a){let r=this.browserPageId,c=b(b({},s),this.generateNgRouterState(o,r));this.location.replaceState(e,"",c)}else{let r=b(b({},s),this.generateNgRouterState(o,this.browserPageId+1));this.location.go(e,"",r)}}restoreHistory(e,t=!1){if(this.canceledNavigationResolution==="computed"){let o=this.browserPageId,a=this.currentPageId-o;a!==0?this.location.historyGo(a):this.getCurrentUrlTree()===e.finalUrl&&a===0&&(this.resetInternalState(e),this.resetUrlToCurrentUrlTree())}else this.canceledNavigationResolution==="replace"&&(t&&this.resetInternalState(e),this.resetUrlToCurrentUrlTree())}resetUrlToCurrentUrlTree(){this.location.replaceState(this.urlSerializer.serialize(this.getRawUrlTree()),"",this.generateNgRouterState(this.lastSuccessfulId,this.currentPageId))}generateNgRouterState(e,t){return this.canceledNavigationResolution==="computed"?{navigationId:e,\u0275routerPageId:t}:{navigationId:e}}static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();function la(i,n){i.events.pipe(ue(e=>e instanceof Je||e instanceof bt||e instanceof Wi||e instanceof At),q(e=>e instanceof Je||e instanceof At?0:(e instanceof bt?e.code===Ne.Redirect||e.code===Ne.SupersededByNewNavigation:!1)?2:1),ue(e=>e!==2),Ke(1)).subscribe(()=>{n()})}var Pm={paths:"exact",fragment:"ignored",matrixParams:"ignored",queryParams:"exact"},qm={paths:"subset",fragment:"ignored",matrixParams:"ignored",queryParams:"subset"},$e=(()=>{class i{get currentUrlTree(){return this.stateManager.getCurrentUrlTree()}get rawUrlTree(){return this.stateManager.getRawUrlTree()}disposed=!1;nonRouterCurrentEntryChangeSubscription;console=l(Ps);stateManager=l(wd);options=l(Xt,{optional:!0})||{};pendingTasks=l(jl);urlUpdateStrategy=this.options.urlUpdateStrategy||"deferred";navigationTransitions=l(ra);urlSerializer=l(hi);location=l(yt);urlHandlingStrategy=l(sa);injector=l(ze);_events=new S;get events(){return this._events}get routerState(){return this.stateManager.getRouterState()}navigated=!1;routeReuseStrategy=l(_d);onSameUrlNavigation=this.options.onSameUrlNavigation||"ignore";config=l(fi,{optional:!0})?.flat()??[];componentInputBindingEnabled=!!l($n,{optional:!0});currentNavigation=this.navigationTransitions.currentNavigation.asReadonly();constructor(){this.resetConfig(this.config),this.navigationTransitions.setupNavigations(this).subscribe({error:e=>{this.console.warn(e)}}),this.subscribeToNavigationEvents()}eventsSubscription=new De;subscribeToNavigationEvents(){let e=this.navigationTransitions.events.subscribe(t=>{try{let o=this.navigationTransitions.currentTransition,a=ft(this.navigationTransitions.currentNavigation);if(o!==null&&a!==null){if(this.stateManager.handleRouterEvent(t,a),t instanceof bt&&t.code!==Ne.Redirect&&t.code!==Ne.SupersededByNewNavigation)this.navigated=!0;else if(t instanceof Je)this.navigated=!0;else if(t instanceof Hi){let s=t.navigationBehaviorOptions,r=this.urlHandlingStrategy.merge(t.url,o.currentRawUrl),c=b({browserUrl:o.extras.browserUrl,info:o.extras.info,skipLocationChange:o.extras.skipLocationChange,replaceUrl:o.extras.replaceUrl||this.urlUpdateStrategy==="eager"||Rm(o.source)},s);this.scheduleNavigation(r,Bi,null,c,{resolve:o.resolve,reject:o.reject,promise:o.promise})}}Op(t)&&this._events.next(t)}catch(o){this.navigationTransitions.transitionAbortWithErrorSubject.next(o)}});this.eventsSubscription.add(e)}resetRootComponentType(e){this.routerState.root.component=e,this.navigationTransitions.rootComponentType=e}initialNavigation(){this.setUpLocationChangeListener(),this.navigationTransitions.hasRequestedNavigation||this.navigateToSyncWithBrowser(this.location.path(!0),Bi,this.stateManager.restoredState())}setUpLocationChangeListener(){this.nonRouterCurrentEntryChangeSubscription??=this.stateManager.registerNonRouterCurrentEntryChangeListener((e,t,o)=>{this.navigateToSyncWithBrowser(e,o,t)})}navigateToSyncWithBrowser(e,t,o){let a={replaceUrl:!0},s=o?.navigationId?o:null;if(o){let c=b({},o);delete c.navigationId,delete c.\u0275routerPageId,Object.keys(c).length!==0&&(a.state=c)}let r=this.parseUrl(e);this.scheduleNavigation(r,t,s,a).catch(c=>{this.disposed||this.injector.get(wo)(c)})}get url(){return this.serializeUrl(this.currentUrlTree)}getCurrentNavigation(){return ft(this.navigationTransitions.currentNavigation)}get lastSuccessfulNavigation(){return this.navigationTransitions.lastSuccessfulNavigation}resetConfig(e){this.config=e.map(Tr),this.navigated=!1}ngOnDestroy(){this.dispose()}dispose(){this._events.unsubscribe(),this.navigationTransitions.complete(),this.nonRouterCurrentEntryChangeSubscription&&(this.nonRouterCurrentEntryChangeSubscription.unsubscribe(),this.nonRouterCurrentEntryChangeSubscription=void 0),this.disposed=!0,this.eventsSubscription.unsubscribe()}createUrlTree(e,t={}){let{relativeTo:o,queryParams:a,fragment:s,queryParamsHandling:r,preserveFragment:c}=t,d=c?this.currentUrlTree.fragment:s,p=null;switch(r??this.options.defaultQueryParamsHandling){case"merge":p=b(b({},this.currentUrlTree.queryParams),a);break;case"preserve":p=this.currentUrlTree.queryParams;break;default:p=a||null}p!==null&&(p=this.removeEmptyProps(p));let v;try{let C=o?o.snapshot:this.routerState.snapshot.root;v=td(C)}catch{(typeof e[0]!="string"||e[0][0]!=="/")&&(e=[]),v=this.currentUrlTree.root}return id(v,e,p,d??null)}navigateByUrl(e,t={skipLocationChange:!1}){let o=Yt(e)?e:this.parseUrl(e),a=this.urlHandlingStrategy.merge(o,this.rawUrlTree);return this.scheduleNavigation(a,Bi,null,t)}navigate(e,t={skipLocationChange:!1}){return Fm(e),this.navigateByUrl(this.createUrlTree(e,t),t)}serializeUrl(e){return this.urlSerializer.serialize(e)}parseUrl(e){try{return this.urlSerializer.parse(e)}catch{return this.urlSerializer.parse("/")}}isActive(e,t){let o;if(t===!0?o=b({},Pm):t===!1?o=b({},qm):o=t,Yt(e))return Mc(this.currentUrlTree,e,o);let a=this.parseUrl(e);return Mc(this.currentUrlTree,a,o)}removeEmptyProps(e){return Object.entries(e).reduce((t,[o,a])=>(a!=null&&(t[o]=a),t),{})}scheduleNavigation(e,t,o,a,s){if(this.disposed)return Promise.resolve(!1);let r,c,d;s?(r=s.resolve,c=s.reject,d=s.promise):d=new Promise((v,C)=>{r=v,c=C});let p=this.pendingTasks.add();return la(this,()=>{queueMicrotask(()=>this.pendingTasks.remove(p))}),this.navigationTransitions.handleNavigationRequest({source:t,restoredState:o,currentUrlTree:this.currentUrlTree,currentRawUrl:this.currentUrlTree,rawUrl:e,extras:a,resolve:r,reject:c,promise:d,currentSnapshot:this.routerState.snapshot,currentRouterState:this.routerState}),d.catch(v=>Promise.reject(v))}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();function Fm(i){for(let n=0;n<i.length;n++)if(i[n]==null)throw new U(4008,!1)}var $i=(()=>{class i{router;route;tabIndexAttribute;renderer;el;locationStrategy;reactiveHref=te(null);get href(){return ft(this.reactiveHref)}set href(e){this.reactiveHref.set(e)}target;queryParams;fragment;queryParamsHandling;state;info;relativeTo;isAnchorElement;subscription;onChanges=new S;applicationErrorHandler=l(wo);options=l(Xt,{optional:!0});constructor(e,t,o,a,s,r){this.router=e,this.route=t,this.tabIndexAttribute=o,this.renderer=a,this.el=s,this.locationStrategy=r,this.reactiveHref.set(l(new Vt("href"),{optional:!0}));let c=s.nativeElement.tagName?.toLowerCase();this.isAnchorElement=c==="a"||c==="area"||!!(typeof customElements=="object"&&customElements.get(c)?.observedAttributes?.includes?.("href")),this.isAnchorElement?this.setTabIndexIfNotOnNativeEl("0"):this.subscribeToNavigationEventsIfNecessary()}subscribeToNavigationEventsIfNecessary(){if(this.subscription!==void 0||!this.isAnchorElement)return;let e=this.preserveFragment,t=o=>o==="merge"||o==="preserve";e||=t(this.queryParamsHandling),e||=!this.queryParamsHandling&&!t(this.options?.defaultQueryParamsHandling),e&&(this.subscription=this.router.events.subscribe(o=>{o instanceof Je&&this.updateHref()}))}preserveFragment=!1;skipLocationChange=!1;replaceUrl=!1;setTabIndexIfNotOnNativeEl(e){this.tabIndexAttribute!=null||this.isAnchorElement||this.applyAttributeValue("tabindex",e)}ngOnChanges(e){this.isAnchorElement&&(this.updateHref(),this.subscribeToNavigationEventsIfNecessary()),this.onChanges.next(this)}routerLinkInput=null;set routerLink(e){e==null?(this.routerLinkInput=null,this.setTabIndexIfNotOnNativeEl(null)):(Yt(e)?this.routerLinkInput=e:this.routerLinkInput=Array.isArray(e)?e:[e],this.setTabIndexIfNotOnNativeEl("0"))}onClick(e,t,o,a,s){let r=this.urlTree;if(r===null||this.isAnchorElement&&(e!==0||t||o||a||s||typeof this.target=="string"&&this.target!="_self"))return!0;let c={skipLocationChange:this.skipLocationChange,replaceUrl:this.replaceUrl,state:this.state,info:this.info};return this.router.navigateByUrl(r,c)?.catch(d=>{this.applicationErrorHandler(d)}),!this.isAnchorElement}ngOnDestroy(){this.subscription?.unsubscribe()}updateHref(){let e=this.urlTree;this.reactiveHref.set(e!==null&&this.locationStrategy?this.locationStrategy?.prepareExternalUrl(this.router.serializeUrl(e))??"":null)}applyAttributeValue(e,t){let o=this.renderer,a=this.el.nativeElement;t!==null?o.setAttribute(a,e,t):o.removeAttribute(a,e)}get urlTree(){return this.routerLinkInput===null?null:Yt(this.routerLinkInput)?this.routerLinkInput:this.router.createUrlTree(this.routerLinkInput,{relativeTo:this.relativeTo!==void 0?this.relativeTo:this.route,queryParams:this.queryParams,fragment:this.fragment,queryParamsHandling:this.queryParamsHandling,preserveFragment:this.preserveFragment})}static \u0275fac=function(t){return new(t||i)(He($e),He(It),Rs("tabindex"),He(Ce),He(R),He(lt))};static \u0275dir=_({type:i,selectors:[["","routerLink",""]],hostVars:2,hostBindings:function(t,o){t&1&&he("click",function(s){return o.onClick(s.button,s.ctrlKey,s.shiftKey,s.altKey,s.metaKey)}),t&2&&X("href",o.reactiveHref(),Ql)("target",o.target)},inputs:{target:"target",queryParams:"queryParams",fragment:"fragment",queryParamsHandling:"queryParamsHandling",state:"state",info:"info",relativeTo:"relativeTo",preserveFragment:[2,"preserveFragment","preserveFragment",K],skipLocationChange:[2,"skipLocationChange","skipLocationChange",K],replaceUrl:[2,"replaceUrl","replaceUrl",K],routerLink:"routerLink"},features:[we]})}return i})(),Fr=(()=>{class i{router;element;renderer;cdr;link;links;classes=[];routerEventsSubscription;linkInputChangesSubscription;_isActive=!1;get isActive(){return this._isActive}routerLinkActiveOptions={exact:!1};ariaCurrentWhenActive;isActiveChange=new Z;constructor(e,t,o,a,s){this.router=e,this.element=t,this.renderer=o,this.cdr=a,this.link=s,this.routerEventsSubscription=e.events.subscribe(r=>{r instanceof Je&&this.update()})}ngAfterContentInit(){I(this.links.changes,I(null)).pipe(wn()).subscribe(e=>{this.update(),this.subscribeToEachLinkOnChanges()})}subscribeToEachLinkOnChanges(){this.linkInputChangesSubscription?.unsubscribe();let e=[...this.links.toArray(),this.link].filter(t=>!!t).map(t=>t.onChanges);this.linkInputChangesSubscription=Oe(e).pipe(wn()).subscribe(t=>{this._isActive!==this.isLinkActive(this.router)(t)&&this.update()})}set routerLinkActive(e){let t=Array.isArray(e)?e:e.split(" ");this.classes=t.filter(o=>!!o)}ngOnChanges(e){this.update()}ngOnDestroy(){this.routerEventsSubscription.unsubscribe(),this.linkInputChangesSubscription?.unsubscribe()}update(){!this.links||!this.router.navigated||queueMicrotask(()=>{let e=this.hasActiveLinks();this.classes.forEach(t=>{e?this.renderer.addClass(this.element.nativeElement,t):this.renderer.removeClass(this.element.nativeElement,t)}),e&&this.ariaCurrentWhenActive!==void 0?this.renderer.setAttribute(this.element.nativeElement,"aria-current",this.ariaCurrentWhenActive.toString()):this.renderer.removeAttribute(this.element.nativeElement,"aria-current"),this._isActive!==e&&(this._isActive=e,this.cdr.markForCheck(),this.isActiveChange.emit(e))})}isLinkActive(e){let t=Mm(this.routerLinkActiveOptions)?this.routerLinkActiveOptions:this.routerLinkActiveOptions.exact||!1;return o=>{let a=o.urlTree;return a?e.isActive(a,t):!1}}hasActiveLinks(){let e=this.isLinkActive(this.router);return this.link&&e(this.link)||this.links.some(e)}static \u0275fac=function(t){return new(t||i)(He($e),He(R),He(Ce),He(me),He($i,8))};static \u0275dir=_({type:i,selectors:[["","routerLinkActive",""]],contentQueries:function(t,o,a){if(t&1&&se(a,$i,5),t&2){let s;B(s=j())&&(o.links=s)}},inputs:{routerLinkActiveOptions:"routerLinkActiveOptions",ariaCurrentWhenActive:"ariaCurrentWhenActive",routerLinkActive:"routerLinkActive"},outputs:{isActiveChange:"isActiveChange"},exportAs:["routerLinkActive"],features:[we]})}return i})();function Mm(i){return!!i.paths}var eo=class{};var Cd=(()=>{class i{router;injector;preloadingStrategy;loader;subscription;constructor(e,t,o,a){this.router=e,this.injector=t,this.preloadingStrategy=o,this.loader=a}setUpPreloading(){this.subscription=this.router.events.pipe(ue(e=>e instanceof Je),xt(()=>this.preload())).subscribe(()=>{})}preload(){return this.processRoutes(this.injector,this.router.config)}ngOnDestroy(){this.subscription&&this.subscription.unsubscribe()}processRoutes(e,t){let o=[];for(let a of t){a.providers&&!a._injector&&(a._injector=ko(a.providers,e,`Route: ${a.path}`));let s=a._injector??e,r=a._loadedInjector??s;(a.loadChildren&&!a._loadedRoutes&&a.canLoad===void 0||a.loadComponent&&!a._loadedComponent)&&o.push(this.preloadConfig(s,a)),(a.children||a._loadedRoutes)&&o.push(this.processRoutes(r,a.children??a._loadedRoutes))}return Oe(o).pipe(wn())}preloadConfig(e,t){return this.preloadingStrategy.preload(t,()=>{let o;t.loadChildren&&t.canLoad===void 0?o=this.loader.loadChildren(e,t):o=I(null);let a=o.pipe(Ge(s=>s===null?I(void 0):(t._loadedRoutes=s.routes,t._loadedInjector=s.injector,this.processRoutes(s.injector??e,s.routes))));if(t.loadComponent&&!t._loadedComponent){let s=this.loader.loadComponent(e,t);return Oe([a,s]).pipe(wn())}else return a})}static \u0275fac=function(t){return new(t||i)(O($e),O(ze),O(eo),O(aa))};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),kd=new A(""),Nm=(()=>{class i{urlSerializer;transitions;viewportScroller;zone;options;routerEventsSubscription;scrollEventsSubscription;lastId=0;lastSource=Bi;restoredId=0;store={};constructor(e,t,o,a,s={}){this.urlSerializer=e,this.transitions=t,this.viewportScroller=o,this.zone=a,this.options=s,s.scrollPositionRestoration||="disabled",s.anchorScrolling||="disabled"}init(){this.options.scrollPositionRestoration!=="disabled"&&this.viewportScroller.setHistoryScrollRestoration("manual"),this.routerEventsSubscription=this.createScrollEvents(),this.scrollEventsSubscription=this.consumeScrollEvents()}createScrollEvents(){return this.transitions.events.subscribe(e=>{e instanceof Zt?(this.store[this.lastId]=this.viewportScroller.getScrollPosition(),this.lastSource=e.navigationTrigger,this.restoredId=e.restoredState?e.restoredState.navigationId:0):e instanceof Je?(this.lastId=e.id,this.scheduleScrollEvent(e,this.urlSerializer.parse(e.urlAfterRedirects).fragment)):e instanceof At&&e.code===Vi.IgnoredSameUrlNavigation&&(this.lastSource=void 0,this.restoredId=0,this.scheduleScrollEvent(e,this.urlSerializer.parse(e.url).fragment))})}consumeScrollEvents(){return this.transitions.events.subscribe(e=>{e instanceof Ui&&(e.position?this.options.scrollPositionRestoration==="top"?this.viewportScroller.scrollToPosition([0,0]):this.options.scrollPositionRestoration==="enabled"&&this.viewportScroller.scrollToPosition(e.position):e.anchor&&this.options.anchorScrolling==="enabled"?this.viewportScroller.scrollToAnchor(e.anchor):this.options.scrollPositionRestoration!=="disabled"&&this.viewportScroller.scrollToPosition([0,0]))})}scheduleScrollEvent(e,t){this.zone.runOutsideAngular(async()=>{await new Promise(o=>{setTimeout(o),typeof requestAnimationFrame<"u"&&requestAnimationFrame(o)}),this.zone.run(()=>{this.transitions.events.next(new Ui(e,this.lastSource==="popstate"?this.store[this.restoredId]:null,t))})})}ngOnDestroy(){this.routerEventsSubscription?.unsubscribe(),this.scrollEventsSubscription?.unsubscribe()}static \u0275fac=function(t){Pi()};static \u0275prov=g({token:i,factory:i.\u0275fac})}return i})();function Mr(i,...n){return Ri([{provide:fi,multi:!0,useValue:i},[],{provide:It,useFactory:Dd,deps:[$e]},{provide:Ms,multi:!0,useFactory:Ed},n.map(e=>e.\u0275providers)])}function Dd(i){return i.routerState.root}function to(i,n){return{\u0275kind:i,\u0275providers:n}}function Ed(){let i=l(V);return n=>{let e=i.get(pt);if(n!==e.components[0])return;let t=i.get($e),o=i.get(xd);i.get(Nr)===1&&t.initialNavigation(),i.get(Sd,null,{optional:!0})?.setUpPreloading(),i.get(kd,null,{optional:!0})?.init(),t.resetRootComponentType(e.componentTypes[0]),o.closed||(o.next(),o.complete(),o.unsubscribe())}}var xd=new A("",{factory:()=>new S}),Nr=new A("",{providedIn:"root",factory:()=>1});function Td(){let i=[{provide:Ss,useValue:!0},{provide:Nr,useValue:0},Fs(()=>{let n=l(V);return n.get(Ks,Promise.resolve()).then(()=>new Promise(t=>{let o=n.get($e),a=n.get(xd);la(o,()=>{t(!0)}),n.get(ra).afterPreactivation=()=>(t(!0),a.closed?I(void 0):a),o.initialNavigation()}))})];return to(2,i)}function Rd(){let i=[Fs(()=>{l($e).setUpLocationChangeListener()}),{provide:Nr,useValue:2}];return to(3,i)}var Sd=new A("");function Od(i){return to(0,[{provide:Sd,useExisting:Cd},{provide:eo,useExisting:i}])}function Pd(){return to(8,[Er,{provide:$n,useExisting:Er}])}function qd(i){Tn("NgRouterViewTransitions");let n=[{provide:Sr,useValue:Id},{provide:Or,useValue:b({skipNextTransition:!!i?.skipInitialTransition},i)}];return to(9,n)}var Fd=[yt,{provide:hi,useClass:Ht},$e,pi,{provide:It,useFactory:Dd,deps:[$e]},aa,[]],io=(()=>{class i{constructor(){}static forRoot(e,t){return{ngModule:i,providers:[Fd,[],{provide:fi,multi:!0,useValue:e},[],t?.errorHandler?{provide:Pr,useValue:t.errorHandler}:[],{provide:Xt,useValue:t||{}},t?.useHash?Gm():Km(),Lm(),t?.preloadingStrategy?Od(t.preloadingStrategy).\u0275providers:[],t?.initialNavigation?zm(t):[],t?.bindToComponentInputs?Pd().\u0275providers:[],t?.enableViewTransitions?qd().\u0275providers:[],Bm()]}}static forChild(e){return{ngModule:i,providers:[{provide:fi,multi:!0,useValue:e}]}}static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({})}return i})();function Lm(){return{provide:kd,useFactory:()=>{let i=l(bc),n=l(F),e=l(Xt),t=l(ra),o=l(hi);return e.scrollOffset&&i.setOffset(e.scrollOffset),new Nm(o,t,i,n,e)}}}function Gm(){return{provide:lt,useClass:zs}}function Km(){return{provide:lt,useClass:To}}function zm(i){return[i.initialNavigation==="disabled"?Rd().\u0275providers:[],i.initialNavigation==="enabledBlocking"?Td().\u0275providers:[]]}var qr=new A("");function Bm(){return[{provide:qr,useFactory:Ed},{provide:Ms,multi:!0,useExisting:qr}]}var Vm="@",Wm=(()=>{class i{doc;delegate;zone;animationType;moduleImpl;_rendererFactoryPromise=null;scheduler=null;injector=l(V);loadingSchedulerFn=l(Um,{optional:!0});_engine;constructor(e,t,o,a,s){this.doc=e,this.delegate=t,this.zone=o,this.animationType=a,this.moduleImpl=s}ngOnDestroy(){this._engine?.flush()}loadImpl(){let e=()=>this.moduleImpl??import("./chunk-OZE6D5ZO.js").then(o=>o),t;return this.loadingSchedulerFn?t=this.loadingSchedulerFn(e):t=e(),t.catch(o=>{throw new U(5300,!1)}).then(({\u0275createEngine:o,\u0275AnimationRendererFactory:a})=>{this._engine=o(this.animationType,this.doc);let s=new a(this.delegate,this._engine,this.zone);return this.delegate=s,s})}createRenderer(e,t){let o=this.delegate.createRenderer(e,t);if(o.\u0275type===0)return o;typeof o.throwOnSyntheticProps=="boolean"&&(o.throwOnSyntheticProps=!1);let a=new Lr(o);return t?.data?.animation&&!this._rendererFactoryPromise&&(this._rendererFactoryPromise=this.loadImpl()),this._rendererFactoryPromise?.then(s=>{let r=s.createRenderer(e,t);a.use(r),this.scheduler??=this.injector.get(Bl,null,{optional:!0}),this.scheduler?.notify(10)}).catch(s=>{a.use(o)}),a}begin(){this.delegate.begin?.()}end(){this.delegate.end?.()}whenRenderingDone(){return this.delegate.whenRenderingDone?.()??Promise.resolve()}componentReplaced(e){this._engine?.flush(),this.delegate.componentReplaced?.(e)}static \u0275fac=function(t){Pi()};static \u0275prov=g({token:i,factory:i.\u0275fac})}return i})(),Lr=class{delegate;replay=[];\u0275type=1;constructor(n){this.delegate=n}use(n){if(this.delegate=n,this.replay!==null){for(let e of this.replay)e(n);this.replay=null}}get data(){return this.delegate.data}destroy(){this.replay=null,this.delegate.destroy()}createElement(n,e){return this.delegate.createElement(n,e)}createComment(n){return this.delegate.createComment(n)}createText(n){return this.delegate.createText(n)}get destroyNode(){return this.delegate.destroyNode}appendChild(n,e){this.delegate.appendChild(n,e)}insertBefore(n,e,t,o){this.delegate.insertBefore(n,e,t,o)}removeChild(n,e,t){this.delegate.removeChild(n,e,t)}selectRootElement(n,e){return this.delegate.selectRootElement(n,e)}parentNode(n){return this.delegate.parentNode(n)}nextSibling(n){return this.delegate.nextSibling(n)}setAttribute(n,e,t,o){this.delegate.setAttribute(n,e,t,o)}removeAttribute(n,e,t){this.delegate.removeAttribute(n,e,t)}addClass(n,e){this.delegate.addClass(n,e)}removeClass(n,e){this.delegate.removeClass(n,e)}setStyle(n,e,t,o){this.delegate.setStyle(n,e,t,o)}removeStyle(n,e,t){this.delegate.removeStyle(n,e,t)}setProperty(n,e,t){this.shouldReplay(e)&&this.replay.push(o=>o.setProperty(n,e,t)),this.delegate.setProperty(n,e,t)}setValue(n,e){this.delegate.setValue(n,e)}listen(n,e,t,o){return this.shouldReplay(e)&&this.replay.push(a=>a.listen(n,e,t,o)),this.delegate.listen(n,e,t,o)}shouldReplay(n){return this.replay!==null&&n.startsWith(Vm)}},Um=new A("");function Md(i="animations"){return Tn("NgAsyncAnimations"),Ri([{provide:qe,useFactory:(n,e,t)=>new Wm(n,e,t,i),deps:[D,Nn,F]},{provide:Si,useValue:i==="noop"?"NoopAnimations":"BrowserAnimations"}])}function yi(i){return i.buttons===0||i.detail===0}function gi(i){let n=i.touches&&i.touches[0]||i.changedTouches&&i.changedTouches[0];return!!n&&n.identifier===-1&&(n.radiusX==null||n.radiusX===1)&&(n.radiusY==null||n.radiusY===1)}var Gr;function Nd(){if(Gr==null){let i=typeof document<"u"?document.head:null;Gr=!!(i&&(i.createShadowRoot||i.attachShadow))}return Gr}function Kr(i){if(Nd()){let n=i.getRootNode?i.getRootNode():null;if(typeof ShadowRoot<"u"&&ShadowRoot&&n instanceof ShadowRoot)return n}return null}function Ve(i){return i.composedPath?i.composedPath()[0]:i.target}var zr;try{zr=typeof Intl<"u"&&Intl.v8BreakIterator}catch{zr=!1}var oe=(()=>{class i{_platformId=l(ai);isBrowser=this._platformId?gc(this._platformId):typeof document=="object"&&!!document;EDGE=this.isBrowser&&/(edge)/i.test(navigator.userAgent);TRIDENT=this.isBrowser&&/(msie|trident)/i.test(navigator.userAgent);BLINK=this.isBrowser&&!!(window.chrome||zr)&&typeof CSS<"u"&&!this.EDGE&&!this.TRIDENT;WEBKIT=this.isBrowser&&/AppleWebKit/i.test(navigator.userAgent)&&!this.BLINK&&!this.EDGE&&!this.TRIDENT;IOS=this.isBrowser&&/iPad|iPhone|iPod/.test(navigator.userAgent)&&!("MSStream"in window);FIREFOX=this.isBrowser&&/(firefox|minefield)/i.test(navigator.userAgent);ANDROID=this.isBrowser&&/android/i.test(navigator.userAgent)&&!this.TRIDENT;SAFARI=this.isBrowser&&/safari/i.test(navigator.userAgent)&&this.WEBKIT;constructor(){}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();var no;function Ld(){if(no==null&&typeof window<"u")try{window.addEventListener("test",null,Object.defineProperty({},"passive",{get:()=>no=!0}))}finally{no=no||!1}return no}function Qi(i){return Ld()?i:!!i.capture}function Ft(i,n=0){return Gd(i)?Number(i):arguments.length===2?n:0}function Gd(i){return!isNaN(parseFloat(i))&&!isNaN(Number(i))}function nt(i){return i instanceof R?i.nativeElement:i}var Kd=new A("cdk-input-modality-detector-options"),zd={ignoreKeys:[18,17,224,91,16]},Bd=650,Br={passive:!0,capture:!0},jd=(()=>{class i{_platform=l(oe);_listenerCleanups;modalityDetected;modalityChanged;get mostRecentModality(){return this._modality.value}_mostRecentTarget=null;_modality=new Ee(null);_options;_lastTouchMs=0;_onKeydown=e=>{this._options?.ignoreKeys?.some(t=>t===e.keyCode)||(this._modality.next("keyboard"),this._mostRecentTarget=Ve(e))};_onMousedown=e=>{Date.now()-this._lastTouchMs<Bd||(this._modality.next(yi(e)?"keyboard":"mouse"),this._mostRecentTarget=Ve(e))};_onTouchstart=e=>{if(gi(e)){this._modality.next("keyboard");return}this._lastTouchMs=Date.now(),this._modality.next("touch"),this._mostRecentTarget=Ve(e)};constructor(){let e=l(F),t=l(D),o=l(Kd,{optional:!0});if(this._options=b(b({},zd),o),this.modalityDetected=this._modality.pipe(Io(1)),this.modalityChanged=this.modalityDetected.pipe(Es()),this._platform.isBrowser){let a=l(qe).createRenderer(null,null);this._listenerCleanups=e.runOutsideAngular(()=>[a.listen(t,"keydown",this._onKeydown,Br),a.listen(t,"mousedown",this._onMousedown,Br),a.listen(t,"touchstart",this._onTouchstart,Br)])}}ngOnDestroy(){this._modality.complete(),this._listenerCleanups?.forEach(e=>e())}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),oo=(function(i){return i[i.IMMEDIATE=0]="IMMEDIATE",i[i.EVENTUAL=1]="EVENTUAL",i})(oo||{}),Vd=new A("cdk-focus-monitor-default-options"),ca=Qi({passive:!0,capture:!0}),Jt=(()=>{class i{_ngZone=l(F);_platform=l(oe);_inputModalityDetector=l(jd);_origin=null;_lastFocusOrigin;_windowFocused=!1;_windowFocusTimeoutId;_originTimeoutId;_originFromTouchInteraction=!1;_elementInfo=new Map;_monitoredElementCount=0;_rootNodeFocusListenerCount=new Map;_detectionMode;_windowFocusListener=()=>{this._windowFocused=!0,this._windowFocusTimeoutId=setTimeout(()=>this._windowFocused=!1)};_document=l(D);_stopInputModalityDetector=new S;constructor(){let e=l(Vd,{optional:!0});this._detectionMode=e?.detectionMode||oo.IMMEDIATE}_rootNodeFocusAndBlurListener=e=>{let t=Ve(e);for(let o=t;o;o=o.parentElement)e.type==="focus"?this._onFocus(e,o):this._onBlur(e,o)};monitor(e,t=!1){let o=nt(e);if(!this._platform.isBrowser||o.nodeType!==1)return I();let a=Kr(o)||this._document,s=this._elementInfo.get(o);if(s)return t&&(s.checkChildren=!0),s.subject;let r={checkChildren:t,subject:new S,rootNode:a};return this._elementInfo.set(o,r),this._registerGlobalListeners(r),r.subject}stopMonitoring(e){let t=nt(e),o=this._elementInfo.get(t);o&&(o.subject.complete(),this._setClasses(t),this._elementInfo.delete(t),this._removeGlobalListeners(o))}focusVia(e,t,o){let a=nt(e),s=this._document.activeElement;a===s?this._getClosestElementsInfo(a).forEach(([r,c])=>this._originChanged(r,t,c)):(this._setOrigin(t),typeof a.focus=="function"&&a.focus(o))}ngOnDestroy(){this._elementInfo.forEach((e,t)=>this.stopMonitoring(t))}_getWindow(){return this._document.defaultView||window}_getFocusOrigin(e){return this._origin?this._originFromTouchInteraction?this._shouldBeAttributedToTouch(e)?"touch":"program":this._origin:this._windowFocused&&this._lastFocusOrigin?this._lastFocusOrigin:e&&this._isLastInteractionFromInputLabel(e)?"mouse":"program"}_shouldBeAttributedToTouch(e){return this._detectionMode===oo.EVENTUAL||!!e?.contains(this._inputModalityDetector._mostRecentTarget)}_setClasses(e,t){e.classList.toggle("cdk-focused",!!t),e.classList.toggle("cdk-touch-focused",t==="touch"),e.classList.toggle("cdk-keyboard-focused",t==="keyboard"),e.classList.toggle("cdk-mouse-focused",t==="mouse"),e.classList.toggle("cdk-program-focused",t==="program")}_setOrigin(e,t=!1){this._ngZone.runOutsideAngular(()=>{if(this._origin=e,this._originFromTouchInteraction=e==="touch"&&t,this._detectionMode===oo.IMMEDIATE){clearTimeout(this._originTimeoutId);let o=this._originFromTouchInteraction?Bd:1;this._originTimeoutId=setTimeout(()=>this._origin=null,o)}})}_onFocus(e,t){let o=this._elementInfo.get(t),a=Ve(e);!o||!o.checkChildren&&t!==a||this._originChanged(t,this._getFocusOrigin(a),o)}_onBlur(e,t){let o=this._elementInfo.get(t);!o||o.checkChildren&&e.relatedTarget instanceof Node&&t.contains(e.relatedTarget)||(this._setClasses(t),this._emitOrigin(o,null))}_emitOrigin(e,t){e.subject.observers.length&&this._ngZone.run(()=>e.subject.next(t))}_registerGlobalListeners(e){if(!this._platform.isBrowser)return;let t=e.rootNode,o=this._rootNodeFocusListenerCount.get(t)||0;o||this._ngZone.runOutsideAngular(()=>{t.addEventListener("focus",this._rootNodeFocusAndBlurListener,ca),t.addEventListener("blur",this._rootNodeFocusAndBlurListener,ca)}),this._rootNodeFocusListenerCount.set(t,o+1),++this._monitoredElementCount===1&&(this._ngZone.runOutsideAngular(()=>{this._getWindow().addEventListener("focus",this._windowFocusListener)}),this._inputModalityDetector.modalityDetected.pipe(pe(this._stopInputModalityDetector)).subscribe(a=>{this._setOrigin(a,!0)}))}_removeGlobalListeners(e){let t=e.rootNode;if(this._rootNodeFocusListenerCount.has(t)){let o=this._rootNodeFocusListenerCount.get(t);o>1?this._rootNodeFocusListenerCount.set(t,o-1):(t.removeEventListener("focus",this._rootNodeFocusAndBlurListener,ca),t.removeEventListener("blur",this._rootNodeFocusAndBlurListener,ca),this._rootNodeFocusListenerCount.delete(t))}--this._monitoredElementCount||(this._getWindow().removeEventListener("focus",this._windowFocusListener),this._stopInputModalityDetector.next(),clearTimeout(this._windowFocusTimeoutId),clearTimeout(this._originTimeoutId))}_originChanged(e,t,o){this._setClasses(e,t),this._emitOrigin(o,t),this._lastFocusOrigin=t}_getClosestElementsInfo(e){let t=[];return this._elementInfo.forEach((o,a)=>{(a===e||o.checkChildren&&a.contains(e))&&t.push([a,o])}),t}_isLastInteractionFromInputLabel(e){let{_mostRecentTarget:t,mostRecentModality:o}=this._inputModalityDetector;if(o!=="mouse"||!t||t===e||e.nodeName!=="INPUT"&&e.nodeName!=="TEXTAREA"||e.disabled)return!1;let a=e.labels;if(a){for(let s=0;s<a.length;s++)if(a[s].contains(t))return!0}return!1}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();var da=new WeakMap,Te=(()=>{class i{_appRef;_injector=l(V);_environmentInjector=l(ze);load(e){let t=this._appRef=this._appRef||this._injector.get(pt),o=da.get(t);o||(o={loaders:new Set,refs:[]},da.set(t,o),t.onDestroy(()=>{da.get(t)?.refs.forEach(a=>a.destroy()),da.delete(t)})),o.loaders.has(e)||(o.loaders.add(e),o.refs.push(Do(e,{environmentInjector:this._environmentInjector})))}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();var Wd=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["ng-component"]],exportAs:["cdkVisuallyHidden"],decls:0,vars:0,template:function(t,o){},styles:[`.cdk-visually-hidden{border:0;clip:rect(0 0 0 0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px;white-space:nowrap;outline:0;-webkit-appearance:none;-moz-appearance:none;left:0}[dir=rtl] .cdk-visually-hidden{left:auto;right:0}
`],encapsulation:2,changeDetection:0})}return i})();function en(i){return Array.isArray(i)?i:[i]}var Ud=new Set,bi,ua=(()=>{class i{_platform=l(oe);_nonce=l(En,{optional:!0});_matchMedia;constructor(){this._matchMedia=this._platform.isBrowser&&window.matchMedia?window.matchMedia.bind(window):Ym}matchMedia(e){return(this._platform.WEBKIT||this._platform.BLINK)&&Hm(e,this._nonce),this._matchMedia(e)}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();function Hm(i,n){if(!Ud.has(i))try{bi||(bi=document.createElement("style"),n&&bi.setAttribute("nonce",n),bi.setAttribute("type","text/css"),document.head.appendChild(bi)),bi.sheet&&(bi.sheet.insertRule(`@media ${i} {body{ }}`,0),Ud.add(i))}catch(e){console.error(e)}}function Ym(i){return{matches:i==="all"||i==="",media:i,addListener:()=>{},removeListener:()=>{}}}var jr=(()=>{class i{_mediaMatcher=l(ua);_zone=l(F);_queries=new Map;_destroySubject=new S;constructor(){}ngOnDestroy(){this._destroySubject.next(),this._destroySubject.complete()}isMatched(e){return Hd(en(e)).some(o=>this._registerQuery(o).mql.matches)}observe(e){let o=Hd(en(e)).map(s=>this._registerQuery(s).observable),a=xi(o);return a=vo(a.pipe(Ke(1)),a.pipe(Io(1),Lt(0))),a.pipe(q(s=>{let r={matches:!1,breakpoints:{}};return s.forEach(({matches:c,query:d})=>{r.matches=r.matches||c,r.breakpoints[d]=c}),r}))}_registerQuery(e){if(this._queries.has(e))return this._queries.get(e);let t=this._mediaMatcher.matchMedia(e),a={observable:new kt(s=>{let r=c=>this._zone.run(()=>s.next(c));return t.addListener(r),()=>{t.removeListener(r)}}).pipe(tt(t),q(({matches:s})=>({query:e,matches:s})),pe(this._destroySubject)),mql:t};return this._queries.set(e,a),a}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();function Hd(i){return i.map(n=>n.split(",")).reduce((n,e)=>n.concat(e)).map(n=>n.trim())}function Zm(i){if(i.type==="characterData"&&i.target instanceof Comment)return!0;if(i.type==="childList"){for(let n=0;n<i.addedNodes.length;n++)if(!(i.addedNodes[n]instanceof Comment))return!1;for(let n=0;n<i.removedNodes.length;n++)if(!(i.removedNodes[n]instanceof Comment))return!1;return!0}return!1}var Yd=(()=>{class i{create(e){return typeof MutationObserver>"u"?null:new MutationObserver(e)}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),Xm=(()=>{class i{_mutationObserverFactory=l(Yd);_observedElements=new Map;_ngZone=l(F);constructor(){}ngOnDestroy(){this._observedElements.forEach((e,t)=>this._cleanupObserver(t))}observe(e){let t=nt(e);return new kt(o=>{let s=this._observeElement(t).pipe(q(r=>r.filter(c=>!Zm(c))),ue(r=>!!r.length)).subscribe(r=>{this._ngZone.run(()=>{o.next(r)})});return()=>{s.unsubscribe(),this._unobserveElement(t)}})}_observeElement(e){return this._ngZone.runOutsideAngular(()=>{if(this._observedElements.has(e))this._observedElements.get(e).count++;else{let t=new S,o=this._mutationObserverFactory.create(a=>t.next(a));o&&o.observe(e,{characterData:!0,childList:!0,subtree:!0}),this._observedElements.set(e,{observer:o,stream:t,count:1})}return this._observedElements.get(e).stream})}_unobserveElement(e){this._observedElements.has(e)&&(this._observedElements.get(e).count--,this._observedElements.get(e).count||this._cleanupObserver(e))}_cleanupObserver(e){if(this._observedElements.has(e)){let{observer:t,stream:o}=this._observedElements.get(e);t&&t.disconnect(),o.complete(),this._observedElements.delete(e)}}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),Zd=(()=>{class i{_contentObserver=l(Xm);_elementRef=l(R);event=new Z;get disabled(){return this._disabled}set disabled(e){this._disabled=e,this._disabled?this._unsubscribe():this._subscribe()}_disabled=!1;get debounce(){return this._debounce}set debounce(e){this._debounce=Ft(e),this._subscribe()}_debounce;_currentSubscription=null;constructor(){}ngAfterContentInit(){!this._currentSubscription&&!this.disabled&&this._subscribe()}ngOnDestroy(){this._unsubscribe()}_subscribe(){this._unsubscribe();let e=this._contentObserver.observe(this._elementRef);this._currentSubscription=(this.debounce?e.pipe(Lt(this.debounce)):e).subscribe(this.event)}_unsubscribe(){this._currentSubscription?.unsubscribe()}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","cdkObserveContent",""]],inputs:{disabled:[2,"cdkObserveContentDisabled","disabled",K],debounce:"debounce"},outputs:{event:"cdkObserveContent"},exportAs:["cdkObserveContent"]})}return i})(),Xd=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({providers:[Yd]})}return i})();var pa=(()=>{class i{_platform=l(oe);constructor(){}isDisabled(e){return e.hasAttribute("disabled")}isVisible(e){return $m(e)&&getComputedStyle(e).visibility==="visible"}isTabbable(e){if(!this._platform.isBrowser)return!1;let t=Jm(rf(e));if(t&&(Jd(t)===-1||!this.isVisible(t)))return!1;let o=e.nodeName.toLowerCase(),a=Jd(e);return e.hasAttribute("contenteditable")?a!==-1:o==="iframe"||o==="object"||this._platform.WEBKIT&&this._platform.IOS&&!af(e)?!1:o==="audio"?e.hasAttribute("controls")?a!==-1:!1:o==="video"?a===-1?!1:a!==null?!0:this._platform.FIREFOX||e.hasAttribute("controls"):e.tabIndex>=0}isFocusable(e,t){return sf(e)&&!this.isDisabled(e)&&(t?.ignoreVisibility||this.isVisible(e))}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();function Jm(i){try{return i.frameElement}catch{return null}}function $m(i){return!!(i.offsetWidth||i.offsetHeight||typeof i.getClientRects=="function"&&i.getClientRects().length)}function Qm(i){let n=i.nodeName.toLowerCase();return n==="input"||n==="select"||n==="button"||n==="textarea"}function ef(i){return nf(i)&&i.type=="hidden"}function tf(i){return of(i)&&i.hasAttribute("href")}function nf(i){return i.nodeName.toLowerCase()=="input"}function of(i){return i.nodeName.toLowerCase()=="a"}function eu(i){if(!i.hasAttribute("tabindex")||i.tabIndex===void 0)return!1;let n=i.getAttribute("tabindex");return!!(n&&!isNaN(parseInt(n,10)))}function Jd(i){if(!eu(i))return null;let n=parseInt(i.getAttribute("tabindex")||"",10);return isNaN(n)?-1:n}function af(i){let n=i.nodeName.toLowerCase(),e=n==="input"&&i.type;return e==="text"||e==="password"||n==="select"||n==="textarea"}function sf(i){return ef(i)?!1:Qm(i)||tf(i)||i.hasAttribute("contenteditable")||eu(i)}function rf(i){return i.ownerDocument&&i.ownerDocument.defaultView||window}var ha=class{_element;_checker;_ngZone;_document;_injector;_startAnchor;_endAnchor;_hasAttached=!1;startAnchorListener=()=>this.focusLastTabbableElement();endAnchorListener=()=>this.focusFirstTabbableElement();get enabled(){return this._enabled}set enabled(n){this._enabled=n,this._startAnchor&&this._endAnchor&&(this._toggleAnchorTabIndex(n,this._startAnchor),this._toggleAnchorTabIndex(n,this._endAnchor))}_enabled=!0;constructor(n,e,t,o,a=!1,s){this._element=n,this._checker=e,this._ngZone=t,this._document=o,this._injector=s,a||this.attachAnchors()}destroy(){let n=this._startAnchor,e=this._endAnchor;n&&(n.removeEventListener("focus",this.startAnchorListener),n.remove()),e&&(e.removeEventListener("focus",this.endAnchorListener),e.remove()),this._startAnchor=this._endAnchor=null,this._hasAttached=!1}attachAnchors(){return this._hasAttached?!0:(this._ngZone.runOutsideAngular(()=>{this._startAnchor||(this._startAnchor=this._createAnchor(),this._startAnchor.addEventListener("focus",this.startAnchorListener)),this._endAnchor||(this._endAnchor=this._createAnchor(),this._endAnchor.addEventListener("focus",this.endAnchorListener))}),this._element.parentNode&&(this._element.parentNode.insertBefore(this._startAnchor,this._element),this._element.parentNode.insertBefore(this._endAnchor,this._element.nextSibling),this._hasAttached=!0),this._hasAttached)}focusInitialElementWhenReady(n){return new Promise(e=>{this._executeOnStable(()=>e(this.focusInitialElement(n)))})}focusFirstTabbableElementWhenReady(n){return new Promise(e=>{this._executeOnStable(()=>e(this.focusFirstTabbableElement(n)))})}focusLastTabbableElementWhenReady(n){return new Promise(e=>{this._executeOnStable(()=>e(this.focusLastTabbableElement(n)))})}_getRegionBoundary(n){let e=this._element.querySelectorAll(`[cdk-focus-region-${n}], [cdkFocusRegion${n}], [cdk-focus-${n}]`);return n=="start"?e.length?e[0]:this._getFirstTabbableElement(this._element):e.length?e[e.length-1]:this._getLastTabbableElement(this._element)}focusInitialElement(n){let e=this._element.querySelector("[cdk-focus-initial], [cdkFocusInitial]");if(e){if(!this._checker.isFocusable(e)){let t=this._getFirstTabbableElement(e);return t?.focus(n),!!t}return e.focus(n),!0}return this.focusFirstTabbableElement(n)}focusFirstTabbableElement(n){let e=this._getRegionBoundary("start");return e&&e.focus(n),!!e}focusLastTabbableElement(n){let e=this._getRegionBoundary("end");return e&&e.focus(n),!!e}hasAttached(){return this._hasAttached}_getFirstTabbableElement(n){if(this._checker.isFocusable(n)&&this._checker.isTabbable(n))return n;let e=n.children;for(let t=0;t<e.length;t++){let o=e[t].nodeType===this._document.ELEMENT_NODE?this._getFirstTabbableElement(e[t]):null;if(o)return o}return null}_getLastTabbableElement(n){if(this._checker.isFocusable(n)&&this._checker.isTabbable(n))return n;let e=n.children;for(let t=e.length-1;t>=0;t--){let o=e[t].nodeType===this._document.ELEMENT_NODE?this._getLastTabbableElement(e[t]):null;if(o)return o}return null}_createAnchor(){let n=this._document.createElement("div");return this._toggleAnchorTabIndex(this._enabled,n),n.classList.add("cdk-visually-hidden"),n.classList.add("cdk-focus-trap-anchor"),n.setAttribute("aria-hidden","true"),n}_toggleAnchorTabIndex(n,e){n?e.setAttribute("tabindex","0"):e.removeAttribute("tabindex")}toggleAnchors(n){this._startAnchor&&this._endAnchor&&(this._toggleAnchorTabIndex(n,this._startAnchor),this._toggleAnchorTabIndex(n,this._endAnchor))}_executeOnStable(n){this._injector?ve(n,{injector:this._injector}):setTimeout(n)}},Wr=(()=>{class i{_checker=l(pa);_ngZone=l(F);_document=l(D);_injector=l(V);constructor(){l(Te).load(Wd)}create(e,t=!1){return new ha(e,this._checker,this._ngZone,this._document,t,this._injector)}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();var $t=(function(i){return i[i.NONE=0]="NONE",i[i.BLACK_ON_WHITE=1]="BLACK_ON_WHITE",i[i.WHITE_ON_BLACK=2]="WHITE_ON_BLACK",i})($t||{}),$d="cdk-high-contrast-black-on-white",Qd="cdk-high-contrast-white-on-black",Vr="cdk-high-contrast-active",Ur=(()=>{class i{_platform=l(oe);_hasCheckedHighContrastMode;_document=l(D);_breakpointSubscription;constructor(){this._breakpointSubscription=l(jr).observe("(forced-colors: active)").subscribe(()=>{this._hasCheckedHighContrastMode&&(this._hasCheckedHighContrastMode=!1,this._applyBodyHighContrastModeCssClasses())})}getHighContrastMode(){if(!this._platform.isBrowser)return $t.NONE;let e=this._document.createElement("div");e.style.backgroundColor="rgb(1,2,3)",e.style.position="absolute",this._document.body.appendChild(e);let t=this._document.defaultView||window,o=t&&t.getComputedStyle?t.getComputedStyle(e):null,a=(o&&o.backgroundColor||"").replace(/ /g,"");switch(e.remove(),a){case"rgb(0,0,0)":case"rgb(45,50,54)":case"rgb(32,32,32)":return $t.WHITE_ON_BLACK;case"rgb(255,255,255)":case"rgb(255,250,239)":return $t.BLACK_ON_WHITE}return $t.NONE}ngOnDestroy(){this._breakpointSubscription.unsubscribe()}_applyBodyHighContrastModeCssClasses(){if(!this._hasCheckedHighContrastMode&&this._platform.isBrowser&&this._document.body){let e=this._document.body.classList;e.remove(Vr,$d,Qd),this._hasCheckedHighContrastMode=!0;let t=this.getHighContrastMode();t===$t.BLACK_ON_WHITE?e.add(Vr,$d):t===$t.WHITE_ON_BLACK&&e.add(Vr,Qd)}}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();var Hr={},vi=(()=>{class i{_appId=l(Dn);getId(e){return this._appId!=="ng"&&(e+=this._appId),Hr.hasOwnProperty(e)||(Hr[e]=0),`${e}${Hr[e]++}`}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();var lf=200,ma=class{_letterKeyStream=new S;_items=[];_selectedItemIndex=-1;_pressedLetters=[];_skipPredicateFn;_selectedItem=new S;selectedItem=this._selectedItem;constructor(n,e){let t=typeof e?.debounceInterval=="number"?e.debounceInterval:lf;e?.skipPredicate&&(this._skipPredicateFn=e.skipPredicate),this.setItems(n),this._setupKeyHandler(t)}destroy(){this._pressedLetters=[],this._letterKeyStream.complete(),this._selectedItem.complete()}setCurrentSelectedItemIndex(n){this._selectedItemIndex=n}setItems(n){this._items=n}handleKey(n){let e=n.keyCode;n.key&&n.key.length===1?this._letterKeyStream.next(n.key.toLocaleUpperCase()):(e>=65&&e<=90||e>=48&&e<=57)&&this._letterKeyStream.next(String.fromCharCode(e))}isTyping(){return this._pressedLetters.length>0}reset(){this._pressedLetters=[]}_setupKeyHandler(n){this._letterKeyStream.pipe(fe(e=>this._pressedLetters.push(e)),Lt(n),ue(()=>this._pressedLetters.length>0),q(()=>this._pressedLetters.join("").toLocaleUpperCase())).subscribe(e=>{for(let t=1;t<this._items.length+1;t++){let o=(this._selectedItemIndex+t)%this._items.length,a=this._items[o];if(!this._skipPredicateFn?.(a)&&a.getLabel?.().toLocaleUpperCase().trim().indexOf(e)===0){this._selectedItem.next(a);break}}this._pressedLetters=[]})}};function tn(i,...n){return n.length?n.some(e=>i[e]):i.altKey||i.shiftKey||i.ctrlKey||i.metaKey}var fa=class{_items;_activeItemIndex=te(-1);_activeItem=te(null);_wrap=!1;_typeaheadSubscription=De.EMPTY;_itemChangesSubscription;_vertical=!0;_horizontal;_allowedModifierKeys=[];_homeAndEnd=!1;_pageUpAndDown={enabled:!1,delta:10};_effectRef;_typeahead;_skipPredicateFn=n=>n.disabled;constructor(n,e){this._items=n,n instanceof zt?this._itemChangesSubscription=n.changes.subscribe(t=>this._itemsChanged(t.toArray())):Ts(n)&&(this._effectRef=Ls(()=>this._itemsChanged(n()),{injector:e}))}tabOut=new S;change=new S;skipPredicate(n){return this._skipPredicateFn=n,this}withWrap(n=!0){return this._wrap=n,this}withVerticalOrientation(n=!0){return this._vertical=n,this}withHorizontalOrientation(n){return this._horizontal=n,this}withAllowedModifierKeys(n){return this._allowedModifierKeys=n,this}withTypeAhead(n=200){this._typeaheadSubscription.unsubscribe();let e=this._getItemsArray();return this._typeahead=new ma(e,{debounceInterval:typeof n=="number"?n:void 0,skipPredicate:t=>this._skipPredicateFn(t)}),this._typeaheadSubscription=this._typeahead.selectedItem.subscribe(t=>{this.setActiveItem(t)}),this}cancelTypeahead(){return this._typeahead?.reset(),this}withHomeAndEnd(n=!0){return this._homeAndEnd=n,this}withPageUpDown(n=!0,e=10){return this._pageUpAndDown={enabled:n,delta:e},this}setActiveItem(n){let e=this._activeItem();this.updateActiveItem(n),this._activeItem()!==e&&this.change.next(this._activeItemIndex())}onKeydown(n){let e=n.keyCode,o=["altKey","ctrlKey","metaKey","shiftKey"].every(a=>!n[a]||this._allowedModifierKeys.indexOf(a)>-1);switch(e){case 9:this.tabOut.next();return;case 40:if(this._vertical&&o){this.setNextItemActive();break}else return;case 38:if(this._vertical&&o){this.setPreviousItemActive();break}else return;case 39:if(this._horizontal&&o){this._horizontal==="rtl"?this.setPreviousItemActive():this.setNextItemActive();break}else return;case 37:if(this._horizontal&&o){this._horizontal==="rtl"?this.setNextItemActive():this.setPreviousItemActive();break}else return;case 36:if(this._homeAndEnd&&o){this.setFirstItemActive();break}else return;case 35:if(this._homeAndEnd&&o){this.setLastItemActive();break}else return;case 33:if(this._pageUpAndDown.enabled&&o){let a=this._activeItemIndex()-this._pageUpAndDown.delta;this._setActiveItemByIndex(a>0?a:0,1);break}else return;case 34:if(this._pageUpAndDown.enabled&&o){let a=this._activeItemIndex()+this._pageUpAndDown.delta,s=this._getItemsArray().length;this._setActiveItemByIndex(a<s?a:s-1,-1);break}else return;default:(o||tn(n,"shiftKey"))&&this._typeahead?.handleKey(n);return}this._typeahead?.reset(),n.preventDefault()}get activeItemIndex(){return this._activeItemIndex()}get activeItem(){return this._activeItem()}isTyping(){return!!this._typeahead&&this._typeahead.isTyping()}setFirstItemActive(){this._setActiveItemByIndex(0,1)}setLastItemActive(){this._setActiveItemByIndex(this._getItemsArray().length-1,-1)}setNextItemActive(){this._activeItemIndex()<0?this.setFirstItemActive():this._setActiveItemByDelta(1)}setPreviousItemActive(){this._activeItemIndex()<0&&this._wrap?this.setLastItemActive():this._setActiveItemByDelta(-1)}updateActiveItem(n){let e=this._getItemsArray(),t=typeof n=="number"?n:e.indexOf(n),o=e[t];this._activeItem.set(o??null),this._activeItemIndex.set(t),this._typeahead?.setCurrentSelectedItemIndex(t)}destroy(){this._typeaheadSubscription.unsubscribe(),this._itemChangesSubscription?.unsubscribe(),this._effectRef?.destroy(),this._typeahead?.destroy(),this.tabOut.complete(),this.change.complete()}_setActiveItemByDelta(n){this._wrap?this._setActiveInWrapMode(n):this._setActiveInDefaultMode(n)}_setActiveInWrapMode(n){let e=this._getItemsArray();for(let t=1;t<=e.length;t++){let o=(this._activeItemIndex()+n*t+e.length)%e.length,a=e[o];if(!this._skipPredicateFn(a)){this.setActiveItem(o);return}}}_setActiveInDefaultMode(n){this._setActiveItemByIndex(this._activeItemIndex()+n,n)}_setActiveItemByIndex(n,e){let t=this._getItemsArray();if(t[n]){for(;this._skipPredicateFn(t[n]);)if(n+=e,!t[n])return;this.setActiveItem(n)}}_getItemsArray(){return Ts(this._items)?this._items():this._items instanceof zt?this._items.toArray():this._items}_itemsChanged(n){this._typeahead?.setItems(n);let e=this._activeItem();if(e){let t=n.indexOf(e);t>-1&&t!==this._activeItemIndex()&&(this._activeItemIndex.set(t),this._typeahead?.setCurrentSelectedItemIndex(t))}}};var ao=class extends fa{_origin="program";setFocusOrigin(n){return this._origin=n,this}setActiveItem(n){super.setActiveItem(n),this.activeItem&&this.activeItem.focus(this._origin)}};var cf=new A("cdk-dir-doc",{providedIn:"root",factory:df});function df(){return l(D)}var uf=/^(ar|ckb|dv|he|iw|fa|nqo|ps|sd|ug|ur|yi|.*[-_](Adlm|Arab|Hebr|Nkoo|Rohg|Thaa))(?!.*[-_](Latn|Cyrl)($|-|_))($|-|_)/i;function nu(i){let n=i?.toLowerCase()||"";return n==="auto"&&typeof navigator<"u"&&navigator?.language?uf.test(navigator.language)?"rtl":"ltr":n==="rtl"?"rtl":"ltr"}var dt=(()=>{class i{get value(){return this.valueSignal()}valueSignal=te("ltr");change=new Z;constructor(){let e=l(cf,{optional:!0});if(e){let t=e.body?e.body.dir:null,o=e.documentElement?e.documentElement.dir:null;this.valueSignal.set(nu(t||o||"ltr"))}}ngOnDestroy(){this.change.complete()}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();var Qt=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({})}return i})();var z=(()=>{class i{constructor(){l(Ur)._applyBodyHighContrastModeCssClasses()}static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[Qt,Qt]})}return i})();var hf=["*"];var pf=[[["","mat-card-avatar",""],["","matCardAvatar",""]],[["mat-card-title"],["mat-card-subtitle"],["","mat-card-title",""],["","mat-card-subtitle",""],["","matCardTitle",""],["","matCardSubtitle",""]],"*"],mf=["[mat-card-avatar], [matCardAvatar]",`mat-card-title, mat-card-subtitle,
      [mat-card-title], [mat-card-subtitle],
      [matCardTitle], [matCardSubtitle]`,"*"],ff=new A("MAT_CARD_CONFIG"),nn=(()=>{class i{appearance;constructor(){let e=l(ff,{optional:!0});this.appearance=e?.appearance||"raised"}static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["mat-card"]],hostAttrs:[1,"mat-mdc-card","mdc-card"],hostVars:8,hostBindings:function(t,o){t&2&&N("mat-mdc-card-outlined",o.appearance==="outlined")("mdc-card--outlined",o.appearance==="outlined")("mat-mdc-card-filled",o.appearance==="filled")("mdc-card--filled",o.appearance==="filled")},inputs:{appearance:"appearance"},exportAs:["matCard"],ngContentSelectors:hf,decls:1,vars:0,template:function(t,o){t&1&&(Y(),T(0))},styles:[`.mat-mdc-card{display:flex;flex-direction:column;box-sizing:border-box;position:relative;border-style:solid;border-width:0;background-color:var(--mat-card-elevated-container-color, var(--mat-sys-surface-container-low));border-color:var(--mat-card-elevated-container-color, var(--mat-sys-surface-container-low));border-radius:var(--mat-card-elevated-container-shape, var(--mat-sys-corner-medium));box-shadow:var(--mat-card-elevated-container-elevation, var(--mat-sys-level1))}.mat-mdc-card::after{position:absolute;top:0;left:0;width:100%;height:100%;border:solid 1px rgba(0,0,0,0);content:"";display:block;pointer-events:none;box-sizing:border-box;border-radius:var(--mat-card-elevated-container-shape, var(--mat-sys-corner-medium))}.mat-mdc-card-outlined{background-color:var(--mat-card-outlined-container-color, var(--mat-sys-surface));border-radius:var(--mat-card-outlined-container-shape, var(--mat-sys-corner-medium));border-width:var(--mat-card-outlined-outline-width, 1px);border-color:var(--mat-card-outlined-outline-color, var(--mat-sys-outline-variant));box-shadow:var(--mat-card-outlined-container-elevation, var(--mat-sys-level0))}.mat-mdc-card-outlined::after{border:none}.mat-mdc-card-filled{background-color:var(--mat-card-filled-container-color, var(--mat-sys-surface-container-highest));border-radius:var(--mat-card-filled-container-shape, var(--mat-sys-corner-medium));box-shadow:var(--mat-card-filled-container-elevation, var(--mat-sys-level0))}.mdc-card__media{position:relative;box-sizing:border-box;background-repeat:no-repeat;background-position:center;background-size:cover}.mdc-card__media::before{display:block;content:""}.mdc-card__media:first-child{border-top-left-radius:inherit;border-top-right-radius:inherit}.mdc-card__media:last-child{border-bottom-left-radius:inherit;border-bottom-right-radius:inherit}.mat-mdc-card-actions{display:flex;flex-direction:row;align-items:center;box-sizing:border-box;min-height:52px;padding:8px}.mat-mdc-card-title{font-family:var(--mat-card-title-text-font, var(--mat-sys-title-large-font));line-height:var(--mat-card-title-text-line-height, var(--mat-sys-title-large-line-height));font-size:var(--mat-card-title-text-size, var(--mat-sys-title-large-size));letter-spacing:var(--mat-card-title-text-tracking, var(--mat-sys-title-large-tracking));font-weight:var(--mat-card-title-text-weight, var(--mat-sys-title-large-weight))}.mat-mdc-card-subtitle{color:var(--mat-card-subtitle-text-color, var(--mat-sys-on-surface));font-family:var(--mat-card-subtitle-text-font, var(--mat-sys-title-medium-font));line-height:var(--mat-card-subtitle-text-line-height, var(--mat-sys-title-medium-line-height));font-size:var(--mat-card-subtitle-text-size, var(--mat-sys-title-medium-size));letter-spacing:var(--mat-card-subtitle-text-tracking, var(--mat-sys-title-medium-tracking));font-weight:var(--mat-card-subtitle-text-weight, var(--mat-sys-title-medium-weight))}.mat-mdc-card-title,.mat-mdc-card-subtitle{display:block;margin:0}.mat-mdc-card-avatar~.mat-mdc-card-header-text .mat-mdc-card-title,.mat-mdc-card-avatar~.mat-mdc-card-header-text .mat-mdc-card-subtitle{padding:16px 16px 0}.mat-mdc-card-header{display:flex;padding:16px 16px 0}.mat-mdc-card-content{display:block;padding:0 16px}.mat-mdc-card-content:first-child{padding-top:16px}.mat-mdc-card-content:last-child{padding-bottom:16px}.mat-mdc-card-title-group{display:flex;justify-content:space-between;width:100%}.mat-mdc-card-avatar{height:40px;width:40px;border-radius:50%;flex-shrink:0;margin-bottom:16px;object-fit:cover}.mat-mdc-card-avatar~.mat-mdc-card-header-text .mat-mdc-card-subtitle,.mat-mdc-card-avatar~.mat-mdc-card-header-text .mat-mdc-card-title{line-height:normal}.mat-mdc-card-sm-image{width:80px;height:80px}.mat-mdc-card-md-image{width:112px;height:112px}.mat-mdc-card-lg-image{width:152px;height:152px}.mat-mdc-card-xl-image{width:240px;height:240px}.mat-mdc-card-subtitle~.mat-mdc-card-title,.mat-mdc-card-title~.mat-mdc-card-subtitle,.mat-mdc-card-header .mat-mdc-card-header-text .mat-mdc-card-title,.mat-mdc-card-header .mat-mdc-card-header-text .mat-mdc-card-subtitle,.mat-mdc-card-title-group .mat-mdc-card-title,.mat-mdc-card-title-group .mat-mdc-card-subtitle{padding-top:0}.mat-mdc-card-content>:last-child:not(.mat-mdc-card-footer){margin-bottom:0}.mat-mdc-card-actions-align-end{justify-content:flex-end}
`],encapsulation:2,changeDetection:0})}return i})(),on=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["mat-card-title"],["","mat-card-title",""],["","matCardTitle",""]],hostAttrs:[1,"mat-mdc-card-title"]})}return i})();var an=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["mat-card-content"]],hostAttrs:[1,"mat-mdc-card-content"]})}return i})(),ou=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["mat-card-subtitle"],["","mat-card-subtitle",""],["","matCardSubtitle",""]],hostAttrs:[1,"mat-mdc-card-subtitle"]})}return i})();var sn=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["mat-card-header"]],hostAttrs:[1,"mat-mdc-card-header"],ngContentSelectors:mf,decls:4,vars:0,consts:[[1,"mat-mdc-card-header-text"]],template:function(t,o){t&1&&(Y(pf),T(0),Q(1,"div",0),T(2,1),ne(),T(3,2))},encapsulation:2,changeDetection:0})}return i})();var _t=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[z,z]})}return i})();var ya=class i{static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-welcome"]],decls:75,vars:0,consts:[["href","https://oecd.ai/en/"],["href","http://localhost:4200/tips"],["href","http://localhost:4200/dashboards"],["href","http://localhost:4200/data/policy-analysis"]],template:function(e,t){e&1&&(u(0,"mat-card")(1,"mat-card-header")(2,"mat-card-title"),m(3,"Welcome to the Education and AI Policy Commons"),h()(),u(4,"mat-card-content")(5,"h1"),m(6,"Explore Our Comprehensive Resource"),h(),u(7,"p"),m(8,"Welcome to the Education and AI Policy Commons, a platform designed for education researchers and policymakers. It draws on the "),u(9,"a",0),m(10,"OECD\u2019s AI Policy Observatory"),h(),m(11,", with a focus on AI and education. Here, you can gain a clear view of how governments are shaping the role of AI in education. With in-depth analysis of over 479 AI-related education policies, this platform offers valuable insights into key themes and policy trends. Discover how AI is being positioned to transform learning environments and drive educational innovation globally. This platform also enables you to participate in building knowledge about the emerging landscape of policies impacting AI, from schools to governments."),h(),u(12,"p"),m(13,"Key Features:"),h(),u(14,"ul")(15,"li"),m(16,"Policy Search: Access a vast database of national and international AI in education policies."),h(),u(17,"li"),m(18,"Data Dashboards: View qualitative analysis completed by our expert team."),h(),u(19,"li"),m(20,"Policy Upload: Contribute by uploading policies that may interest others."),h()(),u(21,"h1"),m(22,"How you could use this site"),h(),u(23,"p"),m(24,"If you are a(an)..."),h(),u(25,"ul")(26,"li"),m(27,"Policy Maker: Conduct quick scans of recent AI policies in education."),h(),u(28,"li"),m(29,"Researcher: Explore the balance between risk and opportunity in AI and education policies."),h(),u(30,"li"),m(31,"Human Rights Advocate: Investigate how different countries address AI and human rights."),h(),u(32,"li"),m(33,"Equity and Inclusion Enthusiast: Identify policies that address equity and inclusion in AI and education."),h(),u(34,"li"),m(35,"Educator: Understand the practical implications of AI policies in classrooms."),h(),u(36,"li"),m(37,"Curriculum Developer: Find examples of how AI policies influence teaching strategies and learning outcomes."),h(),u(38,"li"),m(39,"Public Policy Student: Study global trends and government approaches to AI in education."),h(),u(40,"li"),m(41,"Technology Developer: Learn how policy frameworks impact AI innovations for educational tools."),h(),u(42,"li"),m(43,"Non-Profit Organisation: Discover policies prioritizing access to AI resources in under-resourced communities."),h(),u(44,"li"),m(45,"Data Privacy Expert: Explore how different countries manage student data in the context of AI."),h(),u(46,"li"),m(47,"Journalist: Gain insights into how nations handle ethical challenges in AI for education."),h(),u(48,"li"),m(49,"EdTech Investor: Identify supportive policy environments for AI-driven educational technologies."),h(),u(50,"li"),m(51,"International Relations Professional: Compare how nations use AI in education as part of their strategic development goals."),h()(),u(52,"p")(53,"a",1),m(54,"Tips for Effective Use"),h()(),u(55,"h2"),m(56,"About the Research"),h(),u(57,"p"),m(58,"Our research focuses on the potential of AI to progress equity and inclusion in education. We explore opportunities such as adaptive learning experiences, enhanced content delivery, and increased agency for learners."),h(),u(59,"h2"),m(60,"About the Database"),h(),u(61,"p"),m(62,"Our team conducted qualitative research on 473 policy documents, including all governance and regulation policies. We identified 83 policies relevant to the governance of AI in education, most of which commenced between 2019 and 2021. These policies primarily aim to educate officials, guide organizations, and plan future actions."),h(),u(63,"p"),m(64,"For any questions about the status of our research, please contact us at: education.futures.studio@gmail.com."),h(),u(65,"h2"),m(66,"Key Links"),h(),u(67,"p")(68,"a",2),m(69,"Dashboards"),h()(),u(70,"p")(71,"a",3),m(72,"Policy analysis table"),h()(),u(73,"p"),m(74,"Explore, contribute, and stay informed with the Education and AI Policy Commons."),h()()())},dependencies:[_t,nn,an,sn,on],encapsulation:2})};var ga=class i{static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-tips"]],decls:17,vars:0,template:function(e,t){e&1&&(u(0,"mat-card")(1,"mat-card-header")(2,"mat-card-title"),m(3,"Tips for Effective Use"),h()(),u(4,"mat-card-content")(5,"h2"),m(6,"Getting Started"),h(),u(7,"p"),m(8,"Navigate through the dashboards to explore policy data and trends."),h(),u(9,"h2"),m(10,"Using the Search Features"),h(),u(11,"p"),m(12,"Use filters to narrow down policies by type, status, or jurisdiction."),h(),u(13,"h2"),m(14,"Contributing"),h(),u(15,"p"),m(16,"Add new policies using the Policy Entry Form in the navigation menu."),h()()())},dependencies:[_t,nn,an,sn,on],encapsulation:2})};var ba;function yf(){if(ba===void 0&&(ba=null,typeof window<"u")){let i=window;i.trustedTypes!==void 0&&(ba=i.trustedTypes.createPolicy("angular#components",{createHTML:n=>n}))}return ba}function so(i){return yf()?.createHTML(i)||i}function au(i){return Error(`Unable to find icon with the name "${i}"`)}function gf(){return Error("Could not find HttpClient for use with Angular Material icons. Please add provideHttpClient() to your providers.")}function su(i){return Error(`The URL provided to MatIconRegistry was not trusted as a resource URL via Angular's DomSanitizer. Attempted URL was "${i}".`)}function ru(i){return Error(`The literal provided to MatIconRegistry was not trusted as safe HTML by Angular's DomSanitizer. Attempted literal was "${i}".`)}var Mt=class{url;svgText;options;svgElement;constructor(n,e,t){this.url=n,this.svgText=e,this.options=t}},cu=(()=>{class i{_httpClient;_sanitizer;_errorHandler;_document;_svgIconConfigs=new Map;_iconSetConfigs=new Map;_cachedIconsByUrl=new Map;_inProgressUrlFetches=new Map;_fontCssClassesByAlias=new Map;_resolvers=[];_defaultFontSetClass=["material-icons","mat-ligature-font"];constructor(e,t,o,a){this._httpClient=e,this._sanitizer=t,this._errorHandler=a,this._document=o}addSvgIcon(e,t,o){return this.addSvgIconInNamespace("",e,t,o)}addSvgIconLiteral(e,t,o){return this.addSvgIconLiteralInNamespace("",e,t,o)}addSvgIconInNamespace(e,t,o,a){return this._addSvgIconConfig(e,t,new Mt(o,null,a))}addSvgIconResolver(e){return this._resolvers.push(e),this}addSvgIconLiteralInNamespace(e,t,o,a){let s=this._sanitizer.sanitize(Ue.HTML,o);if(!s)throw ru(o);let r=so(s);return this._addSvgIconConfig(e,t,new Mt("",r,a))}addSvgIconSet(e,t){return this.addSvgIconSetInNamespace("",e,t)}addSvgIconSetLiteral(e,t){return this.addSvgIconSetLiteralInNamespace("",e,t)}addSvgIconSetInNamespace(e,t,o){return this._addSvgIconSetConfig(e,new Mt(t,null,o))}addSvgIconSetLiteralInNamespace(e,t,o){let a=this._sanitizer.sanitize(Ue.HTML,t);if(!a)throw ru(t);let s=so(a);return this._addSvgIconSetConfig(e,new Mt("",s,o))}registerFontClassAlias(e,t=e){return this._fontCssClassesByAlias.set(e,t),this}classNameForFontAlias(e){return this._fontCssClassesByAlias.get(e)||e}setDefaultFontSetClass(...e){return this._defaultFontSetClass=e,this}getDefaultFontSetClass(){return this._defaultFontSetClass}getSvgIconFromUrl(e){let t=this._sanitizer.sanitize(Ue.RESOURCE_URL,e);if(!t)throw su(e);let o=this._cachedIconsByUrl.get(t);return o?I(va(o)):this._loadSvgIconFromConfig(new Mt(e,null)).pipe(fe(a=>this._cachedIconsByUrl.set(t,a)),q(a=>va(a)))}getNamedSvgIcon(e,t=""){let o=lu(t,e),a=this._svgIconConfigs.get(o);if(a)return this._getSvgFromConfig(a);if(a=this._getIconConfigFromResolvers(t,e),a)return this._svgIconConfigs.set(o,a),this._getSvgFromConfig(a);let s=this._iconSetConfigs.get(t);return s?this._getSvgFromIconSetConfigs(e,s):ni(au(o))}ngOnDestroy(){this._resolvers=[],this._svgIconConfigs.clear(),this._iconSetConfigs.clear(),this._cachedIconsByUrl.clear()}_getSvgFromConfig(e){return e.svgText?I(va(this._svgElementFromConfig(e))):this._loadSvgIconFromConfig(e).pipe(q(t=>va(t)))}_getSvgFromIconSetConfigs(e,t){let o=this._extractIconWithNameFromAnySet(e,t);if(o)return I(o);let a=t.filter(s=>!s.svgText).map(s=>this._loadSvgIconSetFromConfig(s).pipe(Et(r=>{let d=`Loading icon set URL: ${this._sanitizer.sanitize(Ue.RESOURCE_URL,s.url)} failed: ${r.message}`;return this._errorHandler.handleError(new Error(d)),I(null)})));return ql(a).pipe(q(()=>{let s=this._extractIconWithNameFromAnySet(e,t);if(!s)throw au(e);return s}))}_extractIconWithNameFromAnySet(e,t){for(let o=t.length-1;o>=0;o--){let a=t[o];if(a.svgText&&a.svgText.toString().indexOf(e)>-1){let s=this._svgElementFromConfig(a),r=this._extractSvgIconFromSet(s,e,a.options);if(r)return r}}return null}_loadSvgIconFromConfig(e){return this._fetchIcon(e).pipe(fe(t=>e.svgText=t),q(()=>this._svgElementFromConfig(e)))}_loadSvgIconSetFromConfig(e){return e.svgText?I(null):this._fetchIcon(e).pipe(fe(t=>e.svgText=t))}_extractSvgIconFromSet(e,t,o){let a=e.querySelector(`[id="${t}"]`);if(!a)return null;let s=a.cloneNode(!0);if(s.removeAttribute("id"),s.nodeName.toLowerCase()==="svg")return this._setSvgAttributes(s,o);if(s.nodeName.toLowerCase()==="symbol")return this._setSvgAttributes(this._toSvgElement(s),o);let r=this._svgElementFromString(so("<svg></svg>"));return r.appendChild(s),this._setSvgAttributes(r,o)}_svgElementFromString(e){let t=this._document.createElement("DIV");t.innerHTML=e;let o=t.querySelector("svg");if(!o)throw Error("<svg> tag not found");return o}_toSvgElement(e){let t=this._svgElementFromString(so("<svg></svg>")),o=e.attributes;for(let a=0;a<o.length;a++){let{name:s,value:r}=o[a];s!=="id"&&t.setAttribute(s,r)}for(let a=0;a<e.childNodes.length;a++)e.childNodes[a].nodeType===this._document.ELEMENT_NODE&&t.appendChild(e.childNodes[a].cloneNode(!0));return t}_setSvgAttributes(e,t){return e.setAttribute("fit",""),e.setAttribute("height","100%"),e.setAttribute("width","100%"),e.setAttribute("preserveAspectRatio","xMidYMid meet"),e.setAttribute("focusable","false"),t&&t.viewBox&&e.setAttribute("viewBox",t.viewBox),e}_fetchIcon(e){let{url:t,options:o}=e,a=o?.withCredentials??!1;if(!this._httpClient)throw gf();if(t==null)throw Error(`Cannot fetch icon from URL "${t}".`);let s=this._sanitizer.sanitize(Ue.RESOURCE_URL,t);if(!s)throw su(t);let r=this._inProgressUrlFetches.get(s);if(r)return r;let c=this._httpClient.get(s,{responseType:"text",withCredentials:a}).pipe(q(d=>so(d)),oi(()=>this._inProgressUrlFetches.delete(s)),Ll());return this._inProgressUrlFetches.set(s,c),c}_addSvgIconConfig(e,t,o){return this._svgIconConfigs.set(lu(e,t),o),this}_addSvgIconSetConfig(e,t){let o=this._iconSetConfigs.get(e);return o?o.push(t):this._iconSetConfigs.set(e,[t]),this}_svgElementFromConfig(e){if(!e.svgElement){let t=this._svgElementFromString(e.svgText);this._setSvgAttributes(t,e.options),e.svgElement=t}return e.svgElement}_getIconConfigFromResolvers(e,t){for(let o=0;o<this._resolvers.length;o++){let a=this._resolvers[o](t,e);if(a)return bf(a)?new Mt(a.url,null,a.options):new Mt(a,null)}}static \u0275fac=function(t){return new(t||i)(O(sr,8),O(rr),O(D,8),O(Kt))};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();function va(i){return i.cloneNode(!0)}function lu(i,n){return i+":"+n}function bf(i){return!!(i.url&&i.options)}var vf=["*"],Af=new A("MAT_ICON_DEFAULT_OPTIONS"),If=new A("mat-icon-location",{providedIn:"root",factory:_f});function _f(){let i=l(D),n=i?i.location:null;return{getPathname:()=>n?n.pathname+n.search:""}}var du=["clip-path","color-profile","src","cursor","fill","filter","marker","marker-start","marker-mid","marker-end","mask","stroke"],wf=du.map(i=>`[${i}]`).join(", "),Cf=/^url\(['"]?#(.*?)['"]?\)$/,rn=(()=>{class i{_elementRef=l(R);_iconRegistry=l(cu);_location=l(If);_errorHandler=l(Kt);_defaultColor;get color(){return this._color||this._defaultColor}set color(e){this._color=e}_color;inline=!1;get svgIcon(){return this._svgIcon}set svgIcon(e){e!==this._svgIcon&&(e?this._updateSvgIcon(e):this._svgIcon&&this._clearSvgElement(),this._svgIcon=e)}_svgIcon;get fontSet(){return this._fontSet}set fontSet(e){let t=this._cleanupFontValue(e);t!==this._fontSet&&(this._fontSet=t,this._updateFontIconClasses())}_fontSet;get fontIcon(){return this._fontIcon}set fontIcon(e){let t=this._cleanupFontValue(e);t!==this._fontIcon&&(this._fontIcon=t,this._updateFontIconClasses())}_fontIcon;_previousFontSetClass=[];_previousFontIconClass;_svgName;_svgNamespace;_previousPath;_elementsWithExternalReferences;_currentIconFetch=De.EMPTY;constructor(){let e=l(new Vt("aria-hidden"),{optional:!0}),t=l(Af,{optional:!0});t&&(t.color&&(this.color=this._defaultColor=t.color),t.fontSet&&(this.fontSet=t.fontSet)),e||this._elementRef.nativeElement.setAttribute("aria-hidden","true")}_splitIconName(e){if(!e)return["",""];let t=e.split(":");switch(t.length){case 1:return["",t[0]];case 2:return t;default:throw Error(`Invalid icon name: "${e}"`)}}ngOnInit(){this._updateFontIconClasses()}ngAfterViewChecked(){let e=this._elementsWithExternalReferences;if(e&&e.size){let t=this._location.getPathname();t!==this._previousPath&&(this._previousPath=t,this._prependPathToReferences(t))}}ngOnDestroy(){this._currentIconFetch.unsubscribe(),this._elementsWithExternalReferences&&this._elementsWithExternalReferences.clear()}_usingFontIcon(){return!this.svgIcon}_setSvgElement(e){this._clearSvgElement();let t=this._location.getPathname();this._previousPath=t,this._cacheChildrenWithExternalReferences(e),this._prependPathToReferences(t),this._elementRef.nativeElement.appendChild(e)}_clearSvgElement(){let e=this._elementRef.nativeElement,t=e.childNodes.length;for(this._elementsWithExternalReferences&&this._elementsWithExternalReferences.clear();t--;){let o=e.childNodes[t];(o.nodeType!==1||o.nodeName.toLowerCase()==="svg")&&o.remove()}}_updateFontIconClasses(){if(!this._usingFontIcon())return;let e=this._elementRef.nativeElement,t=(this.fontSet?this._iconRegistry.classNameForFontAlias(this.fontSet).split(/ +/):this._iconRegistry.getDefaultFontSetClass()).filter(o=>o.length>0);this._previousFontSetClass.forEach(o=>e.classList.remove(o)),t.forEach(o=>e.classList.add(o)),this._previousFontSetClass=t,this.fontIcon!==this._previousFontIconClass&&!t.includes("mat-ligature-font")&&(this._previousFontIconClass&&e.classList.remove(this._previousFontIconClass),this.fontIcon&&e.classList.add(this.fontIcon),this._previousFontIconClass=this.fontIcon)}_cleanupFontValue(e){return typeof e=="string"?e.trim().split(" ")[0]:e}_prependPathToReferences(e){let t=this._elementsWithExternalReferences;t&&t.forEach((o,a)=>{o.forEach(s=>{a.setAttribute(s.name,`url('${e}#${s.value}')`)})})}_cacheChildrenWithExternalReferences(e){let t=e.querySelectorAll(wf),o=this._elementsWithExternalReferences=this._elementsWithExternalReferences||new Map;for(let a=0;a<t.length;a++)du.forEach(s=>{let r=t[a],c=r.getAttribute(s),d=c?c.match(Cf):null;if(d){let p=o.get(r);p||(p=[],o.set(r,p)),p.push({name:s,value:d[1]})}})}_updateSvgIcon(e){if(this._svgNamespace=null,this._svgName=null,this._currentIconFetch.unsubscribe(),e){let[t,o]=this._splitIconName(e);t&&(this._svgNamespace=t),o&&(this._svgName=o),this._currentIconFetch=this._iconRegistry.getNamedSvgIcon(o,t).pipe(Ke(1)).subscribe(a=>this._setSvgElement(a),a=>{let s=`Error retrieving icon ${t}:${o}! ${a.message}`;this._errorHandler.handleError(new Error(s))})}}static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["mat-icon"]],hostAttrs:["role","img",1,"mat-icon","notranslate"],hostVars:10,hostBindings:function(t,o){t&2&&(X("data-mat-icon-type",o._usingFontIcon()?"font":"svg")("data-mat-icon-name",o._svgName||o.fontIcon)("data-mat-icon-namespace",o._svgNamespace||o.fontSet)("fontIcon",o._usingFontIcon()?o.fontIcon:null),Me(o.color?"mat-"+o.color:""),N("mat-icon-inline",o.inline)("mat-icon-no-color",o.color!=="primary"&&o.color!=="accent"&&o.color!=="warn"))},inputs:{color:"color",inline:[2,"inline","inline",K],svgIcon:"svgIcon",fontSet:"fontSet",fontIcon:"fontIcon"},exportAs:["matIcon"],ngContentSelectors:vf,decls:1,vars:0,template:function(t,o){t&1&&(Y(),T(0))},styles:[`mat-icon,mat-icon.mat-primary,mat-icon.mat-accent,mat-icon.mat-warn{color:var(--mat-icon-color, inherit)}.mat-icon{-webkit-user-select:none;user-select:none;background-repeat:no-repeat;display:inline-block;fill:currentColor;height:24px;width:24px;overflow:hidden}.mat-icon.mat-icon-inline{font-size:inherit;height:inherit;line-height:inherit;width:inherit}.mat-icon.mat-ligature-font[fontIcon]::before{content:attr(fontIcon)}[dir=rtl] .mat-icon-rtl-mirror{transform:scale(-1, 1)}.mat-form-field:not(.mat-form-field-appearance-legacy) .mat-form-field-prefix .mat-icon,.mat-form-field:not(.mat-form-field-appearance-legacy) .mat-form-field-suffix .mat-icon{display:block}.mat-form-field:not(.mat-form-field-appearance-legacy) .mat-form-field-prefix .mat-icon-button .mat-icon,.mat-form-field:not(.mat-form-field-appearance-legacy) .mat-form-field-suffix .mat-icon-button .mat-icon{margin:auto}
`],encapsulation:2,changeDetection:0})}return i})(),wt=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[z,z]})}return i})();var ei=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["structural-styles"]],decls:0,vars:0,template:function(t,o){},styles:[`.mat-focus-indicator{position:relative}.mat-focus-indicator::before{top:0;left:0;right:0;bottom:0;position:absolute;box-sizing:border-box;pointer-events:none;display:var(--mat-focus-indicator-display, none);border-width:var(--mat-focus-indicator-border-width, 3px);border-style:var(--mat-focus-indicator-border-style, solid);border-color:var(--mat-focus-indicator-border-color, transparent);border-radius:var(--mat-focus-indicator-border-radius, 4px)}.mat-focus-indicator:focus::before{content:""}@media(forced-colors: active){html{--mat-focus-indicator-display: block}}
`],encapsulation:2,changeDetection:0})}return i})();var ut=(function(i){return i[i.NORMAL=0]="NORMAL",i[i.NEGATED=1]="NEGATED",i[i.INVERTED=2]="INVERTED",i})(ut||{}),Aa,Ai;function Ia(){if(Ai==null){if(typeof document!="object"||!document||typeof Element!="function"||!Element)return Ai=!1,Ai;if("scrollBehavior"in document.documentElement.style)Ai=!0;else{let i=Element.prototype.scrollTo;i?Ai=!/\{\s*\[native code\]\s*\}/.test(i.toString()):Ai=!1}}return Ai}function ln(){if(typeof document!="object"||!document)return ut.NORMAL;if(Aa==null){let i=document.createElement("div"),n=i.style;i.dir="rtl",n.width="1px",n.overflow="auto",n.visibility="hidden",n.pointerEvents="none",n.position="absolute";let e=document.createElement("div"),t=e.style;t.width="2px",t.height="1px",i.appendChild(e),document.body.appendChild(i),Aa=ut.NORMAL,i.scrollLeft===0&&(i.scrollLeft=1,Aa=i.scrollLeft===0?ut.NEGATED:ut.INVERTED),i.remove()}return Aa}function $r(){return typeof __karma__<"u"&&!!__karma__||typeof jasmine<"u"&&!!jasmine||typeof jest<"u"&&!!jest||typeof Mocha<"u"&&!!Mocha}function be(i){return i==null?"":typeof i=="string"?i:`${i}px`}function Qe(i){return i!=null&&`${i}`!="false"}var Df=new A("MATERIAL_ANIMATIONS");var uu=null;function ro(){return l(Df,{optional:!0})?.animationsDisabled||l(Si,{optional:!0})==="NoopAnimations"?"di-disabled":(uu??=l(ua).matchMedia("(prefers-reduced-motion)").matches,uu?"reduced-motion":"enabled")}function Le(){return ro()!=="enabled"}var ot=(function(i){return i[i.FADING_IN=0]="FADING_IN",i[i.VISIBLE=1]="VISIBLE",i[i.FADING_OUT=2]="FADING_OUT",i[i.HIDDEN=3]="HIDDEN",i})(ot||{}),Qr=class{_renderer;element;config;_animationForciblyDisabledThroughCss;state=ot.HIDDEN;constructor(n,e,t,o=!1){this._renderer=n,this.element=e,this.config=t,this._animationForciblyDisabledThroughCss=o}fadeOut(){this._renderer.fadeOutRipple(this)}},hu=Qi({passive:!0,capture:!0}),el=class{_events=new Map;addHandler(n,e,t,o){let a=this._events.get(e);if(a){let s=a.get(t);s?s.add(o):a.set(t,new Set([o]))}else this._events.set(e,new Map([[t,new Set([o])]])),n.runOutsideAngular(()=>{document.addEventListener(e,this._delegateEventHandler,hu)})}removeHandler(n,e,t){let o=this._events.get(n);if(!o)return;let a=o.get(e);a&&(a.delete(t),a.size===0&&o.delete(e),o.size===0&&(this._events.delete(n),document.removeEventListener(n,this._delegateEventHandler,hu)))}_delegateEventHandler=n=>{let e=Ve(n);e&&this._events.get(n.type)?.forEach((t,o)=>{(o===e||o.contains(e))&&t.forEach(a=>a.handleEvent(n))})}},lo={enterDuration:225,exitDuration:150},Ef=800,pu=Qi({passive:!0,capture:!0}),mu=["mousedown","touchstart"],fu=["mouseup","mouseleave","touchend","touchcancel"],xf=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["ng-component"]],hostAttrs:["mat-ripple-style-loader",""],decls:0,vars:0,template:function(t,o){},styles:[`.mat-ripple{overflow:hidden;position:relative}.mat-ripple:not(:empty){transform:translateZ(0)}.mat-ripple.mat-ripple-unbounded{overflow:visible}.mat-ripple-element{position:absolute;border-radius:50%;pointer-events:none;transition:opacity,transform 0ms cubic-bezier(0, 0, 0.2, 1);transform:scale3d(0, 0, 0);background-color:var(--mat-ripple-color, color-mix(in srgb, var(--mat-sys-on-surface) 10%, transparent))}@media(forced-colors: active){.mat-ripple-element{display:none}}.cdk-drag-preview .mat-ripple-element,.cdk-drag-placeholder .mat-ripple-element{display:none}
`],encapsulation:2,changeDetection:0})}return i})(),Ii=class i{_target;_ngZone;_platform;_containerElement;_triggerElement;_isPointerDown=!1;_activeRipples=new Map;_mostRecentTransientRipple;_lastTouchStartEvent;_pointerUpEventsRegistered=!1;_containerRect;static _eventManager=new el;constructor(n,e,t,o,a){this._target=n,this._ngZone=e,this._platform=o,o.isBrowser&&(this._containerElement=nt(t)),a&&a.get(Te).load(xf)}fadeInRipple(n,e,t={}){let o=this._containerRect=this._containerRect||this._containerElement.getBoundingClientRect(),a=b(b({},lo),t.animation);t.centered&&(n=o.left+o.width/2,e=o.top+o.height/2);let s=t.radius||Tf(n,e,o),r=n-o.left,c=e-o.top,d=a.enterDuration,p=document.createElement("div");p.classList.add("mat-ripple-element"),p.style.left=`${r-s}px`,p.style.top=`${c-s}px`,p.style.height=`${s*2}px`,p.style.width=`${s*2}px`,t.color!=null&&(p.style.backgroundColor=t.color),p.style.transitionDuration=`${d}ms`,this._containerElement.appendChild(p);let v=window.getComputedStyle(p),C=v.transitionProperty,P=v.transitionDuration,L=C==="none"||P==="0s"||P==="0s, 0s"||o.width===0&&o.height===0,W=new Qr(this,p,t,L);p.style.transform="scale3d(1, 1, 1)",W.state=ot.FADING_IN,t.persistent||(this._mostRecentTransientRipple=W);let ae=null;return!L&&(d||a.exitDuration)&&this._ngZone.runOutsideAngular(()=>{let ye=()=>{ae&&(ae.fallbackTimer=null),clearTimeout(at),this._finishRippleTransition(W)},et=()=>this._destroyRipple(W),at=setTimeout(et,d+100);p.addEventListener("transitionend",ye),p.addEventListener("transitioncancel",et),ae={onTransitionEnd:ye,onTransitionCancel:et,fallbackTimer:at}}),this._activeRipples.set(W,ae),(L||!d)&&this._finishRippleTransition(W),W}fadeOutRipple(n){if(n.state===ot.FADING_OUT||n.state===ot.HIDDEN)return;let e=n.element,t=b(b({},lo),n.config.animation);e.style.transitionDuration=`${t.exitDuration}ms`,e.style.opacity="0",n.state=ot.FADING_OUT,(n._animationForciblyDisabledThroughCss||!t.exitDuration)&&this._finishRippleTransition(n)}fadeOutAll(){this._getActiveRipples().forEach(n=>n.fadeOut())}fadeOutAllNonPersistent(){this._getActiveRipples().forEach(n=>{n.config.persistent||n.fadeOut()})}setupTriggerEvents(n){let e=nt(n);!this._platform.isBrowser||!e||e===this._triggerElement||(this._removeTriggerEvents(),this._triggerElement=e,mu.forEach(t=>{i._eventManager.addHandler(this._ngZone,t,e,this)}))}handleEvent(n){n.type==="mousedown"?this._onMousedown(n):n.type==="touchstart"?this._onTouchStart(n):this._onPointerUp(),this._pointerUpEventsRegistered||(this._ngZone.runOutsideAngular(()=>{fu.forEach(e=>{this._triggerElement.addEventListener(e,this,pu)})}),this._pointerUpEventsRegistered=!0)}_finishRippleTransition(n){n.state===ot.FADING_IN?this._startFadeOutTransition(n):n.state===ot.FADING_OUT&&this._destroyRipple(n)}_startFadeOutTransition(n){let e=n===this._mostRecentTransientRipple,{persistent:t}=n.config;n.state=ot.VISIBLE,!t&&(!e||!this._isPointerDown)&&n.fadeOut()}_destroyRipple(n){let e=this._activeRipples.get(n)??null;this._activeRipples.delete(n),this._activeRipples.size||(this._containerRect=null),n===this._mostRecentTransientRipple&&(this._mostRecentTransientRipple=null),n.state=ot.HIDDEN,e!==null&&(n.element.removeEventListener("transitionend",e.onTransitionEnd),n.element.removeEventListener("transitioncancel",e.onTransitionCancel),e.fallbackTimer!==null&&clearTimeout(e.fallbackTimer)),n.element.remove()}_onMousedown(n){let e=yi(n),t=this._lastTouchStartEvent&&Date.now()<this._lastTouchStartEvent+Ef;!this._target.rippleDisabled&&!e&&!t&&(this._isPointerDown=!0,this.fadeInRipple(n.clientX,n.clientY,this._target.rippleConfig))}_onTouchStart(n){if(!this._target.rippleDisabled&&!gi(n)){this._lastTouchStartEvent=Date.now(),this._isPointerDown=!0;let e=n.changedTouches;if(e)for(let t=0;t<e.length;t++)this.fadeInRipple(e[t].clientX,e[t].clientY,this._target.rippleConfig)}}_onPointerUp(){this._isPointerDown&&(this._isPointerDown=!1,this._getActiveRipples().forEach(n=>{let e=n.state===ot.VISIBLE||n.config.terminateOnPointerUp&&n.state===ot.FADING_IN;!n.config.persistent&&e&&n.fadeOut()}))}_getActiveRipples(){return Array.from(this._activeRipples.keys())}_removeTriggerEvents(){let n=this._triggerElement;n&&(mu.forEach(e=>i._eventManager.removeHandler(e,n,this)),this._pointerUpEventsRegistered&&(fu.forEach(e=>n.removeEventListener(e,this,pu)),this._pointerUpEventsRegistered=!1))}};function Tf(i,n,e){let t=Math.max(Math.abs(i-e.left),Math.abs(i-e.right)),o=Math.max(Math.abs(n-e.top),Math.abs(n-e.bottom));return Math.sqrt(t*t+o*o)}var co=new A("mat-ripple-global-options"),_a=(()=>{class i{_elementRef=l(R);_animationsDisabled=Le();color;unbounded;centered;radius=0;animation;get disabled(){return this._disabled}set disabled(e){e&&this.fadeOutAllNonPersistent(),this._disabled=e,this._setupTriggerEventsIfEnabled()}_disabled=!1;get trigger(){return this._trigger||this._elementRef.nativeElement}set trigger(e){this._trigger=e,this._setupTriggerEventsIfEnabled()}_trigger;_rippleRenderer;_globalOptions;_isInitialized=!1;constructor(){let e=l(F),t=l(oe),o=l(co,{optional:!0}),a=l(V);this._globalOptions=o||{},this._rippleRenderer=new Ii(this,e,this._elementRef,t,a)}ngOnInit(){this._isInitialized=!0,this._setupTriggerEventsIfEnabled()}ngOnDestroy(){this._rippleRenderer._removeTriggerEvents()}fadeOutAll(){this._rippleRenderer.fadeOutAll()}fadeOutAllNonPersistent(){this._rippleRenderer.fadeOutAllNonPersistent()}get rippleConfig(){return{centered:this.centered,radius:this.radius,color:this.color,animation:b(b(b({},this._globalOptions.animation),this._animationsDisabled?{enterDuration:0,exitDuration:0}:{}),this.animation),terminateOnPointerUp:this._globalOptions.terminateOnPointerUp}}get rippleDisabled(){return this.disabled||!!this._globalOptions.disabled}_setupTriggerEventsIfEnabled(){!this.disabled&&this._isInitialized&&this._rippleRenderer.setupTriggerEvents(this.trigger)}launch(e,t=0,o){return typeof e=="number"?this._rippleRenderer.fadeInRipple(e,t,b(b({},this.rippleConfig),o)):this._rippleRenderer.fadeInRipple(0,0,b(b({},this.rippleConfig),e))}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","mat-ripple",""],["","matRipple",""]],hostAttrs:[1,"mat-ripple"],hostVars:2,hostBindings:function(t,o){t&2&&N("mat-ripple-unbounded",o.unbounded)},inputs:{color:[0,"matRippleColor","color"],unbounded:[0,"matRippleUnbounded","unbounded"],centered:[0,"matRippleCentered","centered"],radius:[0,"matRippleRadius","radius"],animation:[0,"matRippleAnimation","animation"],disabled:[0,"matRippleDisabled","disabled"],trigger:[0,"matRippleTrigger","trigger"]},exportAs:["matRipple"]})}return i})();var uo=class{_attachedHost;attach(n){return this._attachedHost=n,n.attach(this)}detach(){let n=this._attachedHost;n!=null&&(this._attachedHost=null,n.detach())}get isAttached(){return this._attachedHost!=null}setAttachedHost(n){this._attachedHost=n}},tl=class extends uo{component;viewContainerRef;injector;projectableNodes;constructor(n,e,t,o){super(),this.component=n,this.viewContainerRef=e,this.injector=t,this.projectableNodes=o}},cn=class extends uo{templateRef;viewContainerRef;context;injector;constructor(n,e,t,o){super(),this.templateRef=n,this.viewContainerRef=e,this.context=t,this.injector=o}get origin(){return this.templateRef.elementRef}attach(n,e=this.context){return this.context=e,super.attach(n)}detach(){return this.context=void 0,super.detach()}},il=class extends uo{element;constructor(n){super(),this.element=n instanceof R?n.nativeElement:n}},nl=class{_attachedPortal;_disposeFn;_isDisposed=!1;hasAttached(){return!!this._attachedPortal}attach(n){if(n instanceof tl)return this._attachedPortal=n,this.attachComponentPortal(n);if(n instanceof cn)return this._attachedPortal=n,this.attachTemplatePortal(n);if(this.attachDomPortal&&n instanceof il)return this._attachedPortal=n,this.attachDomPortal(n)}attachDomPortal=null;detach(){this._attachedPortal&&(this._attachedPortal.setAttachedHost(null),this._attachedPortal=null),this._invokeDisposeFn()}dispose(){this.hasAttached()&&this.detach(),this._invokeDisposeFn(),this._isDisposed=!0}setDisposeFn(n){this._disposeFn=n}_invokeDisposeFn(){this._disposeFn&&(this._disposeFn(),this._disposeFn=null)}},ho=class extends nl{outletElement;_appRef;_defaultInjector;constructor(n,e,t){super(),this.outletElement=n,this._appRef=e,this._defaultInjector=t}attachComponentPortal(n){let e;if(n.viewContainerRef){let t=n.injector||n.viewContainerRef.injector,o=t.get(ec,null,{optional:!0})||void 0;e=n.viewContainerRef.createComponent(n.component,{index:n.viewContainerRef.length,injector:t,ngModuleRef:o,projectableNodes:n.projectableNodes||void 0}),this.setDisposeFn(()=>e.destroy())}else{let t=this._appRef,o=n.injector||this._defaultInjector||V.NULL,a=o.get(ze,t.injector);e=Do(n.component,{elementInjector:o,environmentInjector:a,projectableNodes:n.projectableNodes||void 0}),t.attachView(e.hostView),this.setDisposeFn(()=>{t.viewCount>0&&t.detachView(e.hostView),e.destroy()})}return this.outletElement.appendChild(this._getComponentRootNode(e)),this._attachedPortal=n,e}attachTemplatePortal(n){let e=n.viewContainerRef,t=e.createEmbeddedView(n.templateRef,n.context,{injector:n.injector});return t.rootNodes.forEach(o=>this.outletElement.appendChild(o)),t.detectChanges(),this.setDisposeFn(()=>{let o=e.indexOf(t);o!==-1&&e.remove(o)}),this._attachedPortal=n,t}attachDomPortal=n=>{let e=n.element;e.parentNode;let t=this.outletElement.ownerDocument.createComment("dom-portal");e.parentNode.insertBefore(t,e),this.outletElement.appendChild(e),this._attachedPortal=n,super.setDisposeFn(()=>{t.parentNode&&t.parentNode.replaceChild(e,t)})};dispose(){super.dispose(),this.outletElement.remove()}_getComponentRootNode(n){return n.hostView.rootNodes[0]}};var yu=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({})}return i})();function wa(i){return i&&typeof i.connect=="function"&&!(i instanceof In)}var ti=(function(i){return i[i.REPLACED=0]="REPLACED",i[i.INSERTED=1]="INSERTED",i[i.MOVED=2]="MOVED",i[i.REMOVED=3]="REMOVED",i})(ti||{}),dn=new A("_ViewRepeater");var Rf=20,wi=(()=>{class i{_ngZone=l(F);_platform=l(oe);_renderer=l(qe).createRenderer(null,null);_cleanupGlobalListener;constructor(){}_scrolled=new S;_scrolledCount=0;scrollContainers=new Map;register(e){this.scrollContainers.has(e)||this.scrollContainers.set(e,e.elementScrolled().subscribe(()=>this._scrolled.next(e)))}deregister(e){let t=this.scrollContainers.get(e);t&&(t.unsubscribe(),this.scrollContainers.delete(e))}scrolled(e=Rf){return this._platform.isBrowser?new kt(t=>{this._cleanupGlobalListener||(this._cleanupGlobalListener=this._ngZone.runOutsideAngular(()=>this._renderer.listen("document","scroll",()=>this._scrolled.next())));let o=e>0?this._scrolled.pipe(Cs(e)).subscribe(t):this._scrolled.subscribe(t);return this._scrolledCount++,()=>{o.unsubscribe(),this._scrolledCount--,this._scrolledCount||(this._cleanupGlobalListener?.(),this._cleanupGlobalListener=void 0)}}):I()}ngOnDestroy(){this._cleanupGlobalListener?.(),this._cleanupGlobalListener=void 0,this.scrollContainers.forEach((e,t)=>this.deregister(t)),this._scrolled.complete()}ancestorScrolled(e,t){let o=this.getAncestorScrollContainers(e);return this.scrolled(t).pipe(ue(a=>!a||o.indexOf(a)>-1))}getAncestorScrollContainers(e){let t=[];return this.scrollContainers.forEach((o,a)=>{this._scrollableContainsElement(a,e)&&t.push(a)}),t}_scrollableContainsElement(e,t){let o=nt(t),a=e.getElementRef().nativeElement;do if(o==a)return!0;while(o=o.parentElement);return!1}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),un=(()=>{class i{elementRef=l(R);scrollDispatcher=l(wi);ngZone=l(F);dir=l(dt,{optional:!0});_scrollElement=this.elementRef.nativeElement;_destroyed=new S;_renderer=l(Ce);_cleanupScroll;_elementScrolled=new S;constructor(){}ngOnInit(){this._cleanupScroll=this.ngZone.runOutsideAngular(()=>this._renderer.listen(this._scrollElement,"scroll",e=>this._elementScrolled.next(e))),this.scrollDispatcher.register(this)}ngOnDestroy(){this._cleanupScroll?.(),this._elementScrolled.complete(),this.scrollDispatcher.deregister(this),this._destroyed.next(),this._destroyed.complete()}elementScrolled(){return this._elementScrolled}getElementRef(){return this.elementRef}scrollTo(e){let t=this.elementRef.nativeElement,o=this.dir&&this.dir.value=="rtl";e.left==null&&(e.left=o?e.end:e.start),e.right==null&&(e.right=o?e.start:e.end),e.bottom!=null&&(e.top=t.scrollHeight-t.clientHeight-e.bottom),o&&ln()!=ut.NORMAL?(e.left!=null&&(e.right=t.scrollWidth-t.clientWidth-e.left),ln()==ut.INVERTED?e.left=e.right:ln()==ut.NEGATED&&(e.left=e.right?-e.right:e.right)):e.right!=null&&(e.left=t.scrollWidth-t.clientWidth-e.right),this._applyScrollToOptions(e)}_applyScrollToOptions(e){let t=this.elementRef.nativeElement;Ia()?t.scrollTo(e):(e.top!=null&&(t.scrollTop=e.top),e.left!=null&&(t.scrollLeft=e.left))}measureScrollOffset(e){let t="left",o="right",a=this.elementRef.nativeElement;if(e=="top")return a.scrollTop;if(e=="bottom")return a.scrollHeight-a.clientHeight-a.scrollTop;let s=this.dir&&this.dir.value=="rtl";return e=="start"?e=s?o:t:e=="end"&&(e=s?t:o),s&&ln()==ut.INVERTED?e==t?a.scrollWidth-a.clientWidth-a.scrollLeft:a.scrollLeft:s&&ln()==ut.NEGATED?e==t?a.scrollLeft+a.scrollWidth-a.clientWidth:-a.scrollLeft:e==t?a.scrollLeft:a.scrollWidth-a.clientWidth-a.scrollLeft}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","cdk-scrollable",""],["","cdkScrollable",""]]})}return i})(),Sf=20,Ct=(()=>{class i{_platform=l(oe);_listeners;_viewportSize;_change=new S;_document=l(D);constructor(){let e=l(F),t=l(qe).createRenderer(null,null);e.runOutsideAngular(()=>{if(this._platform.isBrowser){let o=a=>this._change.next(a);this._listeners=[t.listen("window","resize",o),t.listen("window","orientationchange",o)]}this.change().subscribe(()=>this._viewportSize=null)})}ngOnDestroy(){this._listeners?.forEach(e=>e()),this._change.complete()}getViewportSize(){this._viewportSize||this._updateViewportSize();let e={width:this._viewportSize.width,height:this._viewportSize.height};return this._platform.isBrowser||(this._viewportSize=null),e}getViewportRect(){let e=this.getViewportScrollPosition(),{width:t,height:o}=this.getViewportSize();return{top:e.top,left:e.left,bottom:e.top+o,right:e.left+t,height:o,width:t}}getViewportScrollPosition(){if(!this._platform.isBrowser)return{top:0,left:0};let e=this._document,t=this._getWindow(),o=e.documentElement,a=o.getBoundingClientRect(),s=-a.top||e.body.scrollTop||t.scrollY||o.scrollTop||0,r=-a.left||e.body.scrollLeft||t.scrollX||o.scrollLeft||0;return{top:s,left:r}}change(e=Sf){return e>0?this._change.pipe(Cs(e)):this._change}_getWindow(){return this._document.defaultView||window}_updateViewportSize(){let e=this._getWindow();this._viewportSize=this._platform.isBrowser?{width:e.innerWidth,height:e.innerHeight}:{width:0,height:0}}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();var _i=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({})}return i})(),po=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[Qt,_i,Qt,_i]})}return i})();var gu=Ia();function Cu(i){return new Ca(i.get(Ct),i.get(D))}var Ca=class{_viewportRuler;_previousHTMLStyles={top:"",left:""};_previousScrollPosition;_isEnabled=!1;_document;constructor(n,e){this._viewportRuler=n,this._document=e}attach(){}enable(){if(this._canBeEnabled()){let n=this._document.documentElement;this._previousScrollPosition=this._viewportRuler.getViewportScrollPosition(),this._previousHTMLStyles.left=n.style.left||"",this._previousHTMLStyles.top=n.style.top||"",n.style.left=be(-this._previousScrollPosition.left),n.style.top=be(-this._previousScrollPosition.top),n.classList.add("cdk-global-scrollblock"),this._isEnabled=!0}}disable(){if(this._isEnabled){let n=this._document.documentElement,e=this._document.body,t=n.style,o=e.style,a=t.scrollBehavior||"",s=o.scrollBehavior||"";this._isEnabled=!1,t.left=this._previousHTMLStyles.left,t.top=this._previousHTMLStyles.top,n.classList.remove("cdk-global-scrollblock"),gu&&(t.scrollBehavior=o.scrollBehavior="auto"),window.scroll(this._previousScrollPosition.left,this._previousScrollPosition.top),gu&&(t.scrollBehavior=a,o.scrollBehavior=s)}}_canBeEnabled(){if(this._document.documentElement.classList.contains("cdk-global-scrollblock")||this._isEnabled)return!1;let e=this._document.documentElement,t=this._viewportRuler.getViewportSize();return e.scrollHeight>t.height||e.scrollWidth>t.width}};function ku(i,n){return new ka(i.get(wi),i.get(F),i.get(Ct),n)}var ka=class{_scrollDispatcher;_ngZone;_viewportRuler;_config;_scrollSubscription=null;_overlayRef;_initialScrollPosition;constructor(n,e,t,o){this._scrollDispatcher=n,this._ngZone=e,this._viewportRuler=t,this._config=o}attach(n){this._overlayRef,this._overlayRef=n}enable(){if(this._scrollSubscription)return;let n=this._scrollDispatcher.scrolled(0).pipe(ue(e=>!e||!this._overlayRef.overlayElement.contains(e.getElementRef().nativeElement)));this._config&&this._config.threshold&&this._config.threshold>1?(this._initialScrollPosition=this._viewportRuler.getViewportScrollPosition().top,this._scrollSubscription=n.subscribe(()=>{let e=this._viewportRuler.getViewportScrollPosition().top;Math.abs(e-this._initialScrollPosition)>this._config.threshold?this._detach():this._overlayRef.updatePosition()})):this._scrollSubscription=n.subscribe(this._detach)}disable(){this._scrollSubscription&&(this._scrollSubscription.unsubscribe(),this._scrollSubscription=null)}detach(){this.disable(),this._overlayRef=null}_detach=()=>{this.disable(),this._overlayRef.hasAttached()&&this._ngZone.run(()=>this._overlayRef.detach())}};var mo=class{enable(){}disable(){}attach(){}};function ol(i,n){return n.some(e=>{let t=i.bottom<e.top,o=i.top>e.bottom,a=i.right<e.left,s=i.left>e.right;return t||o||a||s})}function bu(i,n){return n.some(e=>{let t=i.top<e.top,o=i.bottom>e.bottom,a=i.left<e.left,s=i.right>e.right;return t||o||a||s})}function ki(i,n){return new Da(i.get(wi),i.get(Ct),i.get(F),n)}var Da=class{_scrollDispatcher;_viewportRuler;_ngZone;_config;_scrollSubscription=null;_overlayRef;constructor(n,e,t,o){this._scrollDispatcher=n,this._viewportRuler=e,this._ngZone=t,this._config=o}attach(n){this._overlayRef,this._overlayRef=n}enable(){if(!this._scrollSubscription){let n=this._config?this._config.scrollThrottle:0;this._scrollSubscription=this._scrollDispatcher.scrolled(n).subscribe(()=>{if(this._overlayRef.updatePosition(),this._config&&this._config.autoClose){let e=this._overlayRef.overlayElement.getBoundingClientRect(),{width:t,height:o}=this._viewportRuler.getViewportSize();ol(e,[{width:t,height:o,bottom:o,right:t,top:0,left:0}])&&(this.disable(),this._ngZone.run(()=>this._overlayRef.detach()))}})}}disable(){this._scrollSubscription&&(this._scrollSubscription.unsubscribe(),this._scrollSubscription=null)}detach(){this.disable(),this._overlayRef=null}},Du=(()=>{class i{_injector=l(V);constructor(){}noop=()=>new mo;close=e=>ku(this._injector,e);block=()=>Cu(this._injector);reposition=e=>ki(this._injector,e);static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),hn=class{positionStrategy;scrollStrategy=new mo;panelClass="";hasBackdrop=!1;backdropClass="cdk-overlay-dark-backdrop";disableAnimations;width;height;minWidth;minHeight;maxWidth;maxHeight;direction;disposeOnNavigation=!1;constructor(n){if(n){let e=Object.keys(n);for(let t of e)n[t]!==void 0&&(this[t]=n[t])}}};var Ea=class{connectionPair;scrollableViewProperties;constructor(n,e){this.connectionPair=n,this.scrollableViewProperties=e}};var Eu=(()=>{class i{_attachedOverlays=[];_document=l(D);_isAttached;constructor(){}ngOnDestroy(){this.detach()}add(e){this.remove(e),this._attachedOverlays.push(e)}remove(e){let t=this._attachedOverlays.indexOf(e);t>-1&&this._attachedOverlays.splice(t,1),this._attachedOverlays.length===0&&this.detach()}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),xu=(()=>{class i extends Eu{_ngZone=l(F);_renderer=l(qe).createRenderer(null,null);_cleanupKeydown;add(e){super.add(e),this._isAttached||(this._ngZone.runOutsideAngular(()=>{this._cleanupKeydown=this._renderer.listen("body","keydown",this._keydownListener)}),this._isAttached=!0)}detach(){this._isAttached&&(this._cleanupKeydown?.(),this._isAttached=!1)}_keydownListener=e=>{let t=this._attachedOverlays;for(let o=t.length-1;o>-1;o--)if(t[o]._keydownEvents.observers.length>0){this._ngZone.run(()=>t[o]._keydownEvents.next(e));break}};static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),Tu=(()=>{class i extends Eu{_platform=l(oe);_ngZone=l(F);_renderer=l(qe).createRenderer(null,null);_cursorOriginalValue;_cursorStyleIsSet=!1;_pointerDownEventTarget;_cleanups;add(e){if(super.add(e),!this._isAttached){let t=this._document.body,o={capture:!0},a=this._renderer;this._cleanups=this._ngZone.runOutsideAngular(()=>[a.listen(t,"pointerdown",this._pointerDownListener,o),a.listen(t,"click",this._clickListener,o),a.listen(t,"auxclick",this._clickListener,o),a.listen(t,"contextmenu",this._clickListener,o)]),this._platform.IOS&&!this._cursorStyleIsSet&&(this._cursorOriginalValue=t.style.cursor,t.style.cursor="pointer",this._cursorStyleIsSet=!0),this._isAttached=!0}}detach(){this._isAttached&&(this._cleanups?.forEach(e=>e()),this._cleanups=void 0,this._platform.IOS&&this._cursorStyleIsSet&&(this._document.body.style.cursor=this._cursorOriginalValue,this._cursorStyleIsSet=!1),this._isAttached=!1)}_pointerDownListener=e=>{this._pointerDownEventTarget=Ve(e)};_clickListener=e=>{let t=Ve(e),o=e.type==="click"&&this._pointerDownEventTarget?this._pointerDownEventTarget:t;this._pointerDownEventTarget=null;let a=this._attachedOverlays.slice();for(let s=a.length-1;s>-1;s--){let r=a[s];if(r._outsidePointerEvents.observers.length<1||!r.hasAttached())continue;if(vu(r.overlayElement,t)||vu(r.overlayElement,o))break;let c=r._outsidePointerEvents;this._ngZone?this._ngZone.run(()=>c.next(e)):c.next(e)}};static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();function vu(i,n){let e=typeof ShadowRoot<"u"&&ShadowRoot,t=n;for(;t;){if(t===i)return!0;t=e&&t instanceof ShadowRoot?t.host:t.parentNode}return!1}var Ru=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["ng-component"]],hostAttrs:["cdk-overlay-style-loader",""],decls:0,vars:0,template:function(t,o){},styles:[`.cdk-overlay-container,.cdk-global-overlay-wrapper{pointer-events:none;top:0;left:0;height:100%;width:100%}.cdk-overlay-container{position:fixed}@layer cdk-overlay{.cdk-overlay-container{z-index:1000}}.cdk-overlay-container:empty{display:none}.cdk-global-overlay-wrapper{display:flex;position:absolute}@layer cdk-overlay{.cdk-global-overlay-wrapper{z-index:1000}}.cdk-overlay-pane{position:absolute;pointer-events:auto;box-sizing:border-box;display:flex;max-width:100%;max-height:100%}@layer cdk-overlay{.cdk-overlay-pane{z-index:1000}}.cdk-overlay-backdrop{position:absolute;top:0;bottom:0;left:0;right:0;pointer-events:auto;-webkit-tap-highlight-color:rgba(0,0,0,0);opacity:0;touch-action:manipulation}@layer cdk-overlay{.cdk-overlay-backdrop{z-index:1000;transition:opacity 400ms cubic-bezier(0.25, 0.8, 0.25, 1)}}@media(prefers-reduced-motion){.cdk-overlay-backdrop{transition-duration:1ms}}.cdk-overlay-backdrop-showing{opacity:1}@media(forced-colors: active){.cdk-overlay-backdrop-showing{opacity:.6}}@layer cdk-overlay{.cdk-overlay-dark-backdrop{background:rgba(0,0,0,.32)}}.cdk-overlay-transparent-backdrop{transition:visibility 1ms linear,opacity 1ms linear;visibility:hidden;opacity:1}.cdk-overlay-transparent-backdrop.cdk-overlay-backdrop-showing,.cdk-high-contrast-active .cdk-overlay-transparent-backdrop{opacity:0;visibility:visible}.cdk-overlay-backdrop-noop-animation{transition:none}.cdk-overlay-connected-position-bounding-box{position:absolute;display:flex;flex-direction:column;min-width:1px;min-height:1px}@layer cdk-overlay{.cdk-overlay-connected-position-bounding-box{z-index:1000}}.cdk-global-scrollblock{position:fixed;width:100%;overflow-y:scroll}
`],encapsulation:2,changeDetection:0})}return i})(),Su=(()=>{class i{_platform=l(oe);_containerElement;_document=l(D);_styleLoader=l(Te);constructor(){}ngOnDestroy(){this._containerElement?.remove()}getContainerElement(){return this._loadStyles(),this._containerElement||this._createContainer(),this._containerElement}_createContainer(){let e="cdk-overlay-container";if(this._platform.isBrowser||$r()){let o=this._document.querySelectorAll(`.${e}[platform="server"], .${e}[platform="test"]`);for(let a=0;a<o.length;a++)o[a].remove()}let t=this._document.createElement("div");t.classList.add(e),$r()?t.setAttribute("platform","test"):this._platform.isBrowser||t.setAttribute("platform","server"),this._document.body.appendChild(t),this._containerElement=t}_loadStyles(){this._styleLoader.load(Ru)}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})(),al=class{_renderer;_ngZone;element;_cleanupClick;_cleanupTransitionEnd;_fallbackTimeout;constructor(n,e,t,o){this._renderer=e,this._ngZone=t,this.element=n.createElement("div"),this.element.classList.add("cdk-overlay-backdrop"),this._cleanupClick=e.listen(this.element,"click",o)}detach(){this._ngZone.runOutsideAngular(()=>{let n=this.element;clearTimeout(this._fallbackTimeout),this._cleanupTransitionEnd?.(),this._cleanupTransitionEnd=this._renderer.listen(n,"transitionend",this.dispose),this._fallbackTimeout=setTimeout(this.dispose,500),n.style.pointerEvents="none",n.classList.remove("cdk-overlay-backdrop-showing")})}dispose=()=>{clearTimeout(this._fallbackTimeout),this._cleanupClick?.(),this._cleanupTransitionEnd?.(),this._cleanupClick=this._cleanupTransitionEnd=this._fallbackTimeout=void 0,this.element.remove()}},xa=class{_portalOutlet;_host;_pane;_config;_ngZone;_keyboardDispatcher;_document;_location;_outsideClickDispatcher;_animationsDisabled;_injector;_renderer;_backdropClick=new S;_attachments=new S;_detachments=new S;_positionStrategy;_scrollStrategy;_locationChanges=De.EMPTY;_backdropRef=null;_detachContentMutationObserver;_detachContentAfterRenderRef;_previousHostParent;_keydownEvents=new S;_outsidePointerEvents=new S;_afterNextRenderRef;constructor(n,e,t,o,a,s,r,c,d,p=!1,v,C){this._portalOutlet=n,this._host=e,this._pane=t,this._config=o,this._ngZone=a,this._keyboardDispatcher=s,this._document=r,this._location=c,this._outsideClickDispatcher=d,this._animationsDisabled=p,this._injector=v,this._renderer=C,o.scrollStrategy&&(this._scrollStrategy=o.scrollStrategy,this._scrollStrategy.attach(this)),this._positionStrategy=o.positionStrategy}get overlayElement(){return this._pane}get backdropElement(){return this._backdropRef?.element||null}get hostElement(){return this._host}attach(n){!this._host.parentElement&&this._previousHostParent&&this._previousHostParent.appendChild(this._host);let e=this._portalOutlet.attach(n);return this._positionStrategy&&this._positionStrategy.attach(this),this._updateStackingOrder(),this._updateElementSize(),this._updateElementDirection(),this._scrollStrategy&&this._scrollStrategy.enable(),this._afterNextRenderRef?.destroy(),this._afterNextRenderRef=ve(()=>{this.hasAttached()&&this.updatePosition()},{injector:this._injector}),this._togglePointerEvents(!0),this._config.hasBackdrop&&this._attachBackdrop(),this._config.panelClass&&this._toggleClasses(this._pane,this._config.panelClass,!0),this._attachments.next(),this._completeDetachContent(),this._keyboardDispatcher.add(this),this._config.disposeOnNavigation&&(this._locationChanges=this._location.subscribe(()=>this.dispose())),this._outsideClickDispatcher.add(this),typeof e?.onDestroy=="function"&&e.onDestroy(()=>{this.hasAttached()&&this._ngZone.runOutsideAngular(()=>Promise.resolve().then(()=>this.detach()))}),e}detach(){if(!this.hasAttached())return;this.detachBackdrop(),this._togglePointerEvents(!1),this._positionStrategy&&this._positionStrategy.detach&&this._positionStrategy.detach(),this._scrollStrategy&&this._scrollStrategy.disable();let n=this._portalOutlet.detach();return this._detachments.next(),this._completeDetachContent(),this._keyboardDispatcher.remove(this),this._detachContentWhenEmpty(),this._locationChanges.unsubscribe(),this._outsideClickDispatcher.remove(this),n}dispose(){let n=this.hasAttached();this._positionStrategy&&this._positionStrategy.dispose(),this._disposeScrollStrategy(),this._backdropRef?.dispose(),this._locationChanges.unsubscribe(),this._keyboardDispatcher.remove(this),this._portalOutlet.dispose(),this._attachments.complete(),this._backdropClick.complete(),this._keydownEvents.complete(),this._outsidePointerEvents.complete(),this._outsideClickDispatcher.remove(this),this._host?.remove(),this._afterNextRenderRef?.destroy(),this._previousHostParent=this._pane=this._host=this._backdropRef=null,n&&this._detachments.next(),this._detachments.complete(),this._completeDetachContent()}hasAttached(){return this._portalOutlet.hasAttached()}backdropClick(){return this._backdropClick}attachments(){return this._attachments}detachments(){return this._detachments}keydownEvents(){return this._keydownEvents}outsidePointerEvents(){return this._outsidePointerEvents}getConfig(){return this._config}updatePosition(){this._positionStrategy&&this._positionStrategy.apply()}updatePositionStrategy(n){n!==this._positionStrategy&&(this._positionStrategy&&this._positionStrategy.dispose(),this._positionStrategy=n,this.hasAttached()&&(n.attach(this),this.updatePosition()))}updateSize(n){this._config=b(b({},this._config),n),this._updateElementSize()}setDirection(n){this._config=ge(b({},this._config),{direction:n}),this._updateElementDirection()}addPanelClass(n){this._pane&&this._toggleClasses(this._pane,n,!0)}removePanelClass(n){this._pane&&this._toggleClasses(this._pane,n,!1)}getDirection(){let n=this._config.direction;return n?typeof n=="string"?n:n.value:"ltr"}updateScrollStrategy(n){n!==this._scrollStrategy&&(this._disposeScrollStrategy(),this._scrollStrategy=n,this.hasAttached()&&(n.attach(this),n.enable()))}_updateElementDirection(){this._host.setAttribute("dir",this.getDirection())}_updateElementSize(){if(!this._pane)return;let n=this._pane.style;n.width=be(this._config.width),n.height=be(this._config.height),n.minWidth=be(this._config.minWidth),n.minHeight=be(this._config.minHeight),n.maxWidth=be(this._config.maxWidth),n.maxHeight=be(this._config.maxHeight)}_togglePointerEvents(n){this._pane.style.pointerEvents=n?"":"none"}_attachBackdrop(){let n="cdk-overlay-backdrop-showing";this._backdropRef?.dispose(),this._backdropRef=new al(this._document,this._renderer,this._ngZone,e=>{this._backdropClick.next(e)}),this._animationsDisabled&&this._backdropRef.element.classList.add("cdk-overlay-backdrop-noop-animation"),this._config.backdropClass&&this._toggleClasses(this._backdropRef.element,this._config.backdropClass,!0),this._host.parentElement.insertBefore(this._backdropRef.element,this._host),!this._animationsDisabled&&typeof requestAnimationFrame<"u"?this._ngZone.runOutsideAngular(()=>{requestAnimationFrame(()=>this._backdropRef?.element.classList.add(n))}):this._backdropRef.element.classList.add(n)}_updateStackingOrder(){this._host.nextSibling&&this._host.parentNode.appendChild(this._host)}detachBackdrop(){this._animationsDisabled?(this._backdropRef?.dispose(),this._backdropRef=null):this._backdropRef?.detach()}_toggleClasses(n,e,t){let o=en(e||[]).filter(a=>!!a);o.length&&(t?n.classList.add(...o):n.classList.remove(...o))}_detachContentWhenEmpty(){let n=!1;try{this._detachContentAfterRenderRef=ve(()=>{n=!0,this._detachContent()},{injector:this._injector})}catch(e){if(n)throw e;this._detachContent()}globalThis.MutationObserver&&this._pane&&(this._detachContentMutationObserver||=new globalThis.MutationObserver(()=>{this._detachContent()}),this._detachContentMutationObserver.observe(this._pane,{childList:!0}))}_detachContent(){(!this._pane||!this._host||this._pane.children.length===0)&&(this._pane&&this._config.panelClass&&this._toggleClasses(this._pane,this._config.panelClass,!1),this._host&&this._host.parentElement&&(this._previousHostParent=this._host.parentElement,this._host.remove()),this._completeDetachContent())}_completeDetachContent(){this._detachContentAfterRenderRef?.destroy(),this._detachContentAfterRenderRef=void 0,this._detachContentMutationObserver?.disconnect()}_disposeScrollStrategy(){let n=this._scrollStrategy;n?.disable(),n?.detach?.()}},Au="cdk-overlay-connected-position-bounding-box",Of=/([A-Za-z%]+)$/;function Sa(i,n){return new Ta(n,i.get(Ct),i.get(D),i.get(oe),i.get(Su))}var Ta=class{_viewportRuler;_document;_platform;_overlayContainer;_overlayRef;_isInitialRender;_lastBoundingBoxSize={width:0,height:0};_isPushed=!1;_canPush=!0;_growAfterOpen=!1;_hasFlexibleDimensions=!0;_positionLocked=!1;_originRect;_overlayRect;_viewportRect;_containerRect;_viewportMargin=0;_scrollables=[];_preferredPositions=[];_origin;_pane;_isDisposed;_boundingBox;_lastPosition;_lastScrollVisibility;_positionChanges=new S;_resizeSubscription=De.EMPTY;_offsetX=0;_offsetY=0;_transformOriginSelector;_appliedPanelClasses=[];_previousPushAmount;positionChanges=this._positionChanges;get positions(){return this._preferredPositions}constructor(n,e,t,o,a){this._viewportRuler=e,this._document=t,this._platform=o,this._overlayContainer=a,this.setOrigin(n)}attach(n){this._overlayRef&&this._overlayRef,this._validatePositions(),n.hostElement.classList.add(Au),this._overlayRef=n,this._boundingBox=n.hostElement,this._pane=n.overlayElement,this._isDisposed=!1,this._isInitialRender=!0,this._lastPosition=null,this._resizeSubscription.unsubscribe(),this._resizeSubscription=this._viewportRuler.change().subscribe(()=>{this._isInitialRender=!0,this.apply()})}apply(){if(this._isDisposed||!this._platform.isBrowser)return;if(!this._isInitialRender&&this._positionLocked&&this._lastPosition){this.reapplyLastPosition();return}this._clearPanelClasses(),this._resetOverlayElementStyles(),this._resetBoundingBoxStyles(),this._viewportRect=this._getNarrowedViewportRect(),this._originRect=this._getOriginRect(),this._overlayRect=this._pane.getBoundingClientRect(),this._containerRect=this._overlayContainer.getContainerElement().getBoundingClientRect();let n=this._originRect,e=this._overlayRect,t=this._viewportRect,o=this._containerRect,a=[],s;for(let r of this._preferredPositions){let c=this._getOriginPoint(n,o,r),d=this._getOverlayPoint(c,e,r),p=this._getOverlayFit(d,e,t,r);if(p.isCompletelyWithinViewport){this._isPushed=!1,this._applyPosition(r,c);return}if(this._canFitWithFlexibleDimensions(p,d,t)){a.push({position:r,origin:c,overlayRect:e,boundingBoxRect:this._calculateBoundingBoxRect(c,r)});continue}(!s||s.overlayFit.visibleArea<p.visibleArea)&&(s={overlayFit:p,overlayPoint:d,originPoint:c,position:r,overlayRect:e})}if(a.length){let r=null,c=-1;for(let d of a){let p=d.boundingBoxRect.width*d.boundingBoxRect.height*(d.position.weight||1);p>c&&(c=p,r=d)}this._isPushed=!1,this._applyPosition(r.position,r.origin);return}if(this._canPush){this._isPushed=!0,this._applyPosition(s.position,s.originPoint);return}this._applyPosition(s.position,s.originPoint)}detach(){this._clearPanelClasses(),this._lastPosition=null,this._previousPushAmount=null,this._resizeSubscription.unsubscribe()}dispose(){this._isDisposed||(this._boundingBox&&Ci(this._boundingBox.style,{top:"",left:"",right:"",bottom:"",height:"",width:"",alignItems:"",justifyContent:""}),this._pane&&this._resetOverlayElementStyles(),this._overlayRef&&this._overlayRef.hostElement.classList.remove(Au),this.detach(),this._positionChanges.complete(),this._overlayRef=this._boundingBox=null,this._isDisposed=!0)}reapplyLastPosition(){if(this._isDisposed||!this._platform.isBrowser)return;let n=this._lastPosition;if(n){this._originRect=this._getOriginRect(),this._overlayRect=this._pane.getBoundingClientRect(),this._viewportRect=this._getNarrowedViewportRect(),this._containerRect=this._overlayContainer.getContainerElement().getBoundingClientRect();let e=this._getOriginPoint(this._originRect,this._containerRect,n);this._applyPosition(n,e)}else this.apply()}withScrollableContainers(n){return this._scrollables=n,this}withPositions(n){return this._preferredPositions=n,n.indexOf(this._lastPosition)===-1&&(this._lastPosition=null),this._validatePositions(),this}withViewportMargin(n){return this._viewportMargin=n,this}withFlexibleDimensions(n=!0){return this._hasFlexibleDimensions=n,this}withGrowAfterOpen(n=!0){return this._growAfterOpen=n,this}withPush(n=!0){return this._canPush=n,this}withLockedPosition(n=!0){return this._positionLocked=n,this}setOrigin(n){return this._origin=n,this}withDefaultOffsetX(n){return this._offsetX=n,this}withDefaultOffsetY(n){return this._offsetY=n,this}withTransformOriginOn(n){return this._transformOriginSelector=n,this}_getOriginPoint(n,e,t){let o;if(t.originX=="center")o=n.left+n.width/2;else{let s=this._isRtl()?n.right:n.left,r=this._isRtl()?n.left:n.right;o=t.originX=="start"?s:r}e.left<0&&(o-=e.left);let a;return t.originY=="center"?a=n.top+n.height/2:a=t.originY=="top"?n.top:n.bottom,e.top<0&&(a-=e.top),{x:o,y:a}}_getOverlayPoint(n,e,t){let o;t.overlayX=="center"?o=-e.width/2:t.overlayX==="start"?o=this._isRtl()?-e.width:0:o=this._isRtl()?0:-e.width;let a;return t.overlayY=="center"?a=-e.height/2:a=t.overlayY=="top"?0:-e.height,{x:n.x+o,y:n.y+a}}_getOverlayFit(n,e,t,o){let a=_u(e),{x:s,y:r}=n,c=this._getOffset(o,"x"),d=this._getOffset(o,"y");c&&(s+=c),d&&(r+=d);let p=0-s,v=s+a.width-t.width,C=0-r,P=r+a.height-t.height,L=this._subtractOverflows(a.width,p,v),W=this._subtractOverflows(a.height,C,P),ae=L*W;return{visibleArea:ae,isCompletelyWithinViewport:a.width*a.height===ae,fitsInViewportVertically:W===a.height,fitsInViewportHorizontally:L==a.width}}_canFitWithFlexibleDimensions(n,e,t){if(this._hasFlexibleDimensions){let o=t.bottom-e.y,a=t.right-e.x,s=Iu(this._overlayRef.getConfig().minHeight),r=Iu(this._overlayRef.getConfig().minWidth),c=n.fitsInViewportVertically||s!=null&&s<=o,d=n.fitsInViewportHorizontally||r!=null&&r<=a;return c&&d}return!1}_pushOverlayOnScreen(n,e,t){if(this._previousPushAmount&&this._positionLocked)return{x:n.x+this._previousPushAmount.x,y:n.y+this._previousPushAmount.y};let o=_u(e),a=this._viewportRect,s=Math.max(n.x+o.width-a.width,0),r=Math.max(n.y+o.height-a.height,0),c=Math.max(a.top-t.top-n.y,0),d=Math.max(a.left-t.left-n.x,0),p=0,v=0;return o.width<=a.width?p=d||-s:p=n.x<this._viewportMargin?a.left-t.left-n.x:0,o.height<=a.height?v=c||-r:v=n.y<this._viewportMargin?a.top-t.top-n.y:0,this._previousPushAmount={x:p,y:v},{x:n.x+p,y:n.y+v}}_applyPosition(n,e){if(this._setTransformOrigin(n),this._setOverlayElementStyles(e,n),this._setBoundingBoxStyles(e,n),n.panelClass&&this._addPanelClasses(n.panelClass),this._positionChanges.observers.length){let t=this._getScrollVisibility();if(n!==this._lastPosition||!this._lastScrollVisibility||!Pf(this._lastScrollVisibility,t)){let o=new Ea(n,t);this._positionChanges.next(o)}this._lastScrollVisibility=t}this._lastPosition=n,this._isInitialRender=!1}_setTransformOrigin(n){if(!this._transformOriginSelector)return;let e=this._boundingBox.querySelectorAll(this._transformOriginSelector),t,o=n.overlayY;n.overlayX==="center"?t="center":this._isRtl()?t=n.overlayX==="start"?"right":"left":t=n.overlayX==="start"?"left":"right";for(let a=0;a<e.length;a++)e[a].style.transformOrigin=`${t} ${o}`}_calculateBoundingBoxRect(n,e){let t=this._viewportRect,o=this._isRtl(),a,s,r;if(e.overlayY==="top")s=n.y,a=t.height-s+this._viewportMargin;else if(e.overlayY==="bottom")r=t.height-n.y+this._viewportMargin*2,a=t.height-r+this._viewportMargin;else{let P=Math.min(t.bottom-n.y+t.top,n.y),L=this._lastBoundingBoxSize.height;a=P*2,s=n.y-P,a>L&&!this._isInitialRender&&!this._growAfterOpen&&(s=n.y-L/2)}let c=e.overlayX==="start"&&!o||e.overlayX==="end"&&o,d=e.overlayX==="end"&&!o||e.overlayX==="start"&&o,p,v,C;if(d)C=t.width-n.x+this._viewportMargin*2,p=n.x-this._viewportMargin;else if(c)v=n.x,p=t.right-n.x;else{let P=Math.min(t.right-n.x+t.left,n.x),L=this._lastBoundingBoxSize.width;p=P*2,v=n.x-P,p>L&&!this._isInitialRender&&!this._growAfterOpen&&(v=n.x-L/2)}return{top:s,left:v,bottom:r,right:C,width:p,height:a}}_setBoundingBoxStyles(n,e){let t=this._calculateBoundingBoxRect(n,e);!this._isInitialRender&&!this._growAfterOpen&&(t.height=Math.min(t.height,this._lastBoundingBoxSize.height),t.width=Math.min(t.width,this._lastBoundingBoxSize.width));let o={};if(this._hasExactPosition())o.top=o.left="0",o.bottom=o.right=o.maxHeight=o.maxWidth="",o.width=o.height="100%";else{let a=this._overlayRef.getConfig().maxHeight,s=this._overlayRef.getConfig().maxWidth;o.height=be(t.height),o.top=be(t.top),o.bottom=be(t.bottom),o.width=be(t.width),o.left=be(t.left),o.right=be(t.right),e.overlayX==="center"?o.alignItems="center":o.alignItems=e.overlayX==="end"?"flex-end":"flex-start",e.overlayY==="center"?o.justifyContent="center":o.justifyContent=e.overlayY==="bottom"?"flex-end":"flex-start",a&&(o.maxHeight=be(a)),s&&(o.maxWidth=be(s))}this._lastBoundingBoxSize=t,Ci(this._boundingBox.style,o)}_resetBoundingBoxStyles(){Ci(this._boundingBox.style,{top:"0",left:"0",right:"0",bottom:"0",height:"",width:"",alignItems:"",justifyContent:""})}_resetOverlayElementStyles(){Ci(this._pane.style,{top:"",left:"",bottom:"",right:"",position:"",transform:""})}_setOverlayElementStyles(n,e){let t={},o=this._hasExactPosition(),a=this._hasFlexibleDimensions,s=this._overlayRef.getConfig();if(o){let p=this._viewportRuler.getViewportScrollPosition();Ci(t,this._getExactOverlayY(e,n,p)),Ci(t,this._getExactOverlayX(e,n,p))}else t.position="static";let r="",c=this._getOffset(e,"x"),d=this._getOffset(e,"y");c&&(r+=`translateX(${c}px) `),d&&(r+=`translateY(${d}px)`),t.transform=r.trim(),s.maxHeight&&(o?t.maxHeight=be(s.maxHeight):a&&(t.maxHeight="")),s.maxWidth&&(o?t.maxWidth=be(s.maxWidth):a&&(t.maxWidth="")),Ci(this._pane.style,t)}_getExactOverlayY(n,e,t){let o={top:"",bottom:""},a=this._getOverlayPoint(e,this._overlayRect,n);if(this._isPushed&&(a=this._pushOverlayOnScreen(a,this._overlayRect,t)),n.overlayY==="bottom"){let s=this._document.documentElement.clientHeight;o.bottom=`${s-(a.y+this._overlayRect.height)}px`}else o.top=be(a.y);return o}_getExactOverlayX(n,e,t){let o={left:"",right:""},a=this._getOverlayPoint(e,this._overlayRect,n);this._isPushed&&(a=this._pushOverlayOnScreen(a,this._overlayRect,t));let s;if(this._isRtl()?s=n.overlayX==="end"?"left":"right":s=n.overlayX==="end"?"right":"left",s==="right"){let r=this._document.documentElement.clientWidth;o.right=`${r-(a.x+this._overlayRect.width)}px`}else o.left=be(a.x);return o}_getScrollVisibility(){let n=this._getOriginRect(),e=this._pane.getBoundingClientRect(),t=this._scrollables.map(o=>o.getElementRef().nativeElement.getBoundingClientRect());return{isOriginClipped:bu(n,t),isOriginOutsideView:ol(n,t),isOverlayClipped:bu(e,t),isOverlayOutsideView:ol(e,t)}}_subtractOverflows(n,...e){return e.reduce((t,o)=>t-Math.max(o,0),n)}_getNarrowedViewportRect(){let n=this._document.documentElement.clientWidth,e=this._document.documentElement.clientHeight,t=this._viewportRuler.getViewportScrollPosition();return{top:t.top+this._viewportMargin,left:t.left+this._viewportMargin,right:t.left+n-this._viewportMargin,bottom:t.top+e-this._viewportMargin,width:n-2*this._viewportMargin,height:e-2*this._viewportMargin}}_isRtl(){return this._overlayRef.getDirection()==="rtl"}_hasExactPosition(){return!this._hasFlexibleDimensions||this._isPushed}_getOffset(n,e){return e==="x"?n.offsetX==null?this._offsetX:n.offsetX:n.offsetY==null?this._offsetY:n.offsetY}_validatePositions(){}_addPanelClasses(n){this._pane&&en(n).forEach(e=>{e!==""&&this._appliedPanelClasses.indexOf(e)===-1&&(this._appliedPanelClasses.push(e),this._pane.classList.add(e))})}_clearPanelClasses(){this._pane&&(this._appliedPanelClasses.forEach(n=>{this._pane.classList.remove(n)}),this._appliedPanelClasses=[])}_getOriginRect(){let n=this._origin;if(n instanceof R)return n.nativeElement.getBoundingClientRect();if(n instanceof Element)return n.getBoundingClientRect();let e=n.width||0,t=n.height||0;return{top:n.y,bottom:n.y+t,left:n.x,right:n.x+e,height:t,width:e}}};function Ci(i,n){for(let e in n)n.hasOwnProperty(e)&&(i[e]=n[e]);return i}function Iu(i){if(typeof i!="number"&&i!=null){let[n,e]=i.split(Of);return!e||e==="px"?parseFloat(n):null}return i||null}function _u(i){return{top:Math.floor(i.top),right:Math.floor(i.right),bottom:Math.floor(i.bottom),left:Math.floor(i.left),width:Math.floor(i.width),height:Math.floor(i.height)}}function Pf(i,n){return i===n?!0:i.isOriginClipped===n.isOriginClipped&&i.isOriginOutsideView===n.isOriginOutsideView&&i.isOverlayClipped===n.isOverlayClipped&&i.isOverlayOutsideView===n.isOverlayOutsideView}var wu="cdk-global-overlay-wrapper";function Ou(i){return new Ra}var Ra=class{_overlayRef;_cssPosition="static";_topOffset="";_bottomOffset="";_alignItems="";_xPosition="";_xOffset="";_width="";_height="";_isDisposed=!1;attach(n){let e=n.getConfig();this._overlayRef=n,this._width&&!e.width&&n.updateSize({width:this._width}),this._height&&!e.height&&n.updateSize({height:this._height}),n.hostElement.classList.add(wu),this._isDisposed=!1}top(n=""){return this._bottomOffset="",this._topOffset=n,this._alignItems="flex-start",this}left(n=""){return this._xOffset=n,this._xPosition="left",this}bottom(n=""){return this._topOffset="",this._bottomOffset=n,this._alignItems="flex-end",this}right(n=""){return this._xOffset=n,this._xPosition="right",this}start(n=""){return this._xOffset=n,this._xPosition="start",this}end(n=""){return this._xOffset=n,this._xPosition="end",this}width(n=""){return this._overlayRef?this._overlayRef.updateSize({width:n}):this._width=n,this}height(n=""){return this._overlayRef?this._overlayRef.updateSize({height:n}):this._height=n,this}centerHorizontally(n=""){return this.left(n),this._xPosition="center",this}centerVertically(n=""){return this.top(n),this._alignItems="center",this}apply(){if(!this._overlayRef||!this._overlayRef.hasAttached())return;let n=this._overlayRef.overlayElement.style,e=this._overlayRef.hostElement.style,t=this._overlayRef.getConfig(),{width:o,height:a,maxWidth:s,maxHeight:r}=t,c=(o==="100%"||o==="100vw")&&(!s||s==="100%"||s==="100vw"),d=(a==="100%"||a==="100vh")&&(!r||r==="100%"||r==="100vh"),p=this._xPosition,v=this._xOffset,C=this._overlayRef.getConfig().direction==="rtl",P="",L="",W="";c?W="flex-start":p==="center"?(W="center",C?L=v:P=v):C?p==="left"||p==="end"?(W="flex-end",P=v):(p==="right"||p==="start")&&(W="flex-start",L=v):p==="left"||p==="start"?(W="flex-start",P=v):(p==="right"||p==="end")&&(W="flex-end",L=v),n.position=this._cssPosition,n.marginLeft=c?"0":P,n.marginTop=d?"0":this._topOffset,n.marginBottom=this._bottomOffset,n.marginRight=c?"0":L,e.justifyContent=W,e.alignItems=d?"flex-start":this._alignItems}dispose(){if(this._isDisposed||!this._overlayRef)return;let n=this._overlayRef.overlayElement.style,e=this._overlayRef.hostElement,t=e.style;e.classList.remove(wu),t.justifyContent=t.alignItems=n.marginTop=n.marginBottom=n.marginLeft=n.marginRight=n.position="",this._overlayRef=null,this._isDisposed=!0}},Pu=(()=>{class i{_injector=l(V);constructor(){}global(){return Ou()}flexibleConnectedTo(e){return Sa(this._injector,e)}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();function Oa(i,n){i.get(Te).load(Ru);let e=i.get(Su),t=i.get(D),o=i.get(vi),a=i.get(pt),s=i.get(dt),r=t.createElement("div"),c=t.createElement("div");c.id=o.getId("cdk-overlay-"),c.classList.add("cdk-overlay-pane"),r.appendChild(c),e.getContainerElement().appendChild(r);let d=new ho(c,a,i),p=new hn(n),v=i.get(Ce,null,{optional:!0})||i.get(qe).createRenderer(null,null);return p.direction=p.direction||s.value,new xa(d,r,c,p,i.get(F),i.get(xu),t,i.get(yt),i.get(Tu),n?.disableAnimations??i.get(Si,null,{optional:!0})==="NoopAnimations",i.get(ze),v)}var qu=(()=>{class i{scrollStrategies=l(Du);_positionBuilder=l(Pu);_injector=l(V);constructor(){}create(e){return Oa(this._injector,e)}position(){return this._positionBuilder}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();var qf=new A("cdk-connected-overlay-scroll-strategy",{providedIn:"root",factory:()=>{let i=l(V);return()=>ki(i)}});function Ff(i){let n=l(V);return()=>ki(n)}var Mf={provide:qf,useFactory:Ff},sl=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({providers:[qu,Mf],imports:[Qt,yu,po,po]})}return i})();var ii=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[z,z]})}return i})();var Lf=["mat-menu-item",""],Gf=[[["mat-icon"],["","matMenuItemIcon",""]],"*"],Kf=["mat-icon, [matMenuItemIcon]","*"];function zf(i,n){i&1&&(Tt(),u(0,"svg",2),ie(1,"polygon",3),h())}var Bf=["*"];function jf(i,n){if(i&1){let e=Ie();Q(0,"div",0),sc("click",function(){re(e);let o=k();return le(o.closed.emit("click"))})("animationstart",function(o){re(e);let a=k();return le(a._onAnimationStart(o.animationName))})("animationend",function(o){re(e);let a=k();return le(a._onAnimationDone(o.animationName))})("animationcancel",function(o){re(e);let a=k();return le(a._onAnimationDone(o.animationName))}),Q(1,"div",1),T(2),ne()()}if(i&2){let e=k();Me(e._classList),N("mat-menu-panel-animations-disabled",e._animationsDisabled)("mat-menu-panel-exit-animation",e._panelAnimationState==="void")("mat-menu-panel-animating",e._isAnimating),Rn("id",e.panelId),X("aria-label",e.ariaLabel||null)("aria-labelledby",e.ariaLabelledby||null)("aria-describedby",e.ariaDescribedby||null)}}var dl=new A("MAT_MENU_PANEL"),fo=(()=>{class i{_elementRef=l(R);_document=l(D);_focusMonitor=l(Jt);_parentMenu=l(dl,{optional:!0});_changeDetectorRef=l(me);role="menuitem";disabled=!1;disableRipple=!1;_hovered=new S;_focused=new S;_highlighted=!1;_triggersSubmenu=!1;constructor(){l(Te).load(ei),this._parentMenu?.addItem?.(this)}focus(e,t){this._focusMonitor&&e?this._focusMonitor.focusVia(this._getHostElement(),e,t):this._getHostElement().focus(t),this._focused.next(this)}ngAfterViewInit(){this._focusMonitor&&this._focusMonitor.monitor(this._elementRef,!1)}ngOnDestroy(){this._focusMonitor&&this._focusMonitor.stopMonitoring(this._elementRef),this._parentMenu&&this._parentMenu.removeItem&&this._parentMenu.removeItem(this),this._hovered.complete(),this._focused.complete()}_getTabIndex(){return this.disabled?"-1":"0"}_getHostElement(){return this._elementRef.nativeElement}_checkDisabled(e){this.disabled&&(e.preventDefault(),e.stopPropagation())}_handleMouseEnter(){this._hovered.next(this)}getLabel(){let e=this._elementRef.nativeElement.cloneNode(!0),t=e.querySelectorAll("mat-icon, .material-icons");for(let o=0;o<t.length;o++)t[o].remove();return e.textContent?.trim()||""}_setHighlighted(e){this._highlighted=e,this._changeDetectorRef.markForCheck()}_setTriggersSubmenu(e){this._triggersSubmenu=e,this._changeDetectorRef.markForCheck()}_hasFocus(){return this._document&&this._document.activeElement===this._getHostElement()}static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["","mat-menu-item",""]],hostAttrs:[1,"mat-mdc-menu-item","mat-focus-indicator"],hostVars:8,hostBindings:function(t,o){t&1&&he("click",function(s){return o._checkDisabled(s)})("mouseenter",function(){return o._handleMouseEnter()}),t&2&&(X("role",o.role)("tabindex",o._getTabIndex())("aria-disabled",o.disabled)("disabled",o.disabled||null),N("mat-mdc-menu-item-highlighted",o._highlighted)("mat-mdc-menu-item-submenu-trigger",o._triggersSubmenu))},inputs:{role:"role",disabled:[2,"disabled","disabled",K],disableRipple:[2,"disableRipple","disableRipple",K]},exportAs:["matMenuItem"],attrs:Lf,ngContentSelectors:Kf,decls:5,vars:3,consts:[[1,"mat-mdc-menu-item-text"],["matRipple","",1,"mat-mdc-menu-ripple",3,"matRippleDisabled","matRippleTrigger"],["viewBox","0 0 5 10","focusable","false","aria-hidden","true",1,"mat-mdc-menu-submenu-icon"],["points","0,0 5,5 0,10"]],template:function(t,o){t&1&&(Y(Gf),T(0),u(1,"span",0),T(2,1),h(),ie(3,"div",1),J(4,zf,2,0,":svg:svg",2)),t&2&&(f(3),M("matRippleDisabled",o.disableRipple||o.disabled)("matRippleTrigger",o._getHostElement()),f(),$(o._triggersSubmenu?4:-1))},dependencies:[_a],encapsulation:2,changeDetection:0})}return i})();var Vf=new A("MatMenuContent");var Wf=new A("mat-menu-default-options",{providedIn:"root",factory:Uf});function Uf(){return{overlapTrigger:!1,xPosition:"after",yPosition:"below",backdropClass:"cdk-overlay-transparent-backdrop"}}var rl="_mat-menu-enter",Pa="_mat-menu-exit",mn=(()=>{class i{_elementRef=l(R);_changeDetectorRef=l(me);_injector=l(V);_keyManager;_xPosition;_yPosition;_firstItemFocusRef;_exitFallbackTimeout;_animationsDisabled=Le();_allItems;_directDescendantItems=new zt;_classList={};_panelAnimationState="void";_animationDone=new S;_isAnimating=!1;parentMenu;direction;overlayPanelClass;backdropClass;ariaLabel;ariaLabelledby;ariaDescribedby;get xPosition(){return this._xPosition}set xPosition(e){this._xPosition=e,this.setPositionClasses()}get yPosition(){return this._yPosition}set yPosition(e){this._yPosition=e,this.setPositionClasses()}templateRef;items;lazyContent;overlapTrigger;hasBackdrop;set panelClass(e){let t=this._previousPanelClass,o=b({},this._classList);t&&t.length&&t.split(" ").forEach(a=>{o[a]=!1}),this._previousPanelClass=e,e&&e.length&&(e.split(" ").forEach(a=>{o[a]=!0}),this._elementRef.nativeElement.className=""),this._classList=o}_previousPanelClass;get classList(){return this.panelClass}set classList(e){this.panelClass=e}closed=new Z;close=this.closed;panelId=l(vi).getId("mat-menu-panel-");constructor(){let e=l(Wf);this.overlayPanelClass=e.overlayPanelClass||"",this._xPosition=e.xPosition,this._yPosition=e.yPosition,this.backdropClass=e.backdropClass,this.overlapTrigger=e.overlapTrigger,this.hasBackdrop=e.hasBackdrop}ngOnInit(){this.setPositionClasses()}ngAfterContentInit(){this._updateDirectDescendants(),this._keyManager=new ao(this._directDescendantItems).withWrap().withTypeAhead().withHomeAndEnd(),this._keyManager.tabOut.subscribe(()=>this.closed.emit("tab")),this._directDescendantItems.changes.pipe(tt(this._directDescendantItems),Ae(e=>Nt(...e.map(t=>t._focused)))).subscribe(e=>this._keyManager.updateActiveItem(e)),this._directDescendantItems.changes.subscribe(e=>{let t=this._keyManager;if(this._panelAnimationState==="enter"&&t.activeItem?._hasFocus()){let o=e.toArray(),a=Math.max(0,Math.min(o.length-1,t.activeItemIndex||0));o[a]&&!o[a].disabled?t.setActiveItem(a):t.setNextItemActive()}})}ngOnDestroy(){this._keyManager?.destroy(),this._directDescendantItems.destroy(),this.closed.complete(),this._firstItemFocusRef?.destroy(),clearTimeout(this._exitFallbackTimeout)}_hovered(){return this._directDescendantItems.changes.pipe(tt(this._directDescendantItems),Ae(t=>Nt(...t.map(o=>o._hovered))))}addItem(e){}removeItem(e){}_handleKeydown(e){let t=e.keyCode,o=this._keyManager;switch(t){case 27:tn(e)||(e.preventDefault(),this.closed.emit("keydown"));break;case 37:this.parentMenu&&this.direction==="ltr"&&this.closed.emit("keydown");break;case 39:this.parentMenu&&this.direction==="rtl"&&this.closed.emit("keydown");break;default:(t===38||t===40)&&o.setFocusOrigin("keyboard"),o.onKeydown(e);return}}focusFirstItem(e="program"){this._firstItemFocusRef?.destroy(),this._firstItemFocusRef=ve(()=>{let t=this._resolvePanel();if(!t||!t.contains(document.activeElement)){let o=this._keyManager;o.setFocusOrigin(e).setFirstItemActive(),!o.activeItem&&t&&t.focus()}},{injector:this._injector})}resetActiveItem(){this._keyManager.setActiveItem(-1)}setElevation(e){}setPositionClasses(e=this.xPosition,t=this.yPosition){this._classList=ge(b({},this._classList),{"mat-menu-before":e==="before","mat-menu-after":e==="after","mat-menu-above":t==="above","mat-menu-below":t==="below"}),this._changeDetectorRef.markForCheck()}_onAnimationDone(e){let t=e===Pa;(t||e===rl)&&(t&&(clearTimeout(this._exitFallbackTimeout),this._exitFallbackTimeout=void 0),this._animationDone.next(t?"void":"enter"),this._isAnimating=!1)}_onAnimationStart(e){(e===rl||e===Pa)&&(this._isAnimating=!0)}_setIsOpen(e){if(this._panelAnimationState=e?"enter":"void",e){if(this._keyManager.activeItemIndex===0){let t=this._resolvePanel();t&&(t.scrollTop=0)}}else this._animationsDisabled||(this._exitFallbackTimeout=setTimeout(()=>this._onAnimationDone(Pa),200));this._animationsDisabled&&setTimeout(()=>{this._onAnimationDone(e?rl:Pa)}),this._changeDetectorRef.markForCheck()}_updateDirectDescendants(){this._allItems.changes.pipe(tt(this._allItems)).subscribe(e=>{this._directDescendantItems.reset(e.filter(t=>t._parentMenu===this)),this._directDescendantItems.notifyOnChanges()})}_resolvePanel(){let e=null;return this._directDescendantItems.length&&(e=this._directDescendantItems.first._getHostElement().closest('[role="menu"]')),e}static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["mat-menu"]],contentQueries:function(t,o,a){if(t&1&&(se(a,Vf,5),se(a,fo,5),se(a,fo,4)),t&2){let s;B(s=j())&&(o.lazyContent=s.first),B(s=j())&&(o._allItems=s),B(s=j())&&(o.items=s)}},viewQuery:function(t,o){if(t&1&&xe(Pe,5),t&2){let a;B(a=j())&&(o.templateRef=a.first)}},hostVars:3,hostBindings:function(t,o){t&2&&X("aria-label",null)("aria-labelledby",null)("aria-describedby",null)},inputs:{backdropClass:"backdropClass",ariaLabel:[0,"aria-label","ariaLabel"],ariaLabelledby:[0,"aria-labelledby","ariaLabelledby"],ariaDescribedby:[0,"aria-describedby","ariaDescribedby"],xPosition:"xPosition",yPosition:"yPosition",overlapTrigger:[2,"overlapTrigger","overlapTrigger",K],hasBackdrop:[2,"hasBackdrop","hasBackdrop",e=>e==null?null:K(e)],panelClass:[0,"class","panelClass"],classList:"classList"},outputs:{closed:"closed",close:"close"},exportAs:["matMenu"],features:[de([{provide:dl,useExisting:i}])],ngContentSelectors:Bf,decls:1,vars:0,consts:[["tabindex","-1","role","menu",1,"mat-mdc-menu-panel",3,"click","animationstart","animationend","animationcancel","id"],[1,"mat-mdc-menu-content"]],template:function(t,o){t&1&&(Y(),ic(0,jf,3,12,"ng-template"))},styles:[`mat-menu{display:none}.mat-mdc-menu-content{margin:0;padding:8px 0;outline:0}.mat-mdc-menu-content,.mat-mdc-menu-content .mat-mdc-menu-item .mat-mdc-menu-item-text{-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;flex:1;white-space:normal;font-family:var(--mat-menu-item-label-text-font, var(--mat-sys-label-large-font));line-height:var(--mat-menu-item-label-text-line-height, var(--mat-sys-label-large-line-height));font-size:var(--mat-menu-item-label-text-size, var(--mat-sys-label-large-size));letter-spacing:var(--mat-menu-item-label-text-tracking, var(--mat-sys-label-large-tracking));font-weight:var(--mat-menu-item-label-text-weight, var(--mat-sys-label-large-weight))}@keyframes _mat-menu-enter{from{opacity:0;transform:scale(0.8)}to{opacity:1;transform:none}}@keyframes _mat-menu-exit{from{opacity:1}to{opacity:0}}.mat-mdc-menu-panel{min-width:112px;max-width:280px;overflow:auto;box-sizing:border-box;outline:0;animation:_mat-menu-enter 120ms cubic-bezier(0, 0, 0.2, 1);border-radius:var(--mat-menu-container-shape, var(--mat-sys-corner-extra-small));background-color:var(--mat-menu-container-color, var(--mat-sys-surface-container));box-shadow:var(--mat-menu-container-elevation-shadow, 0px 3px 1px -2px rgba(0, 0, 0, 0.2), 0px 2px 2px 0px rgba(0, 0, 0, 0.14), 0px 1px 5px 0px rgba(0, 0, 0, 0.12));will-change:transform,opacity}.mat-mdc-menu-panel.mat-menu-panel-exit-animation{animation:_mat-menu-exit 100ms 25ms linear forwards}.mat-mdc-menu-panel.mat-menu-panel-animations-disabled{animation:none}.mat-mdc-menu-panel.mat-menu-panel-animating{pointer-events:none}.mat-mdc-menu-panel.mat-menu-panel-animating:has(.mat-mdc-menu-content:empty){display:none}@media(forced-colors: active){.mat-mdc-menu-panel{outline:solid 1px}}.mat-mdc-menu-panel .mat-divider{color:var(--mat-menu-divider-color, var(--mat-sys-surface-variant));margin-bottom:var(--mat-menu-divider-bottom-spacing, 8px);margin-top:var(--mat-menu-divider-top-spacing, 8px)}.mat-mdc-menu-item{display:flex;position:relative;align-items:center;justify-content:flex-start;overflow:hidden;padding:0;cursor:pointer;width:100%;text-align:left;box-sizing:border-box;color:inherit;font-size:inherit;background:none;text-decoration:none;margin:0;min-height:48px;padding-left:var(--mat-menu-item-leading-spacing, 12px);padding-right:var(--mat-menu-item-trailing-spacing, 12px);-webkit-user-select:none;user-select:none;cursor:pointer;outline:none;border:none;-webkit-tap-highlight-color:rgba(0,0,0,0)}.mat-mdc-menu-item::-moz-focus-inner{border:0}[dir=rtl] .mat-mdc-menu-item{padding-left:var(--mat-menu-item-trailing-spacing, 12px);padding-right:var(--mat-menu-item-leading-spacing, 12px)}.mat-mdc-menu-item:has(.material-icons,mat-icon,[matButtonIcon]){padding-left:var(--mat-menu-item-with-icon-leading-spacing, 12px);padding-right:var(--mat-menu-item-with-icon-trailing-spacing, 12px)}[dir=rtl] .mat-mdc-menu-item:has(.material-icons,mat-icon,[matButtonIcon]){padding-left:var(--mat-menu-item-with-icon-trailing-spacing, 12px);padding-right:var(--mat-menu-item-with-icon-leading-spacing, 12px)}.mat-mdc-menu-item,.mat-mdc-menu-item:visited,.mat-mdc-menu-item:link{color:var(--mat-menu-item-label-text-color, var(--mat-sys-on-surface))}.mat-mdc-menu-item .mat-icon-no-color,.mat-mdc-menu-item .mat-mdc-menu-submenu-icon{color:var(--mat-menu-item-icon-color, var(--mat-sys-on-surface-variant))}.mat-mdc-menu-item[disabled]{cursor:default;opacity:.38}.mat-mdc-menu-item[disabled]::after{display:block;position:absolute;content:"";top:0;left:0;bottom:0;right:0}.mat-mdc-menu-item:focus{outline:0}.mat-mdc-menu-item .mat-icon{flex-shrink:0;margin-right:var(--mat-menu-item-spacing, 12px);height:var(--mat-menu-item-icon-size, 24px);width:var(--mat-menu-item-icon-size, 24px)}[dir=rtl] .mat-mdc-menu-item{text-align:right}[dir=rtl] .mat-mdc-menu-item .mat-icon{margin-right:0;margin-left:var(--mat-menu-item-spacing, 12px)}.mat-mdc-menu-item:not([disabled]):hover{background-color:var(--mat-menu-item-hover-state-layer-color, color-mix(in srgb, var(--mat-sys-on-surface) calc(var(--mat-sys-hover-state-layer-opacity) * 100%), transparent))}.mat-mdc-menu-item:not([disabled]).cdk-program-focused,.mat-mdc-menu-item:not([disabled]).cdk-keyboard-focused,.mat-mdc-menu-item:not([disabled]).mat-mdc-menu-item-highlighted{background-color:var(--mat-menu-item-focus-state-layer-color, color-mix(in srgb, var(--mat-sys-on-surface) calc(var(--mat-sys-focus-state-layer-opacity) * 100%), transparent))}@media(forced-colors: active){.mat-mdc-menu-item{margin-top:1px}}.mat-mdc-menu-submenu-icon{width:var(--mat-menu-item-icon-size, 24px);height:10px;fill:currentColor;padding-left:var(--mat-menu-item-spacing, 12px)}[dir=rtl] .mat-mdc-menu-submenu-icon{padding-right:var(--mat-menu-item-spacing, 12px);padding-left:0}[dir=rtl] .mat-mdc-menu-submenu-icon polygon{transform:scaleX(-1);transform-origin:center}@media(forced-colors: active){.mat-mdc-menu-submenu-icon{fill:CanvasText}}.mat-mdc-menu-item .mat-mdc-menu-ripple{top:0;left:0;right:0;bottom:0;position:absolute;pointer-events:none}
`],encapsulation:2,changeDetection:0})}return i})(),Fu=new A("mat-menu-scroll-strategy",{providedIn:"root",factory:()=>{let i=l(V);return()=>ki(i)}});function Hf(i){let n=l(V);return()=>ki(n)}var Yf={provide:Fu,deps:[],useFactory:Hf};var pn=new WeakMap,Zf=(()=>{class i{_canHaveBackdrop;_element=l(R);_viewContainerRef=l(Fe);_menuItemInstance=l(fo,{optional:!0,self:!0});_dir=l(dt,{optional:!0});_focusMonitor=l(Jt);_ngZone=l(F);_injector=l(V);_scrollStrategy=l(Fu);_changeDetectorRef=l(me);_animationsDisabled=Le();_portal;_overlayRef=null;_menuOpen=!1;_closingActionsSubscription=De.EMPTY;_menuCloseSubscription=De.EMPTY;_pendingRemoval;_parentMaterialMenu;_parentInnerPadding;_openedBy=void 0;get _menu(){return this._menuInternal}set _menu(e){e!==this._menuInternal&&(this._menuInternal=e,this._menuCloseSubscription.unsubscribe(),e&&(this._parentMaterialMenu,this._menuCloseSubscription=e.close.subscribe(t=>{this._destroyMenu(t),(t==="click"||t==="tab")&&this._parentMaterialMenu&&this._parentMaterialMenu.closed.emit(t)})),this._menuItemInstance?._setTriggersSubmenu(this._triggersSubmenu()))}_menuInternal;constructor(e){this._canHaveBackdrop=e;let t=l(dl,{optional:!0});this._parentMaterialMenu=t instanceof mn?t:void 0}ngOnDestroy(){this._menu&&this._ownsMenu(this._menu)&&pn.delete(this._menu),this._pendingRemoval?.unsubscribe(),this._menuCloseSubscription.unsubscribe(),this._closingActionsSubscription.unsubscribe(),this._overlayRef&&(this._overlayRef.dispose(),this._overlayRef=null)}get menuOpen(){return this._menuOpen}get dir(){return this._dir&&this._dir.value==="rtl"?"rtl":"ltr"}_triggersSubmenu(){return!!(this._menuItemInstance&&this._parentMaterialMenu&&this._menu)}_closeMenu(){this._menu?.close.emit()}_openMenu(e){let t=this._menu;if(this._menuOpen||!t)return;this._pendingRemoval?.unsubscribe();let o=pn.get(t);pn.set(t,this),o&&o!==this&&o._closeMenu();let a=this._createOverlay(t),s=a.getConfig(),r=s.positionStrategy;this._setPosition(t,r),this._canHaveBackdrop?s.hasBackdrop=t.hasBackdrop==null?!this._triggersSubmenu():t.hasBackdrop:s.hasBackdrop=!1,a.hasAttached()||(a.attach(this._getPortal(t)),t.lazyContent?.attach(this.menuData)),this._closingActionsSubscription=this._menuClosingActions().subscribe(()=>this._closeMenu()),t.parentMenu=this._triggersSubmenu()?this._parentMaterialMenu:void 0,t.direction=this.dir,e&&t.focusFirstItem(this._openedBy||"program"),this._setIsMenuOpen(!0),t instanceof mn&&(t._setIsOpen(!0),t._directDescendantItems.changes.pipe(pe(t.close)).subscribe(()=>{r.withLockedPosition(!1).reapplyLastPosition(),r.withLockedPosition(!0)}))}focus(e,t){this._focusMonitor&&e?this._focusMonitor.focusVia(this._element,e,t):this._element.nativeElement.focus(t)}_destroyMenu(e){let t=this._overlayRef,o=this._menu;!t||!this.menuOpen||(this._closingActionsSubscription.unsubscribe(),this._pendingRemoval?.unsubscribe(),o instanceof mn&&this._ownsMenu(o)?(this._pendingRemoval=o._animationDone.pipe(Ke(1)).subscribe(()=>{t.detach(),pn.has(o)||o.lazyContent?.detach()}),o._setIsOpen(!1)):(t.detach(),o?.lazyContent?.detach()),o&&this._ownsMenu(o)&&pn.delete(o),this.restoreFocus&&(e==="keydown"||!this._openedBy||!this._triggersSubmenu())&&this.focus(this._openedBy),this._openedBy=void 0,this._setIsMenuOpen(!1))}_setIsMenuOpen(e){e!==this._menuOpen&&(this._menuOpen=e,this._menuOpen?this.menuOpened.emit():this.menuClosed.emit(),this._triggersSubmenu()&&this._menuItemInstance._setHighlighted(e),this._changeDetectorRef.markForCheck())}_createOverlay(e){if(!this._overlayRef){let t=this._getOverlayConfig(e);this._subscribeToPositions(e,t.positionStrategy),this._overlayRef=Oa(this._injector,t),this._overlayRef.keydownEvents().subscribe(o=>{this._menu instanceof mn&&this._menu._handleKeydown(o)})}return this._overlayRef}_getOverlayConfig(e){return new hn({positionStrategy:Sa(this._injector,this._getOverlayOrigin()).withLockedPosition().withGrowAfterOpen().withTransformOriginOn(".mat-menu-panel, .mat-mdc-menu-panel"),backdropClass:e.backdropClass||"cdk-overlay-transparent-backdrop",panelClass:e.overlayPanelClass,scrollStrategy:this._scrollStrategy(),direction:this._dir||"ltr",disableAnimations:this._animationsDisabled})}_subscribeToPositions(e,t){e.setPositionClasses&&t.positionChanges.subscribe(o=>{this._ngZone.run(()=>{let a=o.connectionPair.overlayX==="start"?"after":"before",s=o.connectionPair.overlayY==="top"?"below":"above";e.setPositionClasses(a,s)})})}_setPosition(e,t){let[o,a]=e.xPosition==="before"?["end","start"]:["start","end"],[s,r]=e.yPosition==="above"?["bottom","top"]:["top","bottom"],[c,d]=[s,r],[p,v]=[o,a],C=0;if(this._triggersSubmenu()){if(v=o=e.xPosition==="before"?"start":"end",a=p=o==="end"?"start":"end",this._parentMaterialMenu){if(this._parentInnerPadding==null){let P=this._parentMaterialMenu.items.first;this._parentInnerPadding=P?P._getHostElement().offsetTop:0}C=s==="bottom"?this._parentInnerPadding:-this._parentInnerPadding}}else e.overlapTrigger||(c=s==="top"?"bottom":"top",d=r==="top"?"bottom":"top");t.withPositions([{originX:o,originY:c,overlayX:p,overlayY:s,offsetY:C},{originX:a,originY:c,overlayX:v,overlayY:s,offsetY:C},{originX:o,originY:d,overlayX:p,overlayY:r,offsetY:-C},{originX:a,originY:d,overlayX:v,overlayY:r,offsetY:-C}])}_menuClosingActions(){let e=this._getOutsideClickStream(this._overlayRef),t=this._overlayRef.detachments(),o=this._parentMaterialMenu?this._parentMaterialMenu.closed:I(),a=this._parentMaterialMenu?this._parentMaterialMenu._hovered().pipe(ue(s=>this._menuOpen&&s!==this._menuItemInstance)):I();return Nt(e,o,a,t)}_getPortal(e){return(!this._portal||this._portal.templateRef!==e.templateRef)&&(this._portal=new cn(e.templateRef,this._viewContainerRef)),this._portal}_ownsMenu(e){return pn.get(e)===this}static \u0275fac=function(t){Pi()};static \u0275dir=_({type:i})}return i})(),Mu=(()=>{class i extends Zf{_cleanupTouchstart;_hoverSubscription=De.EMPTY;get _deprecatedMatMenuTriggerFor(){return this.menu}set _deprecatedMatMenuTriggerFor(e){this.menu=e}get menu(){return this._menu}set menu(e){this._menu=e}menuData;restoreFocus=!0;menuOpened=new Z;onMenuOpen=this.menuOpened;menuClosed=new Z;onMenuClose=this.menuClosed;constructor(){super(!0);let e=l(Ce);this._cleanupTouchstart=e.listen(this._element.nativeElement,"touchstart",t=>{gi(t)||(this._openedBy="touch")},{passive:!0})}triggersSubmenu(){return super._triggersSubmenu()}toggleMenu(){return this.menuOpen?this.closeMenu():this.openMenu()}openMenu(){this._openMenu(!0)}closeMenu(){this._closeMenu()}updatePosition(){this._overlayRef?.updatePosition()}ngAfterContentInit(){this._handleHover()}ngOnDestroy(){super.ngOnDestroy(),this._cleanupTouchstart(),this._hoverSubscription.unsubscribe()}_getOverlayOrigin(){return this._element}_getOutsideClickStream(e){return e.backdropClick()}_handleMousedown(e){yi(e)||(this._openedBy=e.button===0?"mouse":void 0,this.triggersSubmenu()&&e.preventDefault())}_handleKeydown(e){let t=e.keyCode;(t===13||t===32)&&(this._openedBy="keyboard"),this.triggersSubmenu()&&(t===39&&this.dir==="ltr"||t===37&&this.dir==="rtl")&&(this._openedBy="keyboard",this.openMenu())}_handleClick(e){this.triggersSubmenu()?(e.stopPropagation(),this.openMenu()):this.toggleMenu()}_handleHover(){this.triggersSubmenu()&&this._parentMaterialMenu&&(this._hoverSubscription=this._parentMaterialMenu._hovered().subscribe(e=>{e===this._menuItemInstance&&!e.disabled&&(this._openedBy="mouse",this._openMenu(!1))}))}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","mat-menu-trigger-for",""],["","matMenuTriggerFor",""]],hostAttrs:[1,"mat-mdc-menu-trigger"],hostVars:3,hostBindings:function(t,o){t&1&&he("click",function(s){return o._handleClick(s)})("mousedown",function(s){return o._handleMousedown(s)})("keydown",function(s){return o._handleKeydown(s)}),t&2&&X("aria-haspopup",o.menu?"menu":null)("aria-expanded",o.menuOpen)("aria-controls",o.menuOpen?o.menu==null?null:o.menu.panelId:null)},inputs:{_deprecatedMatMenuTriggerFor:[0,"mat-menu-trigger-for","_deprecatedMatMenuTriggerFor"],menu:[0,"matMenuTriggerFor","menu"],menuData:[0,"matMenuTriggerData","menuData"],restoreFocus:[0,"matMenuTriggerRestoreFocus","restoreFocus"]},outputs:{menuOpened:"menuOpened",onMenuOpen:"onMenuOpen",menuClosed:"menuClosed",onMenuClose:"onMenuClose"},exportAs:["matMenuTrigger"],features:[H]})}return i})();var qa=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({providers:[Yf],imports:[ii,z,sl,_i,z]})}return i})(),Nu={transformMenu:{type:7,name:"transformMenu",definitions:[{type:0,name:"void",styles:{type:6,styles:{opacity:0,transform:"scale(0.8)"},offset:null}},{type:1,expr:"void => enter",animation:{type:4,styles:{type:6,styles:{opacity:1,transform:"scale(1)"},offset:null},timings:"120ms cubic-bezier(0, 0, 0.2, 1)"},options:null},{type:1,expr:"* => void",animation:{type:4,styles:{type:6,styles:{opacity:0},offset:null},timings:"100ms 25ms linear"},options:null}],options:{}},fadeInItems:{type:7,name:"fadeInItems",definitions:[{type:0,name:"showing",styles:{type:6,styles:{opacity:1},offset:null}},{type:1,expr:"void => *",animation:[{type:6,styles:{opacity:0},offset:null},{type:4,styles:null,timings:"400ms 100ms cubic-bezier(0.55, 0, 0.55, 0.2)"}],options:null}],options:{}}},h2=Nu.fadeInItems,p2=Nu.transformMenu;var Jf={capture:!0},$f=["focus","mousedown","mouseenter","touchstart"],ul="mat-ripple-loader-uninitialized",hl="mat-ripple-loader-class-name",Lu="mat-ripple-loader-centered",Fa="mat-ripple-loader-disabled",Gu=(()=>{class i{_document=l(D);_animationsDisabled=Le();_globalRippleOptions=l(co,{optional:!0});_platform=l(oe);_ngZone=l(F);_injector=l(V);_eventCleanups;_hosts=new Map;constructor(){let e=l(qe).createRenderer(null,null);this._eventCleanups=this._ngZone.runOutsideAngular(()=>$f.map(t=>e.listen(this._document,t,this._onInteraction,Jf)))}ngOnDestroy(){let e=this._hosts.keys();for(let t of e)this.destroyRipple(t);this._eventCleanups.forEach(t=>t())}configureRipple(e,t){e.setAttribute(ul,this._globalRippleOptions?.namespace??""),(t.className||!e.hasAttribute(hl))&&e.setAttribute(hl,t.className||""),t.centered&&e.setAttribute(Lu,""),t.disabled&&e.setAttribute(Fa,"")}setDisabled(e,t){let o=this._hosts.get(e);o?(o.target.rippleDisabled=t,!t&&!o.hasSetUpEvents&&(o.hasSetUpEvents=!0,o.renderer.setupTriggerEvents(e))):t?e.setAttribute(Fa,""):e.removeAttribute(Fa)}_onInteraction=e=>{let t=Ve(e);if(t instanceof HTMLElement){let o=t.closest(`[${ul}="${this._globalRippleOptions?.namespace??""}"]`);o&&this._createRipple(o)}};_createRipple(e){if(!this._document||this._hosts.has(e))return;e.querySelector(".mat-ripple")?.remove();let t=this._document.createElement("span");t.classList.add("mat-ripple",e.getAttribute(hl)),e.append(t);let o=this._globalRippleOptions,a=this._animationsDisabled?0:o?.animation?.enterDuration??lo.enterDuration,s=this._animationsDisabled?0:o?.animation?.exitDuration??lo.exitDuration,r={rippleDisabled:this._animationsDisabled||o?.disabled||e.hasAttribute(Fa),rippleConfig:{centered:e.hasAttribute(Lu),terminateOnPointerUp:o?.terminateOnPointerUp,animation:{enterDuration:a,exitDuration:s}}},c=new Ii(r,this._ngZone,t,this._platform,this._injector),d=!r.rippleDisabled;d&&c.setupTriggerEvents(e),this._hosts.set(e,{target:r,renderer:c,hasSetUpEvents:d}),e.removeAttribute(ul)}destroyRipple(e){let t=this._hosts.get(e);t&&(t.renderer._removeTriggerEvents(),this._hosts.delete(e))}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();var Qf=["mat-icon-button",""],ey=["*"],ty=new A("MAT_BUTTON_CONFIG");function Ku(i){return i==null?void 0:Ye(i)}var pl=(()=>{class i{_elementRef=l(R);_ngZone=l(F);_animationsDisabled=Le();_config=l(ty,{optional:!0});_focusMonitor=l(Jt);_cleanupClick;_renderer=l(Ce);_rippleLoader=l(Gu);_isAnchor;_isFab=!1;color;get disableRipple(){return this._disableRipple}set disableRipple(e){this._disableRipple=e,this._updateRippleDisabled()}_disableRipple=!1;get disabled(){return this._disabled}set disabled(e){this._disabled=e,this._updateRippleDisabled()}_disabled=!1;ariaDisabled;disabledInteractive;tabIndex;set _tabindex(e){this.tabIndex=e}constructor(){l(Te).load(ei);let e=this._elementRef.nativeElement;this._isAnchor=e.tagName==="A",this.disabledInteractive=this._config?.disabledInteractive??!1,this.color=this._config?.color??null,this._rippleLoader?.configureRipple(e,{className:"mat-mdc-button-ripple"})}ngAfterViewInit(){this._focusMonitor.monitor(this._elementRef,!0),this._isAnchor&&this._setupAsAnchor()}ngOnDestroy(){this._cleanupClick?.(),this._focusMonitor.stopMonitoring(this._elementRef),this._rippleLoader?.destroyRipple(this._elementRef.nativeElement)}focus(e="program",t){e?this._focusMonitor.focusVia(this._elementRef.nativeElement,e,t):this._elementRef.nativeElement.focus(t)}_getAriaDisabled(){return this.ariaDisabled!=null?this.ariaDisabled:this._isAnchor?this.disabled||null:this.disabled&&this.disabledInteractive?!0:null}_getDisabledAttribute(){return this.disabledInteractive||!this.disabled?null:!0}_updateRippleDisabled(){this._rippleLoader?.setDisabled(this._elementRef.nativeElement,this.disableRipple||this.disabled)}_getTabIndex(){return this._isAnchor?this.disabled&&!this.disabledInteractive?-1:this.tabIndex:this.tabIndex}_setupAsAnchor(){this._cleanupClick=this._ngZone.runOutsideAngular(()=>this._renderer.listen(this._elementRef.nativeElement,"click",e=>{this.disabled&&(e.preventDefault(),e.stopImmediatePropagation())}))}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,hostAttrs:[1,"mat-mdc-button-base"],hostVars:13,hostBindings:function(t,o){t&2&&(X("disabled",o._getDisabledAttribute())("aria-disabled",o._getAriaDisabled())("tabindex",o._getTabIndex()),Me(o.color?"mat-"+o.color:""),N("mat-mdc-button-disabled",o.disabled)("mat-mdc-button-disabled-interactive",o.disabledInteractive)("mat-unthemed",!o.color)("_mat-animation-noopable",o._animationsDisabled))},inputs:{color:"color",disableRipple:[2,"disableRipple","disableRipple",K],disabled:[2,"disabled","disabled",K],ariaDisabled:[2,"aria-disabled","ariaDisabled",K],disabledInteractive:[2,"disabledInteractive","disabledInteractive",K],tabIndex:[2,"tabIndex","tabIndex",Ku],_tabindex:[2,"tabindex","_tabindex",Ku]}})}return i})(),yo=(()=>{class i extends pl{constructor(){super(),this._rippleLoader.configureRipple(this._elementRef.nativeElement,{centered:!0})}static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["button","mat-icon-button",""],["a","mat-icon-button",""],["button","matIconButton",""],["a","matIconButton",""]],hostAttrs:[1,"mdc-icon-button","mat-mdc-icon-button"],exportAs:["matButton","matAnchor"],features:[H],attrs:Qf,ngContentSelectors:ey,decls:4,vars:0,consts:[[1,"mat-mdc-button-persistent-ripple","mdc-icon-button__ripple"],[1,"mat-focus-indicator"],[1,"mat-mdc-button-touch-target"]],template:function(t,o){t&1&&(Y(),it(0,"span",0),T(1),it(2,"span",1)(3,"span",2))},styles:[`.mat-mdc-icon-button{-webkit-user-select:none;user-select:none;display:inline-block;position:relative;box-sizing:border-box;border:none;outline:none;background-color:rgba(0,0,0,0);fill:currentColor;text-decoration:none;cursor:pointer;z-index:0;overflow:visible;border-radius:var(--mat-icon-button-container-shape, var(--mat-sys-corner-full, 50%));flex-shrink:0;text-align:center;width:var(--mat-icon-button-state-layer-size, 40px);height:var(--mat-icon-button-state-layer-size, 40px);padding:calc(calc(var(--mat-icon-button-state-layer-size, 40px) - var(--mat-icon-button-icon-size, 24px)) / 2);font-size:var(--mat-icon-button-icon-size, 24px);color:var(--mat-icon-button-icon-color, var(--mat-sys-on-surface-variant));-webkit-tap-highlight-color:rgba(0,0,0,0)}.mat-mdc-icon-button .mat-mdc-button-ripple,.mat-mdc-icon-button .mat-mdc-button-persistent-ripple,.mat-mdc-icon-button .mat-mdc-button-persistent-ripple::before{top:0;left:0;right:0;bottom:0;position:absolute;pointer-events:none;border-radius:inherit}.mat-mdc-icon-button .mat-mdc-button-ripple{overflow:hidden}.mat-mdc-icon-button .mat-mdc-button-persistent-ripple::before{content:"";opacity:0}.mat-mdc-icon-button .mdc-button__label,.mat-mdc-icon-button .mat-icon{z-index:1;position:relative}.mat-mdc-icon-button .mat-focus-indicator{top:0;left:0;right:0;bottom:0;position:absolute;border-radius:inherit}.mat-mdc-icon-button:focus>.mat-focus-indicator::before{content:"";border-radius:inherit}.mat-mdc-icon-button .mat-ripple-element{background-color:var(--mat-icon-button-ripple-color, color-mix(in srgb, var(--mat-sys-on-surface-variant) calc(var(--mat-sys-pressed-state-layer-opacity) * 100%), transparent))}.mat-mdc-icon-button .mat-mdc-button-persistent-ripple::before{background-color:var(--mat-icon-button-state-layer-color, var(--mat-sys-on-surface-variant))}.mat-mdc-icon-button.mat-mdc-button-disabled .mat-mdc-button-persistent-ripple::before{background-color:var(--mat-icon-button-disabled-state-layer-color, var(--mat-sys-on-surface-variant))}.mat-mdc-icon-button:hover>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-icon-button-hover-state-layer-opacity, var(--mat-sys-hover-state-layer-opacity))}.mat-mdc-icon-button.cdk-program-focused>.mat-mdc-button-persistent-ripple::before,.mat-mdc-icon-button.cdk-keyboard-focused>.mat-mdc-button-persistent-ripple::before,.mat-mdc-icon-button.mat-mdc-button-disabled-interactive:focus>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-icon-button-focus-state-layer-opacity, var(--mat-sys-focus-state-layer-opacity))}.mat-mdc-icon-button:active>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-icon-button-pressed-state-layer-opacity, var(--mat-sys-pressed-state-layer-opacity))}.mat-mdc-icon-button .mat-mdc-button-touch-target{position:absolute;top:50%;height:var(--mat-icon-button-touch-target-size, 48px);display:var(--mat-icon-button-touch-target-display, block);left:50%;width:var(--mat-icon-button-touch-target-size, 48px);transform:translate(-50%, -50%)}.mat-mdc-icon-button._mat-animation-noopable{transition:none !important;animation:none !important}.mat-mdc-icon-button[disabled],.mat-mdc-icon-button.mat-mdc-button-disabled{cursor:default;pointer-events:none;color:var(--mat-icon-button-disabled-icon-color, color-mix(in srgb, var(--mat-sys-on-surface) 38%, transparent))}.mat-mdc-icon-button.mat-mdc-button-disabled-interactive{pointer-events:auto}.mat-mdc-icon-button img,.mat-mdc-icon-button svg{width:var(--mat-icon-button-icon-size, 24px);height:var(--mat-icon-button-icon-size, 24px);vertical-align:baseline}.mat-mdc-icon-button .mat-mdc-button-persistent-ripple{border-radius:var(--mat-icon-button-container-shape, var(--mat-sys-corner-full, 50%))}.mat-mdc-icon-button[hidden]{display:none}.mat-mdc-icon-button.mat-unthemed:not(.mdc-ripple-upgraded):focus::before,.mat-mdc-icon-button.mat-primary:not(.mdc-ripple-upgraded):focus::before,.mat-mdc-icon-button.mat-accent:not(.mdc-ripple-upgraded):focus::before,.mat-mdc-icon-button.mat-warn:not(.mdc-ripple-upgraded):focus::before{background:rgba(0,0,0,0);opacity:1}
`,`@media(forced-colors: active){.mat-mdc-button:not(.mdc-button--outlined),.mat-mdc-unelevated-button:not(.mdc-button--outlined),.mat-mdc-raised-button:not(.mdc-button--outlined),.mat-mdc-outlined-button:not(.mdc-button--outlined),.mat-mdc-button-base.mat-tonal-button,.mat-mdc-icon-button.mat-mdc-icon-button,.mat-mdc-outlined-button .mdc-button__ripple{outline:solid 1px}}
`],encapsulation:2,changeDetection:0})}return i})();var iy=["matButton",""],ny=[[["",8,"material-icons",3,"iconPositionEnd",""],["mat-icon",3,"iconPositionEnd",""],["","matButtonIcon","",3,"iconPositionEnd",""]],"*",[["","iconPositionEnd","",8,"material-icons"],["mat-icon","iconPositionEnd",""],["","matButtonIcon","","iconPositionEnd",""]]],oy=[".material-icons:not([iconPositionEnd]), mat-icon:not([iconPositionEnd]), [matButtonIcon]:not([iconPositionEnd])","*",".material-icons[iconPositionEnd], mat-icon[iconPositionEnd], [matButtonIcon][iconPositionEnd]"];var zu=new Map([["text",["mat-mdc-button"]],["filled",["mdc-button--unelevated","mat-mdc-unelevated-button"]],["elevated",["mdc-button--raised","mat-mdc-raised-button"]],["outlined",["mdc-button--outlined","mat-mdc-outlined-button"]],["tonal",["mat-tonal-button"]]]),Ma=(()=>{class i extends pl{get appearance(){return this._appearance}set appearance(e){this.setAppearance(e||this._config?.defaultAppearance||"text")}_appearance=null;constructor(){super();let e=ay(this._elementRef.nativeElement);e&&this.setAppearance(e)}setAppearance(e){if(e===this._appearance)return;let t=this._elementRef.nativeElement.classList,o=this._appearance?zu.get(this._appearance):null,a=zu.get(e);o&&t.remove(...o),t.add(...a),this._appearance=e}static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["button","matButton",""],["a","matButton",""],["button","mat-button",""],["button","mat-raised-button",""],["button","mat-flat-button",""],["button","mat-stroked-button",""],["a","mat-button",""],["a","mat-raised-button",""],["a","mat-flat-button",""],["a","mat-stroked-button",""]],hostAttrs:[1,"mdc-button"],inputs:{appearance:[0,"matButton","appearance"]},exportAs:["matButton","matAnchor"],features:[H],attrs:iy,ngContentSelectors:oy,decls:7,vars:4,consts:[[1,"mat-mdc-button-persistent-ripple"],[1,"mdc-button__label"],[1,"mat-focus-indicator"],[1,"mat-mdc-button-touch-target"]],template:function(t,o){t&1&&(Y(ny),it(0,"span",0),T(1),Q(2,"span",1),T(3,1),ne(),T(4,2),it(5,"span",2)(6,"span",3)),t&2&&N("mdc-button__ripple",!o._isFab)("mdc-fab__ripple",o._isFab)},styles:[`.mat-mdc-button-base{text-decoration:none}.mat-mdc-button-base .mat-icon{min-height:fit-content;flex-shrink:0}.mdc-button{-webkit-user-select:none;user-select:none;position:relative;display:inline-flex;align-items:center;justify-content:center;box-sizing:border-box;min-width:64px;border:none;outline:none;line-height:inherit;-webkit-appearance:none;overflow:visible;vertical-align:middle;background:rgba(0,0,0,0);padding:0 8px}.mdc-button::-moz-focus-inner{padding:0;border:0}.mdc-button:active{outline:none}.mdc-button:hover{cursor:pointer}.mdc-button:disabled{cursor:default;pointer-events:none}.mdc-button[hidden]{display:none}.mdc-button .mdc-button__label{position:relative}.mat-mdc-button{padding:0 var(--mat-button-text-horizontal-padding, 12px);height:var(--mat-button-text-container-height, 40px);font-family:var(--mat-button-text-label-text-font, var(--mat-sys-label-large-font));font-size:var(--mat-button-text-label-text-size, var(--mat-sys-label-large-size));letter-spacing:var(--mat-button-text-label-text-tracking, var(--mat-sys-label-large-tracking));text-transform:var(--mat-button-text-label-text-transform);font-weight:var(--mat-button-text-label-text-weight, var(--mat-sys-label-large-weight))}.mat-mdc-button,.mat-mdc-button .mdc-button__ripple{border-radius:var(--mat-button-text-container-shape, var(--mat-sys-corner-full))}.mat-mdc-button:not(:disabled){color:var(--mat-button-text-label-text-color, var(--mat-sys-primary))}.mat-mdc-button[disabled],.mat-mdc-button.mat-mdc-button-disabled{cursor:default;pointer-events:none;color:var(--mat-button-text-disabled-label-text-color, color-mix(in srgb, var(--mat-sys-on-surface) 38%, transparent))}.mat-mdc-button.mat-mdc-button-disabled-interactive{pointer-events:auto}.mat-mdc-button:has(.material-icons,mat-icon,[matButtonIcon]){padding:0 var(--mat-button-text-with-icon-horizontal-padding, 16px)}.mat-mdc-button>.mat-icon{margin-right:var(--mat-button-text-icon-spacing, 8px);margin-left:var(--mat-button-text-icon-offset, -4px)}[dir=rtl] .mat-mdc-button>.mat-icon{margin-right:var(--mat-button-text-icon-offset, -4px);margin-left:var(--mat-button-text-icon-spacing, 8px)}.mat-mdc-button .mdc-button__label+.mat-icon{margin-right:var(--mat-button-text-icon-offset, -4px);margin-left:var(--mat-button-text-icon-spacing, 8px)}[dir=rtl] .mat-mdc-button .mdc-button__label+.mat-icon{margin-right:var(--mat-button-text-icon-spacing, 8px);margin-left:var(--mat-button-text-icon-offset, -4px)}.mat-mdc-button .mat-ripple-element{background-color:var(--mat-button-text-ripple-color, color-mix(in srgb, var(--mat-sys-primary) calc(var(--mat-sys-pressed-state-layer-opacity) * 100%), transparent))}.mat-mdc-button .mat-mdc-button-persistent-ripple::before{background-color:var(--mat-button-text-state-layer-color, var(--mat-sys-primary))}.mat-mdc-button.mat-mdc-button-disabled .mat-mdc-button-persistent-ripple::before{background-color:var(--mat-button-text-disabled-state-layer-color, var(--mat-sys-on-surface-variant))}.mat-mdc-button:hover>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-text-hover-state-layer-opacity, var(--mat-sys-hover-state-layer-opacity))}.mat-mdc-button.cdk-program-focused>.mat-mdc-button-persistent-ripple::before,.mat-mdc-button.cdk-keyboard-focused>.mat-mdc-button-persistent-ripple::before,.mat-mdc-button.mat-mdc-button-disabled-interactive:focus>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-text-focus-state-layer-opacity, var(--mat-sys-focus-state-layer-opacity))}.mat-mdc-button:active>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-text-pressed-state-layer-opacity, var(--mat-sys-pressed-state-layer-opacity))}.mat-mdc-button .mat-mdc-button-touch-target{position:absolute;top:50%;height:var(--mat-button-text-touch-target-size, 48px);display:var(--mat-button-text-touch-target-display, block);left:0;right:0;transform:translateY(-50%)}.mat-mdc-unelevated-button{transition:box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1);height:var(--mat-button-filled-container-height, 40px);font-family:var(--mat-button-filled-label-text-font, var(--mat-sys-label-large-font));font-size:var(--mat-button-filled-label-text-size, var(--mat-sys-label-large-size));letter-spacing:var(--mat-button-filled-label-text-tracking, var(--mat-sys-label-large-tracking));text-transform:var(--mat-button-filled-label-text-transform);font-weight:var(--mat-button-filled-label-text-weight, var(--mat-sys-label-large-weight));padding:0 var(--mat-button-filled-horizontal-padding, 24px)}.mat-mdc-unelevated-button>.mat-icon{margin-right:var(--mat-button-filled-icon-spacing, 8px);margin-left:var(--mat-button-filled-icon-offset, -8px)}[dir=rtl] .mat-mdc-unelevated-button>.mat-icon{margin-right:var(--mat-button-filled-icon-offset, -8px);margin-left:var(--mat-button-filled-icon-spacing, 8px)}.mat-mdc-unelevated-button .mdc-button__label+.mat-icon{margin-right:var(--mat-button-filled-icon-offset, -8px);margin-left:var(--mat-button-filled-icon-spacing, 8px)}[dir=rtl] .mat-mdc-unelevated-button .mdc-button__label+.mat-icon{margin-right:var(--mat-button-filled-icon-spacing, 8px);margin-left:var(--mat-button-filled-icon-offset, -8px)}.mat-mdc-unelevated-button .mat-ripple-element{background-color:var(--mat-button-filled-ripple-color, color-mix(in srgb, var(--mat-sys-on-primary) calc(var(--mat-sys-pressed-state-layer-opacity) * 100%), transparent))}.mat-mdc-unelevated-button .mat-mdc-button-persistent-ripple::before{background-color:var(--mat-button-filled-state-layer-color, var(--mat-sys-on-primary))}.mat-mdc-unelevated-button.mat-mdc-button-disabled .mat-mdc-button-persistent-ripple::before{background-color:var(--mat-button-filled-disabled-state-layer-color, var(--mat-sys-on-surface-variant))}.mat-mdc-unelevated-button:hover>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-filled-hover-state-layer-opacity, var(--mat-sys-hover-state-layer-opacity))}.mat-mdc-unelevated-button.cdk-program-focused>.mat-mdc-button-persistent-ripple::before,.mat-mdc-unelevated-button.cdk-keyboard-focused>.mat-mdc-button-persistent-ripple::before,.mat-mdc-unelevated-button.mat-mdc-button-disabled-interactive:focus>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-filled-focus-state-layer-opacity, var(--mat-sys-focus-state-layer-opacity))}.mat-mdc-unelevated-button:active>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-filled-pressed-state-layer-opacity, var(--mat-sys-pressed-state-layer-opacity))}.mat-mdc-unelevated-button .mat-mdc-button-touch-target{position:absolute;top:50%;height:var(--mat-button-filled-touch-target-size, 48px);display:var(--mat-button-filled-touch-target-display, block);left:0;right:0;transform:translateY(-50%)}.mat-mdc-unelevated-button:not(:disabled){color:var(--mat-button-filled-label-text-color, var(--mat-sys-on-primary));background-color:var(--mat-button-filled-container-color, var(--mat-sys-primary))}.mat-mdc-unelevated-button,.mat-mdc-unelevated-button .mdc-button__ripple{border-radius:var(--mat-button-filled-container-shape, var(--mat-sys-corner-full))}.mat-mdc-unelevated-button[disabled],.mat-mdc-unelevated-button.mat-mdc-button-disabled{cursor:default;pointer-events:none;color:var(--mat-button-filled-disabled-label-text-color, color-mix(in srgb, var(--mat-sys-on-surface) 38%, transparent));background-color:var(--mat-button-filled-disabled-container-color, color-mix(in srgb, var(--mat-sys-on-surface) 12%, transparent))}.mat-mdc-unelevated-button.mat-mdc-button-disabled-interactive{pointer-events:auto}.mat-mdc-raised-button{transition:box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1);box-shadow:var(--mat-button-protected-container-elevation-shadow, var(--mat-sys-level1));height:var(--mat-button-protected-container-height, 40px);font-family:var(--mat-button-protected-label-text-font, var(--mat-sys-label-large-font));font-size:var(--mat-button-protected-label-text-size, var(--mat-sys-label-large-size));letter-spacing:var(--mat-button-protected-label-text-tracking, var(--mat-sys-label-large-tracking));text-transform:var(--mat-button-protected-label-text-transform);font-weight:var(--mat-button-protected-label-text-weight, var(--mat-sys-label-large-weight));padding:0 var(--mat-button-protected-horizontal-padding, 24px)}.mat-mdc-raised-button>.mat-icon{margin-right:var(--mat-button-protected-icon-spacing, 8px);margin-left:var(--mat-button-protected-icon-offset, -8px)}[dir=rtl] .mat-mdc-raised-button>.mat-icon{margin-right:var(--mat-button-protected-icon-offset, -8px);margin-left:var(--mat-button-protected-icon-spacing, 8px)}.mat-mdc-raised-button .mdc-button__label+.mat-icon{margin-right:var(--mat-button-protected-icon-offset, -8px);margin-left:var(--mat-button-protected-icon-spacing, 8px)}[dir=rtl] .mat-mdc-raised-button .mdc-button__label+.mat-icon{margin-right:var(--mat-button-protected-icon-spacing, 8px);margin-left:var(--mat-button-protected-icon-offset, -8px)}.mat-mdc-raised-button .mat-ripple-element{background-color:var(--mat-button-protected-ripple-color, color-mix(in srgb, var(--mat-sys-primary) calc(var(--mat-sys-pressed-state-layer-opacity) * 100%), transparent))}.mat-mdc-raised-button .mat-mdc-button-persistent-ripple::before{background-color:var(--mat-button-protected-state-layer-color, var(--mat-sys-primary))}.mat-mdc-raised-button.mat-mdc-button-disabled .mat-mdc-button-persistent-ripple::before{background-color:var(--mat-button-protected-disabled-state-layer-color, var(--mat-sys-on-surface-variant))}.mat-mdc-raised-button:hover>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-protected-hover-state-layer-opacity, var(--mat-sys-hover-state-layer-opacity))}.mat-mdc-raised-button.cdk-program-focused>.mat-mdc-button-persistent-ripple::before,.mat-mdc-raised-button.cdk-keyboard-focused>.mat-mdc-button-persistent-ripple::before,.mat-mdc-raised-button.mat-mdc-button-disabled-interactive:focus>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-protected-focus-state-layer-opacity, var(--mat-sys-focus-state-layer-opacity))}.mat-mdc-raised-button:active>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-protected-pressed-state-layer-opacity, var(--mat-sys-pressed-state-layer-opacity))}.mat-mdc-raised-button .mat-mdc-button-touch-target{position:absolute;top:50%;height:var(--mat-button-protected-touch-target-size, 48px);display:var(--mat-button-protected-touch-target-display, block);left:0;right:0;transform:translateY(-50%)}.mat-mdc-raised-button:not(:disabled){color:var(--mat-button-protected-label-text-color, var(--mat-sys-primary));background-color:var(--mat-button-protected-container-color, var(--mat-sys-surface))}.mat-mdc-raised-button,.mat-mdc-raised-button .mdc-button__ripple{border-radius:var(--mat-button-protected-container-shape, var(--mat-sys-corner-full))}.mat-mdc-raised-button:hover{box-shadow:var(--mat-button-protected-hover-container-elevation-shadow, var(--mat-sys-level2))}.mat-mdc-raised-button:focus{box-shadow:var(--mat-button-protected-focus-container-elevation-shadow, var(--mat-sys-level1))}.mat-mdc-raised-button:active,.mat-mdc-raised-button:focus:active{box-shadow:var(--mat-button-protected-pressed-container-elevation-shadow, var(--mat-sys-level1))}.mat-mdc-raised-button[disabled],.mat-mdc-raised-button.mat-mdc-button-disabled{cursor:default;pointer-events:none;color:var(--mat-button-protected-disabled-label-text-color, color-mix(in srgb, var(--mat-sys-on-surface) 38%, transparent));background-color:var(--mat-button-protected-disabled-container-color, color-mix(in srgb, var(--mat-sys-on-surface) 12%, transparent))}.mat-mdc-raised-button[disabled].mat-mdc-button-disabled,.mat-mdc-raised-button.mat-mdc-button-disabled.mat-mdc-button-disabled{box-shadow:var(--mat-button-protected-disabled-container-elevation-shadow, var(--mat-sys-level0))}.mat-mdc-raised-button.mat-mdc-button-disabled-interactive{pointer-events:auto}.mat-mdc-outlined-button{border-style:solid;transition:border 280ms cubic-bezier(0.4, 0, 0.2, 1);height:var(--mat-button-outlined-container-height, 40px);font-family:var(--mat-button-outlined-label-text-font, var(--mat-sys-label-large-font));font-size:var(--mat-button-outlined-label-text-size, var(--mat-sys-label-large-size));letter-spacing:var(--mat-button-outlined-label-text-tracking, var(--mat-sys-label-large-tracking));text-transform:var(--mat-button-outlined-label-text-transform);font-weight:var(--mat-button-outlined-label-text-weight, var(--mat-sys-label-large-weight));border-radius:var(--mat-button-outlined-container-shape, var(--mat-sys-corner-full));border-width:var(--mat-button-outlined-outline-width, 1px);padding:0 var(--mat-button-outlined-horizontal-padding, 24px)}.mat-mdc-outlined-button>.mat-icon{margin-right:var(--mat-button-outlined-icon-spacing, 8px);margin-left:var(--mat-button-outlined-icon-offset, -8px)}[dir=rtl] .mat-mdc-outlined-button>.mat-icon{margin-right:var(--mat-button-outlined-icon-offset, -8px);margin-left:var(--mat-button-outlined-icon-spacing, 8px)}.mat-mdc-outlined-button .mdc-button__label+.mat-icon{margin-right:var(--mat-button-outlined-icon-offset, -8px);margin-left:var(--mat-button-outlined-icon-spacing, 8px)}[dir=rtl] .mat-mdc-outlined-button .mdc-button__label+.mat-icon{margin-right:var(--mat-button-outlined-icon-spacing, 8px);margin-left:var(--mat-button-outlined-icon-offset, -8px)}.mat-mdc-outlined-button .mat-ripple-element{background-color:var(--mat-button-outlined-ripple-color, color-mix(in srgb, var(--mat-sys-primary) calc(var(--mat-sys-pressed-state-layer-opacity) * 100%), transparent))}.mat-mdc-outlined-button .mat-mdc-button-persistent-ripple::before{background-color:var(--mat-button-outlined-state-layer-color, var(--mat-sys-primary))}.mat-mdc-outlined-button.mat-mdc-button-disabled .mat-mdc-button-persistent-ripple::before{background-color:var(--mat-button-outlined-disabled-state-layer-color, var(--mat-sys-on-surface-variant))}.mat-mdc-outlined-button:hover>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-outlined-hover-state-layer-opacity, var(--mat-sys-hover-state-layer-opacity))}.mat-mdc-outlined-button.cdk-program-focused>.mat-mdc-button-persistent-ripple::before,.mat-mdc-outlined-button.cdk-keyboard-focused>.mat-mdc-button-persistent-ripple::before,.mat-mdc-outlined-button.mat-mdc-button-disabled-interactive:focus>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-outlined-focus-state-layer-opacity, var(--mat-sys-focus-state-layer-opacity))}.mat-mdc-outlined-button:active>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-outlined-pressed-state-layer-opacity, var(--mat-sys-pressed-state-layer-opacity))}.mat-mdc-outlined-button .mat-mdc-button-touch-target{position:absolute;top:50%;height:var(--mat-button-outlined-touch-target-size, 48px);display:var(--mat-button-outlined-touch-target-display, block);left:0;right:0;transform:translateY(-50%)}.mat-mdc-outlined-button:not(:disabled){color:var(--mat-button-outlined-label-text-color, var(--mat-sys-primary));border-color:var(--mat-button-outlined-outline-color, var(--mat-sys-outline))}.mat-mdc-outlined-button[disabled],.mat-mdc-outlined-button.mat-mdc-button-disabled{cursor:default;pointer-events:none;color:var(--mat-button-outlined-disabled-label-text-color, color-mix(in srgb, var(--mat-sys-on-surface) 38%, transparent));border-color:var(--mat-button-outlined-disabled-outline-color, color-mix(in srgb, var(--mat-sys-on-surface) 12%, transparent))}.mat-mdc-outlined-button.mat-mdc-button-disabled-interactive{pointer-events:auto}.mat-tonal-button{transition:box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1);height:var(--mat-button-tonal-container-height, 40px);font-family:var(--mat-button-tonal-label-text-font, var(--mat-sys-label-large-font));font-size:var(--mat-button-tonal-label-text-size, var(--mat-sys-label-large-size));letter-spacing:var(--mat-button-tonal-label-text-tracking, var(--mat-sys-label-large-tracking));text-transform:var(--mat-button-tonal-label-text-transform);font-weight:var(--mat-button-tonal-label-text-weight, var(--mat-sys-label-large-weight));padding:0 var(--mat-button-tonal-horizontal-padding, 24px)}.mat-tonal-button:not(:disabled){color:var(--mat-button-tonal-label-text-color, var(--mat-sys-on-secondary-container));background-color:var(--mat-button-tonal-container-color, var(--mat-sys-secondary-container))}.mat-tonal-button,.mat-tonal-button .mdc-button__ripple{border-radius:var(--mat-button-tonal-container-shape, var(--mat-sys-corner-full))}.mat-tonal-button[disabled],.mat-tonal-button.mat-mdc-button-disabled{cursor:default;pointer-events:none;color:var(--mat-button-tonal-disabled-label-text-color, color-mix(in srgb, var(--mat-sys-on-surface) 38%, transparent));background-color:var(--mat-button-tonal-disabled-container-color, color-mix(in srgb, var(--mat-sys-on-surface) 12%, transparent))}.mat-tonal-button.mat-mdc-button-disabled-interactive{pointer-events:auto}.mat-tonal-button>.mat-icon{margin-right:var(--mat-button-tonal-icon-spacing, 8px);margin-left:var(--mat-button-tonal-icon-offset, -8px)}[dir=rtl] .mat-tonal-button>.mat-icon{margin-right:var(--mat-button-tonal-icon-offset, -8px);margin-left:var(--mat-button-tonal-icon-spacing, 8px)}.mat-tonal-button .mdc-button__label+.mat-icon{margin-right:var(--mat-button-tonal-icon-offset, -8px);margin-left:var(--mat-button-tonal-icon-spacing, 8px)}[dir=rtl] .mat-tonal-button .mdc-button__label+.mat-icon{margin-right:var(--mat-button-tonal-icon-spacing, 8px);margin-left:var(--mat-button-tonal-icon-offset, -8px)}.mat-tonal-button .mat-ripple-element{background-color:var(--mat-button-tonal-ripple-color, color-mix(in srgb, var(--mat-sys-on-secondary-container) calc(var(--mat-sys-pressed-state-layer-opacity) * 100%), transparent))}.mat-tonal-button .mat-mdc-button-persistent-ripple::before{background-color:var(--mat-button-tonal-state-layer-color, var(--mat-sys-on-secondary-container))}.mat-tonal-button.mat-mdc-button-disabled .mat-mdc-button-persistent-ripple::before{background-color:var(--mat-button-tonal-disabled-state-layer-color, var(--mat-sys-on-surface-variant))}.mat-tonal-button:hover>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-tonal-hover-state-layer-opacity, var(--mat-sys-hover-state-layer-opacity))}.mat-tonal-button.cdk-program-focused>.mat-mdc-button-persistent-ripple::before,.mat-tonal-button.cdk-keyboard-focused>.mat-mdc-button-persistent-ripple::before,.mat-tonal-button.mat-mdc-button-disabled-interactive:focus>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-tonal-focus-state-layer-opacity, var(--mat-sys-focus-state-layer-opacity))}.mat-tonal-button:active>.mat-mdc-button-persistent-ripple::before{opacity:var(--mat-button-tonal-pressed-state-layer-opacity, var(--mat-sys-pressed-state-layer-opacity))}.mat-tonal-button .mat-mdc-button-touch-target{position:absolute;top:50%;height:var(--mat-button-tonal-touch-target-size, 48px);display:var(--mat-button-tonal-touch-target-display, block);left:0;right:0;transform:translateY(-50%)}.mat-mdc-button,.mat-mdc-unelevated-button,.mat-mdc-raised-button,.mat-mdc-outlined-button,.mat-tonal-button{-webkit-tap-highlight-color:rgba(0,0,0,0)}.mat-mdc-button .mat-mdc-button-ripple,.mat-mdc-button .mat-mdc-button-persistent-ripple,.mat-mdc-button .mat-mdc-button-persistent-ripple::before,.mat-mdc-unelevated-button .mat-mdc-button-ripple,.mat-mdc-unelevated-button .mat-mdc-button-persistent-ripple,.mat-mdc-unelevated-button .mat-mdc-button-persistent-ripple::before,.mat-mdc-raised-button .mat-mdc-button-ripple,.mat-mdc-raised-button .mat-mdc-button-persistent-ripple,.mat-mdc-raised-button .mat-mdc-button-persistent-ripple::before,.mat-mdc-outlined-button .mat-mdc-button-ripple,.mat-mdc-outlined-button .mat-mdc-button-persistent-ripple,.mat-mdc-outlined-button .mat-mdc-button-persistent-ripple::before,.mat-tonal-button .mat-mdc-button-ripple,.mat-tonal-button .mat-mdc-button-persistent-ripple,.mat-tonal-button .mat-mdc-button-persistent-ripple::before{top:0;left:0;right:0;bottom:0;position:absolute;pointer-events:none;border-radius:inherit}.mat-mdc-button .mat-mdc-button-ripple,.mat-mdc-unelevated-button .mat-mdc-button-ripple,.mat-mdc-raised-button .mat-mdc-button-ripple,.mat-mdc-outlined-button .mat-mdc-button-ripple,.mat-tonal-button .mat-mdc-button-ripple{overflow:hidden}.mat-mdc-button .mat-mdc-button-persistent-ripple::before,.mat-mdc-unelevated-button .mat-mdc-button-persistent-ripple::before,.mat-mdc-raised-button .mat-mdc-button-persistent-ripple::before,.mat-mdc-outlined-button .mat-mdc-button-persistent-ripple::before,.mat-tonal-button .mat-mdc-button-persistent-ripple::before{content:"";opacity:0}.mat-mdc-button .mdc-button__label,.mat-mdc-button .mat-icon,.mat-mdc-unelevated-button .mdc-button__label,.mat-mdc-unelevated-button .mat-icon,.mat-mdc-raised-button .mdc-button__label,.mat-mdc-raised-button .mat-icon,.mat-mdc-outlined-button .mdc-button__label,.mat-mdc-outlined-button .mat-icon,.mat-tonal-button .mdc-button__label,.mat-tonal-button .mat-icon{z-index:1;position:relative}.mat-mdc-button .mat-focus-indicator,.mat-mdc-unelevated-button .mat-focus-indicator,.mat-mdc-raised-button .mat-focus-indicator,.mat-mdc-outlined-button .mat-focus-indicator,.mat-tonal-button .mat-focus-indicator{top:0;left:0;right:0;bottom:0;position:absolute;border-radius:inherit}.mat-mdc-button:focus>.mat-focus-indicator::before,.mat-mdc-unelevated-button:focus>.mat-focus-indicator::before,.mat-mdc-raised-button:focus>.mat-focus-indicator::before,.mat-mdc-outlined-button:focus>.mat-focus-indicator::before,.mat-tonal-button:focus>.mat-focus-indicator::before{content:"";border-radius:inherit}.mat-mdc-button._mat-animation-noopable,.mat-mdc-unelevated-button._mat-animation-noopable,.mat-mdc-raised-button._mat-animation-noopable,.mat-mdc-outlined-button._mat-animation-noopable,.mat-tonal-button._mat-animation-noopable{transition:none !important;animation:none !important}.mat-mdc-button>.mat-icon,.mat-mdc-unelevated-button>.mat-icon,.mat-mdc-raised-button>.mat-icon,.mat-mdc-outlined-button>.mat-icon,.mat-tonal-button>.mat-icon{display:inline-block;position:relative;vertical-align:top;font-size:1.125rem;height:1.125rem;width:1.125rem}.mat-mdc-outlined-button .mat-mdc-button-ripple,.mat-mdc-outlined-button .mdc-button__ripple{top:-1px;left:-1px;bottom:-1px;right:-1px}.mat-mdc-unelevated-button .mat-focus-indicator::before,.mat-tonal-button .mat-focus-indicator::before,.mat-mdc-raised-button .mat-focus-indicator::before{margin:calc(calc(var(--mat-focus-indicator-border-width, 3px) + 2px)*-1)}.mat-mdc-outlined-button .mat-focus-indicator::before{margin:calc(calc(var(--mat-focus-indicator-border-width, 3px) + 3px)*-1)}
`,`@media(forced-colors: active){.mat-mdc-button:not(.mdc-button--outlined),.mat-mdc-unelevated-button:not(.mdc-button--outlined),.mat-mdc-raised-button:not(.mdc-button--outlined),.mat-mdc-outlined-button:not(.mdc-button--outlined),.mat-mdc-button-base.mat-tonal-button,.mat-mdc-icon-button.mat-mdc-icon-button,.mat-mdc-outlined-button .mdc-button__ripple{outline:solid 1px}}
`],encapsulation:2,changeDetection:0})}return i})();function ay(i){return i.hasAttribute("mat-raised-button")?"elevated":i.hasAttribute("mat-stroked-button")?"outlined":i.hasAttribute("mat-flat-button")?"filled":i.hasAttribute("mat-button")?"text":null}var fn=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[z,ii,z]})}return i})();function sy(i,n){i&1&&it(0,"div",2)}var ry=new A("MAT_PROGRESS_BAR_DEFAULT_OPTIONS");var Vu=(()=>{class i{_elementRef=l(R);_ngZone=l(F);_changeDetectorRef=l(me);_renderer=l(Ce);_cleanupTransitionEnd;constructor(){let e=ro(),t=l(ry,{optional:!0});this._isNoopAnimation=e==="di-disabled",e==="reduced-motion"&&this._elementRef.nativeElement.classList.add("mat-progress-bar-reduced-motion"),t&&(t.color&&(this.color=this._defaultColor=t.color),this.mode=t.mode||this.mode)}_isNoopAnimation;get color(){return this._color||this._defaultColor}set color(e){this._color=e}_color;_defaultColor="primary";get value(){return this._value}set value(e){this._value=ju(e||0),this._changeDetectorRef.markForCheck()}_value=0;get bufferValue(){return this._bufferValue||0}set bufferValue(e){this._bufferValue=ju(e||0),this._changeDetectorRef.markForCheck()}_bufferValue=0;animationEnd=new Z;get mode(){return this._mode}set mode(e){this._mode=e,this._changeDetectorRef.markForCheck()}_mode="determinate";ngAfterViewInit(){this._ngZone.runOutsideAngular(()=>{this._cleanupTransitionEnd=this._renderer.listen(this._elementRef.nativeElement,"transitionend",this._transitionendHandler)})}ngOnDestroy(){this._cleanupTransitionEnd?.()}_getPrimaryBarTransform(){return`scaleX(${this._isIndeterminate()?1:this.value/100})`}_getBufferBarFlexBasis(){return`${this.mode==="buffer"?this.bufferValue:100}%`}_isIndeterminate(){return this.mode==="indeterminate"||this.mode==="query"}_transitionendHandler=e=>{this.animationEnd.observers.length===0||!e.target||!e.target.classList.contains("mdc-linear-progress__primary-bar")||(this.mode==="determinate"||this.mode==="buffer")&&this._ngZone.run(()=>this.animationEnd.next({value:this.value}))};static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["mat-progress-bar"]],hostAttrs:["role","progressbar","aria-valuemin","0","aria-valuemax","100","tabindex","-1",1,"mat-mdc-progress-bar","mdc-linear-progress"],hostVars:10,hostBindings:function(t,o){t&2&&(X("aria-valuenow",o._isIndeterminate()?null:o.value)("mode",o.mode),Me("mat-"+o.color),N("_mat-animation-noopable",o._isNoopAnimation)("mdc-linear-progress--animation-ready",!o._isNoopAnimation)("mdc-linear-progress--indeterminate",o._isIndeterminate()))},inputs:{color:"color",value:[2,"value","value",Ye],bufferValue:[2,"bufferValue","bufferValue",Ye],mode:"mode"},outputs:{animationEnd:"animationEnd"},exportAs:["matProgressBar"],decls:7,vars:5,consts:[["aria-hidden","true",1,"mdc-linear-progress__buffer"],[1,"mdc-linear-progress__buffer-bar"],[1,"mdc-linear-progress__buffer-dots"],["aria-hidden","true",1,"mdc-linear-progress__bar","mdc-linear-progress__primary-bar"],[1,"mdc-linear-progress__bar-inner"],["aria-hidden","true",1,"mdc-linear-progress__bar","mdc-linear-progress__secondary-bar"]],template:function(t,o){t&1&&(Q(0,"div",0),it(1,"div",1),J(2,sy,1,0,"div",2),ne(),Q(3,"div",3),it(4,"span",4),ne(),Q(5,"div",5),it(6,"span",4),ne()),t&2&&(f(),Be("flex-basis",o._getBufferBarFlexBasis()),f(),$(o.mode==="buffer"?2:-1),f(),Be("transform",o._getPrimaryBarTransform()))},styles:[`.mat-mdc-progress-bar{--mat-progress-bar-animation-multiplier: 1;display:block;text-align:start}.mat-mdc-progress-bar[mode=query]{transform:scaleX(-1)}.mat-mdc-progress-bar._mat-animation-noopable .mdc-linear-progress__buffer-dots,.mat-mdc-progress-bar._mat-animation-noopable .mdc-linear-progress__primary-bar,.mat-mdc-progress-bar._mat-animation-noopable .mdc-linear-progress__secondary-bar,.mat-mdc-progress-bar._mat-animation-noopable .mdc-linear-progress__bar-inner.mdc-linear-progress__bar-inner{animation:none}.mat-mdc-progress-bar._mat-animation-noopable .mdc-linear-progress__primary-bar,.mat-mdc-progress-bar._mat-animation-noopable .mdc-linear-progress__buffer-bar{transition:transform 1ms}.mat-progress-bar-reduced-motion{--mat-progress-bar-animation-multiplier: 2}.mdc-linear-progress{position:relative;width:100%;transform:translateZ(0);outline:1px solid rgba(0,0,0,0);overflow-x:hidden;transition:opacity 250ms 0ms cubic-bezier(0.4, 0, 0.6, 1);height:max(var(--mat-progress-bar-track-height, 4px),var(--mat-progress-bar-active-indicator-height, 4px))}@media(forced-colors: active){.mdc-linear-progress{outline-color:CanvasText}}.mdc-linear-progress__bar{position:absolute;top:0;bottom:0;margin:auto 0;width:100%;animation:none;transform-origin:top left;transition:transform 250ms 0ms cubic-bezier(0.4, 0, 0.6, 1);height:var(--mat-progress-bar-active-indicator-height, 4px)}.mdc-linear-progress--indeterminate .mdc-linear-progress__bar{transition:none}[dir=rtl] .mdc-linear-progress__bar{right:0;transform-origin:center right}.mdc-linear-progress__bar-inner{display:inline-block;position:absolute;width:100%;animation:none;border-top-style:solid;border-color:var(--mat-progress-bar-active-indicator-color, var(--mat-sys-primary));border-top-width:var(--mat-progress-bar-active-indicator-height, 4px)}.mdc-linear-progress__buffer{display:flex;position:absolute;top:0;bottom:0;margin:auto 0;width:100%;overflow:hidden;height:var(--mat-progress-bar-track-height, 4px);border-radius:var(--mat-progress-bar-track-shape, var(--mat-sys-corner-none))}.mdc-linear-progress__buffer-dots{-webkit-mask-image:url("data:image/svg+xml,%3Csvg version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' x='0px' y='0px' enable-background='new 0 0 5 2' xml:space='preserve' viewBox='0 0 5 2' preserveAspectRatio='xMinYMin slice'%3E%3Ccircle cx='1' cy='1' r='1'/%3E%3C/svg%3E");mask-image:url("data:image/svg+xml,%3Csvg version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' x='0px' y='0px' enable-background='new 0 0 5 2' xml:space='preserve' viewBox='0 0 5 2' preserveAspectRatio='xMinYMin slice'%3E%3Ccircle cx='1' cy='1' r='1'/%3E%3C/svg%3E");background-repeat:repeat-x;flex:auto;transform:rotate(180deg);animation:mdc-linear-progress-buffering calc(250ms*var(--mat-progress-bar-animation-multiplier)) infinite linear;background-color:var(--mat-progress-bar-track-color, var(--mat-sys-surface-variant))}@media(forced-colors: active){.mdc-linear-progress__buffer-dots{background-color:ButtonBorder}}[dir=rtl] .mdc-linear-progress__buffer-dots{animation:mdc-linear-progress-buffering-reverse calc(250ms*var(--mat-progress-bar-animation-multiplier)) infinite linear;transform:rotate(0)}.mdc-linear-progress__buffer-bar{flex:0 1 100%;transition:flex-basis 250ms 0ms cubic-bezier(0.4, 0, 0.6, 1);background-color:var(--mat-progress-bar-track-color, var(--mat-sys-surface-variant))}.mdc-linear-progress__primary-bar{transform:scaleX(0)}.mdc-linear-progress--indeterminate .mdc-linear-progress__primary-bar{left:-145.166611%}.mdc-linear-progress--indeterminate.mdc-linear-progress--animation-ready .mdc-linear-progress__primary-bar{animation:mdc-linear-progress-primary-indeterminate-translate calc(2s*var(--mat-progress-bar-animation-multiplier)) infinite linear}.mdc-linear-progress--indeterminate.mdc-linear-progress--animation-ready .mdc-linear-progress__primary-bar>.mdc-linear-progress__bar-inner{animation:mdc-linear-progress-primary-indeterminate-scale calc(2s*var(--mat-progress-bar-animation-multiplier)) infinite linear}[dir=rtl] .mdc-linear-progress.mdc-linear-progress--animation-ready .mdc-linear-progress__primary-bar{animation-name:mdc-linear-progress-primary-indeterminate-translate-reverse}[dir=rtl] .mdc-linear-progress.mdc-linear-progress--indeterminate .mdc-linear-progress__primary-bar{right:-145.166611%;left:auto}.mdc-linear-progress__secondary-bar{display:none}.mdc-linear-progress--indeterminate .mdc-linear-progress__secondary-bar{left:-54.888891%;display:block}.mdc-linear-progress--indeterminate.mdc-linear-progress--animation-ready .mdc-linear-progress__secondary-bar{animation:mdc-linear-progress-secondary-indeterminate-translate calc(2s*var(--mat-progress-bar-animation-multiplier)) infinite linear}.mdc-linear-progress--indeterminate.mdc-linear-progress--animation-ready .mdc-linear-progress__secondary-bar>.mdc-linear-progress__bar-inner{animation:mdc-linear-progress-secondary-indeterminate-scale calc(2s*var(--mat-progress-bar-animation-multiplier)) infinite linear}[dir=rtl] .mdc-linear-progress.mdc-linear-progress--animation-ready .mdc-linear-progress__secondary-bar{animation-name:mdc-linear-progress-secondary-indeterminate-translate-reverse}[dir=rtl] .mdc-linear-progress.mdc-linear-progress--indeterminate .mdc-linear-progress__secondary-bar{right:-54.888891%;left:auto}@keyframes mdc-linear-progress-buffering{from{transform:rotate(180deg) translateX(calc(var(--mat-progress-bar-track-height, 4px) * -2.5))}}@keyframes mdc-linear-progress-primary-indeterminate-translate{0%{transform:translateX(0)}20%{animation-timing-function:cubic-bezier(0.5, 0, 0.701732, 0.495819);transform:translateX(0)}59.15%{animation-timing-function:cubic-bezier(0.302435, 0.381352, 0.55, 0.956352);transform:translateX(83.67142%)}100%{transform:translateX(200.611057%)}}@keyframes mdc-linear-progress-primary-indeterminate-scale{0%{transform:scaleX(0.08)}36.65%{animation-timing-function:cubic-bezier(0.334731, 0.12482, 0.785844, 1);transform:scaleX(0.08)}69.15%{animation-timing-function:cubic-bezier(0.06, 0.11, 0.6, 1);transform:scaleX(0.661479)}100%{transform:scaleX(0.08)}}@keyframes mdc-linear-progress-secondary-indeterminate-translate{0%{animation-timing-function:cubic-bezier(0.15, 0, 0.515058, 0.409685);transform:translateX(0)}25%{animation-timing-function:cubic-bezier(0.31033, 0.284058, 0.8, 0.733712);transform:translateX(37.651913%)}48.35%{animation-timing-function:cubic-bezier(0.4, 0.627035, 0.6, 0.902026);transform:translateX(84.386165%)}100%{transform:translateX(160.277782%)}}@keyframes mdc-linear-progress-secondary-indeterminate-scale{0%{animation-timing-function:cubic-bezier(0.205028, 0.057051, 0.57661, 0.453971);transform:scaleX(0.08)}19.15%{animation-timing-function:cubic-bezier(0.152313, 0.196432, 0.648374, 1.004315);transform:scaleX(0.457104)}44.15%{animation-timing-function:cubic-bezier(0.257759, -0.003163, 0.211762, 1.38179);transform:scaleX(0.72796)}100%{transform:scaleX(0.08)}}@keyframes mdc-linear-progress-primary-indeterminate-translate-reverse{0%{transform:translateX(0)}20%{animation-timing-function:cubic-bezier(0.5, 0, 0.701732, 0.495819);transform:translateX(0)}59.15%{animation-timing-function:cubic-bezier(0.302435, 0.381352, 0.55, 0.956352);transform:translateX(-83.67142%)}100%{transform:translateX(-200.611057%)}}@keyframes mdc-linear-progress-secondary-indeterminate-translate-reverse{0%{animation-timing-function:cubic-bezier(0.15, 0, 0.515058, 0.409685);transform:translateX(0)}25%{animation-timing-function:cubic-bezier(0.31033, 0.284058, 0.8, 0.733712);transform:translateX(-37.651913%)}48.35%{animation-timing-function:cubic-bezier(0.4, 0.627035, 0.6, 0.902026);transform:translateX(-84.386165%)}100%{transform:translateX(-160.277782%)}}@keyframes mdc-linear-progress-buffering-reverse{from{transform:translateX(-10px)}}
`],encapsulation:2,changeDetection:0})}return i})();function ju(i,n=0,e=100){return Math.max(n,Math.min(e,i))}var Na=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[z]})}return i})();var Wu={columns:[{id:"c-5WWbiBHe9B",type:"column",name:"Policy Name",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-5WWbiBHe9B",format:{type:"text",isArray:!1}},{id:"c-JILGl3j9sD",type:"column",name:"Policy creator",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-JILGl3j9sD",format:{table:{id:"grid-2iQy6VFcq_",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-2iQy6VFcq_",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-2iQy6VFcq_",name:"Jurisdictions"},type:"lookup",isArray:!0}},{id:"c-V85VzcYUCM",type:"column",name:"Relevant?",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-V85VzcYUCM",format:{type:"select",isArray:!1}},{id:"c-iohuaEflSp",type:"column",name:'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table',href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-iohuaEflSp",format:{type:"text",isArray:!1}},{id:"c-84Ex4h0pTV",type:"column",name:"File",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-84Ex4h0pTV",format:{type:"attachments",isArray:!0}},{id:"c-FlyVKlvCIx",type:"column",name:"Year of Commencement or Creation",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-FlyVKlvCIx",format:{type:"text",isArray:!1}},{id:"c-2pT34POxIT",type:"column",name:"Relevance Type",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-2pT34POxIT",format:{table:{id:"grid-1ohiEKjQFc",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-1ohiEKjQFc",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-1ohiEKjQFc",name:"Nature of relevance"},type:"lookup",isArray:!0}},{id:"c-fJvB8zmh-Y",type:"column",name:"What kinds of education, if any, are contemplated by the policy?",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-fJvB8zmh-Y",format:{table:{id:"grid-0_3yg-Vkoy",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-0_3yg-Vkoy",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-0_3yg-Vkoy",name:"Which kind of education does it expressly mention?"},type:"lookup",isArray:!0}},{id:"c-zdfmo_m_Tj",type:"column",name:"Principles on AI in education",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-zdfmo_m_Tj",format:{table:{id:"grid-zXkG0jBLna",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-zXkG0jBLna",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-zXkG0jBLna",name:"AI in education principles"},type:"lookup",isArray:!0}},{id:"c-5VlrDV5zWa",type:"column",name:"Governance practices employed",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-5VlrDV5zWa",format:{table:{id:"grid-Xr9iAFDRZl",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-Xr9iAFDRZl",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-Xr9iAFDRZl",name:"Type of policy initaitive"},type:"lookup",isArray:!0}},{id:"c-r-XaOjk8Lk",type:"column",name:"Analysis Complete",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-r-XaOjk8Lk",format:{displayType:"check",type:"checkbox",isArray:!1}},{id:"c-Nq_phIQjPG",type:"column",name:"Link (OECD or Other)",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-Nq_phIQjPG",format:{display:"iconOnly",type:"link",isArray:!1}},{id:"c-gdxdwF0OOx",type:"column",name:"Series #",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-gdxdwF0OOx",format:{precision:22,useThousandsSeparator:!0,type:"number",isArray:!1}},{id:"c-Sm3wWbxOJ2",type:"column",name:"Title",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-Sm3wWbxOJ2",display:!0,calculated:!0,format:{type:"text",isArray:!1},formula:'Concatenate([Policy creator],": ",[Policy Name])'},{id:"c-zAp89itebl",type:"column",name:"Opportunity and risk orientation",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-zAp89itebl",format:{table:{id:"grid-P_wv2uo4M6",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-P_wv2uo4M6",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-P_wv2uo4M6",name:"Considering both opportunities and risks?"},type:"lookup",isArray:!1}},{id:"c-L3R0H6xpKL",type:"column",name:"Category of creator",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-L3R0H6xpKL",calculated:!0,format:{type:"select",isArray:!1},formula:"[Policy creator].[OECD?].ListCombine()"},{id:"c-9Qm-26QJsu",type:"column",name:"Translation Comments",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-9Qm-26QJsu",format:{type:"select",isArray:!1}},{id:"c-wPHcwhpe1X",type:"column",name:"Key quotes on AI in education principles",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-wPHcwhpe1X",format:{type:"canvas",isArray:!1}},{id:"c-5hHdZ0sfu8",type:"column",name:"Does the policy reflect the principle of human rights compatibility?",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-5hHdZ0sfu8",format:{table:{id:"grid-qlBRzb18gd",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-qlBRzb18gd",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-qlBRzb18gd",name:"Does it make reference to human, fundamental, or inalienable rights?"},type:"lookup",isArray:!1}},{id:"c-Y854zWDfFY",type:"column",name:"Key quote on human rights",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-Y854zWDfFY",format:{type:"text",isArray:!1}},{id:"c-LxM7tcl6OJ",type:"column",name:"Does the policy reflect the principle of equity/equality?",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-LxM7tcl6OJ",format:{table:{id:"grid-OWGRQYLMAA",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-OWGRQYLMAA",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-OWGRQYLMAA",name:"Does it make reference to equity?"},type:"lookup",isArray:!1}},{id:"c-U0fCdFgXTA",type:"column",name:"Key quote on equity/equality",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-U0fCdFgXTA",format:{type:"text",isArray:!1}},{id:"c-tQrodNzumD",type:"column",name:"General principles on AI",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-tQrodNzumD",format:{table:{id:"grid-Jef7egIzgb",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-Jef7egIzgb",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-Jef7egIzgb",name:"General AI principles"},type:"lookup",isArray:!0}},{id:"c-81BAzxH2C6",type:"column",name:"Draft Analysis Complete",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-81BAzxH2C6",format:{displayType:"check",type:"checkbox",isArray:!1}},{id:"c-erzTbcFItg",type:"column",name:'Reasons for non-inclusion (other than "Irrelevant")',href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-erzTbcFItg",format:{type:"select",isArray:!1}},{id:"c-cH92ZKzGzy",type:"column",name:"Weekend",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-cH92ZKzGzy",format:{displayType:"check",type:"checkbox",isArray:!1}},{id:"c-lgXRPxQGDm",type:"column",name:"Key quotes on general AI principles",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-lgXRPxQGDm",format:{type:"canvas",isArray:!1}},{id:"c-nKkCVHlbQZ",type:"column",name:"WC Favourite",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-nKkCVHlbQZ",format:{displayType:"check",type:"checkbox",isArray:!1}},{id:"c-OgsmPhUiK0",type:"column",name:"Notable Case Studes - Examples of AI in Education",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-OgsmPhUiK0",format:{type:"canvas",isArray:!1}},{id:"c-O2MdT9sMx2",type:"column",name:"Other Points of Interest",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-O2MdT9sMx2",format:{type:"canvas",isArray:!1}},{id:"c-LT8GCmk4tr",type:"column",name:"Record Entered By",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-LT8GCmk4tr",format:{table:{id:"grid-vq4WMZ5Lm7",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-vq4WMZ5Lm7",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-vq4WMZ5Lm7",name:"Record Entered By"},type:"lookup",isArray:!0}}],rows:[{values:{"Policy Name":"Framework Act on Artificial Intelligence Development and Establishment of a Foundation for Trustworthiness ","Policy creator":["South Korea"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"A general framework regulates high-impact AI including education",File:["\u110B\u1175\u11AB\u1100\u1169\u11BC\u110C\u1175\u1102\u1173\u11BC \u1107\u1161\u11AF\u110C\u1165\u11AB\u1100\u116A \u1109\u1175\u11AB\u1105\u116C \u1100\u1175\u1107\u1161\u11AB \u110C\u1169\u1109\u1165\u11BC \u1103\u1173\u11BC\u110B\u1166 \u1100\u116A\u11AB\u1112\u1161\u11AB \u1100\u1175\u1107\u1169\u11AB\u1107\u1165\u11B8(\u1107\u1165\u11B8\u1105\u1172\u11AF)(\u110C\u116620676\u1112\u1169)(20260122) ENGLISH.pdf","\u110B\u1175\u11AB\u1100\u1169\u11BC\u110C\u1175\u1102\u1173\u11BC \u1107\u1161\u11AF\u110C\u1165\u11AB\u1100\u116A \u1109\u1175\u11AB\u1105\u116C \u1100\u1175\u1107\u1161\u11AB \u110C\u1169\u1109\u1165\u11BC \u1103\u1173\u11BC\u110B\u1166 \u1100\u116A\u11AB\u1112\u1161\u11AB \u1100\u1175\u1107\u1169\u11AB\u1107\u1165\u11B8(\u1107\u1165\u11B8\u1105\u1172\u11AF)(\u110C\u116620676\u1112\u1169)(20260122).pdf"],"Year of Commencement or Creation":"2025","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Binds. It creates binding obligations in relation to AI","Proposes law. It proposes a law or provides a draft law on AI","Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)","Tracks. It sets out to boost understanding specifically of where and how AI is being used","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"https://www.law.go.kr/%25EB%25B2%2595%25EB%25A0%25B9/%25EC%259D%25B8%25EA%25B3%25B5%25EC%25A7%2580%25EB%258A%25A5%2520%25EB%25B0%259C%25EC%25A0%2584%25EA%25B3%25BC%2520%25EC%258B%25A0%25EB%25A2%25B0%2520%25EA%25B8%25B0%25EB%25B0%2598%2520%25EC%25A1%25B0%25EC%2584%25B1%2520%25EB%2593%25B1%25EC%2597%2590%2520%25EA%25B4%2580%25ED%2595%259C%2520%25EA%25B8%25B0%25EB%25B3%25B8%25EB%25B2%2595/(20676,20250121)","Series #":"",Title:"South Korea: Framework Act on Artificial Intelligence Development and Establishment of a Foundation for Trustworthiness ","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["OECD"],"Translation Comments":"Translation Completed (DeepL)","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","R&D. Sufficient resources should be invested in AI R&D.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress."],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-6vjnfILLDk",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-6vjnfILLDk",name:"South Korea: Framework Act on Artificial Intelligence Development and Establishment of a Foundation for Trustworthiness ",index:494,createdAt:"2025-04-30T01:49:31.178Z",updatedAt:"2025-04-30T06:34:32.834Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-6vjnfILLDk"},{values:{"Policy Name":"A pro-innovation approach  to AI regulation","Policy creator":["United Kingdom"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"A general regulation approach but can inform education",File:["a-pro-innovation-approach-to-ai-regulation-amended-web-ready.pdf"],"Year of Commencement or Creation":"2023","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Guides impact assessment. It helps officials anticipate or evaluate the impact of AI","Plans further action. It sets out a strategy on AI","Tracks. It sets out to boost understanding specifically of where and how AI is being used","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper","Series #":"",Title:"United Kingdom: A pro-innovation approach  to AI regulation","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":`We anticipate that regulators will need to:

1. Interpret and articulate \u2018fairness\u2019 as relevant to their sector or domain,

2. Decide in which contexts and specific instances fairness is important and relevant (which it may not always be).

3. Design, implement and enforce appropriate governance requirements for \u2018fairness\u2019 as applicable to the entities that they regulate.

4. Where a decision involving use of an AI system has a legal or similarly significant effect on an individual, regulators will need to consider the suitability of requiring AI system operators to provide an appropriate justification for that decision to affected parties.

5. AI systems should comply with regulatory requirements relating to vulnerability of individuals within specific regulatory domains. Regulators will need to consider how use of AI systems may alter individuals\u2019 vulnerability, pursuant to their existing powers and remits.

6. Consider the role of available technical standards addressing AI fairness, bias mitigation and ethical considerations (for example, ISO/IEC\xA0TR 24027:2021, ISO/IEC\xA012791*, ISO/IEC\xA0TR 24368:2022) to clarify regulatory guidance and support the implementation of risk treatment measures.`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":"","General principles on AI":["Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (explainability). AI systems should be sufficiently explainable.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Interoperability. AI systems should be able to work with other systems. ","Inclusive development. AI systems should be developed inclusively. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-mVcrtMCV1l",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-mVcrtMCV1l",name:"United Kingdom: A pro-innovation approach  to AI regulation",index:493,createdAt:"2025-04-30T01:12:12.328Z",updatedAt:"2025-04-30T01:33:26.550Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-mVcrtMCV1l"},{values:{"Policy Name":"The National Artificial Intelligence Strategy of Mauritania for 2025\u20132029","Policy creator":["Mauritius"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The strategy includes AI in education sector",File:["The National Artificial Intelligence Strategy of Mauritania for 2025\u20132029.pdf"],"Year of Commencement or Creation":"2024","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI","Educates. It helps officials or others understand the opportunities and risks of AI","Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)","Communicates a stance. It expresses a hope for the future of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"https://mtnima.gov.mr/wp-content/uploads/2024/07/strategie-EN-Final-26-07-2024-.pdf","Series #":"",Title:"Mauritius: The National Artificial Intelligence Strategy of Mauritania for 2025\u20132029","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["Non-OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"This strategy will integrate artificial intelligence technologies into the field of education through projects aimed at serving all stakeholders in the educational system. one the one hand , these projects will be used to enhance student learning by providing interactive tools and programs specifically designed to meet their needs, thereby boosting their academic success. On the other hand, teachers will benefit from these projects by creating innovative educational content, analyzing student performance, and tailoring instruction based on each student's individual progress.  At the institutional level, these projects will assist educational institutions in improving resource management, curriculum planning, and decision-making based on accurate data and in-depth analyses.  Additionally, this strategy includes a project for translating various national dialects, which aims to enhance social cohesion by facilitating linguistic communication and access to knowledge resources in the different dialects used in the country.","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Respect for laws [NEW]. AI should respect existing law.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,"],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"This strategic priority focuses on ensure that the development and utilization of artificial intelligence complies with stringent ethical and legal standards. These standards encompass safeguarding personal data, ensuring data protection and privacy, respecting intellectual property rights, and adhering to pertinent regulations. Our commitment to upholding the ethical standards of the Arab League, the African Union and the United Nations is integral to accomplishing this strategy.","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-0SqFdnPRIL",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-0SqFdnPRIL",name:"Mauritius: The National Artificial Intelligence Strategy of Mauritania for 2025\u20132029",index:492,createdAt:"2025-04-30T00:52:07.857Z",updatedAt:"2025-04-30T01:08:56.524Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-0SqFdnPRIL"},{values:{"Policy Name":"Driving U.S. Innovation in Artificial Intelligence: A Roadmap for Artificial Intelligence Policy in the United States Senate","Policy creator":["United States"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"A comprehensive framework aimed at addressing the multifaceted opportunities and risks presented by artificial intelligence (\u201CAI\u201D) technologies could inform the governance of AI in education",File:["Driving U.S. Innovation in Artificial Intelligence A Roadmap for Artificial Intelligence Policy in.pdf"],"Year of Commencement or Creation":"2024","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Plans further action. It sets out a strategy on AI","Proposes law. It proposes a law or provides a draft law on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"United States: Driving U.S. Innovation in Artificial Intelligence: A Roadmap for Artificial Intelligence Policy in the United States Senate","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Transparency (explainability). AI systems should be sufficiently explainable.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Opportunity. The opportunities of AI should be harnessed.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","R&D. Sufficient resources should be invested in AI R&D.","Respect for laws [NEW]. AI should respect existing law.","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-j33OQcVixo",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-j33OQcVixo",name:"United States: Driving U.S. Innovation in Artificial Intelligence: A Roadmap for Artificial Intelligence Policy in the United States Senate",index:491,createdAt:"2025-04-30T00:26:12.572Z",updatedAt:"2025-04-30T00:50:46.186Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-j33OQcVixo"},{values:{"Policy Name":"Sri Lanka's National Strategy on AI","Policy creator":["Sri Lanka"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Mentions education as a high-impact area and a key governance domain",File:["National AI strategy for Sri Lanka.pdf"],"Year of Commencement or Creation":"2024","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Plans further action. It sets out a strategy on AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Educates. It helps officials or others understand the opportunities and risks of AI"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"Sri Lanka: Sri Lanka's National Strategy on AI","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":[""],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"Human-centricity: AI systems should respect human-centred values and pursue benefits for society, including health, well-being, relationships, personhood, and individual dignity. They should not be used for malicious purposes or to sway or deceive users into making harmful decisions.","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":"Fairness and Equity: AI systems should be designed and implemented with fairness in mind, minimizing bias and discrimination to ensure equitable treatment for all individuals. They must not undermine legal rights, discriminate unfairly, or create unfair market outcomes.","General principles on AI":["Augmentation, not replacement. AI systems should augment, not displace, workers.","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Human rights-centred. AI systems should be compatible with human rights. ","Environmental wellbeing. The use of AI should not harm the environment. ","Transparency (explainability). AI systems should be sufficiently explainable.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power.","Freedom of speech and assembly [NEW]. AI systems should not abrogate freedom of speech or assembly. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Respect for laws [NEW]. AI should respect existing law.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-wycemXJq9G",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-wycemXJq9G",name:"Sri Lanka: Sri Lanka's National Strategy on AI",index:490,createdAt:"2025-04-29T08:07:44.766Z",updatedAt:"2025-04-29T08:30:26.654Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-wycemXJq9G"},{values:{"Policy Name":"2024 Artificial Intelligence Strategy","Policy creator":["Spain"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Although not focused on education, the strategy identifies education as one of the social domains for AI supervision and calls for developing flexible yet robust frameworks tailored to contexts such as education.",File:["Spain\u2019s 2024 Artificial Intelligence Strategy.pdf"],"Year of Commencement or Creation":"2024","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)","Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"Spain: 2024 Artificial Intelligence Strategy","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"","General principles on AI":["Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Respect for laws [NEW]. AI should respect existing law.","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Transparency (explainability). AI systems should be sufficiently explainable.","R&D. Sufficient resources should be invested in AI R&D."],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-b9L-R5YgBc",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-b9L-R5YgBc",name:"Spain: 2024 Artificial Intelligence Strategy",index:489,createdAt:"2025-04-29T07:44:44.345Z",updatedAt:"2025-04-29T08:06:18.710Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-b9L-R5YgBc"},{values:{"Policy Name":"AI Adoption Framework","Policy creator":["Saudi Arabia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"not engage with governance of AI in education.",File:"","Year of Commencement or Creation":"2024","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"Saudi Arabia: AI Adoption Framework","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-uSLrgrzipe",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-uSLrgrzipe",name:"Saudi Arabia: AI Adoption Framework",index:488,createdAt:"2025-04-29T07:43:14.954Z",updatedAt:"2025-04-29T07:44:17.439Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-uSLrgrzipe"},{values:{"Policy Name":"Generative Artificial Intelligence Guidelines For Government","Policy creator":["Saudi Arabia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"not engage with governance of AI in education.",File:["Saudi Arabia-Generative Artificial Intelligence Guidelines For Government.pdf"],"Year of Commencement or Creation":"2024","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"Saudi Arabia: Generative Artificial Intelligence Guidelines For Government","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-Igg1ZQ9Nl4",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Igg1ZQ9Nl4",name:"Saudi Arabia: Generative Artificial Intelligence Guidelines For Government",index:487,createdAt:"2025-04-29T07:41:15.118Z",updatedAt:"2025-04-29T07:42:25.286Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Igg1ZQ9Nl4"},{values:{"Policy Name":"Generative Artificial Intelligence Guidelines Public","Policy creator":["Saudi Arabia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"just one sentence acknowledges risks GenAI poses to educational assessment integrity (e.g., certification fraud)",File:"","Year of Commencement or Creation":"2024","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"Saudi Arabia: Generative Artificial Intelligence Guidelines Public","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-HYFubXllDU",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-HYFubXllDU",name:"Saudi Arabia: Generative Artificial Intelligence Guidelines Public",index:486,createdAt:"2025-04-29T07:36:50.252Z",updatedAt:"2025-04-29T07:40:50.700Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-HYFubXllDU"},{values:{"Policy Name":"State of AI in Saudi Arabia","Policy creator":["Saudi Arabia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The policy discusses AI talent development and human capacity building, but it does not address the governance of AI in education systems or the responsible management of AI technologies in education.",File:"","Year of Commencement or Creation":"2024","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"Saudi Arabia: State of AI in Saudi Arabia","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-qlhowcHxuY",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-qlhowcHxuY",name:"Saudi Arabia: State of AI in Saudi Arabia",index:485,createdAt:"2025-04-29T07:34:35.472Z",updatedAt:"2025-04-29T07:36:04.676Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-qlhowcHxuY"},{values:{"Policy Name":"Nigirian National AI Strategy","Policy creator":["Nigeria"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The policy contains some fleeting references to education-related AI initiatives such as training, curriculum development, and capacity building. However, it does not engage with the governance of AI in education or propose frameworks for managing AI technologies within educational systems.",File:"","Year of Commencement or Creation":"2024","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"Nigeria: Nigirian National AI Strategy","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-KW-T-1Ebam",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-KW-T-1Ebam",name:"Nigeria: Nigirian National AI Strategy",index:484,createdAt:"2025-04-29T07:20:00.904Z",updatedAt:"2025-04-29T07:32:20.262Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-KW-T-1Ebam"},{values:{"Policy Name":"National Programme on Artificial Intelligence (NPAI) Skilling Framework","Policy creator":["India"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Addresses AI skilling across education and embeds responsible AI principles into educational governance.",File:["5732498_Report-on-NPAI-Skilling-Framework.pdf"],"Year of Commencement or Creation":"2023","Relevance Type":["Policy is about AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Secondary","Tertiary","Vocational or Professional"],"Principles on AI in education":["Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Managing bias. The risk of bias should be managed with care. ","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ","Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Plans further action. It sets out a strategy on AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"India: National Programme on Artificial Intelligence (NPAI) Skilling Framework","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["Non-OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"Ethical artificial intelligence (AI) refers to the development and use of AI systems in a responsible and morally acceptable manner. It involves ensuring that AI technologies align with ethical principles and values, protect human rights, and minimize potential harms.","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":"Fairness and Bias: AI systems should be designed and trained to avoid bias and discrimination based on factors like race, gender, or ethnicity. Developers should carefully select training data, regularly evaluate, and address biases, and promote transparency in algorithmic decisionmaking.","General principles on AI":["Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Augmentation, not replacement. AI systems should augment, not displace, workers.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Bias testing. AI systems should be tested for bias. ","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Respect for laws [NEW]. AI should respect existing law.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"In summary, ethical AI requires a multidimensional approach that considers fairness, transparency, privacy, accountability, human oversight, social impact, testing, and continuous improvement.","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-KqWfv_mXvr",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-KqWfv_mXvr",name:"India: National Programme on Artificial Intelligence (NPAI) Skilling Framework",index:483,createdAt:"2025-04-29T06:33:28.411Z",updatedAt:"2025-04-29T07:17:34.495Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-KqWfv_mXvr"},{values:{"Policy Name":"Visioning the Future by Transforming Education-National Education Strategy","Policy creator":["Malta"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"It explicitly mentions professional training on AI for teachers\u200B, AI literacy and digital citizenship skills for students\u200B and the use of AI for data analysis and education policy planning\u200B.",File:["Maltese National Education Strategy 2024-2030.pdf"],"Year of Commencement or Creation":"2024","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "],"Governance practices employed":["Communicates a stance. It expresses a hope for the future of AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://www.gov.mt/en/publicconsultation/Pages/2023/NL-0051-2023.aspx","Series #":"",Title:"Malta: Visioning the Future by Transforming Education-National Education Strategy","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"Eventually, it is the Ministry\u2019s plan to employ AI technologies for data analysis and forecasting, the results of which will serve as evidence for future policies and strategies.","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about AI as a tool for promoting equitable/equal access","Key quote on equity/equality":"Internationally, equity and inclusion have been set high on the agenda since there is a general understanding that social gaps have been exacerbated following the pandemic, a higher rate of migration and due to the digital divide28. The Ministry is committed to addressing social fragmentation and inequalities since it is our belief that education is a fundamental tool through which everyone is given the opportunity to reach their potential. To this end, one of the first steps to be taken to understand how different policies and decisions are impacting different groups of students, is employing a system-wide data disaggregation exercise29, which is also one of the SDG indicators for quality education. Eventually, it is the Ministry\u2019s plan to employ AI technologies for data analysis and forecasting, the results of which will serve as evidence for future policies and strategies.","General principles on AI":["Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Inclusive development. AI systems should be developed inclusively. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Opportunity. The opportunities of AI should be harnessed.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-SL_Hq9MiTY",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-SL_Hq9MiTY",name:"Malta: Visioning the Future by Transforming Education-National Education Strategy",index:482,createdAt:"2025-04-28T06:34:16.612Z",updatedAt:"2025-04-28T07:13:32.996Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-SL_Hq9MiTY"},{values:{"Policy Name":"Our AI: Our Ambition for France","Policy creator":["France"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The policy discusses AI\u2019s integration into public services including education",File:["France-Our AI Our Ambition for France.pdf"],"Year of Commencement or Creation":"2024","Relevance Type":["Policy makes fleeting reference to AI in education"],"What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Develops tools. It provides tools and place them in the hands of businesses or governments"],"Analysis Complete":!0,"Link (OECD or Other)":"https://www.info.gouv.fr/upload/media/content/0001/09/02cbcb40c3541390be391feb3d963a4126b12598.pdf","Series #":"",Title:"France: Our AI: Our Ambition for France","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":`Finally, AI systems should be used to improve the quality of public services. Artificial intelligence can improve public services, by helping to personalize education, give patients more time, better support and anticipate professional transitions, and reduce bureaucracy.
We also need to invest in training for everyone, at every age: young people in school and afterschool, specialized and non-specialized students, employees, the self-employed and publicsector workers, retirees This means preparing for tomorrow's professions, in particular by structuring a range of hybrid higher education courses, such as "AI + biology" and "law + AI", or by creating AI chairs in design schools We must also enable the use of AI in today's professions, for example by planning an AI awareness course for all civil servants
`,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`Today, it's up to us to take advantage of AI by putting it in its rightful place: that of a technological means at the service of an ambition for humanity, equality, solidarity, justice, prosperity and freedom.
Algorithms contribute to inequalities in work and employment The massification of uses is accompanied by a growing environmental impact.`,"General principles on AI":["Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Opportunity. The opportunities of AI should be harnessed.","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power."],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-H-8vLe7oN4",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-H-8vLe7oN4",name:"France: Our AI: Our Ambition for France",index:481,createdAt:"2025-04-28T06:14:24.710Z",updatedAt:"2025-04-28T06:33:47.438Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-H-8vLe7oN4"},{values:{"Policy Name":"Policies for the digitalisation of education and training until 2027","Policy creator":["Finland"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The policy focuses on digitalisation across the education system, supporting the development of digital competence, digital infrastructures, and knowledge-based management, and no AI-related regulations, but references principles that could inform the governance of AI in education.",File:["Policies for the digitalisation of education and training until 2027.pdf"],"Year of Commencement or Creation":"2023","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://julkaisut.valtioneuvosto.fi/bitstream/handle/10024/165248/OKM_2023_48.pdf?sequence=1&isAllowed=y","Series #":"",Title:"Finland: Policies for the digitalisation of education and training until 2027","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-hQimX1iSvX",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-hQimX1iSvX",name:"Finland: Policies for the digitalisation of education and training until 2027",index:480,createdAt:"2025-04-28T04:30:01.203Z",updatedAt:"2025-04-28T06:13:13.374Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-hQimX1iSvX"},{values:{"Policy Name":"The Digital Switzerland Strategy 2025","Policy creator":["Switzerland"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"not focus on AI specifically in education.",File:"","Year of Commencement or Creation":"2024","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"Switzerland: The Digital Switzerland Strategy 2025","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-a0B8yTB0oB",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-a0B8yTB0oB",name:"Switzerland: The Digital Switzerland Strategy 2025",index:479,createdAt:"2025-04-28T04:21:46.974Z",updatedAt:"2025-04-28T04:28:59.417Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-a0B8yTB0oB"},{values:{"Policy Name":"AI Opportunity Action Plan","Policy creator":["United Kingdom"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This policy is included because it explicitly proposes developing AI talent through education systems and anticipates AI being used as a tool for assessment within the education sector.",File:["UK-AI Opportunity Action Plan.pdf"],"Year of Commencement or Creation":"2025","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Tertiary","Vocational or Professional"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Communicates a stance. It expresses a hope for the future of AI","Educates. It helps officials or others understand the opportunities and risks of AI"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"United Kingdom: AI Opportunity Action Plan","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"AI directly benefits working people by improving health care and education and how citizens interact with their government.","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women. Achieving parity would mean thousands of additional workers.","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Inclusive development. AI systems should be developed inclusively. ","Opportunity. The opportunities of AI should be harnessed.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-BlChGUymUq",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-BlChGUymUq",name:"United Kingdom: AI Opportunity Action Plan",index:478,createdAt:"2025-04-24T05:16:56.617Z",updatedAt:"2025-04-24T05:30:58.621Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-BlChGUymUq"},{values:{"Policy Name":"Introduction to AI Assurance","Policy creator":["United Kingdom"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"It illustrates a practical approach to AI governance through internal organisational processes. The use of structured \u2018risk assessments\u2019\u2014including staff workshops, detailed questionnaires, and internal audits\u2014demonstrates how educational technology providers can identify and mitigate potential harms (e.g. to user safety, institutional reputation, or learning outcomes).",File:["UK-Introduction to AI Assurance.pdf"],"Year of Commencement or Creation":"2024","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. "],"Governance practices employed":["Guides impact assessment. It helps officials anticipate or evaluate the impact of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Educates. It helps officials or others understand the opportunities and risks of AI"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"United Kingdom: Introduction to AI Assurance","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"Risk assessments are used to consider and identify a range of potential risks that might arise  from the development and/or deployment of an  AI product/systems.","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"Impact assessments are used to anticipate the wider  effects of a system/product on the environment,  equality, human rights, data protection, or other  outcomes.","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"Impact assessments are used to anticipate the wider  effects of a system/product on the environment,  equality, human rights, data protection, or other  outcomes.","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Transparency (explainability). AI systems should be sufficiently explainable.","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-l6Q9QbdRI3",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-l6Q9QbdRI3",name:"United Kingdom: Introduction to AI Assurance",index:477,createdAt:"2025-04-24T05:02:50.459Z",updatedAt:"2025-04-24T05:15:49.398Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-l6Q9QbdRI3"},{values:{"Policy Name":"Council of Europe Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law","Policy creator":["European Union"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"only refer to the rights of children, but not education",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"European Union: Council of Europe Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law","Opportunity and risk orientation":"","Category of creator":["IO"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-aC9vh-8Ol5",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-aC9vh-8Ol5",name:"European Union: Council of Europe Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law",index:476,createdAt:"2025-04-24T04:54:47.382Z",updatedAt:"2025-04-24T05:01:59.943Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-aC9vh-8Ol5"},{values:{"Policy Name":"Policy for the responsible use of AI in government","Policy creator":["Australia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"a coordinated approach to government\u2019s use of AI and has been designed to complement and strengthen the existing frameworks, may provide important insights for education department",File:"","Year of Commencement or Creation":"2024","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"Australia: Policy for the responsible use of AI in government","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-78VCmThDKv",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-78VCmThDKv",name:"Australia: Policy for the responsible use of AI in government",index:475,createdAt:"2025-04-24T04:48:21.284Z",updatedAt:"2025-04-24T04:52:03.544Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-78VCmThDKv"},{values:{"Policy Name":"Guide On The Use Of Generative AI","Policy creator":["Canada"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Involved generative AI may not be suited for use in administrative [such as in the education field] decision-making at this stage.",File:["BT48-37-2023-eng.pdf"],"Year of Commencement or Creation":"2023","Relevance Type":["Policy makes fleeting reference to AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["[N/A]"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"Canada: Guide On The Use Of Generative AI","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"However, generative AI may not be suited for use in administrative  decision-making at this stage. The design and functioning of generative  models can limit federal institutions\u2019 ability to ensure transparency,  8 accountability and fairness in decisions made by generative AI systems or  informed by their outputs. As well, the terms of use for the generative AI  products of many leading technology companies prohibit using their  products to make high-impact decisions. For example, OpenAI instructs  users not to employ ChatGPT in decisions about credit, employment,  educational institutions, or public assistance services; law enforcement and  criminal justice; and migration and asylum.","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"Issue: generative AI poses risks to human rights, privacy, intellectual property protection, and procedural fairness","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`Risks could also arise from the opacity of generative AI models and their  potential for producing inaccurate, biased or inconsistent outputs. This  opacity makes it difficult to trace and understand how the AI system  produces outputs, which can undermine procedural fairness in instances  where a federal institution is obliged to provide clients with reasons for  administrative decisions, such as decisions to deny benefits. The quality of AI outputs can also impact individuals\u2019 legal rights. For example, biased  outputs could lead to discrimination in services, potentially violating human  rights.
To maintain public trust and ensure the responsible use of generative AI  tools, federal institutions should align with the \u201CFASTER\u201D principles-Fair: ensure that content from these tools does not include or amplify  biases and that it complies with human rights, accessibility, and  procedural and substantive fairness obligations`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Human rights-centred. AI systems should be compatible with human rights. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Augmentation, not replacement. AI systems should augment, not displace, workers.","Bias testing. AI systems should be tested for bias. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Environmental wellbeing. The use of AI should not harm the environment. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"This guide also seeks to raise awareness and foster coordination among  federal institutions. It highlights the importance of engaging key  stakeholders before deploying generative AI tools for public use and before  using them for purposes such as service delivery.","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-7EwyhnaVd0",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-7EwyhnaVd0",name:"Canada: Guide On The Use Of Generative AI",index:474,createdAt:"2025-04-24T04:13:43.970Z",updatedAt:"2025-04-24T04:47:33.413Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-7EwyhnaVd0"},{values:{"Policy Name":"Executive Order On Advancing Racial Equity And Support For Underserved Communities Through The Federal Government","Policy creator":["United States"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"mentioned pursuing educational equity so that our Nation\u2019s schools put every student on a path to success, but not AI-related",File:"","Year of Commencement or Creation":"2023","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"United States: Executive Order On Advancing Racial Equity And Support For Underserved Communities Through The Federal Government","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i--IrNbfj3Fx",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i--IrNbfj3Fx",name:"United States: Executive Order On Advancing Racial Equity And Support For Underserved Communities Through The Federal Government",index:473,createdAt:"2025-04-24T04:05:32.364Z",updatedAt:"2025-04-24T04:12:42.874Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui--IrNbfj3Fx"},{values:{"Policy Name":"National framework for the assurance of artificial intelligence in government","Policy creator":"Australia","Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Instead of focusing on technical detail, the framework sets foundations across all aspects of government, so including education.",File:["National framework for the assurance of artificial intelligence in government.pdf"],"Year of Commencement or Creation":"2024","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Human rights-centred. The technology must be consistent with human rights. ","Information. Information about the technology in use should be readily available. ","Managing bias. The risk of bias should be managed with care. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Trust. Organisations seeking to incorporate AI into educational settings must build trust.","Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. ","Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology."],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"Australia: National framework for the assurance of artificial intelligence in government","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`AI systems should respect human rights, diversity and the autonomy of individuals.
Governments should involve people with different lived experiences, including marginalisation, throughout the lifecycles of a use case to gather informed perspectives,  remove preconceptions and avoid overlooking important considerations.`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":"Governments should ensure high-quality data and algorithmic design. Audits of AI inputs and outputs for unfair biases, data quality statements and other data  governance and management practices may assist to understand and mitigate bias in AI systems.","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Environmental wellbeing. The use of AI should not harm the environment. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Respect for laws [NEW]. AI should respect existing law.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":`Australia's 8 AI Ethics Principles, demonstrating how governments can practically apply them to their assurance of AI. 
Human, societal and environmental wellbeing: Throughout their lifecycle, AI systems should benefit  individuals, society and the environment
Human-centred values: AI systems should respect human rights, diversity and the autonomy of individuals.
Fairness: AI systems should be inclusive and accessible, and should not involve or result in unfair discrimination against individuals, communities or groups.
Privacy protection and security: AI systems should respect and uphold privacy rights of individuals and ensure the protection of data.
Reliability and safety: Throughout their lifecycle, AI systems should reliably operate in accordance with their intended purpose.
Transparency and explainability: There should be transparency and responsible disclosure so people can understand when they are being significantly impacted by AI, and can find out when an AI system is engaging with them.
Contestability: When an AI system significantly impacts a person, community,  group or environment, there should be a timely process to allow  people to challenge the use or outcomes of the AI system.
Accountability: Those responsible for the different phases of the AI  system lifecycle should be identifiable and accountable for the outcomes of the AI systems, and human oversight of AI systems should be enabled.`,"WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-OCnVnwg791",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-OCnVnwg791",name:"Australia: National framework for the assurance of artificial intelligence in government",index:472,createdAt:"2025-03-03T02:22:23.278Z",updatedAt:"2025-03-04T23:49:34.774Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-OCnVnwg791"},{values:{"Policy Name":"Italian Strategy for Artificial Intelligence 2024-2026","Policy creator":"Italy","Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Education as one of the four marco-area in the strategic actions",File:["Italian Strategy for Artificial Intelligence 2024-2026.pdf"],"Year of Commencement or Creation":"2024","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Tertiary","Primary","Secondary"],"Principles on AI in education":["Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ","Critical thinking. Use of the tools should not come at the cost of critical thinking.  ","Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"Italy: Italian Strategy for Artificial Intelligence 2024-2026","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":`To harness the benefits of AI, however, high professional skills capable of developing and managing algorithms and AI systems are required...As a preliminary to any strategic action, it is therefore essential to address this structural problem by deploying a major plan to strengthen, integrate, and disseminate AI knowledge and related digital skills throughout the education system: from Higher Technical Institutes (ITS) to universities, with particular attention to research doctorates.
The development of a national strategy for Artificial Intelligence must be based on the premise that, in this exceptionally dynamic context, no worker can be left behind. In order for AI-derived applications to have positive effects on the whole society, reducing risks, it will be necessary to further expand the concept of \u201Ceducation\u201D by aiming in Italy to implement an AI literacy process that involves schools, workers, and all citizens, with attention to the most vulnerable categories.
Objectives: Promote widespread university education on AI; Implement educational pathways on AI in schools
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"(Design of Intalian large molecule models)Development should focus on specific applications contextualized in significant application domains for our country, for example in Public Administration or in the health sector, that fully comply with European values and regulations in terms of: (i) transparency of training data, to ensure compliance with non-discrimination laws, privacy (GDPR), human rights protection, providing reliable information on the sources from which content is generated;","Does the policy reflect the principle of equity/equality?":"[N/A]","Key quote on equity/equality":"","General principles on AI":["Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Environmental wellbeing. The use of AI should not harm the environment. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Interoperability. AI systems should be able to work with other systems. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","R&D. Sufficient resources should be invested in AI R&D.","Respect for laws [NEW]. AI should respect existing law.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-4zUYKmQq-a",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-4zUYKmQq-a",name:"Italy: Italian Strategy for Artificial Intelligence 2024-2026",index:471,createdAt:"2025-03-03T01:04:13.795Z",updatedAt:"2025-03-03T02:18:41.052Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-4zUYKmQq-a"},{values:{"Policy Name":"Continental Artificial Intelligence Strategy","Policy creator":"African Union","Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This includes a section on expanding AI adoption in the education sector in Africa with recommendation and associated actions",File:["African Union-Continental Artificial Intelligence Strategy.pdf"],"Year of Commencement or Creation":"2024","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":"",Title:"African Union: Continental Artificial Intelligence Strategy","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["IO"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"Despite the risks, AI has the potential to facilitate higher-order thinking if guided by proper instructional design and support formative assessment of basic skills.","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"Human Rights and Human Dignity\u2014The production, development, use and assessment of AI systems in Africa will always uphold human dignity, gender equality and respect and promote all the human rights set out under the African Charter on Human and Peoples\u2019 Rights and its subsidiary instruments, as well as the Universal Declaration on Human Rights and related instruments of international human rights law.","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":"Special efforts are needed from continental, regional and national agencies and governments to ensure that the development and adoption of AI are inclusive and benefit all Africans, empower women and girls, and underrepresented groups and respect Africa\u2019s cultural and linguistic diversity.","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Environmental wellbeing. The use of AI should not harm the environment. ","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Interoperability. AI systems should be able to work with other systems. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","R&D. Sufficient resources should be invested in AI R&D.","Respect for laws [NEW]. AI should respect existing law.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-ViAANnebu8",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ViAANnebu8",name:"African Union: Continental Artificial Intelligence Strategy",index:470,createdAt:"2025-03-03T00:55:02.832Z",updatedAt:"2025-03-03T01:01:16.746Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ViAANnebu8"},{values:{"Policy Name":"Inquiry into the Use of Generative Artificial Intelligence in the Australian Education System","Policy creator":["Australia"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This is directly on the topic. Lots of interesting submissions.
Submissions \u2013 Parliament of Australia (aph.gov.au)`,File:"","Year of Commencement or Creation":"2023","Relevance Type":["Policy is about AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["[N/A: This is an inquiry, and does not presuppose the answer to questions]"],"Governance practices employed":["Seeks information. It gathers inputs on public sentiment about AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://www.aph.gov.au/Parliamentary_Business/Committees/House/Employment_Education_and_Training/AIineducation/Terms_of_Reference","Series #":21,Title:"Australia: Inquiry into the Use of Generative Artificial Intelligence in the Australian Education System","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":`\u201CThe House of Representatives Standing Committee on Employment, Education and Training will inquire into the issues and opportunities presented by generative Artificial Intelligence (AI), and comprehensively explore current and future impacts on Australia\u2019s early childhood education, schools, and higher education sectors.
 The inquiry will include consideration of:
The strengths and benefits of generative AI tools for children, students, educators and systems and the ways in which they can be used to improve education outcomes;
The future impact generative AI tools will have on teaching and assessment practices in all education sectors, the role of educators, and the education workforce generally;
The risks and challenges presented by generative AI tools, including in ensuring their safe and ethical use and in promoting ongoing academic and research integrity;
How cohorts of children, students and families experiencing disadvantage can access the benefits of AI;
International and domestic practices and policies in response to the increased use of generative AI tools in education, including examples of best practice implementation, independent evaluation of outcomes, and lessons applicable to the Australian context; and
Recommendations to manage the risks, seize the opportunities, and guide the potential development of generative AI tools including in the area of standards.\u201D

Note that the submissions might be interesting as secondary materials. `,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"The terms of reference do not use the language of \u201Chuman rights\u201D. ","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"The terms of reference do not use the language of \u201Cequity\u201D. ","General principles on AI":["[N/A]"],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-dsHz67wttW",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-dsHz67wttW",name:"Australia: Inquiry into the Use of Generative Artificial Intelligence in the Australian Education System",index:18,createdAt:"2024-06-01T06:56:56.730Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-dsHz67wttW"},{values:{"Policy Name":"Estonia 2035 + 2023 Action Plan","Policy creator":["Estonia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"General remarks on Estonia\u2019s national strategy. ",File:["Eesti 2035_PUHTAND \xDCLDOSA_210512_ENG_0.pdf","Eesti 2035__tegevuskava_ENG_30.06 2.pdf"],"Year of Commencement or Creation":"2021 (Estonia 2035), 2023 (Action Plan)","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"","Series #":13,Title:"Estonia: Estonia 2035 + 2023 Action Plan","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-_yxkr4vXdf",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_yxkr4vXdf",name:"Estonia: Estonia 2035 + 2023 Action Plan",index:17,createdAt:"2024-06-01T06:34:59.151Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_yxkr4vXdf"},{values:{"Policy Name":"Estonia Education Strategy 2035","Policy creator":["Estonia"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is directly on point \u2014 part of their education strategy involves using technology to make progress. Note I have included some supplementary documents in addition to the actual strategy. The big focus is \u201Cdigital pedagogy\u201D. ",File:["Estonia's Education Minister Kristina Kallas on the challenges and opportunities of AI in learning and empowerment [Q&A] - TNGlobal.pdf","Estonia - Education Strategy 2021-2035 _ Digital Skills and Jobs Platform.pdf","Estonia to unleash AI for personalisation of education.pdf","The AI debate in Estonian education_ A balanced approach - Education Estonia.pdf","estonia_education_strategy_2021-2023.pdf"],"Year of Commencement or Creation":"2021","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://technode.global/2024/05/17/estonias-education-minister-kristina-kallas-on-the-challenges-and-opportunities-of-ai-in-learning-and-empowerment-qa/","Series #":12,Title:"Estonia: Estonia Education Strategy 2035","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":`Digital pedagogy:
\u201CEducators are familiar with trends, opportunities, risks and methodologies related to new technologies, and apply the technologies in a purposeful way. Smart learning resources and methodology support captivating and effective learning and teaching, and help to give and receive immediate and substantial feedback.\u201D (2035 Education Strategy (English), p 19)
Smart learning resources:
\u201CSmart learning resources allow personalised and adaptive learning by means of technology. Smart learning resources enable the empowerment of learners and the addition of value to the learning process through the use of technology (learning analytics, AI, etc.).\u201D (2035 Education Strategy (English), p 36)
Summary 
\u201CEducators are familiar with trends, opportunities, risks and methodologies related to new technologies, and apply the technologies in a purposeful way. Smart learning resources and methodology support captivating and effective learning and teaching, and help to give and receive immediate and substantial feedback. Essential action is personalisation and diversification of learning and supporting learning through digital solutions. It is necessary to: promote the development and implementation of diverse methods of learning and teaching (including digital pedagogy); develop and use digital solutions as tools for educational innovation that enable the diversification and personalisation of education, including assessment for learning; raise awareness among participants in the learning process of the opportunities and risks of the information society; adopt a systematic approach to the introduction of new solutions; improve access to Estonian \u2013 language education and learning of Estonian by introducing digital solutions.\u201D (Education Strategy Summary Document, no pinpoint)
Interview with the Minister leading this:
\u201CMinister Kallas acknowledges the challenges of teacher shortages and the need for curriculum adaptation in light of the rapid emergence of AI. However, she remains optimistic, emphasizing the importance of investing in teacher training, developing AI-enhanced learning tools, and fostering collaboration between the public and private sectors. Estonia\u2019s groundbreaking initiatives, such as the AI-enabled infrastructure for personalized learning and the ProgeTiiger Program for teaching programming skills, have garnered international attention. Kallas envisions further collaboration with countries like Singapore, sharing insights and expertise to advance the field of EdTech innovation.\u201D (Interview doc, no pinpoint)`,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"N/A","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"N/A","General principles on AI":["[N/A]"],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!0,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-viyYHzDKAf",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-viyYHzDKAf",name:"Estonia: Estonia Education Strategy 2035",index:16,createdAt:"2024-06-01T06:29:39.281Z",updatedAt:"2024-06-03T23:12:54.856Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-viyYHzDKAf"},{values:{"Policy Name":"Guidance for generative AI in education and research","Policy creator":["UNESCO"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Highly relevant. ",File:["386693eng.pdf"],"Year of Commencement or Creation":"2023","Relevance Type":["Policy is about AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Academic integrity. Students should be supported to use AI tools ethically in their work, which extends to appropriate attribution.","Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Critical thinking. Use of the tools should not come at the cost of critical thinking.  ","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Human rights-centred. The technology must be consistent with human rights. ","Information. Information about the technology in use should be readily available. ","Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.","Managing bias. The risk of bias should be managed with care. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.","Promoting diversity. Technology should be used to expose users to diverse perspectives. ","Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":5,Title:"UNESCO: Guidance for generative AI in education and research","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["IO"],"Translation Comments":"","Key quotes on AI in education principles":`To properly understand where they are coming from, note the introduction:
\u201CHowever, a thematic set of guidance on GenAI for education should not be understood as a claim that GenAI is the solution to education\u2019s fundamental challenges. Despite the media hyperbole, it is unlikely that GenAI alone will solve any of the problems facing education systems around the world. In responding to long-standing educational issues, it is key to uphold the idea that human capacity and collective action, and not technology, is the determining factor in effective solutions to fundamental challenges faced by societies.\u201D (p 7)
There is so much in here that I suggest it is better to read pp 24 to 27
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201CUNESCO\u2019s 2021 Recommendation on the Ethics of Artificial Intelligence provides the requisite normative framework to start addressing the multiple controversies around generative AI, including those that pertain to education and research. It is based on a human-centred approach to AI which advocates that the use of AI should be at the service of the development of human capabilities for inclusive, just and sustainable futures. Such an approach must be guided by human rights principles, and the need to protect human dignity and the cultural diversity that defines the knowledge commons. In terms of governance, a human-centred approach requires proper regulation that can ensure human agency, transparency and public accountability.\u201D (p 18)
\u201CEdGPT. Finally, there is also a need for robust research to ensure that EdGPT does not undermine students\u2019 human rights nor disempower teachers.\u201D (p 13)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`Data poverty: Kalervo Gulson 
As noted earlier, GenAI relies upon huge amounts of data and massive computing power in addition to its iterative innovations in AI architectures and training methods, which are mostly only available to the largest international technology companies and a few economies (mostly the United States, People\u2019s Republic of China, and to a lesser extent Europe). This means that the possibility to create and control GenAI is out of reach of most companies and most countries, especially those in the Global South. 
As access to data becomes increasingly essential for the economic development of countries and for the digital opportunities of individuals, those countries and people who do not have access to or cannot afford enough data are left in a situation of \u2018data poverty\u2019 (Marwala, 2023). The situation is similar for access to computing power. The rapid pervasion of GenAI in technologically advanced countries and regions has accelerated exponentially the generation and processing of data, and has simultaneously intensified the concentration of AI wealth in the Global North. As an immediate consequence, the data-poor regions have been further excluded and put at long-term risk of being colonized by the standards embedded in the GPT models. The current ChatGPT models are trained on data from online users which reflect the values and norms of the Global North, making them inappropriate for locally relevant AI algorithms in data-poor communities in many parts of the Global South or in more disadvantaged communities in the Global North. (p 14)
A few other references:
A starting point for this is the 2022 AI and education: guidance for policy-makers (UNESCO, 2022b). It proposes a comprehensive set of recommendations to guide governments in the development and implementation of sector-wide policies on AI and education with a focus on promoting quality education, social equity and inclusion. Most of the recommendations remain applicable and can be further adapted to guide the formulation of specific policies on GenAI in education. The following eight specific measures for the planning of policies on GenAI in education and research are proposed here to complement this existing guidance. (p 24)
Access and equity: GenAI systems in education may exacerbate existing disparities in access to technology and educational resources, further deepening inequities. (p 36)`,"General principles on AI":["Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Bias testing. AI systems should be tested for bias. ","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Transparency (explainability). AI systems should be sufficiently explainable.","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Human rights-centred. AI systems should be compatible with human rights. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Opportunity. The opportunities of AI should be harnessed.","Inclusive development. AI systems should be developed inclusively. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Environmental wellbeing. The use of AI should not harm the environment. ","Augmentation, not replacement. AI systems should augment, not displace, workers."],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"Note: It is hard to uncouple general and education-specific principles. It is clear that the general principles are intended to apply to education (indeed, they are expressly restated), but one can infer that the narrower principles are intended to apply more broadly. ","WC Favourite":!0,"Notable Case Studes - Examples of AI in Education":"See, for example, p 33 \u2014 \u201CSocratic challenger\u201D and \u201CAdvisor for project-based learning\u201D","Other Points of Interest":"","Record Entered By":""},id:"i-3KYj_XmjkW",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-3KYj_XmjkW",name:"UNESCO: Guidance for generative AI in education and research",index:59,createdAt:"2024-05-30T22:56:41.285Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-3KYj_XmjkW"},{values:{"Policy Name":"Shaping Digital Education Policy","Policy creator":["European Union"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Would have been relevant\u2014but seems to have been a precursor to policies that have now been created. ",File:["TA-9-2021-0095_EN.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"","Series #":4,Title:"European Union: Shaping Digital Education Policy","Opportunity and risk orientation":"","Category of creator":["IO"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-zVxsoTDPNe",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-zVxsoTDPNe",name:"European Union: Shaping Digital Education Policy",index:172,createdAt:"2024-05-30T22:52:27.615Z",updatedAt:"2024-06-04T00:44:52.789Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-zVxsoTDPNe"},{values:{"Policy Name":"AI Act (Resolution on the text of the AI Act)","Policy creator":["European Union"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Note that this regulation lists education as high-risk. ",File:["TA-9-2024-0138_EN.pdf"],"Year of Commencement or Creation":"2024","Relevance Type":["Policy has an AI in education component","Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ","Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.","Human rights-centred. The technology must be consistent with human rights. ","Managing bias. The risk of bias should be managed with care. ","Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Transparency (transparency to government). The extent to which AI is used in educational settings should be clear to the government. ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.","Interoperability. AI systems deployed in educational settings should be able to work with other systems. "],"Governance practices employed":["Proposes law. It proposes a law or provides a draft law on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence","Series #":3,Title:"European Union: AI Act (Resolution on the text of the AI Act)","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["IO"],"Translation Comments":"","Key quotes on AI in education principles":`Note: Given that the entire scheme for \u201Chigh-risk\u201D systems applies to AI in education, there is some duplication here. The norms that directly apply to AI in education are expressed generally, so both sets of boxes have been ticked. I have not spent a disproportionate amount of time thinking about whether the draft AI Act impliedly expresses particular norms. It would be worth getting Jose-Miguel to look over this record and tweak it using his working knowledge of the scheme. 
Note 2: No page numbers provided in text. 

Specification of education as high-risk:
\u201CEducation and vocational training: (a) AI systems intended to be used to determine access or admission or to assign natural persons to educational and vocational training institutions at all levels; (b) AI systems intended to be used to evaluate learning outcomes, including when those outcomes are used to steer the learning process of natural persons in educational and vocational training institutions at all levels; (c) AI systems intended to be used for the purpose of assessing the appropriate level of education that an individual will receive or will be able to access, in the context of or within educational and vocational training institutions; (d) AI systems intended to be used for monitoring and detecting prohibited behaviour of students during tests in the context of or within educational and vocational training institutions.\u201D 
Opportunity:
\u201CBy improving prediction, optimising operations and resource allocation, and personalising digital solutions available for individuals and organisations, the use of AI can provide key competitive advantages to undertakings and support socially and environmentally beneficial outcomes, for example in... education\u201D 
\u201CThe deployment of AI systems in education is important to promote high-quality digital education and training and to allow all learners and teachers to acquire and share the necessary digital skills and competences, including media literacy, and critical thinking, to take an active part in the economy, society, and in democratic processes.\u201D 
Harm:
\u201CConsidering the imbalance of power in the context of work or education, combined with the intrusive nature of these systems, such systems could lead to detrimental or unfavourable treatment of certain natural persons or whole groups thereof. Therefore, the placing on the market, the putting into service, or the use of AI systems intended to be used to detect the emotional state of individuals in situations related to the workplace and education should be prohibited. That prohibition should not cover AI systems placed on the market strictly for medical or safety reasons, such as systems intended for therapeutical use.\u201D 
\u201CHowever, AI systems used in education or vocational training, in particular for determining access or admission, for assigning persons to educational and vocational training institutions or programmes at all levels, for evaluating learning outcomes of persons, for assessing the appropriate level of education for an individual and materially influencing the level of education and training that individuals will receive or will be able to access or for monitoring and detecting prohibited behaviour of students during tests should be classified as high-risk AI systems, since they may determine the educational and professional course of a person\u2019s life and therefore affect that person\u2019s ability to secure a livelihood. When improperly designed and used, such systems may be particularly intrusive and may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation.\u201D 
Impact assessments:
\u201CIn order to efficiently ensure that fundamental rights are protected, deployers of high-risk AI systems that are bodies governed by public law, or private operators providing public services and operators deploying certain high-risk AI systems listed in an annex to this Regulation, such as banking or insurance entities, should carry out a fundamental rights impact assessment prior to putting it into use. Services important for individuals that are of public nature may also be provided by private entities. Private operators providing such services of public nature are linked to tasks in the public interest such as in the area of education, healthcare, social services, housing, administration of justice. The aim of the fundamental rights impact assessment is for the deployer to identify the specific risks to the rights of individuals or groups of individuals likely to be affected, identify measures to be taken in the case of a materialisation of those risk. The impact assessment should apply to the first use of the high-risk AI system, and should be updated when the deployer considers that any of the relevant factors have changed. The impact assessment should identify the deployer\u2019s relevant processes in which the high-risk AI system will be used in line with its intended purpose, and should include a description of the period of time and frequency in which the system is intended to be used as well as of specific categories of natural persons and groups who are likely to be affected in the specific context of use.\u201D `,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`The whole regime is built around rights protections. Examples can be found everywhere. Just one example:
\u201CIn order to efficiently ensure that fundamental rights are protected, deployers of high-risk AI systems that are bodies governed by public law, or private operators providing public services and operators deploying certain high-risk AI systems listed in an annex to this Regulation, such as banking or insurance entities, should carry out a fundamental rights impact assessment prior to putting it into use. Services important for individuals that are of public nature may also be provided by private entities. Private operators providing such services of public nature are linked to tasks in the public interest such as in the area of education, healthcare, social services, housing, administration of justice. The aim of the fundamental rights impact assessment is for the deployer to identify the specific risks to the rights of individuals or groups of individuals likely to be affected, identify measures to be taken in the case of a materialisation of those risk. The impact assessment should apply to the first use of the high-risk AI system, and should be updated when the deployer considers that any of the relevant factors have changed. The impact assessment should identify the deployer\u2019s relevant processes in which the high-risk AI system will be used in line with its intended purpose, and should include a description of the period of time and frequency in which the system is intended to be used as well as of specific categories of natural persons and groups who are likely to be affected in the specific context of use.\u201D `,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`One of the key concerns specific to education is the perpetuation of discrimination:  
\u201CHowever, AI systems used in education or vocational training, in particular for determining access or admission, for assigning persons to educational and vocational training institutions or programmes at all levels, for evaluating learning outcomes of persons, for assessing the appropriate level of education for an individual and materially influencing the level of education and training that individuals will receive or will be able to access or for monitoring and detecting prohibited behaviour of students during tests should be classified as high-risk AI systems, since they may determine the educational and professional course of a person\u2019s life and therefore affect that person\u2019s ability to secure a livelihood. When improperly designed and used, such systems may be particularly intrusive and may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation.\u201D 
`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Environmental wellbeing. The use of AI should not harm the environment. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"Lots to say on this \u2014 JM already an expert in this Act, so will defer spending a lot of time extracting quotations. ","WC Favourite":!0,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-eCAcTesvI4",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-eCAcTesvI4",name:"European Union: AI Act (Resolution on the text of the AI Act)",index:171,createdAt:"2024-05-30T22:45:59.556Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-eCAcTesvI4"},{values:{"Policy Name":"European Parliament resolution of 19 May 2021 on artificial intelligence in education, culture and the audiovisual sector (2020/2017(INI))","Policy creator":["European Union"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is directly relevant\u2014and very broad. It covers (almost) as many principles as one could think of. ",File:["TA-9-2021-0238_EN (2).pdf"],"Year of Commencement or Creation":"2021","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ","Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. ","Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Human rights-centred. The technology must be consistent with human rights. ","Managing bias. The risk of bias should be managed with care. ","Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.","Competition. There should be sufficient competition in the market to ensure that one AI edtech provider does not have excessive market power. ","Interoperability. AI systems deployed in educational settings should be able to work with other systems. ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Transparency (transparency to government). The extent to which AI is used in educational settings should be clear to the government. "],"Governance practices employed":["Communicates a stance. It expresses a hope for the future of AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://www.europarl.europa.eu/doceo/document/TA-9-2021-0238_EN.html","Series #":1,Title:"European Union: European Parliament resolution of 19 May 2021 on artificial intelligence in education, culture and the audiovisual sector (2020/2017(INI))","Opportunity and risk orientation":"","Category of creator":["IO"],"Translation Comments":"","Key quotes on AI in education principles":`Opportunities:
\u201Cwhereas AI has particular potential to offer solutions for the day-to-day challenges of the education sector, such as the personalisation of learning, monitoring learning difficulties, the automation of subject-specific content/knowledge, providing better professional training and supporting the transition to a digital society\u201D (paragraph X)
\u201Cwhereas AI could have practical applications in terms of reducing the administrative work of educators and educational institutions, freeing up time for their core teaching and learning activities\u201D (paragraph Y)
\u201Cwhereas AI-enabled personalised learning experiences can not only help to increase students\u2019 motivation and enable them to reach their full potential, but also reduce drop-out rates\u201D (paragraph AA)
\u201CHighlights that the use of AI in education systems brings a wide range of possibilities, opportunities and tools for making it more innovative, inclusive, efficient and increasingly effective by introducing new high-quality learning methods that are quick, personalised and student-centric; stresses, however, that as it will impact education and social inclusion, the availability of such tools must be ensured for all social groups by establishing equal access to education and learning and leaving no one behind, especially people with disabilities;\u201D (paragraph 31)
\u201CStresses that the real objective of AI in education systems should be to make education as individualised as possible, offering students personalised academic paths in line with their strengths and weaknesses and didactic material tailored to their characteristics, while maintaining educational quality and the integrating principle of our education systems\u201D (paragraph 33)
Opportunities to understand:
\u201Cwhereas it is essential to ensure that all people in the Union acquire the necessary skills from an early age in order to better understand the capabilities and limitations of AI\u201D (paragraph U)
Harm:
\u201Cwhereas the application of AI in education raises concerns around the ethical use of data, learners\u2019 rights, data access and protection of personal data, and therefore entails risks to fundamental rights such as the creation of stereotyped models of learners\u2019 profiles and behaviour that could lead to discrimination or risks of doing harm by the scaling-up of bad pedagogical practices;\u201D (paragraph AD)
Augmentation not replacement:
\u201CAI technologies cannot be used to the detriment or at the expense of in-person education, as teachers must not be replaced by any AI or AI-related technologies\u201D (paragraph 34)
Procurement:
\u201Cencourages public authorities, in this regard, to incentivise the development and deployment of AI technologies through public funding and public procurement\u201D (paragraph 46)
Cooperation and inclusion:
\u201CStresses that the learning benefits of using AI in education will depend not only on AI itself, but on how teachers use AI in the digital learning environment to meet the needs of pupils, students and teachers; points out, therefore, the need for AI programmers to involve teaching communities in the development, deployment and use of AI technologies where possible, creating a nexus environment to form connections and cooperation between AI programmers, developers, companies, schools, teachers and other public and private stakeholders in order to create AI technologies that are suitable for real-life educational environments, reflect the age and developmental readiness of each learner and meet the highest ethical standards; highlights that educational institutions should only deploy trustworthy, ethical, human-centred technologies which are auditable at every stage of their lifecycle by public authorities and civil society; emphasises the advantages of free and open-source solutions in this regard; calls for schools and other educational establishments to be provided with the financial and logistical support as well as the expertise required to introduce solutions for the learning of the future;\u201D (paragraph 35)
Teacher training:
\u201CHighlights, moreover, the need to continuously train teachers so they can adapt to the realities of AI-powered education and acquire the necessary knowledge and skills to use AI technologies in a pedagogical and meaningful way, enabling them to fully embrace the possibilities offered by AI and to understand its limitations\u201D (paragraph 36)
Interoperability:
\u201Ccalls for the data used and produced by AI applications in education to be accessible, interoperable and of high quality, and to be shared with the relevant public authorities in an accessible way and with respect for copyright and trade secrets legislation; recalls that children constitute a vulnerable group who deserve particular attention and protection\u201D (paragraph 43)
So much more could be included, but suffice it to say that all of the boxes ticked reflect clear statements by the European Parliament. `,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`Human rights are built into this document\u2014although they are not the only end pursued. Given acknowledged underinvestment in AI, there are also economic considerations at play. 

Perhaps the strongest statement:
\u201CUnderlines the strategic importance of AI and related technologies for the Union; stresses that the approach to AI and its related technologies must be human-centred and anchored in human rights and ethics, so that AI genuinely becomes an instrument that serves people, the common good and the general interest of citizens;\u201D (paragraph 1)
More education-specific: 
\u201CAsserts that education, culture and the audiovisual sector are sensitive areas as far as the use of AI and related technologies is concerned, as they have the potential to impact on the cornerstones of the fundamental rights and values of our society\u201D (paragraph 3)
`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`There are many, many examples. Education-specific ones include: 
\u201Cwhereas education and educational opportunities are a fundamental right; whereas the development, deployment and use of AI technologies in the education sector should be classified as high risk and subject to stricter requirements on safety, transparency, fairness and accountability;\u201D (paragraph R)
\u201Cwhereas AI and related technologies can be used to improve learning and teaching methods, notably by helping education systems to use fair data to improve educational equity and quality, while promoting tailor-made curricula and better access to education and improving and automating certain administrative tasks; whereas equal and fair access to digital technologies and high-speed connectivity are required in order to make the use of AI beneficial to the whole of society; whereas it is of the utmost importance to ensure that digital education is accessible to all, including those from disadvantaged backgrounds and people with disabilities; whereas learning outcomes do not depend on technology per se, but on how teachers can use technology in pedagogically meaningful ways;\u201D (paragraph W)`,"General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Opportunity. The opportunities of AI should be harnessed.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Inclusive development. AI systems should be developed inclusively. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Environmental wellbeing. The use of AI should not harm the environment. ","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress."],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":`These general principles are referred to as background (\u201DWhereas...\u201D). 

Some of the principles absent here are stated more specifically (e.g., the \u2018augmentation not replacement\u2019 is not expressed generally, but is expressed specifically with regard to teachers. `,"WC Favourite":!0,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"\u201CCalls on the Commission to include education in the regulatory framework for high-risk AI applications, given the importance of ensuring that education continues to contribute to the public good, as well as the high sensitivity of data on pupils, students and other learners;\u201D \u2014 this happened","Record Entered By":""},id:"i-wfPuoK3OXV",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-wfPuoK3OXV",name:"European Union: European Parliament resolution of 19 May 2021 on artificial intelligence in education, culture and the audiovisual sector (2020/2017(INI))",index:19,createdAt:"2024-05-30T22:41:18.325Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-wfPuoK3OXV"},{values:{"Policy Name":"AI Principles","Policy creator":["OECD"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"These are important principles that apply to EdTech. ",File:["AI Principles Overview - OECD.AI.pdf"],"Year of Commencement or Creation":"2019","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":1,Title:"OECD: AI Principles","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["IO"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201CAI actors should respect the rule of law, human rights, democratic and human-centred values throughout the AI system lifecycle. These include non-discrimination and equality, freedom, dignity, autonomy of individuals, privacy and data protection, diversity, fairness, social justice, and internationally recognised labour rights. This also includes addressing misinformation and disinformation amplified by AI, while respecting freedom of expression and other rights and freedoms protected by applicable international law.
To this end, AI actors should implement mechanisms and safeguards, such as capacity for human agency and oversight, including to address risks arising from uses outside of intended purpose, intentional misuse, or unintentional misuse in a manner appropriate to the context and consistent with the state of the art.\u201D (https://oecd.ai/en/dashboards/ai-principles/P6)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":"\u201CStakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for people and the planet, such as augmenting human capabilities and enhancing creativity, advancing inclusion of underrepresented populations, reducing economic, social, gender and other inequalities, and protecting natural environments, thus invigorating inclusive growth, well-being, sustainable development and environmental sustainability.\u201D  (https://oecd.ai/en/dashboards/ai-principles/P5)","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Transparency (explainability). AI systems should be sufficiently explainable.","Human rights-centred. AI systems should be compatible with human rights. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Interoperability. AI systems should be able to work with other systems. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Opportunity. The opportunities of AI should be harnessed.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "],"Draft Analysis Complete":!0,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!0,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-7fKHs4fMnK",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-7fKHs4fMnK",name:"OECD: AI Principles",index:60,createdAt:"2024-05-30T09:47:57.293Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-7fKHs4fMnK"},{values:{"Policy Name":"AI and education: Guidance for policy-makers","Policy creator":["UNESCO"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This is an excellent contribution. Given the subsequent (2023) GenAI document, I have decided to exclude this from the policy table (on the basis of significant overlap) but I will include it in the secondary materials so that it is still captured. 
I cannot help but wonder whether UNESCO\u2019s disposition changed (the old document is more opportunity-oriented) in the direction of being more risk-focused?`,File:["6577a65af258ab9af098691b074dc35a3467c5ad0dd5a7fb4e01d51b7beac85682a0c6938af08caf8cdae3808c9199a919d262fcf16fb6d801eba59e2aa2089e5d8443a45f71da7d922ed36886a3b224fbb98fcf4cd42ab87256f1dd7a717a7b9ad8d3bf.pdf"],"Year of Commencement or Creation":"2021","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"","Series #":4,Title:"UNESCO: AI and education: Guidance for policy-makers","Opportunity and risk orientation":"","Category of creator":["IO"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Would have been relevant but superseded",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-cwFk9KQ50w",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-cwFk9KQ50w",name:"UNESCO: AI and education: Guidance for policy-makers",index:58,createdAt:"2024-05-30T09:46:33.813Z",updatedAt:"2024-06-04T04:51:24.936Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-cwFk9KQ50w"},{values:{"Policy Name":"Recommendation on Ethics in Artificial Intelligence","Policy creator":["UNESCO"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This document provides a general summary of artificial intelligence principles, but has a dedicated section on education and research (see Area 8). This document is also very human rights oriented. ",File:["381137eng (1) (1).pdf"],"Year of Commencement or Creation":"2021","Relevance Type":["Policy has an AI in education component","Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":["Human rights-centred. The technology must be consistent with human rights. ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology.","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. ","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":3,Title:"UNESCO: Recommendation on Ethics in Artificial Intelligence","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["IO"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":`\u201CMember States should promote general awareness programmes about AI developments, including on data and the opportunities and challenges brought about by AI technologies, the impact of AI systems on human rights and their implications, including children\u2019s rights. These programmes should be accessible to nontechnical as well as technical groups.\u201D (p 34)
\u201CAI systems used in learning should be subject to strict requirements when it comes to the monitoring, assessment of abilities, or prediction of the learners\u2019 behaviours. AI should support the learning process without reducing cognitive abilities and without extracting sensitive information, in compliance with relevant personal data protection standards.\u201D (p 34)
\u201CMember States should promote the participation and leadership of girls and women, diverse ethnicities and cultures, persons with disabilities, marginalized and vulnerable people or people in vulnerable situations, minorities and all persons not enjoying the full benefits of digital inclusion, in AI education programmes at all levels, as well as the monitoring and sharing of best practices in this regard with other Member States.\u201D (p 34)
\u201CMember States should ensure that AI researchers are trained in research ethics and require them to include ethical considerations in their designs, products and publications, especially in the analyses of the datasets they use, how they are annotated, and the quality and scope of the results with possible applications.\u201D (p 35)

\u201CMember States should develop guidelines for humanrobot interactions and their impact on human-human relationships, based on research and directed at the future development of robots, and with special attention to the mental and physical health of human beings. Particular attention should be given to the use of robots in health care and the care for older persons and persons with disabilities, in education, and robots for use by children, toy robots, chatbots and companion robots for children and adults. Furthermore, assistance of AI technologies should be applied to increase the safety and ergonomic use of robots, including in a human-robot working environment. Special attention should be paid to the possibility of using AI to manipulate and abuse human cognitive biases.\u201D (p 37)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201CAI systems raise new types of ethical issues that include, but are not limited to, their impact on decision-making, employment and labour, social interaction, health care, education, media, access to information, digital divide, personal data and consumer protection, environment, democracy, rule of law, security and policing, dual use, and human rights and fundamental freedoms, including freedom of expression, privacy and nondiscrimination.\u201D (p 10)

\u201CFrom a socio-technical lens, greater transparency contributes to more peaceful, just, democratic and inclusive societies. It allows for public scrutiny that can decrease corruption and discrimination, and can also help detect and prevent negative impacts on human rights.\u201D (p 22)

\u201CRecalling that, by the terms of its Constitution, UNESCO seeks to contribute to peace and security by promoting collaboration among nations through education, the sciences, culture, and communication and information, in order to further universal respect for justice, for the rule of law and for the human rights and fundamental freedoms which are affirmed for the peoples of the world\u201D (p 5)

\u201CConvinced that the Recommendation presented here, as a standard-setting instrument developed through a global approach, based on international law, focusing on human dignity and human rights, as well as gender equality, social and economic justice and development, physical and mental well-being, diversity, interconnectedness, inclusiveness, and environmental and ecosystem protection can guide AI technologies in a responsible direction\u201D (p 5)

\u201CConsidering that AI technologies can be of great service to humanity and all countries can benefit from them, but also raise fundamental ethical concerns, for instance regarding the biases they can embed and exacerbate, potentially resulting in discrimination, inequality, digital divides, exclusion and a threat to cultural, social and biological diversity and social or economic divides; the need for transparency and understandability of the workings of algorithms and the data with which they have been trained; and their potential impact on, including but not limited to, human dignity, human rights and fundamental freedoms, gender equality, democracy, social, economic, political and cultural processes, scientific and engineering practices, animal welfare, and the environment and ecosystems\u201D (p 5)

\u201CThe objectives of this Recommendations are (c) to protect, promote and respect human rights and fundamental freedoms, human dignity and equality, including gender equality; to safeguard the interests of present and future generations; to preserve the environment, biodiversity and ecosystems; and to respect cultural diversity in all stages of the AI system life cycle.\u201D (p 15) 

\u201CIn all cases, any possible limitations on human rights and fundamental freedoms must have a lawful basis, and be reasonable, necessary and proportionate, and consistent with States\u2019 obligations under international law.\u201D (p 18)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`\u201CAI actors should promote social justice and safeguard fairness and non-discrimination of any kind in compliance with international law. This implies an inclusive approach to ensuring that the benefits of AI technologies are available and accessible to all, taking into consideration the specific needs of different age groups, cultural systems, different language groups, persons with disabilities, girls and women, and disadvantaged, marginalized and vulnerable people or people in vulnerable situations.\u201D (p 20)
\u201CMember States should work to promote inclusive access for all, including local communities, to AI systems with locally relevant content and services, and with respect for multilingualism and cultural diversity.\u201D (p 20)
\u201CMember States should work to tackle digital divides and ensure inclusive access to and participation in the development of AI\u201D (p 20)
\u201CAt the national level, Member States should promote equity between rural and urban areas, and among all persons regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds, in terms of access to and participation in the AI system life cycle.\u201D (p 20)

\u201CAt the international level, the most technologically advanced countries have a responsibility of solidarity with the least advanced to ensure that the benefits of AI technologies are shared such that access to and participation in the AI system life cycle for the latter contributes to a fairer world order with regard to information, communication, culture, education, research and socio-economic and political stability.\u201D (p 20)

\u201CFurthermore, new ethical challenges are created by the potential of AI algorithms to reproduce and reinforce existing biases, and thus to exacerbate already existing forms of discrimination, prejudice and stereotyping.\u201D (p 10)

\u201CAI actors should make all reasonable efforts to minimize and avoid reinforcing or perpetuating discriminatory or biased applications and outcomes throughout the life cycle of the AI system to ensure fairness of such systems. Effective remedy should be available against discrimination and biased algorithmic determination.\u201D (p 20)

\u201CRespect, protection and promotion of diversity and inclusiveness should be ensured throughout the life cycle of AI systems, consistent with international law, including human rights law. This may be done by promoting active participation of all individuals or groups regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds.\u201D (p 19)

\u201CLearning about the impact of AI systems should include learning about, through and for human rights and fundamental freedoms, meaning that the approach and understanding of AI systems should be grounded by their impact on human rights and access to rights, as well as on the environment and ecosystems.\u201D (p 23) `,"General principles on AI":["R&D. Sufficient resources should be invested in AI R&D.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Environmental wellbeing. The use of AI should not harm the environment. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Draft Analysis Complete":!0,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!0,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-eIePcoMdFY",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-eIePcoMdFY",name:"UNESCO: Recommendation on Ethics in Artificial Intelligence",index:57,createdAt:"2024-05-30T09:45:24.008Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-eIePcoMdFY"},{values:{"Policy Name":"AI Standardisation Committee","Policy creator":["India"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a cool initiative \u2014 building a committee around questions of assessing trustworthiness/standards \u2014 but is not directly relevant to EdTech. The committee itself is not super relevant to EdTech. It seems to have produced some handy general resources, but they are not EdTech-focussed, and I have already included general principles included created by the Indian government. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26854","Series #":7,Title:"India: AI Standardisation Committee","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-w9ONOvfaTB",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-w9ONOvfaTB",name:"India: AI Standardisation Committee",index:23,createdAt:"2024-05-30T04:39:58.399Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-w9ONOvfaTB"},{values:{"Policy Name":"IndiaAI 2023: Expert Group Report","Policy creator":["India"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is an interesting document, but it does not have a whole heap of information over and above India\u2019s national strategy, so I will focus on that. ",File:["IndiaAI-Expert-Group-Report-First-Edition.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27604","Series #":6,Title:"India: IndiaAI 2023: Expert Group Report","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-zH86oFtb00",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-zH86oFtb00",name:"India: IndiaAI 2023: Expert Group Report",index:22,createdAt:"2024-05-30T04:38:43.016Z",updatedAt:"2024-06-04T06:32:32.370Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-zH86oFtb00"},{values:{"Policy Name":"India AI: National Program on Artificial Intelligence ","Policy creator":["India"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This seems to be some kind of coordination/monitoring body. Not directly relevant to EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27510","Series #":5,Title:"India: India AI: National Program on Artificial Intelligence ","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-83g0BjFeEs",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-83g0BjFeEs",name:"India: India AI: National Program on Artificial Intelligence ",index:21,createdAt:"2024-05-30T04:37:10.968Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-83g0BjFeEs"},{values:{"Policy Name":"AI Task Force for India\u2019s Economic Transformation ","Policy creator":["India"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The creation of this body is not specifically relevant to EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24667","Series #":4,Title:"India: AI Task Force for India\u2019s Economic Transformation ","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-KnhwFmfPzJ",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-KnhwFmfPzJ",name:"India: AI Task Force for India\u2019s Economic Transformation ",index:20,createdAt:"2024-05-30T04:36:35.014Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-KnhwFmfPzJ"},{values:{"Policy Name":"Approach Document for India \u2014 Operationalizing Principles for Responsible AI","Policy creator":["India"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is about mechanisms for operationalising principles set out in the first of this two-part series. This is all broadly relevant. ",File:["Part2-Responsible-AI-12082021.pdf"],"Year of Commencement or Creation":"2021","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Guides impact assessment. It helps officials anticipate or evaluate the impact of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Develops tools. It provides tools and place them in the hands of businesses or governments"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27226","Series #":3,Title:"India: Approach Document for India \u2014 Operationalizing Principles for Responsible AI","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["Non-OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"Implication of \u201Csecurity risks\u201D - \u201CReal-world deployments may lead to malfunctioning and potentially impact the fundamental rights if underlying AI models are manipulated\u201D (p 3)","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`\u201CThe diversity, scale, digital divide, lack of awareness and inequality serves a fertile ground for the negative effects of AI to amplify. Creating a trusted AI ecosystem is important to realise both the economic and social potential of AI.\u201D (p 7)

\u201CSocial research must be aimed at understanding the interaction of AI systems with the local and marginalised communities. This includes understanding how different communities are impacted by the deployment of AI technologies for the delivery of benefits and services, and if benefits are reaching the population as intended, ramifications of risks and considerations such as discrimination, inclusivity, privacy, etc on local and marginalised communities, and identify any other concerns, both in the short term and long term, shaped by the introduction of Artificial Intelligence.\u201D (p 15)`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Draft Analysis Complete":!0,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!0,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-Zc3haNaboY",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Zc3haNaboY",name:"India: Approach Document for India \u2014 Operationalizing Principles for Responsible AI",index:24,createdAt:"2024-05-30T04:34:33.796Z",updatedAt:"2024-06-03T07:19:30.253Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Zc3haNaboY"},{values:{"Policy Name":"Approach Document for India \u2014 Principles for Responsible AI","Policy creator":["India"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is an interesting little paragraph here on positive discrimination \u2014 helping certain persons access education (which, in context, is to be achieved through AI). These principles are not framed in terms of EdTech, but could be applied.",File:["Responsible-AI-22022021.pdf"],"Year of Commencement or Creation":"2021","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Proposes law. It proposes a law or provides a draft law on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27225","Series #":2,Title:"India: Approach Document for India \u2014 Principles for Responsible AI","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["Non-OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`Under \u201CSystems Consideration 4: Incorrect decisions leading to exclusion from access to services or benefits\u201D, it notes that: 
\u201CIn a beneficiary identification system, an incorrect decision could lead to exclusion of services and benefits guaranteed by the State and in criminal identification systems, it could lead to loss of fundamental rights. When the AI systems are used, particularly for critical services by the Government, it is important to have processes and systems in place for raising an objection.\u201D (p 25)

See also Appendix 2 (p 59) for the review of global regulatory landscape (some mentions of human rights in the context of EU). `,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`Note that both formal equality and substantive equality are captured. 

\u201CPrinciple of Inclusivity and Non-discrimination: AI systems should not deny opportunity to a qualified person on the basis of their identity. It should not deepen the harmful historic and social divisions based on religion, race, caste, sex, descent, place of birth or residence in matters of education, employment, access to public spaces, etc. It should also strive to ensure that unfair exclusion of services or benefits does not happen. In case of an adverse decision, appropriate grievance redressal mechanism should be designed in a manner affordable and accessible to everyone irrespective of their background.\u201D (p 50)

\u201CSafety and robustness of AI systems can pose serious challenges especially in high risk prone applications; unequal access to AI powered applications for marginalized populations can further accentuate digital divide.\u201D (p 17)

\u201CThe \u2018systematic\u2019 exclusion from access to services and benefits could undermine trust in the system.\u201D (p 16)`,"General principles on AI":["Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (explainability). AI systems should be sufficiently explainable.","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Bias testing. AI systems should be tested for bias. ","Human rights-centred. AI systems should be compatible with human rights. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","R&D. Sufficient resources should be invested in AI R&D.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Opportunity. The opportunities of AI should be harnessed."],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!0,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-gW1QzUap3c",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-gW1QzUap3c",name:"India: Approach Document for India \u2014 Principles for Responsible AI",index:26,createdAt:"2024-05-30T04:30:01.440Z",updatedAt:"2024-06-03T07:19:52.294Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-gW1QzUap3c"},{values:{"Policy Name":"National Strategy on AI","Policy creator":["India"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is super important: India is a very linguistically diverse place. So it\u2019s national strategy envisaged leveraging AI technologies to help with education. Education is one of the five areas that AI will be applied to. ",File:["National-Strategy-for-Artificial-Intelligence.pdf"],"Year of Commencement or Creation":"2018","Relevance Type":["Policy has an AI in education component","Policy contains case studies on AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary","Vocational or Professional"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24951","Series #":1,Title:"India: National Strategy on AI","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":`The key story here is: India is experiencing low retention rates and poor learning outcomes, and one of the problems is a lack of technology. 
\u201CAI can potentially solve for quality and access issues observed in the Indian education sector. Potential use cases include augmenting and enhancing the learning experience through personalised learning, automating and expediting administrative tasks, and predicting the need for student intervention to reduce dropouts or recommend vocational training.\u201D (p 20)
\u201CAI has the potential to bring about changes in the sector by supplementing pedagogy and establishing systems to inform and support decision making across stakeholders and administrative levels. However, implementation of AI must be preceded by efforts to digitise records of teacher performance, student performance, and curriculum. Several AI tools are being successfully used in other parts of the world, and they can be adapted to the Indian context to target specific challenges.\u201D
What they are interested in: see use cases below. 
Teacher training:
A recent survey found that level of adoption of technology in schools is lacking, and can be largely attributed to lack of teacher training, despite provision of the ICT infrastructure. (p 36)
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"\u201CAddress and implement data protection framework, which protects human rights and privacy without stifling innovation in India.\u201D (p 93) \u2014 only reference","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"There are a few references to discrimination, but this plan is not really framed in the language of equality/equity. Even the opportunity here is framed as an opportunity to improve education (rather than, for example, decrease educational inequality \u2014 cf Indonesia). ","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (explainability). AI systems should be sufficiently explainable.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society."],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"Note \u2014 education is considered in an \u201Copportunity-only\u201D way. The content on ethics is addressed in broad terms. ","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":`a) Adaptive learning tools for customised learning: While AI may not completely replace a teacher, it has the potential to greatly assist teachers in efficiently and effectively managing multi-level / multi?grade classrooms, by judging learning levels of individual students, and allowing automated development of customised educational content adapted to each child\u2019s class and learning level. Assessing time spent by a student on each part / page of the learning material, for example, would allow real-time feedback on student performance to help the teacher appropriately tailor her guidance to the child. This concept can be extended to automatic grading of tests, as well. 
b) Intelligent and interactive tutoring systems: Intelligent Tutoring Systems can provide great benefit to students through delivery of learning materials adapted to the child\u2019s proficiency level, learning style, and pace of learning. In-built pop-up questions tailored to students, for example, can help increase interactivity, and catch student\u2019s attention and interest. It can also help in assessment of student\u2019s level of attention or comprehension to appropriately design remedial instruction. GradeGuardian, for example, uses predictive models and visualisations for student performance with an interactive dashboard showing anticipated effect of policy changes. Submission includes 3 components packaged as a single web app \u2013 a Chatbot that inputs student information, an Advisor Console that shows students at risk, and a prediction module for policymakers.
c) Predictive tools to inform pre-emptive action for students predicted to drop out of school: Analysis of test results and attendance records using AI can be used to predict probable student activities and inform pre-emptive action. For instance, in a recent preliminary experiment conducted in Andhra Pradesh, AI applications processed data on all students based on parameters such as gender, socio?economic factors, academic performance, school infrastructure, teacher skills, etc., with the objective of helping the government identify students likely to drop out. Test results could inform suggestions to enroll students in vocational studies. Additionally, redressal mechanisms could be put in place to identify students whose performance can be improved by focus of existing schemes to their family.
(d)) Automated rationalisation of teachers: AI tools can be used to develop automated teacher posting and transfer systems, using analytics based on demand \u2013 supply gaps across schools in the State, candidate\u2019s prior postings, candidate preferences, etc. This would help in plugging of gaps in teacher distribution more effectively. 
e) Customised professional development courses: To tackle issues of poorly designed professional development courses with poor coverage, adaptive AI tools can be used to design automated, customised professional development training content for the teacher based on their performance, identification of their knowledge and skill gaps. This could then be continuously adapted as teacher\u2019s skills and concepts improve.
 (p 37-38 \u2014 read this section, noting the pop-out boxes with concrete case studies)
`,"Other Points of Interest":"","Record Entered By":""},id:"i-F0cUMbalq-",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-F0cUMbalq-",name:"India: National Strategy on AI",index:25,createdAt:"2024-05-30T04:29:45.240Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-F0cUMbalq-"},{values:{"Policy Name":"Malta\u2019s educational initiatives: Masters in AI, Skills Development, Start-up Residence Programme, Tax Credit on Higher Educational Qualifications, Future Innovators Summer School, AI Certification Programme, etc","Policy creator":["Malta"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Malta have done a whole heap to encourage \u2014 even financially incentivise \u2014 AI study. It has reduced friction to learning about AI. However, this is not so much an \u201CEdTech\u201D initiative as an education in AI initiative. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives?conceptUris=http:%2F%2Fkim.oecd.org%2FTaxonomy%2FGeographicalAreas%23Malta","Series #":4,Title:"Malta: Malta\u2019s educational initiatives: Masters in AI, Skills Development, Start-up Residence Programme, Tax Credit on Higher Educational Qualifications, Future Innovators Summer School, AI Certification Programme, etc","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-i3W1QFey6_",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-i3W1QFey6_",name:"Malta: Malta\u2019s educational initiatives: Masters in AI, Skills Development, Start-up Residence Programme, Tax Credit on Higher Educational Qualifications, Future Innovators Summer School, AI Certification Programme, etc",index:30,createdAt:"2024-05-30T04:23:44.586Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-i3W1QFey6_"},{values:{"Policy Name":"Malta Digital Innovation Authority","Policy creator":["Malta"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The creation of this body is not EdTech-focused, so its specific initiatives are more relevant. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27518","Series #":3,Title:"Malta: Malta Digital Innovation Authority","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-aw2IreqB1O",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-aw2IreqB1O",name:"Malta: Malta Digital Innovation Authority",index:29,createdAt:"2024-05-30T04:23:07.446Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-aw2IreqB1O"},{values:{"Policy Name":"Technology Assessment Recognition Framework","Policy creator":["Malta"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is an interesting model that could definitely be applied to EdTech. TARF - Technology Assessment Recognition Framework - Malta Digital Innovation Authority (gov.mt)",File:"","Year of Commencement or Creation":"2023","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Guides impact assessment. It helps officials anticipate or evaluate the impact of AI","Develops tools. It provides tools and place them in the hands of businesses or governments"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27583","Series #":2,Title:"Malta: Technology Assessment Recognition Framework","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["Non-OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities."],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!0,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-noNor4BMYA",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-noNor4BMYA",name:"Malta: Technology Assessment Recognition Framework",index:28,createdAt:"2024-05-30T04:22:26.071Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-noNor4BMYA"},{values:{"Policy Name":"Towards Trustworthy AI: Malta\u2019s Ethical AI Framework","Policy creator":["Malta"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a nuanced framework for AI. It talks authorities through precisely what should be done (rather than merely expressing broad norms). Focus on its \u201Cgovernance practices\u201D table. ",File:["Malta_Towards_Ethical_and_Trustworthy_AI_vFINAL.pdf"],"Year of Commencement or Creation":"2019","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Educates. It helps officials or others understand the opportunities and risks of AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24993","Series #":1,Title:"Malta: Towards Trustworthy AI: Malta\u2019s Ethical AI Framework","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"N/A","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`It stresses: \u201CRespect for all applicable laws and regulations, human rights and democratic values;\u201D \u2014 this theme keeps coming back. 
\u201CConduct human rights impact assessment, identifying and documenting potential trade-offs between different principles and rights.\u201D`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":"\u201CEquality, non-discrimination and solidarity \u2014 AI operations can not generate unfairly biased outcomes, and the benefits and opportunities of AI should be equitably available to all.\u201D (p 9)","General principles on AI":["Respect for laws [NEW]. AI should respect existing law.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Environmental wellbeing. The use of AI should not harm the environment. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"Note: These principles are inferred from governance control. ","WC Favourite":!0,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":`This is interesting for its \u201Cgovernance practices\u201D table. Worth paying attention to. 

Note that this has been characterised as being equally interested in risks and opportunities. Why? The primary justification is that it sees ETHICS as being one of the central tools for being the \u201Cultimate launchpad\u201D for AI. This is an important point\u2014it is not merely seeing ethics as belonging to the domain of risk mitigation. `,"Record Entered By":""},id:"i-KzUPzwvpZR",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-KzUPzwvpZR",name:"Malta: Towards Trustworthy AI: Malta\u2019s Ethical AI Framework",index:27,createdAt:"2024-05-30T04:11:49.801Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-KzUPzwvpZR"},{values:{"Policy Name":"National Center for Innovation and Artificial Intelligence ","Policy creator":["Peru"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The creation of this body is not itself relevant to EdTech (though might affect it indirectly). It is the stuff it is doing (captured in other policy entries) that is relevant. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27148","Series #":5,Title:"Peru: National Center for Innovation and Artificial Intelligence ","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-j871MoGjLo",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-j871MoGjLo",name:"Peru: National Center for Innovation and Artificial Intelligence ",index:469,createdAt:"2024-05-30T04:08:06.339Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-j871MoGjLo"},{values:{"Policy Name":"National Artificial Intelligence Authority","Policy creator":["Peru"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The creation of this body is not itself relevant to EdTech (though might affect it indirectly). ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27625","Series #":4,Title:"Peru: National Artificial Intelligence Authority","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-9M8cvKwdSr",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-9M8cvKwdSr",name:"Peru: National Artificial Intelligence Authority",index:34,createdAt:"2024-05-30T04:07:58.370Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-9M8cvKwdSr"},{values:{"Policy Name":"Law 31814, Law that promotes the use of AI in favour of the economic and social development of the country","Policy creator":["Peru"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Does not mention education in the summary, but might well be relevant. ",File:["ley-que-promueve-el-uso-de-la-inteligencia-artificial-en-fav-ley-n-31814.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27613","Series #":3,Title:"Peru: Law 31814, Law that promotes the use of AI in favour of the economic and social development of the country","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Cannot Access",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-ffcn-cX3Rq",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ffcn-cX3Rq",name:"Peru: Law 31814, Law that promotes the use of AI in favour of the economic and social development of the country",index:33,createdAt:"2024-05-30T04:05:36.779Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ffcn-cX3Rq"},{values:{"Policy Name":"Transformacion Digital","Policy creator":["Peru"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This seems to have a fair bit on \u201Ceducativos\u201D. Worth translating to check more thoroughly. ",File:["Pol\xEDtica Nacional de Transformaci\xF3n Digital al 2030.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27620","Series #":2,Title:"Peru: Transformacion Digital","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-Ah0jZ30aTx",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Ah0jZ30aTx",name:"Peru: Transformacion Digital",index:32,createdAt:"2024-05-30T04:03:04.376Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Ah0jZ30aTx"},{values:{"Policy Name":"National AI Strategy (2021-2026)","Policy creator":["Peru"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is directly relevant to AI in education (particularly individualisation of education for each student)",File:["Peru_National_Artificial_Intelligence_Strategy_2021-2026.pdf"],"Year of Commencement or Creation":"2021","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Secondary","Primary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":"","Analysis Complete":!0,"Link (OECD or Other)":"","Series #":1,Title:"Peru: National AI Strategy (2021-2026)","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":`\u201CUse case in education:
AI adapted to the needs of each student
From school to college, AI could individualize the learning needs of each student. 
The system could respond to the needs of the student, placing greater emphasis on certain topics, repeating things until the student masters it. 
In general, helping the student to learn at her own pace, whatever this could be. 
AI could give feedback to students and teachers 
AI could give feedback to teachers and students about the results of the course itself. 
Some AI systems are used to monitor student progress and alert teachers when there might be a problem with student performance. 
These systems could give the support to the students who need it, and to the teacher, to find the areas where he can improve the instructions to the student so that he does not fail with the subject of the course.\u201D (p 19)
 
\u201CThrough the National Center for Innovation and Artificial Intelligence, prioritize the development of use cases where Artificial Intelligence can generate concrete solutions such as those proposed in various investigations aligned to the United Nations 2030 sustainable development goals, such as the elimination of poverty, zero hunger, quality education, clean and accessible energy, clean water and sustainable cities, good health, better qualified jobs, the reduction of social gaps and others.\u201D (p 67)`,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CA.5.1.7. In the public sector, in all cases of use of AI to classify people (to provide benefits, opportunities or sanctions to citizens), they must have a socioeconomic impact study to guarantee equity.\u201D (p 79)","General principles on AI":["Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Bias testing. AI systems should be tested for bias. ","Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities."],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"image.png","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-4zem25qHQm",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-4zem25qHQm",name:"Peru: National AI Strategy (2021-2026)",index:31,createdAt:"2024-05-30T04:01:52.887Z",updatedAt:"2024-06-06T03:04:13.416Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-4zem25qHQm"},{values:{"Policy Name":"Vision 2030 Program","Policy creator":["Saudi Arabia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is focused on \u201Cmatching  educational outcomes to the needs of the labor market\u201D",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26017","Series #":3,Title:"Saudi Arabia: Vision 2030 Program","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-EaM1Ulberi",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-EaM1Ulberi",name:"Saudi Arabia: Vision 2030 Program",index:41,createdAt:"2024-05-30T03:58:53.619Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-EaM1Ulberi"},{values:{"Policy Name":"National Centre for AI","Policy creator":["Saudi Arabia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is not EdTech-focused. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26015","Series #":2,Title:"Saudi Arabia: National Centre for AI","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-MO23ahP2j0",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-MO23ahP2j0",name:"Saudi Arabia: National Centre for AI",index:40,createdAt:"2024-05-30T03:58:22.655Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-MO23ahP2j0"},{values:{"Policy Name":"National Data and AI Strategy","Policy creator":["Saudi Arabia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is about AI education, not AI in education. ",File:["Brochure_NSDAI_Summit version_EN.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26934","Series #":1,Title:"Saudi Arabia: National Data and AI Strategy","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-Xn1rJfBsRO",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Xn1rJfBsRO",name:"Saudi Arabia: National Data and AI Strategy",index:39,createdAt:"2024-05-30T03:56:53.432Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Xn1rJfBsRO"},{values:{"Policy Name":"Ethics Guidelines for AI","Policy creator":["Thailand"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"These guidelines might be broadly applicable to EdTech. Need to translate to get deeper (most of the doc is in Thai). ",File:["Digital-Thailand-AI-Ethics-Principle-and-Guideline.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26337","Series #":4,Title:"Thailand: Ethics Guidelines for AI","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-3tvtidLFCb",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-3tvtidLFCb",name:"Thailand: Ethics Guidelines for AI",index:38,createdAt:"2024-05-30T03:54:23.037Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-3tvtidLFCb"},{values:{"Policy Name":"AI Governance Guidelines for Executives ","Policy creator":["Thailand"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This looks interesting, but needs to be translated fully. ",File:["Thailand AI Ethics Guideline (White paper) Edit Version.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27608","Series #":3,Title:"Thailand: AI Governance Guidelines for Executives ","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-7C093DCOGE",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-7C093DCOGE",name:"Thailand: AI Governance Guidelines for Executives ",index:37,createdAt:"2024-05-30T03:51:53.239Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-7C093DCOGE"},{values:{"Policy Name":"12th National Economic and Social Development Plan","Policy creator":["Thailand"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Not EdTech-focused (and not that EdTech-focused). ",File:["thailand_national_economic_and_social_development_plan_nesdp.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26088","Series #":2,Title:"Thailand: 12th National Economic and Social Development Plan","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-a_AMPDj4WM",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-a_AMPDj4WM",name:"Thailand: 12th National Economic and Social Development Plan",index:36,createdAt:"2024-05-30T03:48:22.308Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-a_AMPDj4WM"},{values:{"Policy Name":"Thailand National AI Plan","Policy creator":["Thailand"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`Based on the very limited information available on the OECD Policy Observatory and online, it seems that this is not EdTech-focused. 
National Artificial Intelligence Action Plan for Thailand Development (2022 \u2013 2027) - AI Thailand`,File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27299","Series #":1,Title:"Thailand: Thailand National AI Plan","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-YpUUxnDmQT",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-YpUUxnDmQT",name:"Thailand: Thailand National AI Plan",index:35,createdAt:"2024-05-30T03:46:41.475Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-YpUUxnDmQT"},{values:{"Policy Name":"National Strategy for the Development of AI in Ukraine","Policy creator":["Ukraine"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`Ukraine is apparently focused on AI in education and defence. I am not sure whether there is project is at\u2014given obvious disruptions. 

Further, questionable source \u2014 need more information. `,File:["Ukraine\u2019s roadmap to an artificial intelligence future - Atlantic Council.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27224","Series #":1,Title:"Ukraine: National Strategy for the Development of AI in Ukraine","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Cannot Access",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-_kRhBVMYRz",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_kRhBVMYRz",name:"Ukraine: National Strategy for the Development of AI in Ukraine",index:42,createdAt:"2024-05-30T03:28:06.898Z",updatedAt:"2024-06-03T02:28:38.370Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_kRhBVMYRz"},{values:{"Policy Name":"Data Science and ML Roadmap","Policy creator":["Uruguay"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Translation needed.",File:["6112019+Hoja+de+Ruta+CD+AA.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"","Series #":4,Title:"Uruguay: Data Science and ML Roadmap","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-m0uQnPjhJ9",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-m0uQnPjhJ9",name:"Uruguay: Data Science and ML Roadmap",index:50,createdAt:"2024-05-30T03:24:55.364Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-m0uQnPjhJ9"},{values:{"Policy Name":"Data Policy and Strategy for Digital Transformation","Policy creator":["Uruguay"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is more foundational than EdTech.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26697","Series #":3,Title:"Uruguay: Data Policy and Strategy for Digital Transformation","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-140mzLUitn",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-140mzLUitn",name:"Uruguay: Data Policy and Strategy for Digital Transformation",index:49,createdAt:"2024-05-30T03:24:32.591Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-140mzLUitn"},{values:{"Policy Name":"AI Use Cases in the Public Sector","Policy creator":["Uruguay"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is about fostering R&D/innovation for the implementation of AI. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27151","Series #":2,Title:"Uruguay: AI Use Cases in the Public Sector","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-b2NNWbWnEW",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-b2NNWbWnEW",name:"Uruguay: AI Use Cases in the Public Sector",index:48,createdAt:"2024-05-30T03:23:38.399Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-b2NNWbWnEW"},{values:{"Policy Name":"AI Strategy for the Digital Government","Policy creator":["Uruguay"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"All this really does is acknowledge that AI is being used in \u2018sensitive\u2019 areas such as education (not wrong!). But Uruguay\u2019s aspirations are more foundational.",File:["Uruguay_Artificial_Intelligence_Strategy_for_Digital_Government_2019.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26477","Series #":1,Title:"Uruguay: AI Strategy for the Digital Government","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-vfqS9r-iRb",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-vfqS9r-iRb",name:"Uruguay: AI Strategy for the Digital Government",index:47,createdAt:"2024-05-30T03:10:21.866Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-vfqS9r-iRb"},{values:{"Policy Name":"Kenya\u2019s Digital Economy Strategy","Policy creator":["Kenya"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`There is a hugely important case study on digital inequality here:
The same assumption was extended to the basic education too where it turned out that only less than 25% of learners could participate in remote/online learning. Similarly, the Kenyan labour force are largely in the informal sector where working remotely was not a solution. Unfortunately, the measures that were put in place to address the digital inequalities during the pandemic were seen more as a necessity and not as priorities.
I am including this for the purpose or asking: How do we roll out AI if the basic infrastructure is not there?`,File:["10TH-JULY-FINAL-COPY-DIGITAL-ECONOMY-STRATEGY-DRAFT-ONE.pdf"],"Year of Commencement or Creation":"2020","Relevance Type":["Policy contains case studies on AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A Other]"],"Governance practices employed":["[N/A]"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27138","Series #":4,Title:"Kenya: Kenya\u2019s Digital Economy Strategy","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"[N/A]","Key quote on equity/equality":"","General principles on AI":["[N/A]"],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":`This is a case study in the failure to get AI in education projects off the ground. 
The key point is as follows:

The same assumption was extended to the basic education too where it turned out that only less than 25% of learners could participate in remote/online learning. Similarly, the Kenyan labour force are largely in the informal sector where working remotely was not a solution. Unfortunately, the measures that were put in place to address the digital inequalities during the pandemic were seen more as a necessity and not as priorities.

This should be read together with Kenya\u2019s other policies, which deal expressly with AI and blockchain. `,"Other Points of Interest":"","Record Entered By":""},id:"i-TkXOJxaGiN",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-TkXOJxaGiN",name:"Kenya: Kenya\u2019s Digital Economy Strategy",index:46,createdAt:"2024-05-30T03:06:58.553Z",updatedAt:"2024-06-04T23:03:49.690Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-TkXOJxaGiN"},{values:{"Policy Name":"Blockchain and AI Task Force","Policy creator":["Kenya"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"I have included materials produced by this body\u2014but it \u2014 as a policy initiative \u2014 is less relevant. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26983","Series #":3,Title:"Kenya: Blockchain and AI Task Force","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-fbSmfNegBW",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-fbSmfNegBW",name:"Kenya: Blockchain and AI Task Force",index:45,createdAt:"2024-05-30T03:05:15.422Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-fbSmfNegBW"},{values:{"Policy Name":"Emerging Digital Technologies for Kenya \u2014 Exploration and Analysis","Policy creator":["Kenya"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This work was undertaken by the government\u2019s Blockchain and AI Taskforce, and is \u201CAI for development\u201D focused. There is broad awareness that this technology could be used to deliver personalised virtual lessons. They also point to systems already in place \u2014 including an SMS-based learning platform. This is a really interesting research paper. ",File:["KenEcon_30.pdf"],"Year of Commencement or Creation":"2019","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27135","Series #":1,Title:"Kenya: Emerging Digital Technologies for Kenya \u2014 Exploration and Analysis","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":`Opportunity
\u201CIn the education sector, AI exhibits the potential to improve learning outcomes by supporting the delivery of personalised virtual lessons. A good example here is M-Shule, an SMS-based learning platform in Kenya, which uses AI to track and analyse student performance and to deliver lessons that satisfy their needs and increase their competency. The platform reduces the fear of failure that is inherent in several learning environments, allowing students to advance at their own pace and to ultimately improve their learning outcomes.\u201D (p 10)
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"\u201CThe technology will enable the constitutional rights of the citizens and is expected to continually ensure transparent elections in the country. Elected officials will also be held accountable relative to the use of public resources and effective delivery of government services.\u201D (p 87)","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CEssentially, the sharing economy is expected to transition to the next level, where the middleman is not extracting maximum value at the expense of the other participants. Instead, depending on the specific use case or design, the created value will be distributed more equitably\u201D (p 107)","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","R&D. Sufficient resources should be invested in AI R&D.","Bias testing. AI systems should be tested for bias. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":`\u201CIn the education sector, AI has the potential to improve learning outcomes through more personalised, virtual lessons. For example, M-Shule, an SMS-based learning platform in Kenya, uses AI to track and analyse student performance and to deliver lessons that meet their individual needs and thereby grow their competency. The M-Shule platform reduces the fear of failure inherent in many learning environments. Students can advance at their own pace and ultimately improve their learning outcomes.\u201D (p 39)

(p 40)`,"Other Points of Interest":"","Record Entered By":""},id:"i-6wgFj6IDsa",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-6wgFj6IDsa",name:"Kenya: Emerging Digital Technologies for Kenya \u2014 Exploration and Analysis",index:44,createdAt:"2024-05-30T03:02:11.353Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-6wgFj6IDsa"},{values:{"Policy Name":"AI Use Cases in the Public Sector","Policy creator":["Kenya"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is no reference to education here. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27140","Series #":2,Title:"Kenya: AI Use Cases in the Public Sector","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-kEFf6ACRZc",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-kEFf6ACRZc",name:"Kenya: AI Use Cases in the Public Sector",index:43,createdAt:"2024-05-30T03:01:50.674Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-kEFf6ACRZc"},{values:{"Policy Name":"National Strategic Framework in the Field of Artificial Intelligence (2023-2027)","Policy creator":["Romania"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Need a translation to assess. ",File:["Strategie-Inteligenta-Artificiala-22012024_clean_final.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27581","Series #":3,Title:"Romania: National Strategic Framework in the Field of Artificial Intelligence (2023-2027)","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-EKk4n9-usB",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-EKk4n9-usB",name:"Romania: National Strategic Framework in the Field of Artificial Intelligence (2023-2027)",index:52,createdAt:"2024-05-30T02:57:32.142Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-EKk4n9-usB"},{values:{"Policy Name":"National Strategy for Research, Innovation and Smart Specialisation 2021-2027","Policy creator":["Romania"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is very \u201CAI Education\u201D focused rather than \u201CAI in education\u201D. ",File:["SNCISIenglish version.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26914","Series #":2,Title:"Romania: National Strategy for Research, Innovation and Smart Specialisation 2021-2027","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-J6wl-zVCYi",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-J6wl-zVCYi",name:"Romania: National Strategy for Research, Innovation and Smart Specialisation 2021-2027",index:51,createdAt:"2024-05-30T02:53:41.765Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-J6wl-zVCYi"},{values:{"Policy Name":"Romania\u2019s National Strategy","Policy creator":["Romania"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`Romania has a clear intention to use AI in education\u2014specifically: 
Personalised content presentation, evaluation and feedback 
Classes augmented with AR & VR technologies
Recommendations for further studying and curation of content
Enhanced blended learning through AI 
Gamification concepts implemented through AI technology
`,File:["Romania-2019.pdf"],"Year of Commencement or Creation":"2019","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24849","Series #":1,Title:"Romania: Romania\u2019s National Strategy","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":`\u201CRomania\u2019s future depends on the education system available to young generations. The obsolete methods used in teaching combined with the poor training of teachers lead to concerning percentages of functional analphabetism in Romania, especially in rural areas. 
AI technologies have the potential to revolutionise the education system through projects such as:
Personalised content presentation, evaluation and feedback
Classes augmented with AR & VR technologies
Recommendations for further studying and curation of content 
Enhanced blended learning through AI 
Gamification concepts implemented through AI technology\u201D (p 9)

Another initiative concerning training (p 15):
`,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["R&D. Sufficient resources should be invested in AI R&D.","Opportunity. The opportunities of AI should be harnessed."],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"Very little of interest in this strategy \u2014 very \u201Ccarpe diem\u201D, but not a lot of detail or discussion of risk. ","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-AkCFVNxew3",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-AkCFVNxew3",name:"Romania: Romania\u2019s National Strategy",index:468,createdAt:"2024-05-30T02:23:12.056Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-AkCFVNxew3"},{values:{"Policy Name":"National Council for AI","Policy creator":["China"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This was not set up for EdTech purposes, so is only very generally/loosely relevant. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26475","Series #":5,Title:"China: National Council for AI","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-9F3OUw9L91",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-9F3OUw9L91",name:"China: National Council for AI",index:467,createdAt:"2024-05-30T02:16:10.238Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-9F3OUw9L91"},{values:{"Policy Name":"Arab AI Working Group","Policy creator":["Egypt"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"It is not clear that they are working on EdTech-related projects. The strategies listed concern eCommerce, social responsibility, cloud computing, etc. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26473","Series #":4,Title:"Egypt: Arab AI Working Group","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-mBhy8jh-sU",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-mBhy8jh-sU",name:"Egypt: Arab AI Working Group",index:466,createdAt:"2024-05-30T02:16:01.522Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-mBhy8jh-sU"},{values:{"Policy Name":"Applied Innovation Center","Policy creator":["Egypt"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"One of the areas it is poised to work with is education. Fleeting reference only \u2014 no significant action in this space. ",File:["STC Establishes First AI Application Center in Smart Village.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26472","Series #":3,Title:"Egypt: Applied Innovation Center","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"Translation Completed (Google Translate)","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-ESexmMrcBn",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ESexmMrcBn",name:"Egypt: Applied Innovation Center",index:465,createdAt:"2024-05-30T02:15:56.407Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ESexmMrcBn"},{values:{"Policy Name":"African Working Group on AI","Policy creator":["Egypt"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This does not make reference to education, let alone EdTech. It focuses on more foundational aspects of AI development. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26474","Series #":2,Title:"Egypt: African Working Group on AI","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-zCUU5ANi-7",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-zCUU5ANi-7",name:"Egypt: African Working Group on AI",index:53,createdAt:"2024-05-30T02:15:50.968Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-zCUU5ANi-7"},{values:{"Policy Name":"Egypt National AI Strategy","Policy creator":["Egypt"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The focus here is on AI education, but it is recognised that EdTech could help Egypt achieve its development goals.",File:["Publications_672021000_Egypt-National-AI-Strategy-English.pdf"],"Year of Commencement or Creation":"2020","Relevance Type":["Policy makes fleeting reference to AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26476","Series #":1,Title:"Egypt: Egypt National AI Strategy","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["Non-OECD"],"Translation Comments":"Official Translation Obtained","Key quotes on AI in education principles":`The key reference to EdTech is as follows:

\u201CApplying AI to areas such as education or healthcare can facilitate access, overcome staff shortages, and reduce risks and costs. On the other hand, concerns are growing about increasingly automated and autonomous AI systems widening the technological, economic, and social gaps due to the lack of basic infrastructure and human capacity capable of exploiting this technology, especially in countries with a large proportion of low-skilled or unskilled labor.\u201D [8]
It shows that Egypt is curious but recognises the practical difficulties of harnessing the technology. `,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"N/A","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`\u201CThe National AI Strategy is a key priority for helping Egypt achieve relevant UN Sustainable Development Goals as they pertain to Egypt (in numerical order 4, 5, 8, 9, 10, 11). The relevant SDGs address inclusive and equitable education\u201D (p 24)
`,"General principles on AI":["Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Bias testing. AI systems should be tested for bias. ","Augmentation, not replacement. AI systems should augment, not displace, workers.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,"],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-dELwsp5J0Y",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-dELwsp5J0Y",name:"Egypt: Egypt National AI Strategy",index:54,createdAt:"2024-05-30T02:11:00.927Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-dELwsp5J0Y"},{values:{"Policy Name":"National Plan for the Development of AI","Policy creator":["Croatia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The government said that it had started working on this and would provide an update. That was in 2020.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26501","Series #":1,Title:"Croatia: National Plan for the Development of AI","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-cvscTZom8Q",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-cvscTZom8Q",name:"Croatia: National Plan for the Development of AI",index:55,createdAt:"2024-05-30T02:09:55.584Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-cvscTZom8Q"},{values:{"Policy Name":"White Paper on Trustworthy AI","Policy creator":["China"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`There is generally relevant material here. Also, interesting commentary surrounding China\u2019s AI governance:
China\u2019s New AI Governance Initiatives Shouldn\u2019t Be Ignored - Carnegie Endowment for International Peace`,File:["t0390_trustworthy_AI_EN.pdf"],"Year of Commencement or Creation":"2021","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27294","Series #":1,Title:"China: White Paper on Trustworthy AI","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["Non-OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":`\u201C(4) AI fairness technology With the widespread application of AI systems, such systems have exhibited unfair decision-making behaviors and discrimination against certain groups. Academia holds that the main reasons for such decision-making biases are as follows: limited by data collection conditions, the weights of different groups in the data are unbalanced; the AI model trained on the unbalanced dataset may then be applied to the overall data, and while performance is sacrificed on a small amount of data, the model's decision-making becomes unfair. In order to ensure the fairness of decision-making in AI systems, relevant researchers have mainly constructed completely heterogeneous datasets to minimize inherent discrimination and bias in the data; datasets are then checked periodically to ensure the high quality of the data. In addition, there are also algorithms that use fair decision-making quantitative indicators to reduce or eliminate decision-making bias and potential discrimination. Such existing fairness indicators can be divided into two categories: individual fairness and group fairness. Specifically, individual fairness measures the degree of prejudice of intelligent decision-making toward different individuals, and group fairness measures the degree of prejudice of intelligent decision-making toward different groups.\u201D (p 11)

\u201CThe number of AI applications in sensitive fields continues to grow, such as in hiring, criminal justice, and healthcare, and its fairness has also been the subject of widespread concern. Fairness technology can balance data from a technical perspective, thereby further guiding the model to give fair results, which is of great significance for improving the fairness of decision-making in AI systems.\u201D (p 11)

\u201CIn terms of diversity and tolerance, attention should be paid to the fairness and diversity of training datasets to avoid lack of trust caused by data bias. The performance of an AI system depends on the quality of the training data. The dataset may contain implicit race, gender, or ideological bias (Table 1), which may cause the AI system\u2019s decision-making to be inaccurate or biased and discriminatory. Enterprises should focus on improving the diversity and fairness of training data to meet the requirements of diversity and inclusion. On the one hand, attention must be paid to the inherent discrimination and prejudice that may appear in the data and proactive measures should be taken to weaken the impact of such prejudice; on the other hand, the dataset should be reviewed periodically to ensure the high quality of the data. Also, the testing process should use quantitative indicators based on fair decision-making capabilities to test the AI system.\u201D (p 15)`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Draft Analysis Complete":!0,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!0,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-88Rbwn15L0",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-88Rbwn15L0",name:"China: White Paper on Trustworthy AI",index:464,createdAt:"2024-05-30T01:18:25.206Z",updatedAt:"2024-06-05T21:37:17.815Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-88Rbwn15L0"},{values:{"Policy Name":"Trustworthy Facial Recognition Applications and Protections Plan","Policy creator":["China"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Tangential to EdTech. There is far more relevant in China\u2019s policy portfolio. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27295","Series #":10,Title:"China: Trustworthy Facial Recognition Applications and Protections Plan","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-jTtgsZIXeF",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-jTtgsZIXeF",name:"China: Trustworthy Facial Recognition Applications and Protections Plan",index:463,createdAt:"2024-05-30T01:18:16.229Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-jTtgsZIXeF"},{values:{"Policy Name":"Three-Year Guidance for Internet Plus AI Plan","Policy creator":["China"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This was from 2016-2018\u2014has been superseded. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24471","Series #":9,Title:"China: Three-Year Guidance for Internet Plus AI Plan","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-or0Bnw6OLs",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-or0Bnw6OLs",name:"China: Three-Year Guidance for Internet Plus AI Plan",index:462,createdAt:"2024-05-30T01:18:08.954Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-or0Bnw6OLs"},{values:{"Policy Name":"National New Generation AI Promotion Office","Policy creator":["China"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This dates back to 2017, and has been superseded. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27192","Series #":8,Title:"China: National New Generation AI Promotion Office","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-I_xhQt8dBI",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-I_xhQt8dBI",name:"China: National New Generation AI Promotion Office",index:461,createdAt:"2024-05-30T01:17:54.534Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-I_xhQt8dBI"},{values:{"Policy Name":"National New Generation AI Governance Specialist Committee","Policy creator":["China"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The creation of this committee is less relevant than the material it has produced, which I have included. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24426","Series #":7,Title:"China: National New Generation AI Governance Specialist Committee","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-6ncAQ_DcZN",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-6ncAQ_DcZN",name:"China: National New Generation AI Governance Specialist Committee",index:460,createdAt:"2024-05-30T01:17:34.411Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-6ncAQ_DcZN"},{values:{"Policy Name":"Guiding Opinions on Strengthening Overall Governance of Internet Information Service Algorithms","Policy creator":["China"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This is only loosely relevant. There is more directly relevant material.
Translation: Guiding Opinions on Strengthening Overall Governance of Internet Information Service Algorithms (stanford.edu)`,File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27297","Series #":6,Title:"China: Guiding Opinions on Strengthening Overall Governance of Internet Information Service Algorithms","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-B-nnpKgtJx",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-B-nnpKgtJx",name:"China: Guiding Opinions on Strengthening Overall Governance of Internet Information Service Algorithms",index:459,createdAt:"2024-05-30T01:17:13.688Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-B-nnpKgtJx"},{values:{"Policy Name":"Governance Principles for New Generation AI","Policy creator":["China"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"These are broadly relevant.",File:["Governance Principles for the New Generation Artificial Intelligence--Developing Responsible Artificial Intelligence - Chinadaily.com.cn.pdf"],"Year of Commencement or Creation":"2019","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24427","Series #":5,Title:"China: Governance Principles for New Generation AI","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["Non-OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201CThe development of AI should be based on the premise of ensuring social security and respecting human rights, and should prevent misuse, abuse and evil use of AI technology by all means.\u201D (p 1)
\u201CAI development should respect and protect the privacy of individuals and fully protect an individual\u2019s rights to know and to choose.\u201D (p 2)`,"Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`\u201CThe development of AI should promote fairness and justice, protect the rights and interests of all stakeholders, and promote equal opportunities.\u201D (p 2)

Could also be interpreted as formal (rather than substantive) equality: 
\u201CThrough technology advancement and management improvement, prejudices and discriminations should be eliminated as much as possible in the process of data acquisition, algorithm design, technology development, and product development and application.\u201D (p 2)`,"General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Bias testing. AI systems should be tested for bias. ","Human rights-centred. AI systems should be compatible with human rights. ","Environmental wellbeing. The use of AI should not harm the environment. ","Inclusive development. AI systems should be developed inclusively. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society."],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!0,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-VbWA0f4jSi",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-VbWA0f4jSi",name:"China: Governance Principles for New Generation AI",index:458,createdAt:"2024-05-30T01:17:03.342Z",updatedAt:"2024-06-04T22:34:36.295Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-VbWA0f4jSi"},{values:{"Policy Name":"14th Five-Year Plan for National Economic and Social Development of the People\u2019s Republic of China","Policy creator":["China"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Did a translation, but not relevant\u2014focused on development broadly, and does not talk about \u201Cintelligent education\u201D in any depth. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27179","Series #":4,Title:"China: 14th Five-Year Plan for National Economic and Social Development of the People\u2019s Republic of China","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"Translation Completed (Google Translate)","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-di6dDFy-xR",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-di6dDFy-xR",name:"China: 14th Five-Year Plan for National Economic and Social Development of the People\u2019s Republic of China",index:457,createdAt:"2024-05-30T01:16:47.649Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-di6dDFy-xR"},{values:{"Policy Name":"National New Generation AI Plan","Policy creator":["China"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`\u201CIntelligent education\u201D is built into China\u2019s plan. 
Note that far more detailed information about its educational intentions are built into its subsequent education policy (included in our policy tool). `,File:["P020210628714286134479.pdf"],"Year of Commencement or Creation":"2017","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24274","Series #":3,Title:"China: National New Generation AI Plan","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["Non-OECD"],"Translation Comments":"Official Translation Obtained","Key quotes on AI in education principles":`(p 7)

Very minimal commentary on risks. This is it: \u201CWhile robustly developing AI, we must highlight the potential safety risks, enhance early prevention and guidance, reduce risks to a maximum degree and ensure the safe, reliable and manageable development of AI.\u201D

The main usage of \u201Cgovernance\u201D relates to \u201Cintelligent social governance\u201D (by which it means \u201Cpublic administration\u201D). 
`,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"N/A","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["[N/A]"],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-5nkZlHdSBx",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-5nkZlHdSBx",name:"China: National New Generation AI Plan",index:456,createdAt:"2024-05-30T01:16:33.257Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-5nkZlHdSBx"},{values:{"Policy Name":"AI Innovation Action Plan for Institutions of Higher Education","Policy creator":["China"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This has a section on \u201Cintelligent education\u201D that is directly relevant\u2014and really interesting. As far back as 2018, it was looking into the following: \u201CAccelerate and promote the deep integration and innovative development of AI in education.\u201D See details below. 
Note, however, that this strategy is broader in scope than \u201CEdTech governance\u201D \u2014 it considers the role of educational institutions in developing a robust AI sector. `,File:["Notice-of-the-Ministry-of-Education-on-Issuing-the-Artificial-Intelligence-Innovation-Action-Plan-for-Institutes-of-Higher-Education.pdf"],"Year of Commencement or Creation":"2018","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Communicates a stance. It expresses a hope for the future of AI","Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26851","Series #":2,Title:"China: AI Innovation Action Plan for Institutions of Higher Education","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["Non-OECD"],"Translation Comments":"Official Translation Obtained","Key quotes on AI in education principles":`There is significant appetite here:
\u201CUsing smart technology to innovate new ways to provide training, revolutionize teaching methods, improve academic administration, and build an intelligentized, networked, personalized, lifelong education system are important measures for promoting the development of balanced education, educational equity, and increased education quality. It is an indispensable driver of and support for educational modernization.\u201D (p 2)

What does it want to do with AI in education?
\u201CPromote the development of intelligent education. Promote educational and teaching reform. Move towards a smart campus model based on digital campuses. Create a technology-enabled teaching environment. Explore new AI-based teaching models. Reconstruct how teachers teach, using AI to monitor the teaching process, analyze students, and assess attainment levels. Set up comprehensive, multi-dimensional, big data-based smart assessments. Accurately evaluate both teacher and student performance. Institute individualized aptitude-based curricula. Promote academic administration reform. Support schools\u2019 use of AI technology to modify their organizational structures and management systems and optimize how they operate and serve their students. Implement delicacy management and personalized service on campuses to completely upgrade schools\u2019 administrative levels. Promote lifelong online learning, encourage the development of student-centric intelligentized learning platforms, provide a rich variety of personalized learning resources, innovate how services are provided, and tailor lifelong learning.\u201D (p 10)
\u201CDemonstrating the application of AI in intelligent education. Accelerate and promote the deep integration and innovative development of AI in education. Research strategies, standards, and specifications for developing intelligent education. Explore channels and methods for integrating AI technology into the educational environment, teaching models, curricula, teaching methods, academic administration, educational assessment, and educational research. Develop an intelligentized, cloud-based education platform and encourage new ways of teaching that are supported by AI to modernize education from the ground up.\u201D (p 11)`,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"N/A","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CUsing smart technology to innovate new ways to provide training, revolutionize teaching methods, improve academic administration, and build an intelligentized, networked, personalized, lifelong education system are important measures for promoting the development of balanced education, educational equity, and increased education quality. It is an indispensable driver of and support for educational modernization\u201D (p 2)","General principles on AI":["[N/A]"],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-SE9pMo8wjZ",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-SE9pMo8wjZ",name:"China: AI Innovation Action Plan for Institutions of Higher Education",index:61,createdAt:"2024-05-30T01:15:57.142Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-SE9pMo8wjZ"},{values:{"Policy Name":"Beijing Consensus on AI and Education","Policy creator":["UNESCO"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"It is difficult to think of a more relevant document than this. It is all about AI empowering teachers, helping manage schools, and so on. ",File:["W020190828311234688933.pdf"],"Year of Commencement or Creation":"2019","Relevance Type":["Policy is about AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Managing bias. The risk of bias should be managed with care. "],"Governance practices employed":"","Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27218","Series #":1,Title:"UNESCO: Beijing Consensus on AI and Education","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["IO"],"Translation Comments":"","Key quotes on AI in education principles":`Opportunities:
\u201CWe are committed to leading appropriate policy responses aimed at the systematic integration of AI and education to innovate education, teaching and learning, and at leveraging AI to accelerate the delivery of open and flexible education systems that enable equitable, relevant and quality lifelong learning opportunities for all that will contribute to achieving the SDGs and the shared future for mankind.\u201D (p 3)
Talks about AI for education management and delivery
\u201C10. Be cognizant of the breakthrough in the use of data in transforming evidence-based policy planning processes. Consider integrating or developing AI technologies and tools that are relevant for upgrading education management information systems (EMIS) in order to enhance data collection and processing, making education management and provision more equitable, inclusive, open and personalized. \u201C
\u201C11. Consider also introducing new models for delivering education and training in different learning institutions and settings that can be enabled by the use of AI, in order to serve different actors such as students, teaching staff, parents and communities\u201D (p 5)
Talks about AI to empower teaching and teachers
\u201CBe mindful that while AI provides opportunities to support teachers in their educational and pedagogical responsibilities, human interaction and collaboration between teachers and learners must remain at the core of education...\u201D (p 5)
\u201CDynamically review and define teachers\u2019 roles and required competencies in the context of teacher policies, strengthen teacher training institutions, and develop appropriate capacity-building programmes to prepare teachers to work effectively in AI-rich education settings.\u201D (p 5)
Talks about AI for learning and assessment
\u201CBe cognizant of trends regarding the potential of AI to support learning and learning assessments\u201D... (p 5)
Augmentation not replacement
\u201CBe aware that teachers cannot be displaced by machines, and ensure that their rights and working conditions are protected\u201D (p 5)
Ethical, transparent, and auditable
See p 8

`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`Starts with a background statement:
\u201CWe also recognize the distinctive features of human intelligence. Recalling the principles set forth in the Universal Declaration of Human Rights, we reaffirm UNESCO\u2019s humanistic approach to the use of AI with a view towards protecting human rights and preparing all people with the appropriate values and skills needed for effective human\u2013machine collaboration in life, learning and work, and for sustainable development.\u201D (p 4)
Moves on to more significant propositions:
\u201CCoordinate collective actions to promote the equitable use of AI in education in the context of the global and regional Education 2030 architecture, including through sharing AI technology, programmes and resources for capacity-building, with due respect for human rights and gender equality\u201D (p 9)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`\u201CRecalling the Qingdao Declaration adopted in 2015 on leveraging information and communication technology (ICT) to achieve SDG 4, which stated that emerging technologies must be harnessed to strengthen education systems, access to education for all, quality and effective learning, and equitable and more efficient service provision, we are cognizant of the urgency of reaffirming and renewing this commitment as we move towards an era characterized by the widespread application of AI.\u201D (p 3)
The main section on equity comes later:
\u201C22. Reaffirm that ensuring inclusion and equity in and through education, and offering lifelong learning opportunities to all, are the cornerstones of achieving SDG 4 \u2013 Education 2030. Reaffirm that technological breakthroughs in the field of AI in education are an opportunity to improve access to education for the most vulnerable groups.\u201D (p 7)
\u201C23. Ensure that AI promotes high-quality education and learning opportunities for all, irrespective of gender, disability, social or economic status, ethnic or cultural background, or geographic location. The development and use of AI in education should not deepen the digital divide and must not display bias against any minority or vulnerable groups.\u201D (p 7)
\u201C24. Ensure that AI tools in teaching and learning enable the effective inclusion of students with learning impairments or disabilities and those studying in a language other than their mother tongue.\u201D (p 7)
Etc`,"General principles on AI":["[N/A]"],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-0pzKRyXc_Y",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-0pzKRyXc_Y",name:"UNESCO: Beijing Consensus on AI and Education",index:56,createdAt:"2024-05-30T01:15:43.255Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-0pzKRyXc_Y"},{values:{"Policy Name":"Development of common standards in the use of artificial intelligence in the digitization process in order to ensure guarantees of equal access and respect for human rights. ","Policy creator":["Bulgaria"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This sounds interesting, sure; but the policy does not seem to exist. There is no link or native-language reference to search. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27670","Series #":3,Title:"Bulgaria: Development of common standards in the use of artificial intelligence in the digitization process in order to ensure guarantees of equal access and respect for human rights. ","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Cannot Access",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-_N74miOuk9",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_N74miOuk9",name:"Bulgaria: Development of common standards in the use of artificial intelligence in the digitization process in order to ensure guarantees of equal access and respect for human rights. ",index:64,createdAt:"2024-05-30T01:10:19.669Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_N74miOuk9"},{values:{"Policy Name":"Innovation Strategy for Smart Specialisation 2021-2027","Policy creator":["Bulgaria"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This does not seem as relevant as the previous document\u2014it is focused in par on informatics, but a lot of other stuff: mechatronics, biotechnology, clean technologies, etc. Education is not mentioned. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27671","Series #":2,Title:"Bulgaria: Innovation Strategy for Smart Specialisation 2021-2027","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-y3WNKE3QaF",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-y3WNKE3QaF",name:"Bulgaria: Innovation Strategy for Smart Specialisation 2021-2027",index:63,createdAt:"2024-05-30T01:07:58.329Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-y3WNKE3QaF"},{values:{"Policy Name":"Concept for the Development of AI in Bulgaria until 2030","Policy creator":["Bulgaria"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is broad acknowledgment that AI will contribute to modernisation of schools, but also generally relevant governance norms. ",File:["conceptforthedevelopmentofaiinbulgariauntil2030.pdf"],"Year of Commencement or Creation":"2020","Relevance Type":["Policy makes fleeting reference to AI in education","Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. ","Human rights-centred. The technology must be consistent with human rights. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Communicates a stance. It expresses a hope for the future of AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26500","Series #":1,Title:"Bulgaria: Concept for the Development of AI in Bulgaria until 2030","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["Non-OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":`The document makes some general remarks regarding the importance of AI education (curriculum) in primary and secondary schools in meeting skills requirements, as well as development of AI-focused university programs (including for noting, but not relevant to current project):
\u201CA key role for the development and implementation of AI is the availability of human potential: specialists who are familiar with the latest discoveries and trends in the field, to master methods and tools for scientific research, implementation in practice and teaching, or to be able explain the benefits of adopting intelligent systems for widespread use.
More relevant content \u2014 
General governance norm: 
\u201CSpecial attention to the study of the impact of AI on society, as well as to the standards for building reliable AI. This suggests, on the one hand, the inclusion in the university educational programmes in informatics and technical specialties of academic disciplines focused on the legal, ethical and social aspects of AI, and on the other hand, the inclusion of disciplines for researching the impact of AI in the schools of social sciences, legal sciences and humanities.\u201D (p 37)
Other norms include preparing students to understand the risks of the technology, which is relevant:
\u201CIncreasing students' competencies in the field of ethical issues related to the use of information technology and their rights in the digital world in which they live.\u201D (p 36)
Relevant to opportunity: 
\u201CApplying AI tools in education to increase the quality, attractiveness and efficiency of the educational process, while strictly observing the protection of fundamental rights and proper consideration of the vulnerable situation of children.\u201D (p 36)
\u201CImplementing AI in university management. Given the breakthrough in the use of data to transform planning processes, to develop and integrate AI technologies and tools that are important for improving education management information systems (EMIS) to optimize data collection and processing to achieve a fairer, more inclusive, open and personalized education.\u201D (p 37)
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":`\u201CIt must create a unique "trust ecosystem" by ensuring compliance with EU rules, including those for the protection of fundamental human rights and consumer rights, especially in relation to high-risk AI systems.\u201D (p 31)
\u201CReliable AI presupposes the development of a legal framework to ensure that the fundamental rights of citizens are preserved, including ensuring product safety and determining legal liability.\u201D (p 16)
\u201CThe principles of respect for fundamental rights, non-discrimination and the protection of personal data should be seen as an integral part of the requirements that ensure the safety of AI technologies.\u201D (p 40)
\u201CTo provide the necessary conditions for ensuring the development of reliable AI technologies in Bulgaria, an assessment of the applicability and effectiveness of the existing regulations on guaranteeing the fundamental rights of citizens and the safety of new products, including AI technologies, as well as the methodology for licensing these products and putting them into operation.\u201D (p 41)`,"Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Bias testing. AI systems should be tested for bias. ","Human rights-centred. AI systems should be compatible with human rights. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!0,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-ks1e65Ehoi",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ks1e65Ehoi",name:"Bulgaria: Concept for the Development of AI in Bulgaria until 2030",index:62,createdAt:"2024-05-30T01:05:01.550Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ks1e65Ehoi"},{values:{"Policy Name":"Jaque and Services Guide","Policy creator":["Brazil"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This is really cool: \u201CJaque is a virtual clerk based on AI made to guide citizens through \u201CServices Guide\u201D, a digital catalogue that centralises all information regarding public services offered by the State Government of Alagoas. Services Guide provides a step-by-step explanation for each service provided by each public agency. It contains information such as the length of processes, documents needed, location and operation time of agencies, availability of services and so on.\u201D
However, it is not super relevant to EdTech. There is no regulatory documentation provided as part of this, so effectively the initiative is the creation of a chatbot. `,File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27235","Series #":5,Title:"Brazil: Jaque and Services Guide","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-g4h_KRp_Ah",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-g4h_KRp_Ah",name:"Brazil: Jaque and Services Guide",index:455,createdAt:"2024-05-29T08:50:45.460Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-g4h_KRp_Ah"},{values:{"Policy Name":"Government Committee of the Brazilian AI Strategy","Policy creator":["Brazil"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The existence of this committee is not the relevant aspect of the broader policy initiative. It is some of the things created, which are included in this list. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27343","Series #":4,Title:"Brazil: Government Committee of the Brazilian AI Strategy","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-BSHcOwqz1n",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-BSHcOwqz1n",name:"Brazil: Government Committee of the Brazilian AI Strategy",index:454,createdAt:"2024-05-29T08:50:31.869Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-BSHcOwqz1n"},{values:{"Policy Name":"Brazilian Strategy for Digital Innovation","Policy creator":["Brazil"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This focuses on basic infrastructure and digitisation \u2014 very limited AI focus, and little (if anything) on EdTech. ",File:["digitalstrategy_2022-2026.pdf"],"Year of Commencement or Creation":"2022","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24273","Series #":3,Title:"Brazil: Brazilian Strategy for Digital Innovation","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-pDgALXxLja",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-pDgALXxLja",name:"Brazil: Brazilian Strategy for Digital Innovation",index:453,createdAt:"2024-05-29T08:50:19.460Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-pDgALXxLja"},{values:{"Policy Name":"AI Use Cases in the Public Sector","Policy creator":["Brazil"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This looks really, really cool. Discussed here:
Artificial ladies against corruption: searching for legitimacy at the Brazilian Supreme Audit Institution (redalyc.org)
However, less relevant to EdTech. Something to be aware of for future projects. `,File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27107","Series #":2,Title:"Brazil: AI Use Cases in the Public Sector","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-QyQqT289r6",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-QyQqT289r6",name:"Brazil: AI Use Cases in the Public Sector",index:452,createdAt:"2024-05-29T08:50:13.960Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-QyQqT289r6"},{values:{"Policy Name":"Brazilian AI Strategy","Policy creator":["Brazil"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"It is worth assessing this, but I can say just looking at the summary that it is at least generally relevant as a broad governance initiative (it expresses key AI governance norms that are familiar\u2014transparency, explainability, etc). ",File:["Brazil_Brazilian_AI_Strategy_2021.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27104","Series #":1,Title:"Brazil: Brazilian AI Strategy","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-_lBFf1wOCQ",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_lBFf1wOCQ",name:"Brazil: Brazilian AI Strategy",index:65,createdAt:"2024-05-29T08:49:45.629Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_lBFf1wOCQ"},{values:{"Policy Name":"AI4T","Policy creator":["France","Italy","Ireland","Luxembourg","Slovenia"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This is highly relevant \u2014 about preparing teachers to embrace AI in education / ensuring that have the skills to manage it. Note that it is France and others. 
AI4T - Artificial Intelligence for and by teachers | France Education international (france-education-international.fr)

Here is a link to the textbook, which I have included as a secondary source:
AI for Teachers \u2014 Textbook`,File:["AI4T - Artificial Intelligence for and by teachers _ France Education international.pdf"],"Year of Commencement or Creation":"2021","Relevance Type":["Policy is about AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary"],"Principles on AI in education":["Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Develops tools. It provides tools and place them in the hands of businesses or governments"],"Analysis Complete":!0,"Link (OECD or Other)":"","Series #":13,Title:"FranceItalyIrelandLuxembourgSlovenia: AI4T","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["OECD","OECD","OECD","OECD","OECD"],"Translation Comments":"Translation Completed (Google Translate)","Key quotes on AI in education principles":`\u201CAt the end of the project, the aim is that teachers will become more confident and aware users of AI-based resources, which will help them to improve their practice. In addition, AI4T is contributing to the implementation of new teaching methods in the classroom and to the informed use of AI as a decision-making aid. A European network is being set up to share experience and best practice.\u201D (no pinpoint)

Note that they actually built a textbook:
Textbook \u2013 AI4T project`,"Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":["[N/A]"],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!0,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-NzS1c7nWDB",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-NzS1c7nWDB",name:"FranceItalyIrelandLuxembourgSlovenia: AI4T",index:441,createdAt:"2024-05-29T08:20:33.114Z",updatedAt:"2024-06-04T22:38:02.206Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-NzS1c7nWDB"},{values:{"Policy Name":"Teleworking: The Rules and Best Practices to Follow","Policy creator":["France"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Initially, I wondered whether this could be applied to surveillance issues pertaining to EdTech. However, it is very particular to \u201Cwork\u201D (and France\u2019s legal framework/culture). Difficult to apply more broadly. ",File:[],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27434","Series #":12,Title:"France: Teleworking: The Rules and Best Practices to Follow","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-lWNXwOfiPL",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-lWNXwOfiPL",name:"France: Teleworking: The Rules and Best Practices to Follow",index:451,createdAt:"2024-05-29T07:50:40.866Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-lWNXwOfiPL"},{values:{"Policy Name":"Our AI: Our Ambition for France","Policy creator":["France"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This seems to be the latest strategy for France. It looks promising, but I need to translate it to assess relevance. ",File:["4d3cc456dd2f5b9d79ee75feea63b47f10d75158.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27690","Series #":11,Title:"France: Our AI: Our Ambition for France","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-0uDK4VOD0p",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-0uDK4VOD0p",name:"France: Our AI: Our Ambition for France",index:450,createdAt:"2024-05-29T07:50:31.398Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-0uDK4VOD0p"},{values:{"Policy Name":"Labour AI","Policy creator":["France"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a research centre. It does not appear to carry out work on EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26504","Series #":10,Title:"France: Labour AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-m3Ejw5rxRR",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-m3Ejw5rxRR",name:"France: Labour AI",index:449,createdAt:"2024-05-29T07:50:23.193Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-m3Ejw5rxRR"},{values:{"Policy Name":"International Panel on AI","Policy creator":["France"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is an \u201Cinternational study group\u201D. It is not EdTech related, so only their specific work on EdTech would make the cut. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27217","Series #":9,Title:"France: International Panel on AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-G63j8tX4ZP",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-G63j8tX4ZP",name:"France: International Panel on AI",index:448,createdAt:"2024-05-29T07:50:13.385Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-G63j8tX4ZP"},{values:{"Policy Name":"Health Data Hub","Policy creator":["France"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"One plausible point of relevance would be if schools were collecting health data on students\u2014but even still, this is not regulatory, but a project designed to collect the data. That collection exercise is not relevant to EdTech governance. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27214","Series #":8,Title:"France: Health Data Hub","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-i6muk9OQS0",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-i6muk9OQS0",name:"France: Health Data Hub",index:447,createdAt:"2024-05-29T07:50:07.804Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-i6muk9OQS0"},{values:{"Policy Name":"Gaia-X","Policy creator":["France"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is an interoperable data exchange for businesses to exchange information. Not especially relevant. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26761","Series #":7,Title:"France: Gaia-X","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-ybly4XtJaP",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ybly4XtJaP",name:"France: Gaia-X",index:446,createdAt:"2024-05-29T07:50:02.602Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ybly4XtJaP"},{values:{"Policy Name":"France AI","Policy creator":["France"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is an old report. It has been superseded by Villani\u2019s report. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-16323","Series #":6,Title:"France: France AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-Nhrznf1Pjy",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Nhrznf1Pjy",name:"France: France AI",index:445,createdAt:"2024-05-29T07:49:47.719Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Nhrznf1Pjy"},{values:{"Policy Name":"Etalab","Policy creator":["France"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a body created to coordinate strategy in the data domain. Its creation is only very loosely related to EdTech governance. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27267","Series #":5,Title:"France: Etalab","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-XvjNjbosTy",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-XvjNjbosTy",name:"France: Etalab",index:444,createdAt:"2024-05-29T07:49:39.283Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-XvjNjbosTy"},{values:{"Policy Name":"Confiance.AI Program","Policy creator":["France"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The body \u2014 as a policy initiative \u2014 is interesting but removed from EdTech. Perhaps some of the work they do \u2014 secondary materials \u2014 would be useful when doing our literature review, but given our focus here on policy, this can be set aside. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27280","Series #":4,Title:"France: Confiance.AI Program","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-knoo63cMO3",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-knoo63cMO3",name:"France: Confiance.AI Program",index:443,createdAt:"2024-05-29T07:49:33.678Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-knoo63cMO3"},{values:{"Policy Name":"Cloud Strategy","Policy creator":["France"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is quite a broad infrastructural project. It is only loosely relevant to EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27279","Series #":3,Title:"France: Cloud Strategy","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-Q4het9T_ad",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Q4het9T_ad",name:"France: Cloud Strategy",index:442,createdAt:"2024-05-29T07:49:29.921Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Q4het9T_ad"},{values:{"Policy Name":"AI Education & Training Development Plan","Policy creator":["France"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"It seems as though the resource linked is incorrect. It seems very focused on building skills/research rather than EdTech, but we cannot be sure. I searched the French title, but could not find the relevant document. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27288","Series #":2,Title:"France: AI Education & Training Development Plan","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Cannot Access",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-BVeDyvWUNx",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-BVeDyvWUNx",name:"France: AI Education & Training Development Plan",index:440,createdAt:"2024-05-29T07:49:22.574Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-BVeDyvWUNx"},{values:{"Policy Name":"National Strategy on AI","Policy creator":["France"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Potentially relevant \u2014 but the report cannot be downloaded (\u201DCannot reach this page\u201D). Try again at a later date. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25374","Series #":1,Title:"France: National Strategy on AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Cannot Access",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-9ZTn46N9cK",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-9ZTn46N9cK",name:"France: National Strategy on AI",index:66,createdAt:"2024-05-29T07:49:15.022Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-9ZTn46N9cK"},{values:{"Policy Name":"Technology Committee within the Framework of the National System of Competitiveness and Innovation","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is only very loosely related \u2014 the initiative is the creation of a body to steer numerous AI initiatives. Only remotely related to EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27696","Series #":17,Title:"Colombia: Technology Committee within the Framework of the National System of Competitiveness and Innovation","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-icfqZ7fYsA",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-icfqZ7fYsA",name:"Colombia: Technology Committee within the Framework of the National System of Competitiveness and Innovation",index:439,createdAt:"2024-05-29T07:10:04.092Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-icfqZ7fYsA"},{values:{"Policy Name":"Strategic Plan for Knowledge Transfer in AI","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is focused on the scientific sector\u2014communicating knowledge to industry. Not especially relevant. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27093","Series #":16,Title:"Colombia: Strategic Plan for Knowledge Transfer in AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-_TEusYyffp",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_TEusYyffp",name:"Colombia: Strategic Plan for Knowledge Transfer in AI",index:438,createdAt:"2024-05-29T07:09:49.403Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_TEusYyffp"},{values:{"Policy Name":"Policy of Research Ethics, Bioethics and Scientific Integrity","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Not relevant to EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26741","Series #":15,Title:"Colombia: Policy of Research Ethics, Bioethics and Scientific Integrity","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-oDKlUj88YN",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-oDKlUj88YN",name:"Colombia: Policy of Research Ethics, Bioethics and Scientific Integrity",index:437,createdAt:"2024-05-29T07:09:37.057Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-oDKlUj88YN"},{values:{"Policy Name":"Mechanism for the Implementation of Principles and International Standards in AI","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This looks like an interesting policy. This initiative could be replicated in the EdTech space. However, a translation is needed before we can make a final assessment of relevance. ",File:["libro final No 2 Parte 1 Libro No 2 Plan_Seguimiento_OCDE_Astrid_Angarita.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27038","Series #":14,Title:"Colombia: Mechanism for the Implementation of Principles and International Standards in AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-tvgopeO6Rq",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-tvgopeO6Rq",name:"Colombia: Mechanism for the Implementation of Principles and International Standards in AI",index:436,createdAt:"2024-05-29T07:08:51.993Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-tvgopeO6Rq"},{values:{"Policy Name":"Law for the Promotion of AI Technology and Entrepreneurship","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"I was interested to see whether education was singled out. It does not appear so. It is a broader regulatory framework. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27183","Series #":13,Title:"Colombia: Law for the Promotion of AI Technology and Entrepreneurship","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-dAbc1DZA4V",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-dAbc1DZA4V",name:"Colombia: Law for the Promotion of AI Technology and Entrepreneurship",index:435,createdAt:"2024-05-29T07:08:44.211Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-dAbc1DZA4V"},{values:{"Policy Name":"GovTech Ecosystem for AI Implementation ","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is procurement-oriented. One imagines that this could be applied to EdTech. There is not a whole heap of information available here about this. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26994","Series #":12,Title:"Colombia: GovTech Ecosystem for AI Implementation ","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Cannot Access",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-rvsG1Riaj1",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-rvsG1Riaj1",name:"Colombia: GovTech Ecosystem for AI Implementation ",index:434,createdAt:"2024-05-29T07:08:33.425Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-rvsG1Riaj1"},{values:{"Policy Name":"Ethical Framework for AI in Columbia","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Cannot presently access this material \u2014 links to one of the Colombian government sites are not opening. Check back as this looks promising. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26737","Series #":11,Title:"Colombia: Ethical Framework for AI in Columbia","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Cannot Access",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-1ykChTTv8T",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-1ykChTTv8T",name:"Colombia: Ethical Framework for AI in Columbia",index:433,createdAt:"2024-05-29T07:08:22.113Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-1ykChTTv8T"},{values:{"Policy Name":"Emerging Technologies Handbook ","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Cannot presently access this material \u2014 links to one of the Colombian government sites are not opening. Check back as this looks promising. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27143","Series #":10,Title:"Colombia: Emerging Technologies Handbook ","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Cannot Access",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-CQu8KC-90B",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-CQu8KC-90B",name:"Colombia: Emerging Technologies Handbook ",index:432,createdAt:"2024-05-29T07:08:10.610Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-CQu8KC-90B"},{values:{"Policy Name":"Data Marketplace and Data Infrastructure","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Only loosely related to EdTech\u2014cool infrastructure, but a little tangential to our work at this stage.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26995","Series #":9,Title:"Colombia: Data Marketplace and Data Infrastructure","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-5xIBSFk8Qs",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-5xIBSFk8Qs",name:"Colombia: Data Marketplace and Data Infrastructure",index:431,createdAt:"2024-05-29T07:08:02.739Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-5xIBSFk8Qs"},{values:{"Policy Name":"Cybersecurity Policy for AI Deployment","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Cybersecurity is a hugely important aspect of AI in education. This seems like a potentially relevant initiative. However, I am facing problems accessing the materials (they cannot be reached). We are probably going to be prioritising more directly relevant materials anyway, but this one would be good to come back to\u2014time permitting. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27185","Series #":8,Title:"Colombia: Cybersecurity Policy for AI Deployment","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-7NQ9ULxsi9",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-7NQ9ULxsi9",name:"Colombia: Cybersecurity Policy for AI Deployment",index:430,createdAt:"2024-05-29T07:07:49.724Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-7NQ9ULxsi9"},{values:{"Policy Name":"Columbian Supercomputing Network","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Not focused here on supercomputers. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27182","Series #":7,Title:"Colombia: Columbian Supercomputing Network","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-UOALbL_G4g",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-UOALbL_G4g",name:"Colombia: Columbian Supercomputing Network",index:429,createdAt:"2024-05-29T07:07:36.966Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-UOALbL_G4g"},{values:{"Policy Name":"Co-Ordination Bodies for AI Policy Implementation","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is about coordinating a whole range of AI work across government. Not especially relevant to EdTech / AI in education. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27187","Series #":6,Title:"Colombia: Co-Ordination Bodies for AI Policy Implementation","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-slPOkrUTED",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-slPOkrUTED",name:"Colombia: Co-Ordination Bodies for AI Policy Implementation",index:428,createdAt:"2024-05-29T07:07:21.127Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-slPOkrUTED"},{values:{"Policy Name":"C4IR Network","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This seems to be some kind of thinktank for research and development. EdTech is not mentioned, and does not appear to be central (or even peripheral) to its agenda. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26448","Series #":5,Title:"Colombia: C4IR Network","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-ZyUBSOjFMP",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ZyUBSOjFMP",name:"Colombia: C4IR Network",index:427,createdAt:"2024-05-29T07:07:18.908Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ZyUBSOjFMP"},{values:{"Policy Name":"Building a Regulatory Ecosystem for AI","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This initiative is designed to enable regulatory experimentation. It does not talk about education per se. Only indirectly relevant. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26723","Series #":4,Title:"Colombia: Building a Regulatory Ecosystem for AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-mlJlLqQ6Ny",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-mlJlLqQ6Ny",name:"Colombia: Building a Regulatory Ecosystem for AI",index:426,createdAt:"2024-05-29T07:07:11.359Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-mlJlLqQ6Ny"},{values:{"Policy Name":"AI in the Public Sector","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Based on a general look at this \u2014 and the time \u201CEducativo\u201D is mentioned, this does not look super relevant. Given that Colombia has so many policy initiatives, more relevant materials may come up elsewhere. ",File:["07-10-2020 Proyectos de TD, Tramites y servicios para el ciudadano_Baja.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26727","Series #":3,Title:"Colombia: AI in the Public Sector","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-IlxQemmFZc",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-IlxQemmFZc",name:"Colombia: AI in the Public Sector",index:425,createdAt:"2024-05-29T07:07:05.705Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-IlxQemmFZc"},{values:{"Policy Name":"AI Expert Mission","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"As an initiative, this is not especially relevant to EdTech. It is a general group set up to guide AI policy. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26993","Series #":2,Title:"Colombia: AI Expert Mission","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-InSdQ-kZ40",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-InSdQ-kZ40",name:"Colombia: AI Expert Mission",index:424,createdAt:"2024-05-29T07:06:59.845Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-InSdQ-kZ40"},{values:{"Policy Name":"AI National Strategy","Policy creator":["Colombia"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This policy is labelled as \u201Cin progress\u201D. It would be interesting to see what is in this, but we cannot consider it yet as it is not publicly available. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27698","Series #":1,Title:"Colombia: AI National Strategy","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-w0UjQQbqI4",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-w0UjQQbqI4",name:"Colombia: AI National Strategy",index:67,createdAt:"2024-05-29T07:06:50.984Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-w0UjQQbqI4"},{values:{"Policy Name":"PhD Scholarships for Technological Revolution and Digital Transformation","Policy creator":["Chile"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is just about incentivising the procurement of valuable skills. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26734","Series #":11,Title:"Chile: PhD Scholarships for Technological Revolution and Digital Transformation","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-Vd4a3YEXQv",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Vd4a3YEXQv",name:"Chile: PhD Scholarships for Technological Revolution and Digital Transformation",index:78,createdAt:"2024-05-29T04:40:58.591Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Vd4a3YEXQv"},{values:{"Policy Name":"Smart Job Retraining","Policy creator":["Chile"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This is more promising \u2014 it is about providing \u201Ctools that help [citizens] in the process of job retraining\u2019. IDB | Smart Job Retraining (iadb.org)
It is not entirely clear what the \u2018machine learnin\u2019 component is. `,File:"","Year of Commencement or Creation":"2020","Relevance Type":["Policy contains case studies on AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Vocational or Professional"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Develops tools. It provides tools and place them in the hands of businesses or governments"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27049","Series #":10,Title:"Chile: Smart Job Retraining","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["[N/A]"],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":`TC \u201Caims at designing a technological platform called "Intelligent Labor Retraining" or RELINT (in Spanish), based on a data intelligence model that allows companies and individuals to be guided in the process of retraining. On the one hand, supporting companies in a digital transformation process by introducing reskilling, upskilling and outplacement mechanisms and, on the other hand, allowing workers to improve their skills for a new type of company or to start a new labor route. This is done by linking interests, experience and employability potential with the demand that the market is requesting for new skills derived from the ongoing digital transformation.\u201D
`,"Other Points of Interest":"","Record Entered By":""},id:"i-H3DXVgh09v",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-H3DXVgh09v",name:"Chile: Smart Job Retraining",index:77,createdAt:"2024-05-29T04:38:15.161Z",updatedAt:"2024-06-06T03:05:20.882Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-H3DXVgh09v"},{values:{"Policy Name":"National Digital Languages Plan","Policy creator":["Chile"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This sounded possible, but it is not about using AI \u2014 or other EdTech \u2014 in education, but about training teachers in computational thinking. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27048","Series #":9,Title:"Chile: National Digital Languages Plan","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-i7GitAY6pz",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-i7GitAY6pz",name:"Chile: National Digital Languages Plan",index:76,createdAt:"2024-05-29T04:36:55.480Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-i7GitAY6pz"},{values:{"Policy Name":"National Challenges","Policy creator":["Chile"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is about building capacity etc\u2014nothing on EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25989","Series #":8,Title:"Chile: National Challenges","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-kqn6BeLHLf",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-kqn6BeLHLf",name:"Chile: National Challenges",index:75,createdAt:"2024-05-29T04:35:24.393Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-kqn6BeLHLf"},{values:{"Policy Name":"National AI Research Centre","Policy creator":["Chile"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is about cutting-edge research. No mention of EdTech.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27335","Series #":7,Title:"Chile: National AI Research Centre","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-C5Xsk1o9dw",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-C5Xsk1o9dw",name:"Chile: National AI Research Centre",index:74,createdAt:"2024-05-29T04:34:45.562Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-C5Xsk1o9dw"},{values:{"Policy Name":"Digital Talent","Policy creator":["Chile"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is about filling gaps in IT professionals. They wanted to train 16,000 professionals between 2019-2022. There is no reference to doing that with education. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27047","Series #":6,Title:"Chile: Digital Talent","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-DJtWUckQ3i",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-DJtWUckQ3i",name:"Chile: Digital Talent",index:73,createdAt:"2024-05-29T04:32:56.676Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-DJtWUckQ3i"},{values:{"Policy Name":"Digital Economy Partnership Agreement","Policy creator":["Chile"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is all very high-level/infrastructural/economic. Nothing specifically on EdTech.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26800","Series #":5,Title:"Chile: Digital Economy Partnership Agreement","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-DAo7xW1P69",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-DAo7xW1P69",name:"Chile: Digital Economy Partnership Agreement",index:72,createdAt:"2024-05-29T04:32:09.725Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-DAo7xW1P69"},{values:{"Policy Name":"Data Observatory","Policy creator":["Chile"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is about the availability of data\u2014quite removed from EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26733","Series #":4,Title:"Chile: Data Observatory","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-_NrvlE_Txc",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_NrvlE_Txc",name:"Chile: Data Observatory",index:71,createdAt:"2024-05-29T04:29:30.911Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_NrvlE_Txc"},{values:{"Policy Name":"Chilean Participation Process on AI","Policy creator":["Chile"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The objectives here are to promote conversation about AI opportunities and challenges. Nothing here specific to EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26732","Series #":3,Title:"Chile: Chilean Participation Process on AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-PrYYQR0Usw",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-PrYYQR0Usw",name:"Chile: Chilean Participation Process on AI",index:70,createdAt:"2024-05-29T04:28:53.496Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-PrYYQR0Usw"},{values:{"Policy Name":"AI Use Cases in the Public Sector","Policy creator":["Chile"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There only appears to be one listing, which is a predictive model on industrial pollution. Not related to EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27144","Series #":2,Title:"Chile: AI Use Cases in the Public Sector","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i--D8jdghw5T",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i--D8jdghw5T",name:"Chile: AI Use Cases in the Public Sector",index:69,createdAt:"2024-05-29T04:27:24.443Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui--D8jdghw5T"},{values:{"Policy Name":"AI National Policy","Policy creator":["Chile"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Need to translate this policy \u2014 could be broadly relevant, but it is difficult to tell. Provisionally assuming \u2018yes\u2019. ",File:["documento_politica_ia_digital_.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24840","Series #":1,Title:"Chile: AI National Policy","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-Oxs8aeoG3r",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Oxs8aeoG3r",name:"Chile: AI National Policy",index:68,createdAt:"2024-05-29T04:24:57.897Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Oxs8aeoG3r"},{values:{"Policy Name":"National AI Strategy","Policy creator":["Cyprus"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There was not a whole heap of content on the OECD entry, but I have located an EC summary: Cyprus AI Strategy Report - European Commission (europa.eu)The key point is that there is a focus on education in AI, but not AI in education. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24848","Series #":1,Title:"Cyprus: National AI Strategy","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-LIfKhG8VFT",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-LIfKhG8VFT",name:"Cyprus: National AI Strategy",index:79,createdAt:"2024-05-29T04:09:58.707Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-LIfKhG8VFT"},{values:{"Policy Name":"The Development of the Digital Government of the Bicentenary","Policy creator":["Costa Rica"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a directive focused on building a digital government. It doesn\u2019t reach into the realm of EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25908","Series #":6,Title:"Costa Rica: The Development of the Digital Government of the Bicentenary","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-spk0OG1Xdc",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-spk0OG1Xdc",name:"Costa Rica: The Development of the Digital Government of the Bicentenary",index:423,createdAt:"2024-05-29T03:58:13.748Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-spk0OG1Xdc"},{values:{"Policy Name":"Regulation and Standardisation of Technology Acquisitions And/Or Development of Management Support Computer Systems","Policy creator":["Costa Rica"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Another foundational policy concerned with the acquisition of electronic equipment and using software in the public service. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25917","Series #":5,Title:"Costa Rica: Regulation and Standardisation of Technology Acquisitions And/Or Development of Management Support Computer Systems","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-AeVwSrF1Al",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-AeVwSrF1Al",name:"Costa Rica: Regulation and Standardisation of Technology Acquisitions And/Or Development of Management Support Computer Systems",index:422,createdAt:"2024-05-29T03:57:55.267Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-AeVwSrF1Al"},{values:{"Policy Name":"Improvements in the Efficiency of Public Spending Through the Appropriate Use of Digital Technologies in the Costa Rican Public Sector ","Policy creator":["Costa Rica"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is more of a FinTech initiative. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25917","Series #":4,Title:"Costa Rica: Improvements in the Efficiency of Public Spending Through the Appropriate Use of Digital Technologies in the Costa Rican Public Sector ","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-fHLKx461fD",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-fHLKx461fD",name:"Costa Rica: Improvements in the Efficiency of Public Spending Through the Appropriate Use of Digital Technologies in the Costa Rican Public Sector ",index:421,createdAt:"2024-05-29T03:57:32.016Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-fHLKx461fD"},{values:{"Policy Name":"Implementation of Accessible Websites in the Costa Rican Public Sector","Policy creator":["Costa Rica"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"A third policy initiative that is public sector oriented. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25914","Series #":3,Title:"Costa Rica: Implementation of Accessible Websites in the Costa Rican Public Sector","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-inBajDAtSL",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-inBajDAtSL",name:"Costa Rica: Implementation of Accessible Websites in the Costa Rican Public Sector",index:420,createdAt:"2024-05-29T03:57:17.427Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-inBajDAtSL"},{values:{"Policy Name":"Digital transformation strategy: The bicentennial of Costa Rica","Policy creator":["Costa Rica"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This work is more fundamental \u2014 foundational \u2014 than \u2018EdTech in education\u2019. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25382","Series #":2,Title:"Costa Rica: Digital transformation strategy: The bicentennial of Costa Rica","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-Wr3CxbOtsJ",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Wr3CxbOtsJ",name:"Costa Rica: Digital transformation strategy: The bicentennial of Costa Rica",index:419,createdAt:"2024-05-29T03:57:09.144Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Wr3CxbOtsJ"},{values:{"Policy Name":"Creation of a high-level commission for digital government of the bicentennial","Policy creator":["Costa Rica"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The goal here was to improve the functioning of the public service at large. Perhaps EdTech is the icing on a cake that they have not built yet?",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25910","Series #":1,Title:"Costa Rica: Creation of a high-level commission for digital government of the bicentennial","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-WMkPlNJqUJ",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-WMkPlNJqUJ",name:"Costa Rica: Creation of a high-level commission for digital government of the bicentennial",index:80,createdAt:"2024-05-29T03:56:50.366Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-WMkPlNJqUJ"},{values:{"Policy Name":"Regional Innovation Plan","Policy creator":["Belgium"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This regional innovation plan dates back to 2016, and seems to have been superseded by Belgium\u2019s other policy initiatives. In any case, it focused on areas other than education technology. Even the new iteration of this plan is not focused on education. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-2316","Series #":9,Title:"Belgium: Regional Innovation Plan","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-SHsoJYU0uK",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-SHsoJYU0uK",name:"Belgium: Regional Innovation Plan",index:86,createdAt:"2024-05-29T03:52:35.491Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-SHsoJYU0uK"},{values:{"Policy Name":"Plan Next Tech Brussels","Policy creator":["Belgium"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is about boosting ICT entrepreneurship, and is quite old now. The link to the documentation is broken, and there was no suggestion that this was EdTech-focused. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-14797","Series #":8,Title:"Belgium: Plan Next Tech Brussels","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-hzvMDDzi03",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-hzvMDDzi03",name:"Belgium: Plan Next Tech Brussels",index:85,createdAt:"2024-05-29T03:51:31.810Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-hzvMDDzi03"},{values:{"Policy Name":"Flemish Policy Plan AI","Policy creator":["Belgium"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There was significant expenditure here ($32m), but not \u2014 it seems \u2014 on EdTech. Sounds like a useful but now dated research initiative that was not focused on EdTech.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24902","Series #":7,Title:"Belgium: Flemish Policy Plan AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-ABmWuLOKGm",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ABmWuLOKGm",name:"Belgium: Flemish Policy Plan AI",index:84,createdAt:"2024-05-29T03:49:51.618Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ABmWuLOKGm"},{values:{"Policy Name":"DigitalWallinia4AI","Policy creator":["Belgium"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The purpose of this 2019 was to integrate European strategies in AI with Belgian initiatives. The goal was to boost regional companies\u2019 competitiveness. This is all quite removed from EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24904","Series #":6,Title:"Belgium: DigitalWallinia4AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-oJ-isBGok3",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-oJ-isBGok3",name:"Belgium: DigitalWallinia4AI",index:83,createdAt:"2024-05-29T03:47:40.331Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-oJ-isBGok3"},{values:{"Policy Name":"Clusters Hub.Brussels","Policy creator":["Belgium"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This policy was designed to stimulate regional cooperation in R&I. There is no reference to education here.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-2981","Series #":5,Title:"Belgium: Clusters Hub.Brussels","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-H2JFEh-sQI",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-H2JFEh-sQI",name:"Belgium: Clusters Hub.Brussels",index:82,createdAt:"2024-05-29T03:45:01.532Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-H2JFEh-sQI"},{values:{"Policy Name":"Brussels Region AI Policy","Policy creator":["Belgium"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is R&D-focused, and dates back to 2018. Too remote to be included. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24907","Series #":4,Title:"Belgium: Brussels Region AI Policy","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-9pGqh4qi-y",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-9pGqh4qi-y",name:"Belgium: Brussels Region AI Policy",index:81,createdAt:"2024-05-29T03:44:29.667Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-9pGqh4qi-y"},{values:{"Policy Name":"AI 4 Belgium","Policy creator":["Belgium"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`These guidelines have a section of \u201CAI as an education tool\u201D. Definitely translate the broader policy document to check for relevant content\u2014but if not, you can firmly say that, in principle, the Belgium government supports two use cases:
Deploy AI as a tool for individualised training adapted to each individual student 
Apply AI as a tool for teachers to enhance their teaching`,File:["report_en.pdf"],"Year of Commencement or Creation":"2019","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24234","Series #":3,Title:"Belgium: AI 4 Belgium","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"Note \u2014 the existence of risk is recognised, but this is a predominantly \u201Cseize the day\u201D policy. ","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"N/A","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CFinally, AI can also be a tool in education. It can drastically improve quality and equity in many cases.\u201D","General principles on AI":["Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (explainability). AI systems should be sufficiently explainable.","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Interoperability. AI systems should be able to work with other systems. ","Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D."],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-zLeK3YsXOk",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-zLeK3YsXOk",name:"Belgium: AI 4 Belgium",index:88,createdAt:"2024-05-29T03:41:10.073Z",updatedAt:"2024-06-03T02:37:13.450Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-zLeK3YsXOk"},{values:{"Policy Name":"Action Plan AI","Policy creator":["Belgium"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This plan has been superseded, and focused on strategic research rather than the generation of EdTech.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26101","Series #":2,Title:"Belgium: Action Plan AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-AdIiWoBxhk",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-AdIiWoBxhk",name:"Belgium: Action Plan AI",index:87,createdAt:"2024-05-29T03:40:03.684Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-AdIiWoBxhk"},{values:{"Policy Name":"National Convergence Plan for the Development of AI","Policy creator":["Belgium"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`The information about this plan does not seem to focus on EdTech. I have attached the original document, but it is difficult to see how EdTech fits into the (English) summary available online. Possibly not a high-priority policy. One to translate if time permits. 
Belgium adopts a national plan for the development of artificial intelligence - ActuIA`,File:["Nationaal_convergentieplan_voor_de_ontwikkeling_van_artificiele_intelligentie (1).pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"","Series #":1,Title:"Belgium: National Convergence Plan for the Development of AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-3lvQMPp8Sh",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-3lvQMPp8Sh",name:"Belgium: National Convergence Plan for the Development of AI",index:89,createdAt:"2024-05-29T03:36:48.393Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-3lvQMPp8Sh"},{values:{"Policy Name":"Technology Pact ","Policy creator":["Denmark"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a commitment to developing AI capabilities more than anything. There was, apparently, a shortage of tech-capable people, and they wanted to solve it. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24780","Series #":4,Title:"Denmark: Technology Pact ","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-52TMeuHguM",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-52TMeuHguM",name:"Denmark: Technology Pact ",index:418,createdAt:"2024-05-29T03:31:37.477Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-52TMeuHguM"},{values:{"Policy Name":"National Centre for Public Sector Innovation","Policy creator":["Denmark"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This Centre is a cool idea, but there is no reference to EdTech. It would be better characterised as a GovTech initiative, and I cannot see any generally applicable norms that could be applied to education.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26491","Series #":3,Title:"Denmark: National Centre for Public Sector Innovation","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-VrYNH0y7Vv",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-VrYNH0y7Vv",name:"Denmark: National Centre for Public Sector Innovation",index:92,createdAt:"2024-05-29T03:31:29.510Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-VrYNH0y7Vv"},{values:{"Policy Name":"Disruption Council ","Policy creator":["Denmark"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a partnership between businesses and government institutions dating back to 2017, and focused on employment. No reference to EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26486","Series #":2,Title:"Denmark: Disruption Council ","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-aIqsOBL8vG",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-aIqsOBL8vG",name:"Denmark: Disruption Council ",index:91,createdAt:"2024-05-29T03:31:02.432Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-aIqsOBL8vG"},{values:{"Policy Name":"The Danish National Strategy for AI","Policy creator":["Denmark"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Education here is understood mostly as education for AI. However, there is one small case study on the Department of Education using a chatbot to handle enquiries from citizens. However, this is a little remote from EdTech. I am not convinced that this makes it over the line. ",File:["305755_gb_version_final-a.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24241","Series #":1,Title:"Denmark: The Danish National Strategy for AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-Gj-55ez5zA",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Gj-55ez5zA",name:"Denmark: The Danish National Strategy for AI",index:90,createdAt:"2024-05-29T03:26:36.762Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Gj-55ez5zA"},{values:{"Policy Name":"Website for Personal Data Protection Impact Assessments","Policy creator":["Mexico"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a really cool, interactive impact assessment tool worth noting (though not for AI per se \u2014 focuses on data protection). A version of this could be developed for EdTech, whether the data protection aspect or otherwise. Am I required to file a DPIA? \u2013 EIPDP (inai.org.mx) ",File:"","Year of Commencement or Creation":"2020","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27479","Series #":10,Title:"Mexico: Website for Personal Data Protection Impact Assessments","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":`This kind of system could be useful \u2014 an impact assessment tool of sorts. 
image.png`,"Record Entered By":""},id:"i-1xjaXeD9Ml",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-1xjaXeD9Ml",name:"Mexico: Website for Personal Data Protection Impact Assessments",index:417,createdAt:"2024-05-29T03:06:42.064Z",updatedAt:"2024-06-03T04:55:12.590Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-1xjaXeD9Ml"},{values:{"Policy Name":"Towards an AI Strategy in Mexico: Harnessing the AI Revolution","Policy creator":["Mexico"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is the whitepaper that came before the strategy. It has been superseded by the strategy. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24265","Series #":9,Title:"Mexico: Towards an AI Strategy in Mexico: Harnessing the AI Revolution","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-xMU58B4DzQ",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-xMU58B4DzQ",name:"Mexico: Towards an AI Strategy in Mexico: Harnessing the AI Revolution",index:416,createdAt:"2024-05-29T03:06:26.597Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-xMU58B4DzQ"},{values:{"Policy Name":"Specific Guidelines for Compliance with the Principles and Rights that Govern the Protection of Personal Data in AI Projects","Policy creator":["Mexico"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is the more detailed version of the \u201CRIPD document\u201D. It was approved as far back as 2017, but might still be relevant and useful on data protection issues within schools. Need to translate. ",File:["guia-orientaciones-espec\xEDficas-proteccion-datos-ia.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27475","Series #":8,Title:"Mexico: Specific Guidelines for Compliance with the Principles and Rights that Govern the Protection of Personal Data in AI Projects","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-yRO_xPJLwx",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-yRO_xPJLwx",name:"Mexico: Specific Guidelines for Compliance with the Principles and Rights that Govern the Protection of Personal Data in AI Projects",index:415,createdAt:"2024-05-29T03:01:52.447Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-yRO_xPJLwx"},{values:{"Policy Name":"Principles and Impact Analysis Guide for the Development and Use of Systems Based on AI in the Federal Public Administration","Policy creator":["Mexico"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This would be worth translating and having a look at. ",File:["Consolidado_Comentarios_Consulta_IA__1_.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24666","Series #":7,Title:"Mexico: Principles and Impact Analysis Guide for the Development and Use of Systems Based on AI in the Federal Public Administration","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-SEw5vlcrsh",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-SEw5vlcrsh",name:"Mexico: Principles and Impact Analysis Guide for the Development and Use of Systems Based on AI in the Federal Public Administration",index:414,createdAt:"2024-05-29T03:01:22.341Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-SEw5vlcrsh"},{values:{"Policy Name":"National Ecosystem of Open Innovation","Policy creator":["Mexico"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This initiative is designed to drive innovation\u2014no reference to EdTech.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26852","Series #":6,Title:"Mexico: National Ecosystem of Open Innovation","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-czwSmtrTC1",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-czwSmtrTC1",name:"Mexico: National Ecosystem of Open Innovation",index:413,createdAt:"2024-05-29T03:01:15.158Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-czwSmtrTC1"},{values:{"Policy Name":"National Alliance of AI","Policy creator":["Mexico"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is focused on sustainable development. Does not make reference to EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27473","Series #":5,Title:"Mexico: National Alliance of AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-xbb8KTKzei",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-xbb8KTKzei",name:"Mexico: National Alliance of AI",index:412,createdAt:"2024-05-29T03:01:11.725Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-xbb8KTKzei"},{values:{"Policy Name":"Guideline for the Elaboration of Privacy Impact Assessments","Policy creator":["Mexico"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"As described: \u201CThe Guideline offers a series of recommendations based on international standards and best practices in information security that may be applicable depending on the nature of the data, the purposes of processing, and the technical and economic capabilities of the data processors.\u201D Given that information security is one of the salient concerns for schools, this is worth treating as provisionally relevant and translating. ",File:["guiaeip.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27477","Series #":4,Title:"Mexico: Guideline for the Elaboration of Privacy Impact Assessments","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-JN-gPXDgVk",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-JN-gPXDgVk",name:"Mexico: Guideline for the Elaboration of Privacy Impact Assessments",index:411,createdAt:"2024-05-29T03:00:55.543Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-JN-gPXDgVk"},{values:{"Policy Name":"General Recommendations for Data Processing in AI","Policy creator":["Mexico"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This looks interesting, but very narrow. Not EdTech-focused, and only loosely related to it. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27474","Series #":3,Title:"Mexico: General Recommendations for Data Processing in AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-I73lSn6XXQ",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-I73lSn6XXQ",name:"Mexico: General Recommendations for Data Processing in AI",index:410,createdAt:"2024-05-29T03:00:34.283Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-I73lSn6XXQ"},{values:{"Policy Name":"AI Use Cases in the Public Sector","Policy creator":["Mexico"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This seems to be another initiative designed to catalogue uses of AI. None of the examples were especially education-focused. Only loosely related (in the sense that AI tools used in schools could be stored in a database managed by the state).",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27149","Series #":2,Title:"Mexico: AI Use Cases in the Public Sector","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-gqaD8100ST",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-gqaD8100ST",name:"Mexico: AI Use Cases in the Public Sector",index:409,createdAt:"2024-05-29T03:00:28.508Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-gqaD8100ST"},{values:{"Policy Name":"Mexican National AI Agenda","Policy creator":["Mexico"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This strategy looks extensive, but I cannot read it (it\u2019s in Spanish). Provisionally assuming that it is relevant, and I will translate it in due course. ",File:["7be025_6f45f669e2fa4910b32671a001074987.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26703","Series #":1,Title:"Mexico: Mexican National AI Agenda","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-67LU4XWALv",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-67LU4XWALv",name:"Mexico: Mexican National AI Agenda",index:93,createdAt:"2024-05-29T03:00:23.195Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-67LU4XWALv"},{values:{"Policy Name":"AI Ethical Guidelines","Policy creator":["Hungary"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This policy entry seems to concern the drawing up of ethical guidelines. No material was linked to the initiative. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25009","Series #":3,Title:"Hungary: AI Ethical Guidelines","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-8-XEmkvnWQ",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-8-XEmkvnWQ",name:"Hungary: AI Ethical Guidelines",index:96,createdAt:"2024-05-29T02:56:17.613Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-8-XEmkvnWQ"},{values:{"Policy Name":"AI Action Plan","Policy creator":["Hungary"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The documents linked do not go anywhere, but this does not look particularly education-focused. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26459","Series #":2,Title:"Hungary: AI Action Plan","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-WMxHd-VBhN",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-WMxHd-VBhN",name:"Hungary: AI Action Plan",index:95,createdAt:"2024-05-29T02:52:48.181Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-WMxHd-VBhN"},{values:{"Policy Name":"Hungary\u2019s AI Strategy","Policy creator":["Hungary"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Locating this document was a bit of a nightmare. In any case, it\u2019s out there and in English, which is convenient (for us). There is a fair bit of relevant content\u2014including reference to \u201CAI-supported education\u201D. It is committed to: \u201Cintensive use of AI technologies in the developments associated with data management in higher education\u201D (p 31). ",File:["Hungary\u2019s Artificial Intelligence Strategy.pdf"],"Year of Commencement or Creation":"2020","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Plans further action. It sets out a strategy on AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26765","Series #":1,Title:"Hungary: Hungary\u2019s AI Strategy","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":`Under \u201CObjectives by 2030 directly affecting citizens\u201D, it notes that \u201C2.5 million citizens benefit from AI-supported education\u201D (p 20)
\u201CThe aim is to collect, promote and make available Hungarian language versions of personalised learning support products available internationally for people at risk of falling behind (disabled, elderly, digital illiterates, those with a low level of education), using AI technologies, as well as to identify and provide priority development and support for talented people from an early age. \u2022 International collection and Hungarian translation of guidance material prepared for the groups at risk of falling behind in the labour market.
Continuous dialogue on the development results and the special demands that may be formulated as the development goals.
Introducing games for improving high-level mathematical and logical skills from an early age and identifying talented children and teenagers. 
Provision of mentors and tutors; online and in-person training for recognised talents and providing support for them beyond the school system.\u201D (p 31)

\u201CIntensive use of AI technologies in the developments associated with data management in higher education.\u201D (p 30)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":`\u201CA general regulatory environment needs to be put in place for data assets with functions such as supporting the AIrelated use of public data assets and facilitating the process of turning data into assets (assetization), together with the development of the relevant financial and legal regulations \u2013 taking into account the various sectors\u2019 specificities and responsibilities in terms of data processing, as well as the relevant fundamental rights and the international framework of data regulations. 
Creation of a framework law on data assets. 
Introduction of a sector-specific regulatory environment to enable data to be turned into assets and their use for purposes of AI. 
Developing rules to govern the use of public data, along with a concept for and rules on their assetization.\u201D (p 34)

\u201CThe goal is to enable citizens to participate, as active and responsible actors, in the data economy where the secondary use of data takes place and to exercise their fundamental rights relating to the protection of personal data. To this end, they need to be enabled to dispose over data pertaining to them and to participate actively and securely in the secondary use of such data.\u201D (p 43)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about AI as a tool for promoting equitable/equal access","Key quote on equity/equality":"\u201CInclusion and talent coaching for groups at risk of falling behind in the labour market The aim is to collect, promote and make available Hungarian language versions of personalised learning support products available internationally for people at risk of falling behind (disabled, elderly, digital illiterates, those with a low level of education), using AI technologies, as well as to identify and provide priority development and support for talented people from an early age.\u201D (p 31)","General principles on AI":["Augmentation, not replacement. AI systems should augment, not displace, workers.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. "],"Draft Analysis Complete":!0,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!0,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i--PZ-g1Dix2",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i--PZ-g1Dix2",name:"Hungary: Hungary\u2019s AI Strategy",index:94,createdAt:"2024-05-29T02:46:55.324Z",updatedAt:"2024-06-03T00:01:55.281Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui--PZ-g1Dix2"},{values:{"Policy Name":"Action Plan for Iceland in the Fourth Industrial Revolution","Policy creator":["Iceland"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Nothing listed, but found the document elsewhere. Does not say anything interesting about EdTech\u2014it is focused on job training/skills. ",File:["Iceland&4thIndustrialRevolution-2019.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26846","Series #":2,Title:"Iceland: Action Plan for Iceland in the Fourth Industrial Revolution","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-bb_wbORPQv",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-bb_wbORPQv",name:"Iceland: Action Plan for Iceland in the Fourth Industrial Revolution",index:408,createdAt:"2024-05-29T02:14:30.887Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-bb_wbORPQv"},{values:{"Policy Name":"Iceland\u2019s AI Strategy","Policy creator":["Iceland"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This policy was marked as \u201Cforthcoming\u201D in 2021. Nothing seems to have benn added. Will check the separately-listed Action Plan. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26847","Series #":1,Title:"Iceland: Iceland\u2019s AI Strategy","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-LKY7zJDjLk",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-LKY7zJDjLk",name:"Iceland: Iceland\u2019s AI Strategy",index:97,createdAt:"2024-05-29T02:14:24.968Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-LKY7zJDjLk"},{values:{"Policy Name":"Mauririus AI Strategy","Policy creator":["Mauritius"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The relevant thing here is its summary of what other countries were doing in 2018 (it has a table of their AI strategies). I have saved this document elsewhere for that purpose. However, it says nothing about EdTech.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27393","Series #":1,Title:"Mauritius: Mauririus AI Strategy","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-NLfhoHrLUG",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-NLfhoHrLUG",name:"Mauritius: Mauririus AI Strategy",index:98,createdAt:"2024-05-29T02:09:41.891Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-NLfhoHrLUG"},{values:{"Policy Name":"Presidential Commission on Fourth Industrial Revolution","Policy creator":["South Africa"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a 2019 initiative outlining some vague intentions. It seems that South Africa is in the early stages of its AI journey, and that developing or deploying EdTech is not something that has happened yet. ",File:["42388gen209.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26873","Series #":1,Title:"South Africa: Presidential Commission on Fourth Industrial Revolution","Opportunity and risk orientation":"","Category of creator":["Non-OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-OwDQAylnHX",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-OwDQAylnHX",name:"South Africa: Presidential Commission on Fourth Industrial Revolution",index:99,createdAt:"2024-05-29T02:07:13.372Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-OwDQAylnHX"},{values:{"Policy Name":"Work of upcoming Swedish Digitalisation Strategy including AI","Policy creator":["Sweden"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Ah, finally: the document that explains what Sweden is doing? No. There is nothing listed on the OECD page, and no links. I found some stuff on screen use in school, quantum computing, etc\u2014but it\u2019s all very thin. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27681","Series #":8,Title:"Sweden: Work of upcoming Swedish Digitalisation Strategy including AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-VH4E1FQe9q",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-VH4E1FQe9q",name:"Sweden: Work of upcoming Swedish Digitalisation Strategy including AI",index:107,createdAt:"2024-05-29T02:00:56.498Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-VH4E1FQe9q"},{values:{"Policy Name":"Swedish National Digitalisation Council","Policy creator":["Sweden"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is very little information about what this renewed Digitalisation Council will do. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24976","Series #":7,Title:"Sweden: Swedish National Digitalisation Council","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-THGKTF6V2q",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-THGKTF6V2q",name:"Sweden: Swedish National Digitalisation Council",index:106,createdAt:"2024-05-29T01:58:29.685Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-THGKTF6V2q"},{values:{"Policy Name":"Strategy for Increased Access to Data","Policy creator":["Sweden"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is focused on data-sharing. Tenuous connection to AI in education. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27331","Series #":6,Title:"Sweden: Strategy for Increased Access to Data","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-dAqXybdHxM",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-dAqXybdHxM",name:"Sweden: Strategy for Increased Access to Data",index:105,createdAt:"2024-05-29T01:56:20.581Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-dAqXybdHxM"},{values:{"Policy Name":"Government Assignment on SMEs and Data as a Strategic Resource","Policy creator":["Sweden"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is about governments promoting SMEs\u2019 ability to use data as a strategic resource. Tenuous connection to AI in education. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26681","Series #":5,Title:"Sweden: Government Assignment on SMEs and Data as a Strategic Resource","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-lP_EK8nXFo",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-lP_EK8nXFo",name:"Sweden: Government Assignment on SMEs and Data as a Strategic Resource",index:104,createdAt:"2024-05-29T01:55:27.815Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-lP_EK8nXFo"},{values:{"Policy Name":"Digital Excellence","Policy creator":["Sweden"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This focuses on skill development for AI \u2014 with no special mention of using AI to do so \u2014 rather than EdTech. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26631","Series #":4,Title:"Sweden: Digital Excellence","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-9Kc_EArn6U",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-9Kc_EArn6U",name:"Sweden: Digital Excellence",index:103,createdAt:"2024-05-29T01:54:08.134Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-9Kc_EArn6U"},{values:{"Policy Name":"Big Data Analysis","Policy creator":["Sweden"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is about mapping \u2018big data analysis\u2019. Only very loosely relevant to AI in education. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26680","Series #":3,Title:"Sweden: Big Data Analysis","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-_80G-6Wl-r",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_80G-6Wl-r",name:"Sweden: Big Data Analysis",index:102,createdAt:"2024-05-29T01:52:14.502Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_80G-6Wl-r"},{values:{"Policy Name":"AI Commission","Policy creator":["Sweden"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This does not look especially relevant. The description is all about AI R&D and education for AI. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27679","Series #":2,Title:"Sweden: AI Commission","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-p2fHhiHy0W",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-p2fHhiHy0W",name:"Sweden: AI Commission",index:101,createdAt:"2024-05-29T01:51:18.865Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-p2fHhiHy0W"},{values:{"Policy Name":"National Approach to AI","Policy creator":["Sweden"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a very thin strategy that says nothing about EdTech. Note that it is quite old (2018) so perhaps before \u2018AI in everything\u2019 was all the rage. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24975","Series #":1,Title:"Sweden: National Approach to AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-7xCxRXGt99",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-7xCxRXGt99",name:"Sweden: National Approach to AI",index:100,createdAt:"2024-05-29T01:50:25.116Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-7xCxRXGt99"},{values:{"Policy Name":"Human-Centred AI for Human Resources","Policy creator":["Turkiye"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The policy initiative here was to produce guidance on AI in HR. Similar issues are raised in education (hiring, admissions, etc) so it is worth including this. Might need to add some new \u201CAI in education principles\u201D. Also note the \u201Ccreated from the Human-Centred Artificial Intelligence for Human Resources project.\u201D",File:["WEF_Human_Centred_AI_for_HR_2021.pdf"],"Year of Commencement or Creation":"2021","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Develops tools. It provides tools and place them in the hands of businesses or governments","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27318","Series #":10,Title:"Turkiye: Human-Centred AI for Human Resources","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CIn addition to being a target specifically for the regulation of AI, HR already operates in a highly regulated space. Most countries have numerous labour laws that would apply to AI-based HR tools. In some ways, this existing regulation may already be providing safeguards and even useful guidance. For instance, a number of countries already have anti-discrimination regulations on employment decisions and hiring tests, which include a recognition that such practices can have unintended discriminatory effects (known as adverse impact or indirect discrimination)\u201D (p 15)","General principles on AI":["Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "],"Draft Analysis Complete":!0,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!0,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-OX3xS8Y5MT",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-OX3xS8Y5MT",name:"Turkiye: Human-Centred AI for Human Resources",index:108,createdAt:"2024-05-29T01:42:21.376Z",updatedAt:"2024-06-05T21:37:17.815Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-OX3xS8Y5MT"},{values:{"Policy Name":"12th Development Plan","Policy creator":["Turkiye"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"I will need to update my DeepL account to translate this 253-page document. It likely provides the most authoritative statement of what Turkey is doing in this space. ",File:["On-Ikinci-Kalkinma-Plani_2024-2028_11122023.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27676","Series #":9,Title:"Turkiye: 12th Development Plan","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-y5uMqxZAKs",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-y5uMqxZAKs",name:"Turkiye: 12th Development Plan",index:113,createdAt:"2024-05-29T01:38:08.256Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-y5uMqxZAKs"},{values:{"Policy Name":"Medum Term Program (2024\u20142026)","Policy creator":["Turkiye"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is nothing in here about EdTech. Query whether references to it in the national strategy were long-term aspirations that never translated into action?",File:["Medium-Term-Program-2024-2026.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27677","Series #":8,Title:"Turkiye: Medum Term Program (2024\u20142026)","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-TZge-4Hhb3",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-TZge-4Hhb3",name:"Turkiye: Medum Term Program (2024\u20142026)",index:112,createdAt:"2024-05-29T01:34:56.156Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-TZge-4Hhb3"},{values:{"Policy Name":"The Digital Youth AI Ecosystem","Policy creator":["Turkiye"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This initiative was designed to provide a support network to students of AI. Not EdTech-focused. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27678","Series #":7,Title:"Turkiye: The Digital Youth AI Ecosystem","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-d5ZiOWQuzQ",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-d5ZiOWQuzQ",name:"Turkiye: The Digital Youth AI Ecosystem",index:111,createdAt:"2024-05-29T01:33:55.104Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-d5ZiOWQuzQ"},{values:{"Policy Name":"Priority Areas and the Upcoming Technology Roadmap in AI","Policy creator":["Turkiye"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is very little detail listed here, but no mention of EdTech/AI in education.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26202","Series #":6,Title:"Turkiye: Priority Areas and the Upcoming Technology Roadmap in AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-YxqXchd1hp",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-YxqXchd1hp",name:"Turkiye: Priority Areas and the Upcoming Technology Roadmap in AI",index:110,createdAt:"2024-05-29T01:17:40.477Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-YxqXchd1hp"},{values:{"Policy Name":"Eleventh Development Plan","Policy creator":["Turkiye"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This has been superseded by the 12th Development Plan.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26781","Series #":5,Title:"Turkiye: Eleventh Development Plan","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-UMzE9GTz-B",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-UMzE9GTz-B",name:"Turkiye: Eleventh Development Plan",index:109,createdAt:"2024-05-29T01:16:54.307Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-UMzE9GTz-B"},{values:{"Policy Name":"Digital Innovation Cooperation Platform","Policy creator":["Turkiye"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is very thin on details, regrettably; but there is no mention of EdTech in the material I can find. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"","Series #":4,Title:"Turkiye: Digital Innovation Cooperation Platform","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-qYSz4CYaiU",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-qYSz4CYaiU",name:"Turkiye: Digital Innovation Cooperation Platform",index:117,createdAt:"2024-05-29T01:12:40.068Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-qYSz4CYaiU"},{values:{"Policy Name":"Action Plan on Human Rights","Policy creator":["Turkiye"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is one page in this document (p 108) that I thought would be interesting. It is about the intersection between AI and human rights. However, the extent of the measure is just to consider a body to address the issue. If anything relevant came out of it, it would presumably have been included in Turkey\u2019s (very large) policy repository on the OECD. The only other AI principles concerned the use of AI in the judiciary. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27321","Series #":3,Title:"Turkiye: Action Plan on Human Rights","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-Cq4NjtGYP0",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Cq4NjtGYP0",name:"Turkiye: Action Plan on Human Rights",index:116,createdAt:"2024-05-29T01:09:05.211Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Cq4NjtGYP0"},{values:{"Policy Name":"2023 Industry and Technology Strategy","Policy creator":["Turkiye"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is very R&D-focused, and not written with EdTech in mind. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25608","Series #":2,Title:"Turkiye: 2023 Industry and Technology Strategy","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-lMMZHfB_0K",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-lMMZHfB_0K",name:"Turkiye: 2023 Industry and Technology Strategy",index:115,createdAt:"2024-05-29T01:07:06.806Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-lMMZHfB_0K"},{values:{"Policy Name":"National AI Strategy","Policy creator":["Turkiye"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Most of this strategy is about \u201CAI education\u201D, but there is an initiative in here about education technology.",File:["TRNationalAIStrategy2021-2025.pdf"],"Year of Commencement or Creation":"2021","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26590","Series #":1,Title:"Turkiye: National AI Strategy","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":`\u201CThe Education Technologies Incubation and Innovation Center will be implemented in 2021 by the Ministry of National Education, General Directorate of Innovation and Education Technologies, within the scope of the World Bank's \u201CSafe Schooling and Distance Education Project\u201D. The Center will operate in METU Technopolis and will work in cooperation with the public-private sector. Within the scope of the project, an innovation ecosystem in education will be developed, and through this ecosystem, new digital tools and pedagogical models will be developed and released, and blended education processes will be supported through the cooperation of various stakeholders. In this direction, working groups for AI education will be established, capacity building activities and R&D activities will be carried out for AI applications in education.\u201D (p 54)
The rest of the content is about teaching AI as a discipline (quite different to using AI to teach). 
This policy does not make it clear which principles will govern this specific EdTech initiative, so the broad principles expressed in this document will only be included below (under general principles). [CF my analysis of the Netherlands Strategy or the EU AI Act, where it is made clear that broad principles expressed extend to AI in education.]`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`Expressed generally, but not specifically in relation to EdTech:
\u201CThe implementation of AI technologies also raises privacy and national security concerns in many cases. In addition, the widespread use of AI-powered autonomous or semi-autonomous decision-making mechanisms raises ethical problems such as the protection of human rights and the prevention of discrimination. Therefore, building an effective AI ecosystem requires establishing an appropriate ethical and legal framework that takes into account the technological nature of AI\u201D (p 15)
\u201CThe OECD Council Recommendation on Artificial Intelligence, to which our country is also a party, was adopted on 22 May 2019 in order to strengthen the global AI policy ecosystem that respects human rights, democratic and ethical values.1 These principles, supported by the EU, were soon adopted by the G20 as well. The document also provides recommendations for international cooperation on trustworthy AI.\u201D
\u201CHuman dignity, human rights and fundamental freedoms must be essential throughout the lifecycle of AI systems. All AI technologies to be developed in our country should be designed in compliance with national ethical values and by prioritizing human rights, democratic values and the rule of law so that all members of society can benefit from such technologies. No human should be harmed physically, economically, socially, politically or psychologically at any stage in the lifecycle of AI systems. In interactions with AI systems throughout their lifecycle, people should never be objectified, their dignity should never be harmed, and human rights should never be violated or abused.\u201D (p 59)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`This strategy uses the language of \u201Cfairness\u201D. The concept is not specifically used in relation to AI in education, but generally:
\u201CFairness AI systems should be designed to provide an equal and fair service to all stakeholders while adhering to the rule of law and fundamental rights and freedoms. The fairness of AI systems means that the benefits of AI technology are shared at local, national and international levels, while taking into account the specific needs of different age groups, different cultural systems, different language groups, people with disabilities, and disadvantaged, marginalized and vulnerable segments of the society. It should be ensured that decisions made based on algorithms do not give rise to discriminatory or unfair effects on different demographic populations. In order to prevent the emergence of unintentional discrimination in decision-making processes, monitoring and accountability mechanisms should be developed and those mechanisms should be included in the implementation process.\u201D (p 60)`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Environmental wellbeing. The use of AI should not harm the environment. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":`\u201CAn impact analysis framework will be established to monitor and evaluate the level of implementation of AI values and principles\u201D (p 73)
On collaborative development and interoperability:
\u201CThe participation of different stakeholders throughout the lifecycle of AI systems is essential for inclusive and agile AI governance, the benefits of AI passing through society, and for AI to contribute to technological progress and development. Stakeholders of AI systems include public institutions, NGOs, international organizations, researchers, academia, media, educators, policy makers, the private sector, human rights institutions, and other bodies established for the youth and children. It is important to adopt open standards and interoperability to facilitate collaboration among AI stakeholders. Agile governance measures should be taken in line with technological developments and new sociotechnical needs.\u201D (p 61)
Procurement:
It makes reference to the WEF\u2019s Procurement toolkit:
\u201CThe WEF has developed and piloted common tools for governments to deliver AI solutions built with ethical principles in mind. The AI Procurement Toolkit for the Public and Private Sector prepared for this purpose includes concrete recommendations on purchasing, risk assessments, proposal drafting and evaluation.34 In addition, a toolkit for recruitment, performance evaluation and promotion is being developed with the contribution of public institutions and private sector organizations in our country in order to base the use of AI applications in human resources on human-centric and ethical values.\u201D  (p 31)
Later it expressly says:
\u201CThe commercialization of developed AI solutions will be supported by prioritizing them in public procurement.\u201D (p 69)
Could we infer that it recognises the normative influence procurement exerts? Or is it simply saying that it will support R&D here, and not delving into ethics? I have assumed the latter. `,"WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"One of the more progressive strategies I have seen. Have these ideals been realised in practice?","Record Entered By":""},id:"i-JGZxJmkxIv",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-JGZxJmkxIv",name:"Turkiye: National AI Strategy",index:114,createdAt:"2024-05-29T00:58:49.546Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-JGZxJmkxIv"},{values:{"Policy Name":"AI Strategy","Policy creator":["Lithuania"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is a generally relevant collection of policies from p 8, but all of the education-related content concerns preparing people for a life with AI \u2014 education for AI \u2014 rather than AI in education. Including this on the basis of the broadly applicable principles. ",File:["Lithuania_Artificial_Intelligence_Strategy_2019.pdf"],"Year of Commencement or Creation":"2019","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Plans further action. It sets out a strategy on AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24220","Series #":1,Title:"Lithuania: AI Strategy","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"All of the education-related content concerns preparing people for a life with AI \u2014 education for AI \u2014 rather than AI in education.","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":`\u201CTo ensure that we stay on the right track, a human-centric approach to AI is needed. Trustworthy AI has two components: (1) ethical purpose - it should respect fundamental rights, applicable regulation and core principles and values and (2) it should be technically robust and reliable since, even with good intentions, a lack of technological mastery can cause unintentional harm.\u201D (p 8)

\u201CPrinciple 1: To advice the public sector on ethical AI regulation and implementation. Mechanism: Establish AI ethics committee that reviews impact of technology on fundamental rights.\u201D (p 8)`,"Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Interoperability. AI systems should be able to work with other systems. ","R&D. Sufficient resources should be invested in AI R&D.","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Opportunity. The opportunities of AI should be harnessed."],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!0,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-4u9qJ87NTG",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-4u9qJ87NTG",name:"Lithuania: AI Strategy",index:118,createdAt:"2024-05-29T00:52:23.424Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-4u9qJ87NTG"},{values:{"Policy Name":"Action Plan for the Digital Transformation of Slovakia","Policy creator":["Slovakia"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This makes reference to support for AI-based tools in education, and \u2014 more generally \u2014 using \u201Cdigital technologies for innovations and improvement of the quality of education\u201D (p 21)",File:["AP-DT-English-Version-FINAL.pdf"],"Year of Commencement or Creation":"2019","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25880","Series #":1,Title:"Slovakia: Action Plan for the Digital Transformation of Slovakia","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":`Opportunity
\u201Cwe will support the use of digital technologies in order to increase the success of the process of education\u201D (p 20)
\u201CWe will support innovation capacity and introduction of solutions built on artificial intelligence, in particular, at the level of SMEs. Therefore, we will set up a network of digital innovation centres and improve possibilities of cooperation with the academic sector in applied research in the field of artificial intelligence, which is significantly based on source data. At the same time, we will support new business models in the digital economy, in order to make conditions in Slovakia for the rise of platforms transforming standard sectors, such as transport, finance, health care and education. It means setting up \u201Cregulatory sandboxes\u201D, introducing \u201Cfuture-proof regulations\u201D and redesigning permits for the needs of the digital era.\u201D (p 32)
\u201CSupport increasing higher and specialised skills for IoT, data science, artificial intelligence, programming, for the needs of STEM studies (science, technology, engineering and mathematics), team work and collaborative and co-creative procedures, creative designing and trading as well as other fields of economy and public administration due to their digital transformation,\u201D (p 27)
Do not consider education holistically \u2014 no reference to privacy risks specifically in education, for instance. 
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":`Two key references:
\u201CThe intent of the Action Plan also encompasses building trust of persons using digital technologies, ensuring protection of shared data and setting conditions for creating responsible and adequate process of digital transformation. Specific attention in implementation of proposed measures of this Action Plan will be paid to protection of fundamental rights and freedoms of natural persons, in particular right to privacy in connection to personal data processing and compliance with requirements put on personal data protection in relevant European3 as well as national legislation4 .\u201D (p 16)
\u201CIt is necessary to make sure that selected methods are reliable, they are primarily not intended for activities aimed at damaging humans, their rights and freedoms,\u201D (p 65)`,"Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`It speaks about:
\u201CFair access to technologies for all groups of population (justice, non-discrimination)\u201D (p 65)`,"General principles on AI":["Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (explainability). AI systems should be sufficiently explainable.","R&D. Sufficient resources should be invested in AI R&D.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Human rights-centred. AI systems should be compatible with human rights. ","Opportunity. The opportunities of AI should be harnessed.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":`\u201CPrinciple of not causing harm \u2013 to assets, health, social status, etc.,\u201D (p 65)
\u201CTransparency and controllability of system using AI, comprehensibility of basic principles of functioning for the general public (application of the informed consent principle),\u201D (p 65)
Impact assessment:
The intent of the Action Plan also encompasses building trust of persons using digital technologies, ensuring protection of shared data and setting conditions for creating responsible and adequate process of digital transformation. Specific attention in implementation of proposed measures of this Action Plan will be paid to protection of fundamental rights and freedoms of natural persons, in particular right to privacy in connection to personal data processing and compliance with requirements put on personal data protection in relevant European3 as well as national legislation4 . Before the process of implementation of those measures referred to in this Action Plan, when personal data is processed (in particular setting up and deployment of new information systems and technologies), the data protection impact assessment will be made in the sense of Art. 35 of the General Data Protection Regulation and prior consultation with the supervisory authority will be used in the sense of Art. 36 of the General Data Protection Regulation prior to the data processing, if the data protection impact assessment implies that such processing could lead to high risk unless the controller adopts measures to mitigate the risk. (p 16-17)
(This is a narrow impact assessment)`,"WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-Jzg5JOd1pY",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Jzg5JOd1pY",name:"Slovakia: Action Plan for the Digital Transformation of Slovakia",index:119,createdAt:"2024-05-29T00:39:04.985Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Jzg5JOd1pY"},{values:{"Policy Name":"Greek National Strategy for AI","Policy creator":["Greece"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This strategy is (1) Greek, and (2) 400 pages, so unable to be translated with my DeepL subscription. I am going to have to upgrade it later. 
Given what Greece has said in its (newer) GenAI strategy, this is not a super high-priority document to review, but it would be worth taking a look at it.  `,File:["digital_strategy.pdf"],"Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26788","Series #":2,Title:"Greece: Greek National Strategy for AI","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"Translation Needed","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"Pending translation",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-Gzw5TXyORw",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Gzw5TXyORw",name:"Greece: Greek National Strategy for AI",index:120,createdAt:"2024-05-28T23:29:30.202Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Gzw5TXyORw"},{values:{"Policy Name":"Generative AI Greece 20230 \u201CFuture of Generative AI in Greece\u201D","Policy creator":["Greece"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This report is interesting and bold. It recognises that autonomous education applications could be hugely significant. This is definitely worth coming back to.",File:["Gen_AI_Greece_EN_s.pdf"],"Year of Commencement or Creation":"2023","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary","Vocational or Professional"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Seeks information. It gathers inputs on public sentiment about AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Educates. It helps officials or others understand the opportunities and risks of AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27603","Series #":1,Title:"Greece: Generative AI Greece 20230 \u201CFuture of Generative AI in Greece\u201D","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":`Opportunity:
\u201CFocusing even at the classroom level, NLP has the potential to enhance the educational process in various ways. At the international level, in a recent report by the IE University Center for Governance1, in the section concerning education, among the scenarios discussed regarding the future of the educational process with the introduction of NLP, a scenario emerged with a significant margin, suggesting the existence of potential (virtual) classrooms where an AI tutor facilitator will play a significant role, while NLP will be utilized to facilitate the creation of potential virtual experiences outside the classroom environment, thus making the educational process more empirical in this specific sense. It is within its technological capabilities for NLP to operate as an assistant to teachers in the classroom, offering students a better understanding of subjects by creating notes, reports, diagrams, and lesson summaries. According to the estimation of Konstantinos Karpouzis, Associate Professor at the Department of Communication, Media and Culture of the Panteion University, "the integration of NLP into the educational system through the production of personalized content, descriptive assessment, and the use of its tools for the education of students and teachers in new technologies" is one of the greatest opportunities.\u201D (p 45)
This is interesting too \u2014 lifelong learning:
\u201CAn opportunity for the Greek reality could also be the enhancement of lifelong learning and adult education in general. One of the main benefits of NLP in lifelong learning is its ability to provide personalized educational experiences. Traditional education usually follows a "one size fits all" model, where students are expected to learn at the same pace and in the same way, which is incompatible with adult learners who have unique needs and learning preferences. NLP can analyze large amounts of data on the strengths, weaknesses, and learning styles of a student to create a personalized learning plan.\u201D (p 45)

Note that principles concerned with risks are not addressed at this lower level of abstraction (education-specific) \u2014 see below. `,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":`\u201CThrough the establishment of proactive monitoring and control mechanisms, systematic and effective monitoring of the implementation of ethical guidelines and legislation will be feasible, ensuring that AI is used in a way that respects human rights and the demand for individual and social well-being. Overall, this approach concerns the preparedness of Greek society for the development of AI in a just and sustainable manner, while promoting innovation and growth in this sector. It also involves strengthening the necessary "institutional triangle" between digital governance, digital regulation, and digital ethics\u201D (p 105)
\u201CThere is a need to provide a framework of broader universal political guidelines and standards for developers and AI users to ensure that their systems are designed and used ethically. This includes principles such as transparency, justice, and the protection of privacy and human rights.\u201D (p 27)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`Increasing equality
\u201CFurthermore, NLP capabilities can be particularly beneficial in special education, where it can be tailored to students' specific difficulties, creating real-time lessons tailored to their individual needs108. 109 Additionally, natural language learning and teaching systems can assess students' levels of knowledge, identify gaps in their understanding, and then address them through personalized learning materials and explanations.\u201D (p 45)
\u201CThe guidelines should reflect both societal values and general ethical principles, promoting excellence and safety, transparency and innovation, human benefit, and the fight against digital (or algorithmic) social discrimination and inequalities, as well as human control.\u201D (p 104)
Augmenting inequality
\u201CThe tendency of AI systems to perpetuate or even exacerbate existing biases, prejudices, and inequalities poses a significant ethical challenge.\u201D (p 82)`,"General principles on AI":["Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Bias testing. AI systems should be tested for bias. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","R&D. Sufficient resources should be invested in AI R&D.","Opportunity. The opportunities of AI should be harnessed.","Interoperability. AI systems should be able to work with other systems. ","Human rights-centred. AI systems should be compatible with human rights. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":`Note that these are framed as \u201Crisks\u201D rather than principles, but there are implicit normative ideas within the text. 

Cyber security:
They speak of \u2018adversarial attacks\u2019
AI models may be susceptible to adversarial attacks. Adversarial attacks are deliberate modifications to input data that attempt to compromise the performance of an AI model, and this can also affect AI models. Adversarial attacks can have unintended consequences, such as compromising image creation in an AI model by adding small modifications to input data, thus leading to undesirable outputs (such as misleading images or images containing unwanted information, e.g., reproduction of stereotypes, etc.) (p 65)`,"WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":'Before delving into specific possibilities of future application, it may be worth mentioning that in recent years there have already been examples of utilizing the capabilities of NLP and AI in the digital educational industry through metrics linking it to qualifications certification and the job market. The intersection of work capabilities and educational skills is now emerging as a privileged investment field98. It is worth noting that in the international educational industry, the development of platform economy models has favored an algorithmically oriented "demand-driven education," competency-based education, using NLP to develop predictive talent analytics, to match students and graduates with potential career paths through matching tools. This technological capability is offered to them to integrate into the constantly evolving job market (between learning and earning). Based on mass-collected data from educational platforms, from reports on the completion of digital asynchronous educational programs and skills certification tests, the goal pursued is now to shape some algorithmic matching models of successful course completion cycles with professional performance indicators in the job market. (p 42)',"Other Points of Interest":"","Record Entered By":""},id:"i-JhOfOAT4Ya",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-JhOfOAT4Ya",name:"Greece: Generative AI Greece 20230 \u201CFuture of Generative AI in Greece\u201D",index:121,createdAt:"2024-05-28T23:25:29.038Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-JhOfOAT4Ya"},{values:{"Policy Name":"Policy for the Development of Artificial Intelligence in Poland from 2020","Policy creator":["Poland"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a super interesting policy. Poland is proud of its PISA results and sees AI as being an essential tool for \u201Cboosting\u201D its strong position. The fourth pillar of its strategy is titled AI and Education (see p 42). Bold vision expressed \u2014 worth analysing further. ",File:["Poland_Policy_for_Artificial_Intelligence_Development_in_Poland_from_2020_2020.pdf"],"Year of Commencement or Creation":"2020","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Trust. Organisations seeking to incorporate AI into educational settings must build trust.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24268","Series #":1,Title:"Poland: Policy for the Development of Artificial Intelligence in Poland from 2020","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":`Opportunities
\u201CThe issues of AI-related skill development and the use of AI-based tools in educational processes are the key issues of the Integrated Skills Strategy 2030 in Poland, which is currently undergoing development.\u201D (p 23)
\u201Censuring high availability of educational tools in Poland, including online tools, enabling all people who want to get educated in the field of AI to gain knowledge, both theoretical and practical.\u201D (p 42)
Teacher training:
\u201Cintensification of the use of tools and embedded systems in education, accompanied with training for teachers in their proper use in the teaching process;\u201D (p 43)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201CAnalysis of the ethical ramifications of AI implementation and the impact of AI systems on the sphere of human rights\u201D (p 25)
\u201Cassessing the societal impact of AI-based systems (in particular the impact on human rights and freedoms) and developing methods for their independent auditing, according a predefined manner and scope;\u201D (p 25)
\u201CPoland\u2019s continued activity in the Council of Europe in the initiative to develop recommendations for AI with regard to the protection of human rights, the rule of law and democracy.\u201D (p 25)
\u201Cinternational activities that will support the promotion of Polish business in the field of AI and the development of AI technologies that respect human dignity and fundamental human rights, in accordance with EU and OECD standards, as well as digital diplomacy activities in the area of policies or regulations concerning artificial intelligence\u201D (p 6)
Additional material on fundamental rights (see, eg, p 23)`,"Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`Fairness
\u201Cdiversity, non-discrimination and fairness\u201D (p 63)
Equality
\u201CArtificial intelligence is redefining many professions due to process optimisation and automation, and as a result machines replace humans in doing standard and repeatable tasks on an unprecedented scale. This risks aggravating problems in socially and economically excluded regions, increasing unemployment, as well as exacerbating various forms of inequality and discrimination.\u201D`,"General principles on AI":["Trust. AI systems should not be used so as to undermine society\u2019s trust. ","R&D. Sufficient resources should be invested in AI R&D.","Human rights-centred. AI systems should be compatible with human rights. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Transparency (explainability). AI systems should be sufficiently explainable.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Environmental wellbeing. The use of AI should not harm the environment. ","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Bias testing. AI systems should be tested for bias. ","Interoperability. AI systems should be able to work with other systems. ","Opportunity. The opportunities of AI should be harnessed.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,"],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"Note Poland\u2019s aspiration: \u201CPoland is the European leader in education in AI and other digital technologies at secondary school level\u201D (p 45)","Record Entered By":""},id:"i-z5-nxrhEvU",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-z5-nxrhEvU",name:"Poland: Policy for the Development of Artificial Intelligence in Poland from 2020",index:122,createdAt:"2024-05-28T23:21:18.902Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-z5-nxrhEvU"},{values:{"Policy Name":"Spaceresources.lu","Policy creator":["Luxembourg"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Not relevant at all \u2014 about space companies.",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-1335","Series #":3,Title:"Luxembourg: Spaceresources.lu","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-tZvURqdj0L",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-tZvURqdj0L",name:"Luxembourg: Spaceresources.lu",index:125,createdAt:"2024-05-28T23:18:35.944Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-tZvURqdj0L"},{values:{"Policy Name":"Digital Luxembourg","Policy creator":["Luxembourg"],"Relevant?":"No",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is an old, low-investment initiative that is not at all education-centred. ",File:"","Year of Commencement or Creation":"","Relevance Type":"","What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":"","Governance practices employed":"","Analysis Complete":!1,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-1337","Series #":2,Title:"Luxembourg: Digital Luxembourg","Opportunity and risk orientation":"","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":"","Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-vHzm5pUBfk",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-vHzm5pUBfk",name:"Luxembourg: Digital Luxembourg",index:124,createdAt:"2024-05-28T23:17:50.943Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-vHzm5pUBfk"},{values:{"Policy Name":"AI: A Strategic Vision for Luxembourg","Policy creator":["Luxembourg"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Very little is said about education, but what is said is about the promise of EdTech: \u201CIn the domain of education, AI could help in defining and generating personalized teaching/learning methods and tools, especially in the field of differentiated education.\u201D Worth noting. ",File:["AI_EN_0.pdf"],"Year of Commencement or Creation":"2019","Relevance Type":["Policy makes fleeting reference to AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24335","Series #":1,Title:"Luxembourg: AI: A Strategic Vision for Luxembourg","Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity","Category of creator":["OECD"],"Translation Comments":"","Key quotes on AI in education principles":`\u201CWhile AI is not radically new, especially for Luxembourg\u2019s researchers, it is on the threshold of being accessible and applicable across industries and throughout society: digital health, finance, mobility, logistics, clean technologies, space and beyond \u2013 not to mention education, environment and art\u201D (p 8)
\u201CIn the domain of education, AI could help in defining and generating personalized teaching/learning methods and tools, especially in the field of differentiated education\u201D (p 14)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":"\u201CAs a diverse, innovative nation, we will decide what impact this technology will have on human rights, on people\u2019s lives and on our democratic values.\u201D (p 4)","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "],"Draft Analysis Complete":!1,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!1,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-5t3qlI4mpu",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-5t3qlI4mpu",name:"Luxembourg: AI: A Strategic Vision for Luxembourg",index:123,createdAt:"2024-05-28T23:15:53.248Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-5t3qlI4mpu"},{values:{"Policy Name":"Guidelines on AI","Policy creator":["Switzerland"],"Relevant?":"Yes",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a pretty standard AI framework. Included in case of interest. Could be applied to AI in education. ",File:["_Artificial Intelligence_ \u2013 Adoption of Guidelines for the Federal Government.pdf"],"Year of Commencement or Creation":"2020","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Analysis Complete":!0,"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26987","Series #":5,Title:"Switzerland: Guidelines on AI","Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)","Category of creator":["OECD"],"Translation Comments":"N/A - English","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"\u201CPut people at the centre: The dignity and well-being of every individual, as well as the public interest, must be at the forefront of the development and use of AI systems. Particular attention is paid to the protection of fundamental rights in the use of AI.\u201D (p 1)","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Human rights-centred. AI systems should be compatible with human rights. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. "],"Draft Analysis Complete":!0,'Reasons for non-inclusion (other than "Irrelevant")':"",Weekend:!0,"Key quotes on general AI principles":"","WC Favourite":!1,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"","Record Entered By":""},id:"i-ptJWDz_6mV",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ptJWDz_6mV",name:"Switzerland: Guidelines on AI",index:130,createdAt:"2024-05-28T23:11:48.516Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ptJWDz_6mV"}]};var Uu={columns:[{id:"c-L3R0H6xpKL",type:"column",name:"Category of creator",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-L3R0H6xpKL",calculated:!0,format:{type:"select",isArray:!1},formula:"[Policy creator].[OECD?].ListCombine()"},{id:"c-JILGl3j9sD",type:"column",name:"Policy creator",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-JILGl3j9sD",format:{table:{id:"grid-2iQy6VFcq_",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-2iQy6VFcq_",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-2iQy6VFcq_",name:"Jurisdictions"},type:"lookup",isArray:!0}},{id:"c-5WWbiBHe9B",type:"column",name:"Policy Name",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-5WWbiBHe9B",format:{type:"text",isArray:!1}},{id:"c-FlyVKlvCIx",type:"column",name:"Year of Commencement or Creation",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-FlyVKlvCIx",format:{type:"text",isArray:!1}},{id:"c-iohuaEflSp",type:"column",name:'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table',href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-iohuaEflSp",format:{type:"text",isArray:!1}},{id:"c-2pT34POxIT",type:"column",name:"Relevance Type",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-2pT34POxIT",format:{table:{id:"grid-1ohiEKjQFc",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-1ohiEKjQFc",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-1ohiEKjQFc",name:"Nature of relevance"},type:"lookup",isArray:!0}},{id:"c-fJvB8zmh-Y",type:"column",name:"What kinds of education, if any, are contemplated by the policy?",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-fJvB8zmh-Y",format:{table:{id:"grid-0_3yg-Vkoy",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-0_3yg-Vkoy",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-0_3yg-Vkoy",name:"Which kind of education does it expressly mention?"},type:"lookup",isArray:!0}},{id:"c-zdfmo_m_Tj",type:"column",name:"Principles on AI in education",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-zdfmo_m_Tj",format:{table:{id:"grid-zXkG0jBLna",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-zXkG0jBLna",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-zXkG0jBLna",name:"AI in education principles"},type:"lookup",isArray:!0}},{id:"c-5VlrDV5zWa",type:"column",name:"Governance practices employed",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-5VlrDV5zWa",format:{table:{id:"grid-Xr9iAFDRZl",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-Xr9iAFDRZl",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-Xr9iAFDRZl",name:"Type of policy initaitive"},type:"lookup",isArray:!0}},{id:"c-zAp89itebl",type:"column",name:"Opportunity and risk orientation",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-zAp89itebl",format:{table:{id:"grid-P_wv2uo4M6",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-P_wv2uo4M6",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-P_wv2uo4M6",name:"Considering both opportunities and risks?"},type:"lookup",isArray:!1}},{id:"c-84Ex4h0pTV",type:"column",name:"File",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-84Ex4h0pTV",format:{type:"attachments",isArray:!0}},{id:"c-wPHcwhpe1X",type:"column",name:"Key quotes on AI in education principles",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-wPHcwhpe1X",format:{type:"canvas",isArray:!1}},{id:"c-5hHdZ0sfu8",type:"column",name:"Does the policy reflect the principle of human rights compatibility?",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-5hHdZ0sfu8",format:{table:{id:"grid-qlBRzb18gd",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-qlBRzb18gd",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-qlBRzb18gd",name:"Does it make reference to human, fundamental, or inalienable rights?"},type:"lookup",isArray:!1}},{id:"c-Y854zWDfFY",type:"column",name:"Key quote on human rights",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-Y854zWDfFY",format:{type:"text",isArray:!1}},{id:"c-LxM7tcl6OJ",type:"column",name:"Does the policy reflect the principle of equity/equality?",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-LxM7tcl6OJ",format:{table:{id:"grid-OWGRQYLMAA",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-OWGRQYLMAA",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-OWGRQYLMAA",name:"Does it make reference to equity?"},type:"lookup",isArray:!1}},{id:"c-U0fCdFgXTA",type:"column",name:"Key quote on equity/equality",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-U0fCdFgXTA",format:{type:"text",isArray:!1}},{id:"c-tQrodNzumD",type:"column",name:"General principles on AI",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-tQrodNzumD",format:{table:{id:"grid-Jef7egIzgb",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-Jef7egIzgb",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-Jef7egIzgb",name:"General AI principles"},type:"lookup",isArray:!0}},{id:"c-Nq_phIQjPG",type:"column",name:"Link (OECD or Other)",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-Nq_phIQjPG",format:{display:"iconOnly",type:"link",isArray:!1}},{id:"c-r-XaOjk8Lk",type:"column",name:"Analysis Complete",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-r-XaOjk8Lk",format:{displayType:"check",type:"checkbox",isArray:!1}},{id:"c-81BAzxH2C6",type:"column",name:"Draft Analysis Complete",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-81BAzxH2C6",format:{displayType:"check",type:"checkbox",isArray:!1}},{id:"c-lgXRPxQGDm",type:"column",name:"Key quotes on general AI principles",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-lgXRPxQGDm",format:{type:"canvas",isArray:!1}},{id:"c-OgsmPhUiK0",type:"column",name:"Notable Case Studes - Examples of AI in Education",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-OgsmPhUiK0",format:{type:"canvas",isArray:!1}},{id:"c-O2MdT9sMx2",type:"column",name:"Other Points of Interest",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-O2MdT9sMx2",format:{type:"canvas",isArray:!1}},{id:"c-erzTbcFItg",type:"column",name:'Reasons for non-inclusion (other than "Irrelevant")',href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-erzTbcFItg",format:{type:"select",isArray:!1}},{id:"c-LT8GCmk4tr",type:"column",name:"Record Entered By",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-LT8GCmk4tr",format:{table:{id:"grid-vq4WMZ5Lm7",type:"table",tableType:"table",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-vq4WMZ5Lm7",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tugrid-vq4WMZ5Lm7",name:"Record Entered By"},type:"lookup",isArray:!0}},{id:"c-V85VzcYUCM",type:"column",name:"Relevant?",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-V85VzcYUCM",format:{type:"select",isArray:!1}},{id:"c-gdxdwF0OOx",type:"column",name:"Series #",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-gdxdwF0OOx",format:{precision:22,useThousandsSeparator:!0,type:"number",isArray:!1}},{id:"c-Sm3wWbxOJ2",type:"column",name:"Title",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-Sm3wWbxOJ2",display:!0,calculated:!0,format:{type:"text",isArray:!1},formula:'Concatenate([Policy creator],": ",[Policy Name])'},{id:"c-9Qm-26QJsu",type:"column",name:"Translation Comments",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-9Qm-26QJsu",format:{type:"select",isArray:!1}}],rows:[{values:{"Category of creator":["OECD"],"Policy creator":["South Korea"],"Policy Name":"Framework Act on Artificial Intelligence Development and Establishment of a Foundation for Trustworthiness ","Year of Commencement or Creation":"2025",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"A general framework regulates high-impact AI including education","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Binds. It creates binding obligations in relation to AI","Proposes law. It proposes a law or provides a draft law on AI","Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)","Tracks. It sets out to boost understanding specifically of where and how AI is being used","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["\u110B\u1175\u11AB\u1100\u1169\u11BC\u110C\u1175\u1102\u1173\u11BC \u1107\u1161\u11AF\u110C\u1165\u11AB\u1100\u116A \u1109\u1175\u11AB\u1105\u116C \u1100\u1175\u1107\u1161\u11AB \u110C\u1169\u1109\u1165\u11BC \u1103\u1173\u11BC\u110B\u1166 \u1100\u116A\u11AB\u1112\u1161\u11AB \u1100\u1175\u1107\u1169\u11AB\u1107\u1165\u11B8(\u1107\u1165\u11B8\u1105\u1172\u11AF)(\u110C\u116620676\u1112\u1169)(20260122) ENGLISH.pdf","\u110B\u1175\u11AB\u1100\u1169\u11BC\u110C\u1175\u1102\u1173\u11BC \u1107\u1161\u11AF\u110C\u1165\u11AB\u1100\u116A \u1109\u1175\u11AB\u1105\u116C \u1100\u1175\u1107\u1161\u11AB \u110C\u1169\u1109\u1165\u11BC \u1103\u1173\u11BC\u110B\u1166 \u1100\u116A\u11AB\u1112\u1161\u11AB \u1100\u1175\u1107\u1169\u11AB\u1107\u1165\u11B8(\u1107\u1165\u11B8\u1105\u1172\u11AF)(\u110C\u116620676\u1112\u1169)(20260122).pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","R&D. Sufficient resources should be invested in AI R&D.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress."],"Link (OECD or Other)":"https://www.law.go.kr/%25EB%25B2%2595%25EB%25A0%25B9/%25EC%259D%25B8%25EA%25B3%25B5%25EC%25A7%2580%25EB%258A%25A5%2520%25EB%25B0%259C%25EC%25A0%2584%25EA%25B3%25BC%2520%25EC%258B%25A0%25EB%25A2%25B0%2520%25EA%25B8%25B0%25EB%25B0%2598%2520%25EC%25A1%25B0%25EC%2584%25B1%2520%25EB%2593%25B1%25EC%2597%2590%2520%25EA%25B4%2580%25ED%2595%259C%2520%25EA%25B8%25B0%25EB%25B3%25B8%25EB%25B2%2595/(20676,20250121)","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"South Korea: Framework Act on Artificial Intelligence Development and Establishment of a Foundation for Trustworthiness ","Translation Comments":"Translation Completed (DeepL)"},id:"i-6vjnfILLDk",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-6vjnfILLDk",name:"South Korea: Framework Act on Artificial Intelligence Development and Establishment of a Foundation for Trustworthiness ",index:494,createdAt:"2025-04-30T01:49:31.178Z",updatedAt:"2025-04-30T06:34:32.834Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-6vjnfILLDk"},{values:{"Category of creator":["OECD"],"Policy creator":["United Kingdom"],"Policy Name":"A pro-innovation approach  to AI regulation","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"A general regulation approach but can inform education","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Guides impact assessment. It helps officials anticipate or evaluate the impact of AI","Plans further action. It sets out a strategy on AI","Tracks. It sets out to boost understanding specifically of where and how AI is being used","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["a-pro-innovation-approach-to-ai-regulation-amended-web-ready.pdf"],"Key quotes on AI in education principles":`We anticipate that regulators will need to:

1. Interpret and articulate \u2018fairness\u2019 as relevant to their sector or domain,

2. Decide in which contexts and specific instances fairness is important and relevant (which it may not always be).

3. Design, implement and enforce appropriate governance requirements for \u2018fairness\u2019 as applicable to the entities that they regulate.

4. Where a decision involving use of an AI system has a legal or similarly significant effect on an individual, regulators will need to consider the suitability of requiring AI system operators to provide an appropriate justification for that decision to affected parties.

5. AI systems should comply with regulatory requirements relating to vulnerability of individuals within specific regulatory domains. Regulators will need to consider how use of AI systems may alter individuals\u2019 vulnerability, pursuant to their existing powers and remits.

6. Consider the role of available technical standards addressing AI fairness, bias mitigation and ethical considerations (for example, ISO/IEC\xA0TR 24027:2021, ISO/IEC\xA012791*, ISO/IEC\xA0TR 24368:2022) to clarify regulatory guidance and support the implementation of risk treatment measures.`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":"","General principles on AI":["Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (explainability). AI systems should be sufficiently explainable.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Interoperability. AI systems should be able to work with other systems. ","Inclusive development. AI systems should be developed inclusively. "],"Link (OECD or Other)":"https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"United Kingdom: A pro-innovation approach  to AI regulation","Translation Comments":"N/A - English"},id:"i-mVcrtMCV1l",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-mVcrtMCV1l",name:"United Kingdom: A pro-innovation approach  to AI regulation",index:493,createdAt:"2025-04-30T01:12:12.328Z",updatedAt:"2025-04-30T01:33:26.550Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-mVcrtMCV1l"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Mauritius"],"Policy Name":"The National Artificial Intelligence Strategy of Mauritania for 2025\u20132029","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The strategy includes AI in education sector","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI","Educates. It helps officials or others understand the opportunities and risks of AI","Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)","Communicates a stance. It expresses a hope for the future of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["The National Artificial Intelligence Strategy of Mauritania for 2025\u20132029.pdf"],"Key quotes on AI in education principles":"This strategy will integrate artificial intelligence technologies into the field of education through projects aimed at serving all stakeholders in the educational system. one the one hand , these projects will be used to enhance student learning by providing interactive tools and programs specifically designed to meet their needs, thereby boosting their academic success. On the other hand, teachers will benefit from these projects by creating innovative educational content, analyzing student performance, and tailoring instruction based on each student's individual progress.  At the institutional level, these projects will assist educational institutions in improving resource management, curriculum planning, and decision-making based on accurate data and in-depth analyses.  Additionally, this strategy includes a project for translating various national dialects, which aims to enhance social cohesion by facilitating linguistic communication and access to knowledge resources in the different dialects used in the country.","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Respect for laws [NEW]. AI should respect existing law.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,"],"Link (OECD or Other)":"https://mtnima.gov.mr/wp-content/uploads/2024/07/strategie-EN-Final-26-07-2024-.pdf","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"This strategic priority focuses on ensure that the development and utilization of artificial intelligence complies with stringent ethical and legal standards. These standards encompass safeguarding personal data, ensuring data protection and privacy, respecting intellectual property rights, and adhering to pertinent regulations. Our commitment to upholding the ethical standards of the Arab League, the African Union and the United Nations is integral to accomplishing this strategy.","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"Mauritius: The National Artificial Intelligence Strategy of Mauritania for 2025\u20132029","Translation Comments":"N/A - English"},id:"i-0SqFdnPRIL",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-0SqFdnPRIL",name:"Mauritius: The National Artificial Intelligence Strategy of Mauritania for 2025\u20132029",index:492,createdAt:"2025-04-30T00:52:07.857Z",updatedAt:"2025-04-30T01:08:56.524Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-0SqFdnPRIL"},{values:{"Category of creator":["OECD"],"Policy creator":["United States"],"Policy Name":"Driving U.S. Innovation in Artificial Intelligence: A Roadmap for Artificial Intelligence Policy in the United States Senate","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"A comprehensive framework aimed at addressing the multifaceted opportunities and risks presented by artificial intelligence (\u201CAI\u201D) technologies could inform the governance of AI in education","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Plans further action. It sets out a strategy on AI","Proposes law. It proposes a law or provides a draft law on AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["Driving U.S. Innovation in Artificial Intelligence A Roadmap for Artificial Intelligence Policy in.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Transparency (explainability). AI systems should be sufficiently explainable.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Opportunity. The opportunities of AI should be harnessed.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","R&D. Sufficient resources should be invested in AI R&D.","Respect for laws [NEW]. AI should respect existing law.","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"United States: Driving U.S. Innovation in Artificial Intelligence: A Roadmap for Artificial Intelligence Policy in the United States Senate","Translation Comments":"N/A - English"},id:"i-j33OQcVixo",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-j33OQcVixo",name:"United States: Driving U.S. Innovation in Artificial Intelligence: A Roadmap for Artificial Intelligence Policy in the United States Senate",index:491,createdAt:"2025-04-30T00:26:12.572Z",updatedAt:"2025-04-30T00:50:46.186Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-j33OQcVixo"},{values:{"Category of creator":[""],"Policy creator":["Sri Lanka"],"Policy Name":"Sri Lanka's National Strategy on AI","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Mentions education as a high-impact area and a key governance domain","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Plans further action. It sets out a strategy on AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Educates. It helps officials or others understand the opportunities and risks of AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["National AI strategy for Sri Lanka.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"Human-centricity: AI systems should respect human-centred values and pursue benefits for society, including health, well-being, relationships, personhood, and individual dignity. They should not be used for malicious purposes or to sway or deceive users into making harmful decisions.","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":"Fairness and Equity: AI systems should be designed and implemented with fairness in mind, minimizing bias and discrimination to ensure equitable treatment for all individuals. They must not undermine legal rights, discriminate unfairly, or create unfair market outcomes.","General principles on AI":["Augmentation, not replacement. AI systems should augment, not displace, workers.","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Human rights-centred. AI systems should be compatible with human rights. ","Environmental wellbeing. The use of AI should not harm the environment. ","Transparency (explainability). AI systems should be sufficiently explainable.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power.","Freedom of speech and assembly [NEW]. AI systems should not abrogate freedom of speech or assembly. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Respect for laws [NEW]. AI should respect existing law.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. "],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"Sri Lanka: Sri Lanka's National Strategy on AI","Translation Comments":""},id:"i-wycemXJq9G",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-wycemXJq9G",name:"Sri Lanka: Sri Lanka's National Strategy on AI",index:490,createdAt:"2025-04-29T08:07:44.766Z",updatedAt:"2025-04-29T08:30:26.654Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-wycemXJq9G"},{values:{"Category of creator":["OECD"],"Policy creator":["Spain"],"Policy Name":"2024 Artificial Intelligence Strategy","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Although not focused on education, the strategy identifies education as one of the social domains for AI supervision and calls for developing flexible yet robust frameworks tailored to contexts such as education.","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)","Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["Spain\u2019s 2024 Artificial Intelligence Strategy.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"","General principles on AI":["Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Respect for laws [NEW]. AI should respect existing law.","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Transparency (explainability). AI systems should be sufficiently explainable.","R&D. Sufficient resources should be invested in AI R&D."],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"Spain: 2024 Artificial Intelligence Strategy","Translation Comments":""},id:"i-b9L-R5YgBc",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-b9L-R5YgBc",name:"Spain: 2024 Artificial Intelligence Strategy",index:489,createdAt:"2025-04-29T07:44:44.345Z",updatedAt:"2025-04-29T08:06:18.710Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-b9L-R5YgBc"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["India"],"Policy Name":"National Programme on Artificial Intelligence (NPAI) Skilling Framework","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Addresses AI skilling across education and embeds responsible AI principles into educational governance.","Relevance Type":["Policy is about AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Secondary","Tertiary","Vocational or Professional"],"Principles on AI in education":["Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Managing bias. The risk of bias should be managed with care. ","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ","Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Plans further action. It sets out a strategy on AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["5732498_Report-on-NPAI-Skilling-Framework.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"Ethical artificial intelligence (AI) refers to the development and use of AI systems in a responsible and morally acceptable manner. It involves ensuring that AI technologies align with ethical principles and values, protect human rights, and minimize potential harms.","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":"Fairness and Bias: AI systems should be designed and trained to avoid bias and discrimination based on factors like race, gender, or ethnicity. Developers should carefully select training data, regularly evaluate, and address biases, and promote transparency in algorithmic decisionmaking.","General principles on AI":["Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Augmentation, not replacement. AI systems should augment, not displace, workers.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Bias testing. AI systems should be tested for bias. ","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Respect for laws [NEW]. AI should respect existing law.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. "],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"In summary, ethical AI requires a multidimensional approach that considers fairness, transparency, privacy, accountability, human oversight, social impact, testing, and continuous improvement.","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"India: National Programme on Artificial Intelligence (NPAI) Skilling Framework","Translation Comments":"N/A - English"},id:"i-KqWfv_mXvr",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-KqWfv_mXvr",name:"India: National Programme on Artificial Intelligence (NPAI) Skilling Framework",index:483,createdAt:"2025-04-29T06:33:28.411Z",updatedAt:"2025-04-29T07:17:34.495Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-KqWfv_mXvr"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Malta"],"Policy Name":"Visioning the Future by Transforming Education-National Education Strategy","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"It explicitly mentions professional training on AI for teachers\u200B, AI literacy and digital citizenship skills for students\u200B and the use of AI for data analysis and education policy planning\u200B.","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "],"Governance practices employed":["Communicates a stance. It expresses a hope for the future of AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["Maltese National Education Strategy 2024-2030.pdf"],"Key quotes on AI in education principles":"Eventually, it is the Ministry\u2019s plan to employ AI technologies for data analysis and forecasting, the results of which will serve as evidence for future policies and strategies.","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about AI as a tool for promoting equitable/equal access","Key quote on equity/equality":"Internationally, equity and inclusion have been set high on the agenda since there is a general understanding that social gaps have been exacerbated following the pandemic, a higher rate of migration and due to the digital divide28. The Ministry is committed to addressing social fragmentation and inequalities since it is our belief that education is a fundamental tool through which everyone is given the opportunity to reach their potential. To this end, one of the first steps to be taken to understand how different policies and decisions are impacting different groups of students, is employing a system-wide data disaggregation exercise29, which is also one of the SDG indicators for quality education. Eventually, it is the Ministry\u2019s plan to employ AI technologies for data analysis and forecasting, the results of which will serve as evidence for future policies and strategies.","General principles on AI":["Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Inclusive development. AI systems should be developed inclusively. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Opportunity. The opportunities of AI should be harnessed.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. "],"Link (OECD or Other)":"https://www.gov.mt/en/publicconsultation/Pages/2023/NL-0051-2023.aspx","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"Malta: Visioning the Future by Transforming Education-National Education Strategy","Translation Comments":""},id:"i-SL_Hq9MiTY",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-SL_Hq9MiTY",name:"Malta: Visioning the Future by Transforming Education-National Education Strategy",index:482,createdAt:"2025-04-28T06:34:16.612Z",updatedAt:"2025-04-28T07:13:32.996Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-SL_Hq9MiTY"},{values:{"Category of creator":["OECD"],"Policy creator":["France"],"Policy Name":"Our AI: Our Ambition for France","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The policy discusses AI\u2019s integration into public services including education","Relevance Type":["Policy makes fleeting reference to AI in education"],"What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Develops tools. It provides tools and place them in the hands of businesses or governments"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["France-Our AI Our Ambition for France.pdf"],"Key quotes on AI in education principles":`Finally, AI systems should be used to improve the quality of public services. Artificial intelligence can improve public services, by helping to personalize education, give patients more time, better support and anticipate professional transitions, and reduce bureaucracy.
We also need to invest in training for everyone, at every age: young people in school and afterschool, specialized and non-specialized students, employees, the self-employed and publicsector workers, retirees This means preparing for tomorrow's professions, in particular by structuring a range of hybrid higher education courses, such as "AI + biology" and "law + AI", or by creating AI chairs in design schools We must also enable the use of AI in today's professions, for example by planning an AI awareness course for all civil servants
`,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`Today, it's up to us to take advantage of AI by putting it in its rightful place: that of a technological means at the service of an ambition for humanity, equality, solidarity, justice, prosperity and freedom.
Algorithms contribute to inequalities in work and employment The massification of uses is accompanied by a growing environmental impact.`,"General principles on AI":["Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Opportunity. The opportunities of AI should be harnessed.","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power."],"Link (OECD or Other)":"https://www.info.gouv.fr/upload/media/content/0001/09/02cbcb40c3541390be391feb3d963a4126b12598.pdf","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"France: Our AI: Our Ambition for France","Translation Comments":""},id:"i-H-8vLe7oN4",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-H-8vLe7oN4",name:"France: Our AI: Our Ambition for France",index:481,createdAt:"2025-04-28T06:14:24.710Z",updatedAt:"2025-04-28T06:33:47.438Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-H-8vLe7oN4"},{values:{"Category of creator":["OECD"],"Policy creator":["United Kingdom"],"Policy Name":"AI Opportunity Action Plan","Year of Commencement or Creation":"2025",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This policy is included because it explicitly proposes developing AI talent through education systems and anticipates AI being used as a tool for assessment within the education sector.","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Tertiary","Vocational or Professional"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Communicates a stance. It expresses a hope for the future of AI","Educates. It helps officials or others understand the opportunities and risks of AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["UK-AI Opportunity Action Plan.pdf"],"Key quotes on AI in education principles":"AI directly benefits working people by improving health care and education and how citizens interact with their government.","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women. Achieving parity would mean thousands of additional workers.","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Inclusive development. AI systems should be developed inclusively. ","Opportunity. The opportunities of AI should be harnessed.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"United Kingdom: AI Opportunity Action Plan","Translation Comments":"N/A - English"},id:"i-BlChGUymUq",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-BlChGUymUq",name:"United Kingdom: AI Opportunity Action Plan",index:478,createdAt:"2025-04-24T05:16:56.617Z",updatedAt:"2025-04-24T05:30:58.621Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-BlChGUymUq"},{values:{"Category of creator":["OECD"],"Policy creator":["United Kingdom"],"Policy Name":"Introduction to AI Assurance","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"It illustrates a practical approach to AI governance through internal organisational processes. The use of structured \u2018risk assessments\u2019\u2014including staff workshops, detailed questionnaires, and internal audits\u2014demonstrates how educational technology providers can identify and mitigate potential harms (e.g. to user safety, institutional reputation, or learning outcomes).","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. "],"Governance practices employed":["Guides impact assessment. It helps officials anticipate or evaluate the impact of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Educates. It helps officials or others understand the opportunities and risks of AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["UK-Introduction to AI Assurance.pdf"],"Key quotes on AI in education principles":"Risk assessments are used to consider and identify a range of potential risks that might arise  from the development and/or deployment of an  AI product/systems.","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"Impact assessments are used to anticipate the wider  effects of a system/product on the environment,  equality, human rights, data protection, or other  outcomes.","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"Impact assessments are used to anticipate the wider  effects of a system/product on the environment,  equality, human rights, data protection, or other  outcomes.","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Transparency (explainability). AI systems should be sufficiently explainable.","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"United Kingdom: Introduction to AI Assurance","Translation Comments":"N/A - English"},id:"i-l6Q9QbdRI3",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-l6Q9QbdRI3",name:"United Kingdom: Introduction to AI Assurance",index:477,createdAt:"2025-04-24T05:02:50.459Z",updatedAt:"2025-04-24T05:15:49.398Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-l6Q9QbdRI3"},{values:{"Category of creator":["OECD"],"Policy creator":["Canada"],"Policy Name":"Guide On The Use Of Generative AI","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Involved generative AI may not be suited for use in administrative [such as in the education field] decision-making at this stage.","Relevance Type":["Policy makes fleeting reference to AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["[N/A]"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["BT48-37-2023-eng.pdf"],"Key quotes on AI in education principles":"However, generative AI may not be suited for use in administrative  decision-making at this stage. The design and functioning of generative  models can limit federal institutions\u2019 ability to ensure transparency,  8 accountability and fairness in decisions made by generative AI systems or  informed by their outputs. As well, the terms of use for the generative AI  products of many leading technology companies prohibit using their  products to make high-impact decisions. For example, OpenAI instructs  users not to employ ChatGPT in decisions about credit, employment,  educational institutions, or public assistance services; law enforcement and  criminal justice; and migration and asylum.","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"Issue: generative AI poses risks to human rights, privacy, intellectual property protection, and procedural fairness","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`Risks could also arise from the opacity of generative AI models and their  potential for producing inaccurate, biased or inconsistent outputs. This  opacity makes it difficult to trace and understand how the AI system  produces outputs, which can undermine procedural fairness in instances  where a federal institution is obliged to provide clients with reasons for  administrative decisions, such as decisions to deny benefits. The quality of AI outputs can also impact individuals\u2019 legal rights. For example, biased  outputs could lead to discrimination in services, potentially violating human  rights.
To maintain public trust and ensure the responsible use of generative AI  tools, federal institutions should align with the \u201CFASTER\u201D principles-Fair: ensure that content from these tools does not include or amplify  biases and that it complies with human rights, accessibility, and  procedural and substantive fairness obligations`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Human rights-centred. AI systems should be compatible with human rights. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Augmentation, not replacement. AI systems should augment, not displace, workers.","Bias testing. AI systems should be tested for bias. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Environmental wellbeing. The use of AI should not harm the environment. "],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"This guide also seeks to raise awareness and foster coordination among  federal institutions. It highlights the importance of engaging key  stakeholders before deploying generative AI tools for public use and before  using them for purposes such as service delivery.","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"Canada: Guide On The Use Of Generative AI","Translation Comments":""},id:"i-7EwyhnaVd0",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-7EwyhnaVd0",name:"Canada: Guide On The Use Of Generative AI",index:474,createdAt:"2025-04-24T04:13:43.970Z",updatedAt:"2025-04-24T04:47:33.413Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-7EwyhnaVd0"},{values:{"Category of creator":["OECD"],"Policy creator":"Australia","Policy Name":"National framework for the assurance of artificial intelligence in government","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Instead of focusing on technical detail, the framework sets foundations across all aspects of government, so including education.","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Human rights-centred. The technology must be consistent with human rights. ","Information. Information about the technology in use should be readily available. ","Managing bias. The risk of bias should be managed with care. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Trust. Organisations seeking to incorporate AI into educational settings must build trust.","Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. ","Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology."],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["National framework for the assurance of artificial intelligence in government.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`AI systems should respect human rights, diversity and the autonomy of individuals.
Governments should involve people with different lived experiences, including marginalisation, throughout the lifecycles of a use case to gather informed perspectives,  remove preconceptions and avoid overlooking important considerations.`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":"Governments should ensure high-quality data and algorithmic design. Audits of AI inputs and outputs for unfair biases, data quality statements and other data  governance and management practices may assist to understand and mitigate bias in AI systems.","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Environmental wellbeing. The use of AI should not harm the environment. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Respect for laws [NEW]. AI should respect existing law.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`Australia's 8 AI Ethics Principles, demonstrating how governments can practically apply them to their assurance of AI. 
Human, societal and environmental wellbeing: Throughout their lifecycle, AI systems should benefit  individuals, society and the environment
Human-centred values: AI systems should respect human rights, diversity and the autonomy of individuals.
Fairness: AI systems should be inclusive and accessible, and should not involve or result in unfair discrimination against individuals, communities or groups.
Privacy protection and security: AI systems should respect and uphold privacy rights of individuals and ensure the protection of data.
Reliability and safety: Throughout their lifecycle, AI systems should reliably operate in accordance with their intended purpose.
Transparency and explainability: There should be transparency and responsible disclosure so people can understand when they are being significantly impacted by AI, and can find out when an AI system is engaging with them.
Contestability: When an AI system significantly impacts a person, community,  group or environment, there should be a timely process to allow  people to challenge the use or outcomes of the AI system.
Accountability: Those responsible for the different phases of the AI  system lifecycle should be identifiable and accountable for the outcomes of the AI systems, and human oversight of AI systems should be enabled.`,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"Australia: National framework for the assurance of artificial intelligence in government","Translation Comments":"N/A - English"},id:"i-OCnVnwg791",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-OCnVnwg791",name:"Australia: National framework for the assurance of artificial intelligence in government",index:472,createdAt:"2025-03-03T02:22:23.278Z",updatedAt:"2025-03-04T23:49:34.774Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-OCnVnwg791"},{values:{"Category of creator":["OECD"],"Policy creator":"Italy","Policy Name":"Italian Strategy for Artificial Intelligence 2024-2026","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Education as one of the four marco-area in the strategic actions","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Tertiary","Primary","Secondary"],"Principles on AI in education":["Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ","Critical thinking. Use of the tools should not come at the cost of critical thinking.  ","Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["Italian Strategy for Artificial Intelligence 2024-2026.pdf"],"Key quotes on AI in education principles":`To harness the benefits of AI, however, high professional skills capable of developing and managing algorithms and AI systems are required...As a preliminary to any strategic action, it is therefore essential to address this structural problem by deploying a major plan to strengthen, integrate, and disseminate AI knowledge and related digital skills throughout the education system: from Higher Technical Institutes (ITS) to universities, with particular attention to research doctorates.
The development of a national strategy for Artificial Intelligence must be based on the premise that, in this exceptionally dynamic context, no worker can be left behind. In order for AI-derived applications to have positive effects on the whole society, reducing risks, it will be necessary to further expand the concept of \u201Ceducation\u201D by aiming in Italy to implement an AI literacy process that involves schools, workers, and all citizens, with attention to the most vulnerable categories.
Objectives: Promote widespread university education on AI; Implement educational pathways on AI in schools
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"(Design of Intalian large molecule models)Development should focus on specific applications contextualized in significant application domains for our country, for example in Public Administration or in the health sector, that fully comply with European values and regulations in terms of: (i) transparency of training data, to ensure compliance with non-discrimination laws, privacy (GDPR), human rights protection, providing reliable information on the sources from which content is generated;","Does the policy reflect the principle of equity/equality?":"[N/A]","Key quote on equity/equality":"","General principles on AI":["Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Environmental wellbeing. The use of AI should not harm the environment. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Interoperability. AI systems should be able to work with other systems. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","R&D. Sufficient resources should be invested in AI R&D.","Respect for laws [NEW]. AI should respect existing law.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. "],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"Italy: Italian Strategy for Artificial Intelligence 2024-2026","Translation Comments":"N/A - English"},id:"i-4zUYKmQq-a",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-4zUYKmQq-a",name:"Italy: Italian Strategy for Artificial Intelligence 2024-2026",index:471,createdAt:"2025-03-03T01:04:13.795Z",updatedAt:"2025-03-03T02:18:41.052Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-4zUYKmQq-a"},{values:{"Category of creator":["IO"],"Policy creator":"African Union","Policy Name":"Continental Artificial Intelligence Strategy","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This includes a section on expanding AI adoption in the education sector in Africa with recommendation and associated actions","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["African Union-Continental Artificial Intelligence Strategy.pdf"],"Key quotes on AI in education principles":"Despite the risks, AI has the potential to facilitate higher-order thinking if guided by proper instructional design and support formative assessment of basic skills.","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"Human Rights and Human Dignity\u2014The production, development, use and assessment of AI systems in Africa will always uphold human dignity, gender equality and respect and promote all the human rights set out under the African Charter on Human and Peoples\u2019 Rights and its subsidiary instruments, as well as the Universal Declaration on Human Rights and related instruments of international human rights law.","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":"Special efforts are needed from continental, regional and national agencies and governments to ensure that the development and adoption of AI are inclusive and benefit all Africans, empower women and girls, and underrepresented groups and respect Africa\u2019s cultural and linguistic diversity.","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Environmental wellbeing. The use of AI should not harm the environment. ","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Interoperability. AI systems should be able to work with other systems. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","R&D. Sufficient resources should be invested in AI R&D.","Respect for laws [NEW]. AI should respect existing law.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"African Union: Continental Artificial Intelligence Strategy","Translation Comments":"N/A - English"},id:"i-ViAANnebu8",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-ViAANnebu8",name:"African Union: Continental Artificial Intelligence Strategy",index:470,createdAt:"2025-03-03T00:55:02.832Z",updatedAt:"2025-03-03T01:01:16.746Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-ViAANnebu8"},{values:{"Category of creator":["OECD"],"Policy creator":["Australia"],"Policy Name":"Inquiry into the Use of Generative Artificial Intelligence in the Australian Education System","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This is directly on the topic. Lots of interesting submissions.
Submissions \u2013 Parliament of Australia (aph.gov.au)`,"Relevance Type":["Policy is about AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["[N/A: This is an inquiry, and does not presuppose the answer to questions]"],"Governance practices employed":["Seeks information. It gathers inputs on public sentiment about AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:"","Key quotes on AI in education principles":`\u201CThe House of Representatives Standing Committee on Employment, Education and Training will inquire into the issues and opportunities presented by generative Artificial Intelligence (AI), and comprehensively explore current and future impacts on Australia\u2019s early childhood education, schools, and higher education sectors.
 The inquiry will include consideration of:
The strengths and benefits of generative AI tools for children, students, educators and systems and the ways in which they can be used to improve education outcomes;
The future impact generative AI tools will have on teaching and assessment practices in all education sectors, the role of educators, and the education workforce generally;
The risks and challenges presented by generative AI tools, including in ensuring their safe and ethical use and in promoting ongoing academic and research integrity;
How cohorts of children, students and families experiencing disadvantage can access the benefits of AI;
International and domestic practices and policies in response to the increased use of generative AI tools in education, including examples of best practice implementation, independent evaluation of outcomes, and lessons applicable to the Australian context; and
Recommendations to manage the risks, seize the opportunities, and guide the potential development of generative AI tools including in the area of standards.\u201D

Note that the submissions might be interesting as secondary materials. `,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"The terms of reference do not use the language of \u201Chuman rights\u201D. ","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"The terms of reference do not use the language of \u201Cequity\u201D. ","General principles on AI":["[N/A]"],"Link (OECD or Other)":"https://www.aph.gov.au/Parliamentary_Business/Committees/House/Employment_Education_and_Training/AIineducation/Terms_of_Reference","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":21,Title:"Australia: Inquiry into the Use of Generative Artificial Intelligence in the Australian Education System","Translation Comments":"N/A - English"},id:"i-dsHz67wttW",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-dsHz67wttW",name:"Australia: Inquiry into the Use of Generative Artificial Intelligence in the Australian Education System",index:18,createdAt:"2024-06-01T06:56:56.730Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-dsHz67wttW"},{values:{"Category of creator":["OECD"],"Policy creator":["Estonia"],"Policy Name":"Estonia Education Strategy 2035","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is directly on point \u2014 part of their education strategy involves using technology to make progress. Note I have included some supplementary documents in addition to the actual strategy. The big focus is \u201Cdigital pedagogy\u201D. ","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["Estonia's Education Minister Kristina Kallas on the challenges and opportunities of AI in learning and empowerment [Q&A] - TNGlobal.pdf","Estonia - Education Strategy 2021-2035 _ Digital Skills and Jobs Platform.pdf","Estonia to unleash AI for personalisation of education.pdf","The AI debate in Estonian education_ A balanced approach - Education Estonia.pdf","estonia_education_strategy_2021-2023.pdf"],"Key quotes on AI in education principles":`Digital pedagogy:
\u201CEducators are familiar with trends, opportunities, risks and methodologies related to new technologies, and apply the technologies in a purposeful way. Smart learning resources and methodology support captivating and effective learning and teaching, and help to give and receive immediate and substantial feedback.\u201D (2035 Education Strategy (English), p 19)
Smart learning resources:
\u201CSmart learning resources allow personalised and adaptive learning by means of technology. Smart learning resources enable the empowerment of learners and the addition of value to the learning process through the use of technology (learning analytics, AI, etc.).\u201D (2035 Education Strategy (English), p 36)
Summary 
\u201CEducators are familiar with trends, opportunities, risks and methodologies related to new technologies, and apply the technologies in a purposeful way. Smart learning resources and methodology support captivating and effective learning and teaching, and help to give and receive immediate and substantial feedback. Essential action is personalisation and diversification of learning and supporting learning through digital solutions. It is necessary to: promote the development and implementation of diverse methods of learning and teaching (including digital pedagogy); develop and use digital solutions as tools for educational innovation that enable the diversification and personalisation of education, including assessment for learning; raise awareness among participants in the learning process of the opportunities and risks of the information society; adopt a systematic approach to the introduction of new solutions; improve access to Estonian \u2013 language education and learning of Estonian by introducing digital solutions.\u201D (Education Strategy Summary Document, no pinpoint)
Interview with the Minister leading this:
\u201CMinister Kallas acknowledges the challenges of teacher shortages and the need for curriculum adaptation in light of the rapid emergence of AI. However, she remains optimistic, emphasizing the importance of investing in teacher training, developing AI-enhanced learning tools, and fostering collaboration between the public and private sectors. Estonia\u2019s groundbreaking initiatives, such as the AI-enabled infrastructure for personalized learning and the ProgeTiiger Program for teaching programming skills, have garnered international attention. Kallas envisions further collaboration with countries like Singapore, sharing insights and expertise to advance the field of EdTech innovation.\u201D (Interview doc, no pinpoint)`,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"N/A","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"N/A","General principles on AI":["[N/A]"],"Link (OECD or Other)":"https://technode.global/2024/05/17/estonias-education-minister-kristina-kallas-on-the-challenges-and-opportunities-of-ai-in-learning-and-empowerment-qa/","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":12,Title:"Estonia: Estonia Education Strategy 2035","Translation Comments":"N/A - English"},id:"i-viyYHzDKAf",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-viyYHzDKAf",name:"Estonia: Estonia Education Strategy 2035",index:16,createdAt:"2024-06-01T06:29:39.281Z",updatedAt:"2024-06-03T23:12:54.856Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-viyYHzDKAf"},{values:{"Category of creator":["IO"],"Policy creator":["UNESCO"],"Policy Name":"Guidance for generative AI in education and research","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Highly relevant. ","Relevance Type":["Policy is about AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Academic integrity. Students should be supported to use AI tools ethically in their work, which extends to appropriate attribution.","Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Critical thinking. Use of the tools should not come at the cost of critical thinking.  ","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Human rights-centred. The technology must be consistent with human rights. ","Information. Information about the technology in use should be readily available. ","Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.","Managing bias. The risk of bias should be managed with care. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.","Promoting diversity. Technology should be used to expose users to diverse perspectives. ","Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["386693eng.pdf"],"Key quotes on AI in education principles":`To properly understand where they are coming from, note the introduction:
\u201CHowever, a thematic set of guidance on GenAI for education should not be understood as a claim that GenAI is the solution to education\u2019s fundamental challenges. Despite the media hyperbole, it is unlikely that GenAI alone will solve any of the problems facing education systems around the world. In responding to long-standing educational issues, it is key to uphold the idea that human capacity and collective action, and not technology, is the determining factor in effective solutions to fundamental challenges faced by societies.\u201D (p 7)
There is so much in here that I suggest it is better to read pp 24 to 27
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201CUNESCO\u2019s 2021 Recommendation on the Ethics of Artificial Intelligence provides the requisite normative framework to start addressing the multiple controversies around generative AI, including those that pertain to education and research. It is based on a human-centred approach to AI which advocates that the use of AI should be at the service of the development of human capabilities for inclusive, just and sustainable futures. Such an approach must be guided by human rights principles, and the need to protect human dignity and the cultural diversity that defines the knowledge commons. In terms of governance, a human-centred approach requires proper regulation that can ensure human agency, transparency and public accountability.\u201D (p 18)
\u201CEdGPT. Finally, there is also a need for robust research to ensure that EdGPT does not undermine students\u2019 human rights nor disempower teachers.\u201D (p 13)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`Data poverty: Kalervo Gulson 
As noted earlier, GenAI relies upon huge amounts of data and massive computing power in addition to its iterative innovations in AI architectures and training methods, which are mostly only available to the largest international technology companies and a few economies (mostly the United States, People\u2019s Republic of China, and to a lesser extent Europe). This means that the possibility to create and control GenAI is out of reach of most companies and most countries, especially those in the Global South. 
As access to data becomes increasingly essential for the economic development of countries and for the digital opportunities of individuals, those countries and people who do not have access to or cannot afford enough data are left in a situation of \u2018data poverty\u2019 (Marwala, 2023). The situation is similar for access to computing power. The rapid pervasion of GenAI in technologically advanced countries and regions has accelerated exponentially the generation and processing of data, and has simultaneously intensified the concentration of AI wealth in the Global North. As an immediate consequence, the data-poor regions have been further excluded and put at long-term risk of being colonized by the standards embedded in the GPT models. The current ChatGPT models are trained on data from online users which reflect the values and norms of the Global North, making them inappropriate for locally relevant AI algorithms in data-poor communities in many parts of the Global South or in more disadvantaged communities in the Global North. (p 14)
A few other references:
A starting point for this is the 2022 AI and education: guidance for policy-makers (UNESCO, 2022b). It proposes a comprehensive set of recommendations to guide governments in the development and implementation of sector-wide policies on AI and education with a focus on promoting quality education, social equity and inclusion. Most of the recommendations remain applicable and can be further adapted to guide the formulation of specific policies on GenAI in education. The following eight specific measures for the planning of policies on GenAI in education and research are proposed here to complement this existing guidance. (p 24)
Access and equity: GenAI systems in education may exacerbate existing disparities in access to technology and educational resources, further deepening inequities. (p 36)`,"General principles on AI":["Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Bias testing. AI systems should be tested for bias. ","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Transparency (explainability). AI systems should be sufficiently explainable.","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Human rights-centred. AI systems should be compatible with human rights. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Opportunity. The opportunities of AI should be harnessed.","Inclusive development. AI systems should be developed inclusively. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Environmental wellbeing. The use of AI should not harm the environment. ","Augmentation, not replacement. AI systems should augment, not displace, workers."],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"Note: It is hard to uncouple general and education-specific principles. It is clear that the general principles are intended to apply to education (indeed, they are expressly restated), but one can infer that the narrower principles are intended to apply more broadly. ","Notable Case Studes - Examples of AI in Education":"See, for example, p 33 \u2014 \u201CSocratic challenger\u201D and \u201CAdvisor for project-based learning\u201D","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":5,Title:"UNESCO: Guidance for generative AI in education and research","Translation Comments":""},id:"i-3KYj_XmjkW",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-3KYj_XmjkW",name:"UNESCO: Guidance for generative AI in education and research",index:59,createdAt:"2024-05-30T22:56:41.285Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-3KYj_XmjkW"},{values:{"Category of creator":["IO"],"Policy creator":["European Union"],"Policy Name":"AI Act (Resolution on the text of the AI Act)","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Note that this regulation lists education as high-risk. ","Relevance Type":["Policy has an AI in education component","Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ","Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.","Human rights-centred. The technology must be consistent with human rights. ","Managing bias. The risk of bias should be managed with care. ","Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Transparency (transparency to government). The extent to which AI is used in educational settings should be clear to the government. ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.","Interoperability. AI systems deployed in educational settings should be able to work with other systems. "],"Governance practices employed":["Proposes law. It proposes a law or provides a draft law on AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["TA-9-2024-0138_EN.pdf"],"Key quotes on AI in education principles":`Note: Given that the entire scheme for \u201Chigh-risk\u201D systems applies to AI in education, there is some duplication here. The norms that directly apply to AI in education are expressed generally, so both sets of boxes have been ticked. I have not spent a disproportionate amount of time thinking about whether the draft AI Act impliedly expresses particular norms. It would be worth getting Jose-Miguel to look over this record and tweak it using his working knowledge of the scheme. 
Note 2: No page numbers provided in text. 

Specification of education as high-risk:
\u201CEducation and vocational training: (a) AI systems intended to be used to determine access or admission or to assign natural persons to educational and vocational training institutions at all levels; (b) AI systems intended to be used to evaluate learning outcomes, including when those outcomes are used to steer the learning process of natural persons in educational and vocational training institutions at all levels; (c) AI systems intended to be used for the purpose of assessing the appropriate level of education that an individual will receive or will be able to access, in the context of or within educational and vocational training institutions; (d) AI systems intended to be used for monitoring and detecting prohibited behaviour of students during tests in the context of or within educational and vocational training institutions.\u201D 
Opportunity:
\u201CBy improving prediction, optimising operations and resource allocation, and personalising digital solutions available for individuals and organisations, the use of AI can provide key competitive advantages to undertakings and support socially and environmentally beneficial outcomes, for example in... education\u201D 
\u201CThe deployment of AI systems in education is important to promote high-quality digital education and training and to allow all learners and teachers to acquire and share the necessary digital skills and competences, including media literacy, and critical thinking, to take an active part in the economy, society, and in democratic processes.\u201D 
Harm:
\u201CConsidering the imbalance of power in the context of work or education, combined with the intrusive nature of these systems, such systems could lead to detrimental or unfavourable treatment of certain natural persons or whole groups thereof. Therefore, the placing on the market, the putting into service, or the use of AI systems intended to be used to detect the emotional state of individuals in situations related to the workplace and education should be prohibited. That prohibition should not cover AI systems placed on the market strictly for medical or safety reasons, such as systems intended for therapeutical use.\u201D 
\u201CHowever, AI systems used in education or vocational training, in particular for determining access or admission, for assigning persons to educational and vocational training institutions or programmes at all levels, for evaluating learning outcomes of persons, for assessing the appropriate level of education for an individual and materially influencing the level of education and training that individuals will receive or will be able to access or for monitoring and detecting prohibited behaviour of students during tests should be classified as high-risk AI systems, since they may determine the educational and professional course of a person\u2019s life and therefore affect that person\u2019s ability to secure a livelihood. When improperly designed and used, such systems may be particularly intrusive and may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation.\u201D 
Impact assessments:
\u201CIn order to efficiently ensure that fundamental rights are protected, deployers of high-risk AI systems that are bodies governed by public law, or private operators providing public services and operators deploying certain high-risk AI systems listed in an annex to this Regulation, such as banking or insurance entities, should carry out a fundamental rights impact assessment prior to putting it into use. Services important for individuals that are of public nature may also be provided by private entities. Private operators providing such services of public nature are linked to tasks in the public interest such as in the area of education, healthcare, social services, housing, administration of justice. The aim of the fundamental rights impact assessment is for the deployer to identify the specific risks to the rights of individuals or groups of individuals likely to be affected, identify measures to be taken in the case of a materialisation of those risk. The impact assessment should apply to the first use of the high-risk AI system, and should be updated when the deployer considers that any of the relevant factors have changed. The impact assessment should identify the deployer\u2019s relevant processes in which the high-risk AI system will be used in line with its intended purpose, and should include a description of the period of time and frequency in which the system is intended to be used as well as of specific categories of natural persons and groups who are likely to be affected in the specific context of use.\u201D `,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`The whole regime is built around rights protections. Examples can be found everywhere. Just one example:
\u201CIn order to efficiently ensure that fundamental rights are protected, deployers of high-risk AI systems that are bodies governed by public law, or private operators providing public services and operators deploying certain high-risk AI systems listed in an annex to this Regulation, such as banking or insurance entities, should carry out a fundamental rights impact assessment prior to putting it into use. Services important for individuals that are of public nature may also be provided by private entities. Private operators providing such services of public nature are linked to tasks in the public interest such as in the area of education, healthcare, social services, housing, administration of justice. The aim of the fundamental rights impact assessment is for the deployer to identify the specific risks to the rights of individuals or groups of individuals likely to be affected, identify measures to be taken in the case of a materialisation of those risk. The impact assessment should apply to the first use of the high-risk AI system, and should be updated when the deployer considers that any of the relevant factors have changed. The impact assessment should identify the deployer\u2019s relevant processes in which the high-risk AI system will be used in line with its intended purpose, and should include a description of the period of time and frequency in which the system is intended to be used as well as of specific categories of natural persons and groups who are likely to be affected in the specific context of use.\u201D `,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`One of the key concerns specific to education is the perpetuation of discrimination:  
\u201CHowever, AI systems used in education or vocational training, in particular for determining access or admission, for assigning persons to educational and vocational training institutions or programmes at all levels, for evaluating learning outcomes of persons, for assessing the appropriate level of education for an individual and materially influencing the level of education and training that individuals will receive or will be able to access or for monitoring and detecting prohibited behaviour of students during tests should be classified as high-risk AI systems, since they may determine the educational and professional course of a person\u2019s life and therefore affect that person\u2019s ability to secure a livelihood. When improperly designed and used, such systems may be particularly intrusive and may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation.\u201D 
`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Environmental wellbeing. The use of AI should not harm the environment. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "],"Link (OECD or Other)":"https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"Lots to say on this \u2014 JM already an expert in this Act, so will defer spending a lot of time extracting quotations. ","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":3,Title:"European Union: AI Act (Resolution on the text of the AI Act)","Translation Comments":""},id:"i-eCAcTesvI4",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-eCAcTesvI4",name:"European Union: AI Act (Resolution on the text of the AI Act)",index:171,createdAt:"2024-05-30T22:45:59.556Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-eCAcTesvI4"},{values:{"Category of creator":["IO"],"Policy creator":["European Union"],"Policy Name":"European Parliament resolution of 19 May 2021 on artificial intelligence in education, culture and the audiovisual sector (2020/2017(INI))","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is directly relevant\u2014and very broad. It covers (almost) as many principles as one could think of. ","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ","Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. ","Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Human rights-centred. The technology must be consistent with human rights. ","Managing bias. The risk of bias should be managed with care. ","Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.","Competition. There should be sufficient competition in the market to ensure that one AI edtech provider does not have excessive market power. ","Interoperability. AI systems deployed in educational settings should be able to work with other systems. ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Transparency (transparency to government). The extent to which AI is used in educational settings should be clear to the government. "],"Governance practices employed":["Communicates a stance. It expresses a hope for the future of AI"],"Opportunity and risk orientation":"",File:["TA-9-2021-0238_EN (2).pdf"],"Key quotes on AI in education principles":`Opportunities:
\u201Cwhereas AI has particular potential to offer solutions for the day-to-day challenges of the education sector, such as the personalisation of learning, monitoring learning difficulties, the automation of subject-specific content/knowledge, providing better professional training and supporting the transition to a digital society\u201D (paragraph X)
\u201Cwhereas AI could have practical applications in terms of reducing the administrative work of educators and educational institutions, freeing up time for their core teaching and learning activities\u201D (paragraph Y)
\u201Cwhereas AI-enabled personalised learning experiences can not only help to increase students\u2019 motivation and enable them to reach their full potential, but also reduce drop-out rates\u201D (paragraph AA)
\u201CHighlights that the use of AI in education systems brings a wide range of possibilities, opportunities and tools for making it more innovative, inclusive, efficient and increasingly effective by introducing new high-quality learning methods that are quick, personalised and student-centric; stresses, however, that as it will impact education and social inclusion, the availability of such tools must be ensured for all social groups by establishing equal access to education and learning and leaving no one behind, especially people with disabilities;\u201D (paragraph 31)
\u201CStresses that the real objective of AI in education systems should be to make education as individualised as possible, offering students personalised academic paths in line with their strengths and weaknesses and didactic material tailored to their characteristics, while maintaining educational quality and the integrating principle of our education systems\u201D (paragraph 33)
Opportunities to understand:
\u201Cwhereas it is essential to ensure that all people in the Union acquire the necessary skills from an early age in order to better understand the capabilities and limitations of AI\u201D (paragraph U)
Harm:
\u201Cwhereas the application of AI in education raises concerns around the ethical use of data, learners\u2019 rights, data access and protection of personal data, and therefore entails risks to fundamental rights such as the creation of stereotyped models of learners\u2019 profiles and behaviour that could lead to discrimination or risks of doing harm by the scaling-up of bad pedagogical practices;\u201D (paragraph AD)
Augmentation not replacement:
\u201CAI technologies cannot be used to the detriment or at the expense of in-person education, as teachers must not be replaced by any AI or AI-related technologies\u201D (paragraph 34)
Procurement:
\u201Cencourages public authorities, in this regard, to incentivise the development and deployment of AI technologies through public funding and public procurement\u201D (paragraph 46)
Cooperation and inclusion:
\u201CStresses that the learning benefits of using AI in education will depend not only on AI itself, but on how teachers use AI in the digital learning environment to meet the needs of pupils, students and teachers; points out, therefore, the need for AI programmers to involve teaching communities in the development, deployment and use of AI technologies where possible, creating a nexus environment to form connections and cooperation between AI programmers, developers, companies, schools, teachers and other public and private stakeholders in order to create AI technologies that are suitable for real-life educational environments, reflect the age and developmental readiness of each learner and meet the highest ethical standards; highlights that educational institutions should only deploy trustworthy, ethical, human-centred technologies which are auditable at every stage of their lifecycle by public authorities and civil society; emphasises the advantages of free and open-source solutions in this regard; calls for schools and other educational establishments to be provided with the financial and logistical support as well as the expertise required to introduce solutions for the learning of the future;\u201D (paragraph 35)
Teacher training:
\u201CHighlights, moreover, the need to continuously train teachers so they can adapt to the realities of AI-powered education and acquire the necessary knowledge and skills to use AI technologies in a pedagogical and meaningful way, enabling them to fully embrace the possibilities offered by AI and to understand its limitations\u201D (paragraph 36)
Interoperability:
\u201Ccalls for the data used and produced by AI applications in education to be accessible, interoperable and of high quality, and to be shared with the relevant public authorities in an accessible way and with respect for copyright and trade secrets legislation; recalls that children constitute a vulnerable group who deserve particular attention and protection\u201D (paragraph 43)
So much more could be included, but suffice it to say that all of the boxes ticked reflect clear statements by the European Parliament. `,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`Human rights are built into this document\u2014although they are not the only end pursued. Given acknowledged underinvestment in AI, there are also economic considerations at play. 

Perhaps the strongest statement:
\u201CUnderlines the strategic importance of AI and related technologies for the Union; stresses that the approach to AI and its related technologies must be human-centred and anchored in human rights and ethics, so that AI genuinely becomes an instrument that serves people, the common good and the general interest of citizens;\u201D (paragraph 1)
More education-specific: 
\u201CAsserts that education, culture and the audiovisual sector are sensitive areas as far as the use of AI and related technologies is concerned, as they have the potential to impact on the cornerstones of the fundamental rights and values of our society\u201D (paragraph 3)
`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`There are many, many examples. Education-specific ones include: 
\u201Cwhereas education and educational opportunities are a fundamental right; whereas the development, deployment and use of AI technologies in the education sector should be classified as high risk and subject to stricter requirements on safety, transparency, fairness and accountability;\u201D (paragraph R)
\u201Cwhereas AI and related technologies can be used to improve learning and teaching methods, notably by helping education systems to use fair data to improve educational equity and quality, while promoting tailor-made curricula and better access to education and improving and automating certain administrative tasks; whereas equal and fair access to digital technologies and high-speed connectivity are required in order to make the use of AI beneficial to the whole of society; whereas it is of the utmost importance to ensure that digital education is accessible to all, including those from disadvantaged backgrounds and people with disabilities; whereas learning outcomes do not depend on technology per se, but on how teachers can use technology in pedagogically meaningful ways;\u201D (paragraph W)`,"General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Opportunity. The opportunities of AI should be harnessed.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Inclusive development. AI systems should be developed inclusively. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Environmental wellbeing. The use of AI should not harm the environment. ","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress."],"Link (OECD or Other)":"https://www.europarl.europa.eu/doceo/document/TA-9-2021-0238_EN.html","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`These general principles are referred to as background (\u201DWhereas...\u201D). 

Some of the principles absent here are stated more specifically (e.g., the \u2018augmentation not replacement\u2019 is not expressed generally, but is expressed specifically with regard to teachers. `,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"\u201CCalls on the Commission to include education in the regulatory framework for high-risk AI applications, given the importance of ensuring that education continues to contribute to the public good, as well as the high sensitivity of data on pupils, students and other learners;\u201D \u2014 this happened",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"European Union: European Parliament resolution of 19 May 2021 on artificial intelligence in education, culture and the audiovisual sector (2020/2017(INI))","Translation Comments":""},id:"i-wfPuoK3OXV",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-wfPuoK3OXV",name:"European Union: European Parliament resolution of 19 May 2021 on artificial intelligence in education, culture and the audiovisual sector (2020/2017(INI))",index:19,createdAt:"2024-05-30T22:41:18.325Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-wfPuoK3OXV"},{values:{"Category of creator":["IO"],"Policy creator":["OECD"],"Policy Name":"AI Principles","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"These are important principles that apply to EdTech. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["AI Principles Overview - OECD.AI.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201CAI actors should respect the rule of law, human rights, democratic and human-centred values throughout the AI system lifecycle. These include non-discrimination and equality, freedom, dignity, autonomy of individuals, privacy and data protection, diversity, fairness, social justice, and internationally recognised labour rights. This also includes addressing misinformation and disinformation amplified by AI, while respecting freedom of expression and other rights and freedoms protected by applicable international law.
To this end, AI actors should implement mechanisms and safeguards, such as capacity for human agency and oversight, including to address risks arising from uses outside of intended purpose, intentional misuse, or unintentional misuse in a manner appropriate to the context and consistent with the state of the art.\u201D (https://oecd.ai/en/dashboards/ai-principles/P6)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":"\u201CStakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for people and the planet, such as augmenting human capabilities and enhancing creativity, advancing inclusion of underrepresented populations, reducing economic, social, gender and other inequalities, and protecting natural environments, thus invigorating inclusive growth, well-being, sustainable development and environmental sustainability.\u201D  (https://oecd.ai/en/dashboards/ai-principles/P5)","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Transparency (explainability). AI systems should be sufficiently explainable.","Human rights-centred. AI systems should be compatible with human rights. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Interoperability. AI systems should be able to work with other systems. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Opportunity. The opportunities of AI should be harnessed.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"OECD: AI Principles","Translation Comments":"N/A - English"},id:"i-7fKHs4fMnK",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-7fKHs4fMnK",name:"OECD: AI Principles",index:60,createdAt:"2024-05-30T09:47:57.293Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-7fKHs4fMnK"},{values:{"Category of creator":["IO"],"Policy creator":["UNESCO"],"Policy Name":"Recommendation on Ethics in Artificial Intelligence","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This document provides a general summary of artificial intelligence principles, but has a dedicated section on education and research (see Area 8). This document is also very human rights oriented. ","Relevance Type":["Policy has an AI in education component","Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":["Human rights-centred. The technology must be consistent with human rights. ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology.","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. ","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["381137eng (1) (1).pdf"],"Key quotes on AI in education principles":`\u201CMember States should promote general awareness programmes about AI developments, including on data and the opportunities and challenges brought about by AI technologies, the impact of AI systems on human rights and their implications, including children\u2019s rights. These programmes should be accessible to nontechnical as well as technical groups.\u201D (p 34)
\u201CAI systems used in learning should be subject to strict requirements when it comes to the monitoring, assessment of abilities, or prediction of the learners\u2019 behaviours. AI should support the learning process without reducing cognitive abilities and without extracting sensitive information, in compliance with relevant personal data protection standards.\u201D (p 34)
\u201CMember States should promote the participation and leadership of girls and women, diverse ethnicities and cultures, persons with disabilities, marginalized and vulnerable people or people in vulnerable situations, minorities and all persons not enjoying the full benefits of digital inclusion, in AI education programmes at all levels, as well as the monitoring and sharing of best practices in this regard with other Member States.\u201D (p 34)
\u201CMember States should ensure that AI researchers are trained in research ethics and require them to include ethical considerations in their designs, products and publications, especially in the analyses of the datasets they use, how they are annotated, and the quality and scope of the results with possible applications.\u201D (p 35)

\u201CMember States should develop guidelines for humanrobot interactions and their impact on human-human relationships, based on research and directed at the future development of robots, and with special attention to the mental and physical health of human beings. Particular attention should be given to the use of robots in health care and the care for older persons and persons with disabilities, in education, and robots for use by children, toy robots, chatbots and companion robots for children and adults. Furthermore, assistance of AI technologies should be applied to increase the safety and ergonomic use of robots, including in a human-robot working environment. Special attention should be paid to the possibility of using AI to manipulate and abuse human cognitive biases.\u201D (p 37)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201CAI systems raise new types of ethical issues that include, but are not limited to, their impact on decision-making, employment and labour, social interaction, health care, education, media, access to information, digital divide, personal data and consumer protection, environment, democracy, rule of law, security and policing, dual use, and human rights and fundamental freedoms, including freedom of expression, privacy and nondiscrimination.\u201D (p 10)

\u201CFrom a socio-technical lens, greater transparency contributes to more peaceful, just, democratic and inclusive societies. It allows for public scrutiny that can decrease corruption and discrimination, and can also help detect and prevent negative impacts on human rights.\u201D (p 22)

\u201CRecalling that, by the terms of its Constitution, UNESCO seeks to contribute to peace and security by promoting collaboration among nations through education, the sciences, culture, and communication and information, in order to further universal respect for justice, for the rule of law and for the human rights and fundamental freedoms which are affirmed for the peoples of the world\u201D (p 5)

\u201CConvinced that the Recommendation presented here, as a standard-setting instrument developed through a global approach, based on international law, focusing on human dignity and human rights, as well as gender equality, social and economic justice and development, physical and mental well-being, diversity, interconnectedness, inclusiveness, and environmental and ecosystem protection can guide AI technologies in a responsible direction\u201D (p 5)

\u201CConsidering that AI technologies can be of great service to humanity and all countries can benefit from them, but also raise fundamental ethical concerns, for instance regarding the biases they can embed and exacerbate, potentially resulting in discrimination, inequality, digital divides, exclusion and a threat to cultural, social and biological diversity and social or economic divides; the need for transparency and understandability of the workings of algorithms and the data with which they have been trained; and their potential impact on, including but not limited to, human dignity, human rights and fundamental freedoms, gender equality, democracy, social, economic, political and cultural processes, scientific and engineering practices, animal welfare, and the environment and ecosystems\u201D (p 5)

\u201CThe objectives of this Recommendations are (c) to protect, promote and respect human rights and fundamental freedoms, human dignity and equality, including gender equality; to safeguard the interests of present and future generations; to preserve the environment, biodiversity and ecosystems; and to respect cultural diversity in all stages of the AI system life cycle.\u201D (p 15) 

\u201CIn all cases, any possible limitations on human rights and fundamental freedoms must have a lawful basis, and be reasonable, necessary and proportionate, and consistent with States\u2019 obligations under international law.\u201D (p 18)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`\u201CAI actors should promote social justice and safeguard fairness and non-discrimination of any kind in compliance with international law. This implies an inclusive approach to ensuring that the benefits of AI technologies are available and accessible to all, taking into consideration the specific needs of different age groups, cultural systems, different language groups, persons with disabilities, girls and women, and disadvantaged, marginalized and vulnerable people or people in vulnerable situations.\u201D (p 20)
\u201CMember States should work to promote inclusive access for all, including local communities, to AI systems with locally relevant content and services, and with respect for multilingualism and cultural diversity.\u201D (p 20)
\u201CMember States should work to tackle digital divides and ensure inclusive access to and participation in the development of AI\u201D (p 20)
\u201CAt the national level, Member States should promote equity between rural and urban areas, and among all persons regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds, in terms of access to and participation in the AI system life cycle.\u201D (p 20)

\u201CAt the international level, the most technologically advanced countries have a responsibility of solidarity with the least advanced to ensure that the benefits of AI technologies are shared such that access to and participation in the AI system life cycle for the latter contributes to a fairer world order with regard to information, communication, culture, education, research and socio-economic and political stability.\u201D (p 20)

\u201CFurthermore, new ethical challenges are created by the potential of AI algorithms to reproduce and reinforce existing biases, and thus to exacerbate already existing forms of discrimination, prejudice and stereotyping.\u201D (p 10)

\u201CAI actors should make all reasonable efforts to minimize and avoid reinforcing or perpetuating discriminatory or biased applications and outcomes throughout the life cycle of the AI system to ensure fairness of such systems. Effective remedy should be available against discrimination and biased algorithmic determination.\u201D (p 20)

\u201CRespect, protection and promotion of diversity and inclusiveness should be ensured throughout the life cycle of AI systems, consistent with international law, including human rights law. This may be done by promoting active participation of all individuals or groups regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds.\u201D (p 19)

\u201CLearning about the impact of AI systems should include learning about, through and for human rights and fundamental freedoms, meaning that the approach and understanding of AI systems should be grounded by their impact on human rights and access to rights, as well as on the environment and ecosystems.\u201D (p 23) `,"General principles on AI":["R&D. Sufficient resources should be invested in AI R&D.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Environmental wellbeing. The use of AI should not harm the environment. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":3,Title:"UNESCO: Recommendation on Ethics in Artificial Intelligence","Translation Comments":"N/A - English"},id:"i-eIePcoMdFY",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-eIePcoMdFY",name:"UNESCO: Recommendation on Ethics in Artificial Intelligence",index:57,createdAt:"2024-05-30T09:45:24.008Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-eIePcoMdFY"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["India"],"Policy Name":"Approach Document for India \u2014 Operationalizing Principles for Responsible AI","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is about mechanisms for operationalising principles set out in the first of this two-part series. This is all broadly relevant. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Guides impact assessment. It helps officials anticipate or evaluate the impact of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Develops tools. It provides tools and place them in the hands of businesses or governments"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Part2-Responsible-AI-12082021.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"Implication of \u201Csecurity risks\u201D - \u201CReal-world deployments may lead to malfunctioning and potentially impact the fundamental rights if underlying AI models are manipulated\u201D (p 3)","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`\u201CThe diversity, scale, digital divide, lack of awareness and inequality serves a fertile ground for the negative effects of AI to amplify. Creating a trusted AI ecosystem is important to realise both the economic and social potential of AI.\u201D (p 7)

\u201CSocial research must be aimed at understanding the interaction of AI systems with the local and marginalised communities. This includes understanding how different communities are impacted by the deployment of AI technologies for the delivery of benefits and services, and if benefits are reaching the population as intended, ramifications of risks and considerations such as discrimination, inclusivity, privacy, etc on local and marginalised communities, and identify any other concerns, both in the short term and long term, shaped by the introduction of Artificial Intelligence.\u201D (p 15)`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27226","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":3,Title:"India: Approach Document for India \u2014 Operationalizing Principles for Responsible AI","Translation Comments":"N/A - English"},id:"i-Zc3haNaboY",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-Zc3haNaboY",name:"India: Approach Document for India \u2014 Operationalizing Principles for Responsible AI",index:24,createdAt:"2024-05-30T04:34:33.796Z",updatedAt:"2024-06-03T07:19:30.253Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-Zc3haNaboY"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["India"],"Policy Name":"Approach Document for India \u2014 Principles for Responsible AI","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is an interesting little paragraph here on positive discrimination \u2014 helping certain persons access education (which, in context, is to be achieved through AI). These principles are not framed in terms of EdTech, but could be applied.","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Proposes law. It proposes a law or provides a draft law on AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Responsible-AI-22022021.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`Under \u201CSystems Consideration 4: Incorrect decisions leading to exclusion from access to services or benefits\u201D, it notes that: 
\u201CIn a beneficiary identification system, an incorrect decision could lead to exclusion of services and benefits guaranteed by the State and in criminal identification systems, it could lead to loss of fundamental rights. When the AI systems are used, particularly for critical services by the Government, it is important to have processes and systems in place for raising an objection.\u201D (p 25)

See also Appendix 2 (p 59) for the review of global regulatory landscape (some mentions of human rights in the context of EU). `,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`Note that both formal equality and substantive equality are captured. 

\u201CPrinciple of Inclusivity and Non-discrimination: AI systems should not deny opportunity to a qualified person on the basis of their identity. It should not deepen the harmful historic and social divisions based on religion, race, caste, sex, descent, place of birth or residence in matters of education, employment, access to public spaces, etc. It should also strive to ensure that unfair exclusion of services or benefits does not happen. In case of an adverse decision, appropriate grievance redressal mechanism should be designed in a manner affordable and accessible to everyone irrespective of their background.\u201D (p 50)

\u201CSafety and robustness of AI systems can pose serious challenges especially in high risk prone applications; unequal access to AI powered applications for marginalized populations can further accentuate digital divide.\u201D (p 17)

\u201CThe \u2018systematic\u2019 exclusion from access to services and benefits could undermine trust in the system.\u201D (p 16)`,"General principles on AI":["Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (explainability). AI systems should be sufficiently explainable.","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Bias testing. AI systems should be tested for bias. ","Human rights-centred. AI systems should be compatible with human rights. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","R&D. Sufficient resources should be invested in AI R&D.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Opportunity. The opportunities of AI should be harnessed."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27225","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":2,Title:"India: Approach Document for India \u2014 Principles for Responsible AI","Translation Comments":"N/A - English"},id:"i-gW1QzUap3c",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-gW1QzUap3c",name:"India: Approach Document for India \u2014 Principles for Responsible AI",index:26,createdAt:"2024-05-30T04:30:01.440Z",updatedAt:"2024-06-03T07:19:52.294Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-gW1QzUap3c"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["India"],"Policy Name":"National Strategy on AI","Year of Commencement or Creation":"2018",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is super important: India is a very linguistically diverse place. So it\u2019s national strategy envisaged leveraging AI technologies to help with education. Education is one of the five areas that AI will be applied to. ","Relevance Type":["Policy has an AI in education component","Policy contains case studies on AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary","Vocational or Professional"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["National-Strategy-for-Artificial-Intelligence.pdf"],"Key quotes on AI in education principles":`The key story here is: India is experiencing low retention rates and poor learning outcomes, and one of the problems is a lack of technology. 
\u201CAI can potentially solve for quality and access issues observed in the Indian education sector. Potential use cases include augmenting and enhancing the learning experience through personalised learning, automating and expediting administrative tasks, and predicting the need for student intervention to reduce dropouts or recommend vocational training.\u201D (p 20)
\u201CAI has the potential to bring about changes in the sector by supplementing pedagogy and establishing systems to inform and support decision making across stakeholders and administrative levels. However, implementation of AI must be preceded by efforts to digitise records of teacher performance, student performance, and curriculum. Several AI tools are being successfully used in other parts of the world, and they can be adapted to the Indian context to target specific challenges.\u201D
What they are interested in: see use cases below. 
Teacher training:
A recent survey found that level of adoption of technology in schools is lacking, and can be largely attributed to lack of teacher training, despite provision of the ICT infrastructure. (p 36)
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"\u201CAddress and implement data protection framework, which protects human rights and privacy without stifling innovation in India.\u201D (p 93) \u2014 only reference","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"There are a few references to discrimination, but this plan is not really framed in the language of equality/equity. Even the opportunity here is framed as an opportunity to improve education (rather than, for example, decrease educational inequality \u2014 cf Indonesia). ","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (explainability). AI systems should be sufficiently explainable.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24951","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"Note \u2014 education is considered in an \u201Copportunity-only\u201D way. The content on ethics is addressed in broad terms. ","Notable Case Studes - Examples of AI in Education":`a) Adaptive learning tools for customised learning: While AI may not completely replace a teacher, it has the potential to greatly assist teachers in efficiently and effectively managing multi-level / multi?grade classrooms, by judging learning levels of individual students, and allowing automated development of customised educational content adapted to each child\u2019s class and learning level. Assessing time spent by a student on each part / page of the learning material, for example, would allow real-time feedback on student performance to help the teacher appropriately tailor her guidance to the child. This concept can be extended to automatic grading of tests, as well. 
b) Intelligent and interactive tutoring systems: Intelligent Tutoring Systems can provide great benefit to students through delivery of learning materials adapted to the child\u2019s proficiency level, learning style, and pace of learning. In-built pop-up questions tailored to students, for example, can help increase interactivity, and catch student\u2019s attention and interest. It can also help in assessment of student\u2019s level of attention or comprehension to appropriately design remedial instruction. GradeGuardian, for example, uses predictive models and visualisations for student performance with an interactive dashboard showing anticipated effect of policy changes. Submission includes 3 components packaged as a single web app \u2013 a Chatbot that inputs student information, an Advisor Console that shows students at risk, and a prediction module for policymakers.
c) Predictive tools to inform pre-emptive action for students predicted to drop out of school: Analysis of test results and attendance records using AI can be used to predict probable student activities and inform pre-emptive action. For instance, in a recent preliminary experiment conducted in Andhra Pradesh, AI applications processed data on all students based on parameters such as gender, socio?economic factors, academic performance, school infrastructure, teacher skills, etc., with the objective of helping the government identify students likely to drop out. Test results could inform suggestions to enroll students in vocational studies. Additionally, redressal mechanisms could be put in place to identify students whose performance can be improved by focus of existing schemes to their family.
(d)) Automated rationalisation of teachers: AI tools can be used to develop automated teacher posting and transfer systems, using analytics based on demand \u2013 supply gaps across schools in the State, candidate\u2019s prior postings, candidate preferences, etc. This would help in plugging of gaps in teacher distribution more effectively. 
e) Customised professional development courses: To tackle issues of poorly designed professional development courses with poor coverage, adaptive AI tools can be used to design automated, customised professional development training content for the teacher based on their performance, identification of their knowledge and skill gaps. This could then be continuously adapted as teacher\u2019s skills and concepts improve.
 (p 37-38 \u2014 read this section, noting the pop-out boxes with concrete case studies)
`,"Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"India: National Strategy on AI","Translation Comments":""},id:"i-F0cUMbalq-",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-F0cUMbalq-",name:"India: National Strategy on AI",index:25,createdAt:"2024-05-30T04:29:45.240Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-F0cUMbalq-"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Malta"],"Policy Name":"Technology Assessment Recognition Framework","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is an interesting model that could definitely be applied to EdTech. TARF - Technology Assessment Recognition Framework - Malta Digital Innovation Authority (gov.mt)","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Guides impact assessment. It helps officials anticipate or evaluate the impact of AI","Develops tools. It provides tools and place them in the hands of businesses or governments"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27583","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":2,Title:"Malta: Technology Assessment Recognition Framework","Translation Comments":"N/A - English"},id:"i-noNor4BMYA",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-noNor4BMYA",name:"Malta: Technology Assessment Recognition Framework",index:28,createdAt:"2024-05-30T04:22:26.071Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-noNor4BMYA"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Malta"],"Policy Name":"Towards Trustworthy AI: Malta\u2019s Ethical AI Framework","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a nuanced framework for AI. It talks authorities through precisely what should be done (rather than merely expressing broad norms). Focus on its \u201Cgovernance practices\u201D table. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Educates. It helps officials or others understand the opportunities and risks of AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["Malta_Towards_Ethical_and_Trustworthy_AI_vFINAL.pdf"],"Key quotes on AI in education principles":"N/A","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`It stresses: \u201CRespect for all applicable laws and regulations, human rights and democratic values;\u201D \u2014 this theme keeps coming back. 
\u201CConduct human rights impact assessment, identifying and documenting potential trade-offs between different principles and rights.\u201D`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":"\u201CEquality, non-discrimination and solidarity \u2014 AI operations can not generate unfairly biased outcomes, and the benefits and opportunities of AI should be equitably available to all.\u201D (p 9)","General principles on AI":["Respect for laws [NEW]. AI should respect existing law.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Environmental wellbeing. The use of AI should not harm the environment. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24993","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"Note: These principles are inferred from governance control. ","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":`This is interesting for its \u201Cgovernance practices\u201D table. Worth paying attention to. 

Note that this has been characterised as being equally interested in risks and opportunities. Why? The primary justification is that it sees ETHICS as being one of the central tools for being the \u201Cultimate launchpad\u201D for AI. This is an important point\u2014it is not merely seeing ethics as belonging to the domain of risk mitigation. `,'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Malta: Towards Trustworthy AI: Malta\u2019s Ethical AI Framework","Translation Comments":""},id:"i-KzUPzwvpZR",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-KzUPzwvpZR",name:"Malta: Towards Trustworthy AI: Malta\u2019s Ethical AI Framework",index:27,createdAt:"2024-05-30T04:11:49.801Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-KzUPzwvpZR"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Peru"],"Policy Name":"National AI Strategy (2021-2026)","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is directly relevant to AI in education (particularly individualisation of education for each student)","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Secondary","Primary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":"","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["Peru_National_Artificial_Intelligence_Strategy_2021-2026.pdf"],"Key quotes on AI in education principles":`\u201CUse case in education:
AI adapted to the needs of each student
From school to college, AI could individualize the learning needs of each student. 
The system could respond to the needs of the student, placing greater emphasis on certain topics, repeating things until the student masters it. 
In general, helping the student to learn at her own pace, whatever this could be. 
AI could give feedback to students and teachers 
AI could give feedback to teachers and students about the results of the course itself. 
Some AI systems are used to monitor student progress and alert teachers when there might be a problem with student performance. 
These systems could give the support to the students who need it, and to the teacher, to find the areas where he can improve the instructions to the student so that he does not fail with the subject of the course.\u201D (p 19)
 
\u201CThrough the National Center for Innovation and Artificial Intelligence, prioritize the development of use cases where Artificial Intelligence can generate concrete solutions such as those proposed in various investigations aligned to the United Nations 2030 sustainable development goals, such as the elimination of poverty, zero hunger, quality education, clean and accessible energy, clean water and sustainable cities, good health, better qualified jobs, the reduction of social gaps and others.\u201D (p 67)`,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CA.5.1.7. In the public sector, in all cases of use of AI to classify people (to provide benefits, opportunities or sanctions to citizens), they must have a socioeconomic impact study to guarantee equity.\u201D (p 79)","General principles on AI":["Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Bias testing. AI systems should be tested for bias. ","Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities."],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"image.png","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Peru: National AI Strategy (2021-2026)","Translation Comments":""},id:"i-4zem25qHQm",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-4zem25qHQm",name:"Peru: National AI Strategy (2021-2026)",index:31,createdAt:"2024-05-30T04:01:52.887Z",updatedAt:"2024-06-06T03:04:13.416Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-4zem25qHQm"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Kenya"],"Policy Name":"Kenya\u2019s Digital Economy Strategy","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`There is a hugely important case study on digital inequality here:
The same assumption was extended to the basic education too where it turned out that only less than 25% of learners could participate in remote/online learning. Similarly, the Kenyan labour force are largely in the informal sector where working remotely was not a solution. Unfortunately, the measures that were put in place to address the digital inequalities during the pandemic were seen more as a necessity and not as priorities.
I am including this for the purpose or asking: How do we roll out AI if the basic infrastructure is not there?`,"Relevance Type":["Policy contains case studies on AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A Other]"],"Governance practices employed":["[N/A]"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["10TH-JULY-FINAL-COPY-DIGITAL-ECONOMY-STRATEGY-DRAFT-ONE.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"[N/A]","Key quote on equity/equality":"","General principles on AI":["[N/A]"],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27138","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":`This is a case study in the failure to get AI in education projects off the ground. 
The key point is as follows:

The same assumption was extended to the basic education too where it turned out that only less than 25% of learners could participate in remote/online learning. Similarly, the Kenyan labour force are largely in the informal sector where working remotely was not a solution. Unfortunately, the measures that were put in place to address the digital inequalities during the pandemic were seen more as a necessity and not as priorities.

This should be read together with Kenya\u2019s other policies, which deal expressly with AI and blockchain. `,"Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":4,Title:"Kenya: Kenya\u2019s Digital Economy Strategy","Translation Comments":""},id:"i-TkXOJxaGiN",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-TkXOJxaGiN",name:"Kenya: Kenya\u2019s Digital Economy Strategy",index:46,createdAt:"2024-05-30T03:06:58.553Z",updatedAt:"2024-06-04T23:03:49.690Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-TkXOJxaGiN"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Kenya"],"Policy Name":"Emerging Digital Technologies for Kenya \u2014 Exploration and Analysis","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This work was undertaken by the government\u2019s Blockchain and AI Taskforce, and is \u201CAI for development\u201D focused. There is broad awareness that this technology could be used to deliver personalised virtual lessons. They also point to systems already in place \u2014 including an SMS-based learning platform. This is a really interesting research paper. ","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["KenEcon_30.pdf"],"Key quotes on AI in education principles":`Opportunity
\u201CIn the education sector, AI exhibits the potential to improve learning outcomes by supporting the delivery of personalised virtual lessons. A good example here is M-Shule, an SMS-based learning platform in Kenya, which uses AI to track and analyse student performance and to deliver lessons that satisfy their needs and increase their competency. The platform reduces the fear of failure that is inherent in several learning environments, allowing students to advance at their own pace and to ultimately improve their learning outcomes.\u201D (p 10)
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"\u201CThe technology will enable the constitutional rights of the citizens and is expected to continually ensure transparent elections in the country. Elected officials will also be held accountable relative to the use of public resources and effective delivery of government services.\u201D (p 87)","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CEssentially, the sharing economy is expected to transition to the next level, where the middleman is not extracting maximum value at the expense of the other participants. Instead, depending on the specific use case or design, the created value will be distributed more equitably\u201D (p 107)","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","R&D. Sufficient resources should be invested in AI R&D.","Bias testing. AI systems should be tested for bias. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27135","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":`\u201CIn the education sector, AI has the potential to improve learning outcomes through more personalised, virtual lessons. For example, M-Shule, an SMS-based learning platform in Kenya, uses AI to track and analyse student performance and to deliver lessons that meet their individual needs and thereby grow their competency. The M-Shule platform reduces the fear of failure inherent in many learning environments. Students can advance at their own pace and ultimately improve their learning outcomes.\u201D (p 39)

(p 40)`,"Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Kenya: Emerging Digital Technologies for Kenya \u2014 Exploration and Analysis","Translation Comments":""},id:"i-6wgFj6IDsa",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-6wgFj6IDsa",name:"Kenya: Emerging Digital Technologies for Kenya \u2014 Exploration and Analysis",index:44,createdAt:"2024-05-30T03:02:11.353Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-6wgFj6IDsa"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Romania"],"Policy Name":"Romania\u2019s National Strategy","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`Romania has a clear intention to use AI in education\u2014specifically: 
Personalised content presentation, evaluation and feedback 
Classes augmented with AR & VR technologies
Recommendations for further studying and curation of content
Enhanced blended learning through AI 
Gamification concepts implemented through AI technology
`,"Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["Romania-2019.pdf"],"Key quotes on AI in education principles":`\u201CRomania\u2019s future depends on the education system available to young generations. The obsolete methods used in teaching combined with the poor training of teachers lead to concerning percentages of functional analphabetism in Romania, especially in rural areas. 
AI technologies have the potential to revolutionise the education system through projects such as:
Personalised content presentation, evaluation and feedback
Classes augmented with AR & VR technologies
Recommendations for further studying and curation of content 
Enhanced blended learning through AI 
Gamification concepts implemented through AI technology\u201D (p 9)

Another initiative concerning training (p 15):
`,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["R&D. Sufficient resources should be invested in AI R&D.","Opportunity. The opportunities of AI should be harnessed."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24849","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"Very little of interest in this strategy \u2014 very \u201Ccarpe diem\u201D, but not a lot of detail or discussion of risk. ","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Romania: Romania\u2019s National Strategy","Translation Comments":""},id:"i-AkCFVNxew3",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-AkCFVNxew3",name:"Romania: Romania\u2019s National Strategy",index:468,createdAt:"2024-05-30T02:23:12.056Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-AkCFVNxew3"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Egypt"],"Policy Name":"Egypt National AI Strategy","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The focus here is on AI education, but it is recognised that EdTech could help Egypt achieve its development goals.","Relevance Type":["Policy makes fleeting reference to AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["Publications_672021000_Egypt-National-AI-Strategy-English.pdf"],"Key quotes on AI in education principles":`The key reference to EdTech is as follows:

\u201CApplying AI to areas such as education or healthcare can facilitate access, overcome staff shortages, and reduce risks and costs. On the other hand, concerns are growing about increasingly automated and autonomous AI systems widening the technological, economic, and social gaps due to the lack of basic infrastructure and human capacity capable of exploiting this technology, especially in countries with a large proportion of low-skilled or unskilled labor.\u201D [8]
It shows that Egypt is curious but recognises the practical difficulties of harnessing the technology. `,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"N/A","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`\u201CThe National AI Strategy is a key priority for helping Egypt achieve relevant UN Sustainable Development Goals as they pertain to Egypt (in numerical order 4, 5, 8, 9, 10, 11). The relevant SDGs address inclusive and equitable education\u201D (p 24)
`,"General principles on AI":["Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Bias testing. AI systems should be tested for bias. ","Augmentation, not replacement. AI systems should augment, not displace, workers.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,"],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26476","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Egypt: Egypt National AI Strategy","Translation Comments":"Official Translation Obtained"},id:"i-dELwsp5J0Y",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-dELwsp5J0Y",name:"Egypt: Egypt National AI Strategy",index:54,createdAt:"2024-05-30T02:11:00.927Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-dELwsp5J0Y"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["China"],"Policy Name":"White Paper on Trustworthy AI","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`There is generally relevant material here. Also, interesting commentary surrounding China\u2019s AI governance:
China\u2019s New AI Governance Initiatives Shouldn\u2019t Be Ignored - Carnegie Endowment for International Peace`,"Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["t0390_trustworthy_AI_EN.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":`\u201C(4) AI fairness technology With the widespread application of AI systems, such systems have exhibited unfair decision-making behaviors and discrimination against certain groups. Academia holds that the main reasons for such decision-making biases are as follows: limited by data collection conditions, the weights of different groups in the data are unbalanced; the AI model trained on the unbalanced dataset may then be applied to the overall data, and while performance is sacrificed on a small amount of data, the model's decision-making becomes unfair. In order to ensure the fairness of decision-making in AI systems, relevant researchers have mainly constructed completely heterogeneous datasets to minimize inherent discrimination and bias in the data; datasets are then checked periodically to ensure the high quality of the data. In addition, there are also algorithms that use fair decision-making quantitative indicators to reduce or eliminate decision-making bias and potential discrimination. Such existing fairness indicators can be divided into two categories: individual fairness and group fairness. Specifically, individual fairness measures the degree of prejudice of intelligent decision-making toward different individuals, and group fairness measures the degree of prejudice of intelligent decision-making toward different groups.\u201D (p 11)

\u201CThe number of AI applications in sensitive fields continues to grow, such as in hiring, criminal justice, and healthcare, and its fairness has also been the subject of widespread concern. Fairness technology can balance data from a technical perspective, thereby further guiding the model to give fair results, which is of great significance for improving the fairness of decision-making in AI systems.\u201D (p 11)

\u201CIn terms of diversity and tolerance, attention should be paid to the fairness and diversity of training datasets to avoid lack of trust caused by data bias. The performance of an AI system depends on the quality of the training data. The dataset may contain implicit race, gender, or ideological bias (Table 1), which may cause the AI system\u2019s decision-making to be inaccurate or biased and discriminatory. Enterprises should focus on improving the diversity and fairness of training data to meet the requirements of diversity and inclusion. On the one hand, attention must be paid to the inherent discrimination and prejudice that may appear in the data and proactive measures should be taken to weaken the impact of such prejudice; on the other hand, the dataset should be reviewed periodically to ensure the high quality of the data. Also, the testing process should use quantitative indicators based on fair decision-making capabilities to test the AI system.\u201D (p 15)`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27294","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"China: White Paper on Trustworthy AI","Translation Comments":"N/A - English"},id:"i-88Rbwn15L0",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-88Rbwn15L0",name:"China: White Paper on Trustworthy AI",index:464,createdAt:"2024-05-30T01:18:25.206Z",updatedAt:"2024-06-05T21:37:17.815Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-88Rbwn15L0"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["China"],"Policy Name":"Governance Principles for New Generation AI","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"These are broadly relevant.","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Governance Principles for the New Generation Artificial Intelligence--Developing Responsible Artificial Intelligence - Chinadaily.com.cn.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201CThe development of AI should be based on the premise of ensuring social security and respecting human rights, and should prevent misuse, abuse and evil use of AI technology by all means.\u201D (p 1)
\u201CAI development should respect and protect the privacy of individuals and fully protect an individual\u2019s rights to know and to choose.\u201D (p 2)`,"Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`\u201CThe development of AI should promote fairness and justice, protect the rights and interests of all stakeholders, and promote equal opportunities.\u201D (p 2)

Could also be interpreted as formal (rather than substantive) equality: 
\u201CThrough technology advancement and management improvement, prejudices and discriminations should be eliminated as much as possible in the process of data acquisition, algorithm design, technology development, and product development and application.\u201D (p 2)`,"General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Bias testing. AI systems should be tested for bias. ","Human rights-centred. AI systems should be compatible with human rights. ","Environmental wellbeing. The use of AI should not harm the environment. ","Inclusive development. AI systems should be developed inclusively. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24427","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":5,Title:"China: Governance Principles for New Generation AI","Translation Comments":"N/A - English"},id:"i-VbWA0f4jSi",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-VbWA0f4jSi",name:"China: Governance Principles for New Generation AI",index:458,createdAt:"2024-05-30T01:17:03.342Z",updatedAt:"2024-06-04T22:34:36.295Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-VbWA0f4jSi"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["China"],"Policy Name":"National New Generation AI Plan","Year of Commencement or Creation":"2017",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`\u201CIntelligent education\u201D is built into China\u2019s plan. 
Note that far more detailed information about its educational intentions are built into its subsequent education policy (included in our policy tool). `,"Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["P020210628714286134479.pdf"],"Key quotes on AI in education principles":`(p 7)

Very minimal commentary on risks. This is it: \u201CWhile robustly developing AI, we must highlight the potential safety risks, enhance early prevention and guidance, reduce risks to a maximum degree and ensure the safe, reliable and manageable development of AI.\u201D

The main usage of \u201Cgovernance\u201D relates to \u201Cintelligent social governance\u201D (by which it means \u201Cpublic administration\u201D). 
`,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"N/A","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["[N/A]"],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24274","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":3,Title:"China: National New Generation AI Plan","Translation Comments":"Official Translation Obtained"},id:"i-5nkZlHdSBx",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-5nkZlHdSBx",name:"China: National New Generation AI Plan",index:456,createdAt:"2024-05-30T01:16:33.257Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-5nkZlHdSBx"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["China"],"Policy Name":"AI Innovation Action Plan for Institutions of Higher Education","Year of Commencement or Creation":"2018",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This has a section on \u201Cintelligent education\u201D that is directly relevant\u2014and really interesting. As far back as 2018, it was looking into the following: \u201CAccelerate and promote the deep integration and innovative development of AI in education.\u201D See details below. 
Note, however, that this strategy is broader in scope than \u201CEdTech governance\u201D \u2014 it considers the role of educational institutions in developing a robust AI sector. `,"Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Communicates a stance. It expresses a hope for the future of AI","Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["Notice-of-the-Ministry-of-Education-on-Issuing-the-Artificial-Intelligence-Innovation-Action-Plan-for-Institutes-of-Higher-Education.pdf"],"Key quotes on AI in education principles":`There is significant appetite here:
\u201CUsing smart technology to innovate new ways to provide training, revolutionize teaching methods, improve academic administration, and build an intelligentized, networked, personalized, lifelong education system are important measures for promoting the development of balanced education, educational equity, and increased education quality. It is an indispensable driver of and support for educational modernization.\u201D (p 2)

What does it want to do with AI in education?
\u201CPromote the development of intelligent education. Promote educational and teaching reform. Move towards a smart campus model based on digital campuses. Create a technology-enabled teaching environment. Explore new AI-based teaching models. Reconstruct how teachers teach, using AI to monitor the teaching process, analyze students, and assess attainment levels. Set up comprehensive, multi-dimensional, big data-based smart assessments. Accurately evaluate both teacher and student performance. Institute individualized aptitude-based curricula. Promote academic administration reform. Support schools\u2019 use of AI technology to modify their organizational structures and management systems and optimize how they operate and serve their students. Implement delicacy management and personalized service on campuses to completely upgrade schools\u2019 administrative levels. Promote lifelong online learning, encourage the development of student-centric intelligentized learning platforms, provide a rich variety of personalized learning resources, innovate how services are provided, and tailor lifelong learning.\u201D (p 10)
\u201CDemonstrating the application of AI in intelligent education. Accelerate and promote the deep integration and innovative development of AI in education. Research strategies, standards, and specifications for developing intelligent education. Explore channels and methods for integrating AI technology into the educational environment, teaching models, curricula, teaching methods, academic administration, educational assessment, and educational research. Develop an intelligentized, cloud-based education platform and encourage new ways of teaching that are supported by AI to modernize education from the ground up.\u201D (p 11)`,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"N/A","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CUsing smart technology to innovate new ways to provide training, revolutionize teaching methods, improve academic administration, and build an intelligentized, networked, personalized, lifelong education system are important measures for promoting the development of balanced education, educational equity, and increased education quality. It is an indispensable driver of and support for educational modernization\u201D (p 2)","General principles on AI":["[N/A]"],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26851","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":2,Title:"China: AI Innovation Action Plan for Institutions of Higher Education","Translation Comments":"Official Translation Obtained"},id:"i-SE9pMo8wjZ",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-SE9pMo8wjZ",name:"China: AI Innovation Action Plan for Institutions of Higher Education",index:61,createdAt:"2024-05-30T01:15:57.142Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-SE9pMo8wjZ"},{values:{"Category of creator":["IO"],"Policy creator":["UNESCO"],"Policy Name":"Beijing Consensus on AI and Education","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"It is difficult to think of a more relevant document than this. It is all about AI empowering teachers, helping manage schools, and so on. ","Relevance Type":["Policy is about AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Managing bias. The risk of bias should be managed with care. "],"Governance practices employed":"","Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["W020190828311234688933.pdf"],"Key quotes on AI in education principles":`Opportunities:
\u201CWe are committed to leading appropriate policy responses aimed at the systematic integration of AI and education to innovate education, teaching and learning, and at leveraging AI to accelerate the delivery of open and flexible education systems that enable equitable, relevant and quality lifelong learning opportunities for all that will contribute to achieving the SDGs and the shared future for mankind.\u201D (p 3)
Talks about AI for education management and delivery
\u201C10. Be cognizant of the breakthrough in the use of data in transforming evidence-based policy planning processes. Consider integrating or developing AI technologies and tools that are relevant for upgrading education management information systems (EMIS) in order to enhance data collection and processing, making education management and provision more equitable, inclusive, open and personalized. \u201C
\u201C11. Consider also introducing new models for delivering education and training in different learning institutions and settings that can be enabled by the use of AI, in order to serve different actors such as students, teaching staff, parents and communities\u201D (p 5)
Talks about AI to empower teaching and teachers
\u201CBe mindful that while AI provides opportunities to support teachers in their educational and pedagogical responsibilities, human interaction and collaboration between teachers and learners must remain at the core of education...\u201D (p 5)
\u201CDynamically review and define teachers\u2019 roles and required competencies in the context of teacher policies, strengthen teacher training institutions, and develop appropriate capacity-building programmes to prepare teachers to work effectively in AI-rich education settings.\u201D (p 5)
Talks about AI for learning and assessment
\u201CBe cognizant of trends regarding the potential of AI to support learning and learning assessments\u201D... (p 5)
Augmentation not replacement
\u201CBe aware that teachers cannot be displaced by machines, and ensure that their rights and working conditions are protected\u201D (p 5)
Ethical, transparent, and auditable
See p 8

`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`Starts with a background statement:
\u201CWe also recognize the distinctive features of human intelligence. Recalling the principles set forth in the Universal Declaration of Human Rights, we reaffirm UNESCO\u2019s humanistic approach to the use of AI with a view towards protecting human rights and preparing all people with the appropriate values and skills needed for effective human\u2013machine collaboration in life, learning and work, and for sustainable development.\u201D (p 4)
Moves on to more significant propositions:
\u201CCoordinate collective actions to promote the equitable use of AI in education in the context of the global and regional Education 2030 architecture, including through sharing AI technology, programmes and resources for capacity-building, with due respect for human rights and gender equality\u201D (p 9)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`\u201CRecalling the Qingdao Declaration adopted in 2015 on leveraging information and communication technology (ICT) to achieve SDG 4, which stated that emerging technologies must be harnessed to strengthen education systems, access to education for all, quality and effective learning, and equitable and more efficient service provision, we are cognizant of the urgency of reaffirming and renewing this commitment as we move towards an era characterized by the widespread application of AI.\u201D (p 3)
The main section on equity comes later:
\u201C22. Reaffirm that ensuring inclusion and equity in and through education, and offering lifelong learning opportunities to all, are the cornerstones of achieving SDG 4 \u2013 Education 2030. Reaffirm that technological breakthroughs in the field of AI in education are an opportunity to improve access to education for the most vulnerable groups.\u201D (p 7)
\u201C23. Ensure that AI promotes high-quality education and learning opportunities for all, irrespective of gender, disability, social or economic status, ethnic or cultural background, or geographic location. The development and use of AI in education should not deepen the digital divide and must not display bias against any minority or vulnerable groups.\u201D (p 7)
\u201C24. Ensure that AI tools in teaching and learning enable the effective inclusion of students with learning impairments or disabilities and those studying in a language other than their mother tongue.\u201D (p 7)
Etc`,"General principles on AI":["[N/A]"],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27218","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"UNESCO: Beijing Consensus on AI and Education","Translation Comments":""},id:"i-0pzKRyXc_Y",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-0pzKRyXc_Y",name:"UNESCO: Beijing Consensus on AI and Education",index:56,createdAt:"2024-05-30T01:15:43.255Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-0pzKRyXc_Y"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Bulgaria"],"Policy Name":"Concept for the Development of AI in Bulgaria until 2030","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is broad acknowledgment that AI will contribute to modernisation of schools, but also generally relevant governance norms. ","Relevance Type":["Policy makes fleeting reference to AI in education","Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. ","Human rights-centred. The technology must be consistent with human rights. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Communicates a stance. It expresses a hope for the future of AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["conceptforthedevelopmentofaiinbulgariauntil2030.pdf"],"Key quotes on AI in education principles":`The document makes some general remarks regarding the importance of AI education (curriculum) in primary and secondary schools in meeting skills requirements, as well as development of AI-focused university programs (including for noting, but not relevant to current project):
\u201CA key role for the development and implementation of AI is the availability of human potential: specialists who are familiar with the latest discoveries and trends in the field, to master methods and tools for scientific research, implementation in practice and teaching, or to be able explain the benefits of adopting intelligent systems for widespread use.
More relevant content \u2014 
General governance norm: 
\u201CSpecial attention to the study of the impact of AI on society, as well as to the standards for building reliable AI. This suggests, on the one hand, the inclusion in the university educational programmes in informatics and technical specialties of academic disciplines focused on the legal, ethical and social aspects of AI, and on the other hand, the inclusion of disciplines for researching the impact of AI in the schools of social sciences, legal sciences and humanities.\u201D (p 37)
Other norms include preparing students to understand the risks of the technology, which is relevant:
\u201CIncreasing students' competencies in the field of ethical issues related to the use of information technology and their rights in the digital world in which they live.\u201D (p 36)
Relevant to opportunity: 
\u201CApplying AI tools in education to increase the quality, attractiveness and efficiency of the educational process, while strictly observing the protection of fundamental rights and proper consideration of the vulnerable situation of children.\u201D (p 36)
\u201CImplementing AI in university management. Given the breakthrough in the use of data to transform planning processes, to develop and integrate AI technologies and tools that are important for improving education management information systems (EMIS) to optimize data collection and processing to achieve a fairer, more inclusive, open and personalized education.\u201D (p 37)
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":`\u201CIt must create a unique "trust ecosystem" by ensuring compliance with EU rules, including those for the protection of fundamental human rights and consumer rights, especially in relation to high-risk AI systems.\u201D (p 31)
\u201CReliable AI presupposes the development of a legal framework to ensure that the fundamental rights of citizens are preserved, including ensuring product safety and determining legal liability.\u201D (p 16)
\u201CThe principles of respect for fundamental rights, non-discrimination and the protection of personal data should be seen as an integral part of the requirements that ensure the safety of AI technologies.\u201D (p 40)
\u201CTo provide the necessary conditions for ensuring the development of reliable AI technologies in Bulgaria, an assessment of the applicability and effectiveness of the existing regulations on guaranteeing the fundamental rights of citizens and the safety of new products, including AI technologies, as well as the methodology for licensing these products and putting them into operation.\u201D (p 41)`,"Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Bias testing. AI systems should be tested for bias. ","Human rights-centred. AI systems should be compatible with human rights. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26500","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Bulgaria: Concept for the Development of AI in Bulgaria until 2030","Translation Comments":"N/A - English"},id:"i-ks1e65Ehoi",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-ks1e65Ehoi",name:"Bulgaria: Concept for the Development of AI in Bulgaria until 2030",index:62,createdAt:"2024-05-30T01:05:01.550Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-ks1e65Ehoi"},{values:{"Category of creator":["OECD","OECD","OECD","OECD","OECD"],"Policy creator":["France","Italy","Ireland","Luxembourg","Slovenia"],"Policy Name":"AI4T","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This is highly relevant \u2014 about preparing teachers to embrace AI in education / ensuring that have the skills to manage it. Note that it is France and others. 
AI4T - Artificial Intelligence for and by teachers | France Education international (france-education-international.fr)

Here is a link to the textbook, which I have included as a secondary source:
AI for Teachers \u2014 Textbook`,"Relevance Type":["Policy is about AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary"],"Principles on AI in education":["Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Develops tools. It provides tools and place them in the hands of businesses or governments"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["AI4T - Artificial Intelligence for and by teachers _ France Education international.pdf"],"Key quotes on AI in education principles":`\u201CAt the end of the project, the aim is that teachers will become more confident and aware users of AI-based resources, which will help them to improve their practice. In addition, AI4T is contributing to the implementation of new teaching methods in the classroom and to the informed use of AI as a decision-making aid. A European network is being set up to share experience and best practice.\u201D (no pinpoint)

Note that they actually built a textbook:
Textbook \u2013 AI4T project`,"Does the policy reflect the principle of human rights compatibility?":"","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"","Key quote on equity/equality":"","General principles on AI":["[N/A]"],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":13,Title:"FranceItalyIrelandLuxembourgSlovenia: AI4T","Translation Comments":"Translation Completed (Google Translate)"},id:"i-NzS1c7nWDB",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-NzS1c7nWDB",name:"FranceItalyIrelandLuxembourgSlovenia: AI4T",index:441,createdAt:"2024-05-29T08:20:33.114Z",updatedAt:"2024-06-04T22:38:02.206Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-NzS1c7nWDB"},{values:{"Category of creator":["OECD"],"Policy creator":["Chile"],"Policy Name":"Smart Job Retraining","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This is more promising \u2014 it is about providing \u201Ctools that help [citizens] in the process of job retraining\u2019. IDB | Smart Job Retraining (iadb.org)
It is not entirely clear what the \u2018machine learnin\u2019 component is. `,"Relevance Type":["Policy contains case studies on AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Vocational or Professional"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Develops tools. It provides tools and place them in the hands of businesses or governments"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["[N/A]"],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27049","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":`TC \u201Caims at designing a technological platform called "Intelligent Labor Retraining" or RELINT (in Spanish), based on a data intelligence model that allows companies and individuals to be guided in the process of retraining. On the one hand, supporting companies in a digital transformation process by introducing reskilling, upskilling and outplacement mechanisms and, on the other hand, allowing workers to improve their skills for a new type of company or to start a new labor route. This is done by linking interests, experience and employability potential with the demand that the market is requesting for new skills derived from the ongoing digital transformation.\u201D
`,"Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":10,Title:"Chile: Smart Job Retraining","Translation Comments":""},id:"i-H3DXVgh09v",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-H3DXVgh09v",name:"Chile: Smart Job Retraining",index:77,createdAt:"2024-05-29T04:38:15.161Z",updatedAt:"2024-06-06T03:05:20.882Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-H3DXVgh09v"},{values:{"Category of creator":["OECD"],"Policy creator":["Belgium"],"Policy Name":"AI 4 Belgium","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`These guidelines have a section of \u201CAI as an education tool\u201D. Definitely translate the broader policy document to check for relevant content\u2014but if not, you can firmly say that, in principle, the Belgium government supports two use cases:
Deploy AI as a tool for individualised training adapted to each individual student 
Apply AI as a tool for teachers to enhance their teaching`,"Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["report_en.pdf"],"Key quotes on AI in education principles":"Note \u2014 the existence of risk is recognised, but this is a predominantly \u201Cseize the day\u201D policy. ","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"N/A","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CFinally, AI can also be a tool in education. It can drastically improve quality and equity in many cases.\u201D","General principles on AI":["Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (explainability). AI systems should be sufficiently explainable.","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Interoperability. AI systems should be able to work with other systems. ","Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24234","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":3,Title:"Belgium: AI 4 Belgium","Translation Comments":"Translation Needed"},id:"i-zLeK3YsXOk",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-zLeK3YsXOk",name:"Belgium: AI 4 Belgium",index:88,createdAt:"2024-05-29T03:41:10.073Z",updatedAt:"2024-06-03T02:37:13.450Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-zLeK3YsXOk"},{values:{"Category of creator":["OECD"],"Policy creator":["Mexico"],"Policy Name":"Website for Personal Data Protection Impact Assessments","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a really cool, interactive impact assessment tool worth noting (though not for AI per se \u2014 focuses on data protection). A version of this could be developed for EdTech, whether the data protection aspect or otherwise. Am I required to file a DPIA? \u2013 EIPDP (inai.org.mx) ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27479","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":`This kind of system could be useful \u2014 an impact assessment tool of sorts. 
image.png`,'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":10,Title:"Mexico: Website for Personal Data Protection Impact Assessments","Translation Comments":"Translation Needed"},id:"i-1xjaXeD9Ml",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-1xjaXeD9Ml",name:"Mexico: Website for Personal Data Protection Impact Assessments",index:417,createdAt:"2024-05-29T03:06:42.064Z",updatedAt:"2024-06-03T04:55:12.590Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-1xjaXeD9Ml"},{values:{"Category of creator":["OECD"],"Policy creator":["Hungary"],"Policy Name":"Hungary\u2019s AI Strategy","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Locating this document was a bit of a nightmare. In any case, it\u2019s out there and in English, which is convenient (for us). There is a fair bit of relevant content\u2014including reference to \u201CAI-supported education\u201D. It is committed to: \u201Cintensive use of AI technologies in the developments associated with data management in higher education\u201D (p 31). ","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Plans further action. It sets out a strategy on AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["Hungary\u2019s Artificial Intelligence Strategy.pdf"],"Key quotes on AI in education principles":`Under \u201CObjectives by 2030 directly affecting citizens\u201D, it notes that \u201C2.5 million citizens benefit from AI-supported education\u201D (p 20)
\u201CThe aim is to collect, promote and make available Hungarian language versions of personalised learning support products available internationally for people at risk of falling behind (disabled, elderly, digital illiterates, those with a low level of education), using AI technologies, as well as to identify and provide priority development and support for talented people from an early age. \u2022 International collection and Hungarian translation of guidance material prepared for the groups at risk of falling behind in the labour market.
Continuous dialogue on the development results and the special demands that may be formulated as the development goals.
Introducing games for improving high-level mathematical and logical skills from an early age and identifying talented children and teenagers. 
Provision of mentors and tutors; online and in-person training for recognised talents and providing support for them beyond the school system.\u201D (p 31)

\u201CIntensive use of AI technologies in the developments associated with data management in higher education.\u201D (p 30)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":`\u201CA general regulatory environment needs to be put in place for data assets with functions such as supporting the AIrelated use of public data assets and facilitating the process of turning data into assets (assetization), together with the development of the relevant financial and legal regulations \u2013 taking into account the various sectors\u2019 specificities and responsibilities in terms of data processing, as well as the relevant fundamental rights and the international framework of data regulations. 
Creation of a framework law on data assets. 
Introduction of a sector-specific regulatory environment to enable data to be turned into assets and their use for purposes of AI. 
Developing rules to govern the use of public data, along with a concept for and rules on their assetization.\u201D (p 34)

\u201CThe goal is to enable citizens to participate, as active and responsible actors, in the data economy where the secondary use of data takes place and to exercise their fundamental rights relating to the protection of personal data. To this end, they need to be enabled to dispose over data pertaining to them and to participate actively and securely in the secondary use of such data.\u201D (p 43)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about AI as a tool for promoting equitable/equal access","Key quote on equity/equality":"\u201CInclusion and talent coaching for groups at risk of falling behind in the labour market The aim is to collect, promote and make available Hungarian language versions of personalised learning support products available internationally for people at risk of falling behind (disabled, elderly, digital illiterates, those with a low level of education), using AI technologies, as well as to identify and provide priority development and support for talented people from an early age.\u201D (p 31)","General principles on AI":["Augmentation, not replacement. AI systems should augment, not displace, workers.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26765","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Hungary: Hungary\u2019s AI Strategy","Translation Comments":"N/A - English"},id:"i--PZ-g1Dix2",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i--PZ-g1Dix2",name:"Hungary: Hungary\u2019s AI Strategy",index:94,createdAt:"2024-05-29T02:46:55.324Z",updatedAt:"2024-06-03T00:01:55.281Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui--PZ-g1Dix2"},{values:{"Category of creator":["OECD"],"Policy creator":["Turkiye"],"Policy Name":"Human-Centred AI for Human Resources","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The policy initiative here was to produce guidance on AI in HR. Similar issues are raised in education (hiring, admissions, etc) so it is worth including this. Might need to add some new \u201CAI in education principles\u201D. Also note the \u201Ccreated from the Human-Centred Artificial Intelligence for Human Resources project.\u201D","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Develops tools. It provides tools and place them in the hands of businesses or governments","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["WEF_Human_Centred_AI_for_HR_2021.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CIn addition to being a target specifically for the regulation of AI, HR already operates in a highly regulated space. Most countries have numerous labour laws that would apply to AI-based HR tools. In some ways, this existing regulation may already be providing safeguards and even useful guidance. For instance, a number of countries already have anti-discrimination regulations on employment decisions and hiring tests, which include a recognition that such practices can have unintended discriminatory effects (known as adverse impact or indirect discrimination)\u201D (p 15)","General principles on AI":["Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27318","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":10,Title:"Turkiye: Human-Centred AI for Human Resources","Translation Comments":"N/A - English"},id:"i-OX3xS8Y5MT",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-OX3xS8Y5MT",name:"Turkiye: Human-Centred AI for Human Resources",index:108,createdAt:"2024-05-29T01:42:21.376Z",updatedAt:"2024-06-05T21:37:17.815Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-OX3xS8Y5MT"},{values:{"Category of creator":["OECD"],"Policy creator":["Turkiye"],"Policy Name":"National AI Strategy","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Most of this strategy is about \u201CAI education\u201D, but there is an initiative in here about education technology.","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["TRNationalAIStrategy2021-2025.pdf"],"Key quotes on AI in education principles":`\u201CThe Education Technologies Incubation and Innovation Center will be implemented in 2021 by the Ministry of National Education, General Directorate of Innovation and Education Technologies, within the scope of the World Bank's \u201CSafe Schooling and Distance Education Project\u201D. The Center will operate in METU Technopolis and will work in cooperation with the public-private sector. Within the scope of the project, an innovation ecosystem in education will be developed, and through this ecosystem, new digital tools and pedagogical models will be developed and released, and blended education processes will be supported through the cooperation of various stakeholders. In this direction, working groups for AI education will be established, capacity building activities and R&D activities will be carried out for AI applications in education.\u201D (p 54)
The rest of the content is about teaching AI as a discipline (quite different to using AI to teach). 
This policy does not make it clear which principles will govern this specific EdTech initiative, so the broad principles expressed in this document will only be included below (under general principles). [CF my analysis of the Netherlands Strategy or the EU AI Act, where it is made clear that broad principles expressed extend to AI in education.]`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`Expressed generally, but not specifically in relation to EdTech:
\u201CThe implementation of AI technologies also raises privacy and national security concerns in many cases. In addition, the widespread use of AI-powered autonomous or semi-autonomous decision-making mechanisms raises ethical problems such as the protection of human rights and the prevention of discrimination. Therefore, building an effective AI ecosystem requires establishing an appropriate ethical and legal framework that takes into account the technological nature of AI\u201D (p 15)
\u201CThe OECD Council Recommendation on Artificial Intelligence, to which our country is also a party, was adopted on 22 May 2019 in order to strengthen the global AI policy ecosystem that respects human rights, democratic and ethical values.1 These principles, supported by the EU, were soon adopted by the G20 as well. The document also provides recommendations for international cooperation on trustworthy AI.\u201D
\u201CHuman dignity, human rights and fundamental freedoms must be essential throughout the lifecycle of AI systems. All AI technologies to be developed in our country should be designed in compliance with national ethical values and by prioritizing human rights, democratic values and the rule of law so that all members of society can benefit from such technologies. No human should be harmed physically, economically, socially, politically or psychologically at any stage in the lifecycle of AI systems. In interactions with AI systems throughout their lifecycle, people should never be objectified, their dignity should never be harmed, and human rights should never be violated or abused.\u201D (p 59)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`This strategy uses the language of \u201Cfairness\u201D. The concept is not specifically used in relation to AI in education, but generally:
\u201CFairness AI systems should be designed to provide an equal and fair service to all stakeholders while adhering to the rule of law and fundamental rights and freedoms. The fairness of AI systems means that the benefits of AI technology are shared at local, national and international levels, while taking into account the specific needs of different age groups, different cultural systems, different language groups, people with disabilities, and disadvantaged, marginalized and vulnerable segments of the society. It should be ensured that decisions made based on algorithms do not give rise to discriminatory or unfair effects on different demographic populations. In order to prevent the emergence of unintentional discrimination in decision-making processes, monitoring and accountability mechanisms should be developed and those mechanisms should be included in the implementation process.\u201D (p 60)`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Environmental wellbeing. The use of AI should not harm the environment. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26590","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`\u201CAn impact analysis framework will be established to monitor and evaluate the level of implementation of AI values and principles\u201D (p 73)
On collaborative development and interoperability:
\u201CThe participation of different stakeholders throughout the lifecycle of AI systems is essential for inclusive and agile AI governance, the benefits of AI passing through society, and for AI to contribute to technological progress and development. Stakeholders of AI systems include public institutions, NGOs, international organizations, researchers, academia, media, educators, policy makers, the private sector, human rights institutions, and other bodies established for the youth and children. It is important to adopt open standards and interoperability to facilitate collaboration among AI stakeholders. Agile governance measures should be taken in line with technological developments and new sociotechnical needs.\u201D (p 61)
Procurement:
It makes reference to the WEF\u2019s Procurement toolkit:
\u201CThe WEF has developed and piloted common tools for governments to deliver AI solutions built with ethical principles in mind. The AI Procurement Toolkit for the Public and Private Sector prepared for this purpose includes concrete recommendations on purchasing, risk assessments, proposal drafting and evaluation.34 In addition, a toolkit for recruitment, performance evaluation and promotion is being developed with the contribution of public institutions and private sector organizations in our country in order to base the use of AI applications in human resources on human-centric and ethical values.\u201D  (p 31)
Later it expressly says:
\u201CThe commercialization of developed AI solutions will be supported by prioritizing them in public procurement.\u201D (p 69)
Could we infer that it recognises the normative influence procurement exerts? Or is it simply saying that it will support R&D here, and not delving into ethics? I have assumed the latter. `,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"One of the more progressive strategies I have seen. Have these ideals been realised in practice?",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Turkiye: National AI Strategy","Translation Comments":""},id:"i-JGZxJmkxIv",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-JGZxJmkxIv",name:"Turkiye: National AI Strategy",index:114,createdAt:"2024-05-29T00:58:49.546Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-JGZxJmkxIv"},{values:{"Category of creator":["OECD"],"Policy creator":["Lithuania"],"Policy Name":"AI Strategy","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is a generally relevant collection of policies from p 8, but all of the education-related content concerns preparing people for a life with AI \u2014 education for AI \u2014 rather than AI in education. Including this on the basis of the broadly applicable principles. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Plans further action. It sets out a strategy on AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["Lithuania_Artificial_Intelligence_Strategy_2019.pdf"],"Key quotes on AI in education principles":"All of the education-related content concerns preparing people for a life with AI \u2014 education for AI \u2014 rather than AI in education.","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":`\u201CTo ensure that we stay on the right track, a human-centric approach to AI is needed. Trustworthy AI has two components: (1) ethical purpose - it should respect fundamental rights, applicable regulation and core principles and values and (2) it should be technically robust and reliable since, even with good intentions, a lack of technological mastery can cause unintentional harm.\u201D (p 8)

\u201CPrinciple 1: To advice the public sector on ethical AI regulation and implementation. Mechanism: Establish AI ethics committee that reviews impact of technology on fundamental rights.\u201D (p 8)`,"Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Interoperability. AI systems should be able to work with other systems. ","R&D. Sufficient resources should be invested in AI R&D.","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Opportunity. The opportunities of AI should be harnessed."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24220","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Lithuania: AI Strategy","Translation Comments":""},id:"i-4u9qJ87NTG",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-4u9qJ87NTG",name:"Lithuania: AI Strategy",index:118,createdAt:"2024-05-29T00:52:23.424Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-4u9qJ87NTG"},{values:{"Category of creator":["OECD"],"Policy creator":["Slovakia"],"Policy Name":"Action Plan for the Digital Transformation of Slovakia","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This makes reference to support for AI-based tools in education, and \u2014 more generally \u2014 using \u201Cdigital technologies for innovations and improvement of the quality of education\u201D (p 21)","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["AP-DT-English-Version-FINAL.pdf"],"Key quotes on AI in education principles":`Opportunity
\u201Cwe will support the use of digital technologies in order to increase the success of the process of education\u201D (p 20)
\u201CWe will support innovation capacity and introduction of solutions built on artificial intelligence, in particular, at the level of SMEs. Therefore, we will set up a network of digital innovation centres and improve possibilities of cooperation with the academic sector in applied research in the field of artificial intelligence, which is significantly based on source data. At the same time, we will support new business models in the digital economy, in order to make conditions in Slovakia for the rise of platforms transforming standard sectors, such as transport, finance, health care and education. It means setting up \u201Cregulatory sandboxes\u201D, introducing \u201Cfuture-proof regulations\u201D and redesigning permits for the needs of the digital era.\u201D (p 32)
\u201CSupport increasing higher and specialised skills for IoT, data science, artificial intelligence, programming, for the needs of STEM studies (science, technology, engineering and mathematics), team work and collaborative and co-creative procedures, creative designing and trading as well as other fields of economy and public administration due to their digital transformation,\u201D (p 27)
Do not consider education holistically \u2014 no reference to privacy risks specifically in education, for instance. 
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":`Two key references:
\u201CThe intent of the Action Plan also encompasses building trust of persons using digital technologies, ensuring protection of shared data and setting conditions for creating responsible and adequate process of digital transformation. Specific attention in implementation of proposed measures of this Action Plan will be paid to protection of fundamental rights and freedoms of natural persons, in particular right to privacy in connection to personal data processing and compliance with requirements put on personal data protection in relevant European3 as well as national legislation4 .\u201D (p 16)
\u201CIt is necessary to make sure that selected methods are reliable, they are primarily not intended for activities aimed at damaging humans, their rights and freedoms,\u201D (p 65)`,"Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`It speaks about:
\u201CFair access to technologies for all groups of population (justice, non-discrimination)\u201D (p 65)`,"General principles on AI":["Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (explainability). AI systems should be sufficiently explainable.","R&D. Sufficient resources should be invested in AI R&D.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Human rights-centred. AI systems should be compatible with human rights. ","Opportunity. The opportunities of AI should be harnessed.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25880","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`\u201CPrinciple of not causing harm \u2013 to assets, health, social status, etc.,\u201D (p 65)
\u201CTransparency and controllability of system using AI, comprehensibility of basic principles of functioning for the general public (application of the informed consent principle),\u201D (p 65)
Impact assessment:
The intent of the Action Plan also encompasses building trust of persons using digital technologies, ensuring protection of shared data and setting conditions for creating responsible and adequate process of digital transformation. Specific attention in implementation of proposed measures of this Action Plan will be paid to protection of fundamental rights and freedoms of natural persons, in particular right to privacy in connection to personal data processing and compliance with requirements put on personal data protection in relevant European3 as well as national legislation4 . Before the process of implementation of those measures referred to in this Action Plan, when personal data is processed (in particular setting up and deployment of new information systems and technologies), the data protection impact assessment will be made in the sense of Art. 35 of the General Data Protection Regulation and prior consultation with the supervisory authority will be used in the sense of Art. 36 of the General Data Protection Regulation prior to the data processing, if the data protection impact assessment implies that such processing could lead to high risk unless the controller adopts measures to mitigate the risk. (p 16-17)
(This is a narrow impact assessment)`,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Slovakia: Action Plan for the Digital Transformation of Slovakia","Translation Comments":""},id:"i-Jzg5JOd1pY",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-Jzg5JOd1pY",name:"Slovakia: Action Plan for the Digital Transformation of Slovakia",index:119,createdAt:"2024-05-29T00:39:04.985Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-Jzg5JOd1pY"},{values:{"Category of creator":["OECD"],"Policy creator":["Greece"],"Policy Name":"Generative AI Greece 20230 \u201CFuture of Generative AI in Greece\u201D","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This report is interesting and bold. It recognises that autonomous education applications could be hugely significant. This is definitely worth coming back to.","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary","Vocational or Professional"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Seeks information. It gathers inputs on public sentiment about AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Educates. It helps officials or others understand the opportunities and risks of AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["Gen_AI_Greece_EN_s.pdf"],"Key quotes on AI in education principles":`Opportunity:
\u201CFocusing even at the classroom level, NLP has the potential to enhance the educational process in various ways. At the international level, in a recent report by the IE University Center for Governance1, in the section concerning education, among the scenarios discussed regarding the future of the educational process with the introduction of NLP, a scenario emerged with a significant margin, suggesting the existence of potential (virtual) classrooms where an AI tutor facilitator will play a significant role, while NLP will be utilized to facilitate the creation of potential virtual experiences outside the classroom environment, thus making the educational process more empirical in this specific sense. It is within its technological capabilities for NLP to operate as an assistant to teachers in the classroom, offering students a better understanding of subjects by creating notes, reports, diagrams, and lesson summaries. According to the estimation of Konstantinos Karpouzis, Associate Professor at the Department of Communication, Media and Culture of the Panteion University, "the integration of NLP into the educational system through the production of personalized content, descriptive assessment, and the use of its tools for the education of students and teachers in new technologies" is one of the greatest opportunities.\u201D (p 45)
This is interesting too \u2014 lifelong learning:
\u201CAn opportunity for the Greek reality could also be the enhancement of lifelong learning and adult education in general. One of the main benefits of NLP in lifelong learning is its ability to provide personalized educational experiences. Traditional education usually follows a "one size fits all" model, where students are expected to learn at the same pace and in the same way, which is incompatible with adult learners who have unique needs and learning preferences. NLP can analyze large amounts of data on the strengths, weaknesses, and learning styles of a student to create a personalized learning plan.\u201D (p 45)

Note that principles concerned with risks are not addressed at this lower level of abstraction (education-specific) \u2014 see below. `,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":`\u201CThrough the establishment of proactive monitoring and control mechanisms, systematic and effective monitoring of the implementation of ethical guidelines and legislation will be feasible, ensuring that AI is used in a way that respects human rights and the demand for individual and social well-being. Overall, this approach concerns the preparedness of Greek society for the development of AI in a just and sustainable manner, while promoting innovation and growth in this sector. It also involves strengthening the necessary "institutional triangle" between digital governance, digital regulation, and digital ethics\u201D (p 105)
\u201CThere is a need to provide a framework of broader universal political guidelines and standards for developers and AI users to ensure that their systems are designed and used ethically. This includes principles such as transparency, justice, and the protection of privacy and human rights.\u201D (p 27)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`Increasing equality
\u201CFurthermore, NLP capabilities can be particularly beneficial in special education, where it can be tailored to students' specific difficulties, creating real-time lessons tailored to their individual needs108. 109 Additionally, natural language learning and teaching systems can assess students' levels of knowledge, identify gaps in their understanding, and then address them through personalized learning materials and explanations.\u201D (p 45)
\u201CThe guidelines should reflect both societal values and general ethical principles, promoting excellence and safety, transparency and innovation, human benefit, and the fight against digital (or algorithmic) social discrimination and inequalities, as well as human control.\u201D (p 104)
Augmenting inequality
\u201CThe tendency of AI systems to perpetuate or even exacerbate existing biases, prejudices, and inequalities poses a significant ethical challenge.\u201D (p 82)`,"General principles on AI":["Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Bias testing. AI systems should be tested for bias. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","R&D. Sufficient resources should be invested in AI R&D.","Opportunity. The opportunities of AI should be harnessed.","Interoperability. AI systems should be able to work with other systems. ","Human rights-centred. AI systems should be compatible with human rights. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27603","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`Note that these are framed as \u201Crisks\u201D rather than principles, but there are implicit normative ideas within the text. 

Cyber security:
They speak of \u2018adversarial attacks\u2019
AI models may be susceptible to adversarial attacks. Adversarial attacks are deliberate modifications to input data that attempt to compromise the performance of an AI model, and this can also affect AI models. Adversarial attacks can have unintended consequences, such as compromising image creation in an AI model by adding small modifications to input data, thus leading to undesirable outputs (such as misleading images or images containing unwanted information, e.g., reproduction of stereotypes, etc.) (p 65)`,"Notable Case Studes - Examples of AI in Education":'Before delving into specific possibilities of future application, it may be worth mentioning that in recent years there have already been examples of utilizing the capabilities of NLP and AI in the digital educational industry through metrics linking it to qualifications certification and the job market. The intersection of work capabilities and educational skills is now emerging as a privileged investment field98. It is worth noting that in the international educational industry, the development of platform economy models has favored an algorithmically oriented "demand-driven education," competency-based education, using NLP to develop predictive talent analytics, to match students and graduates with potential career paths through matching tools. This technological capability is offered to them to integrate into the constantly evolving job market (between learning and earning). Based on mass-collected data from educational platforms, from reports on the completion of digital asynchronous educational programs and skills certification tests, the goal pursued is now to shape some algorithmic matching models of successful course completion cycles with professional performance indicators in the job market. (p 42)',"Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Greece: Generative AI Greece 20230 \u201CFuture of Generative AI in Greece\u201D","Translation Comments":""},id:"i-JhOfOAT4Ya",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-JhOfOAT4Ya",name:"Greece: Generative AI Greece 20230 \u201CFuture of Generative AI in Greece\u201D",index:121,createdAt:"2024-05-28T23:25:29.038Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-JhOfOAT4Ya"},{values:{"Category of creator":["OECD"],"Policy creator":["Poland"],"Policy Name":"Policy for the Development of Artificial Intelligence in Poland from 2020","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a super interesting policy. Poland is proud of its PISA results and sees AI as being an essential tool for \u201Cboosting\u201D its strong position. The fourth pillar of its strategy is titled AI and Education (see p 42). Bold vision expressed \u2014 worth analysing further. ","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Trust. Organisations seeking to incorporate AI into educational settings must build trust.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["Poland_Policy_for_Artificial_Intelligence_Development_in_Poland_from_2020_2020.pdf"],"Key quotes on AI in education principles":`Opportunities
\u201CThe issues of AI-related skill development and the use of AI-based tools in educational processes are the key issues of the Integrated Skills Strategy 2030 in Poland, which is currently undergoing development.\u201D (p 23)
\u201Censuring high availability of educational tools in Poland, including online tools, enabling all people who want to get educated in the field of AI to gain knowledge, both theoretical and practical.\u201D (p 42)
Teacher training:
\u201Cintensification of the use of tools and embedded systems in education, accompanied with training for teachers in their proper use in the teaching process;\u201D (p 43)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201CAnalysis of the ethical ramifications of AI implementation and the impact of AI systems on the sphere of human rights\u201D (p 25)
\u201Cassessing the societal impact of AI-based systems (in particular the impact on human rights and freedoms) and developing methods for their independent auditing, according a predefined manner and scope;\u201D (p 25)
\u201CPoland\u2019s continued activity in the Council of Europe in the initiative to develop recommendations for AI with regard to the protection of human rights, the rule of law and democracy.\u201D (p 25)
\u201Cinternational activities that will support the promotion of Polish business in the field of AI and the development of AI technologies that respect human dignity and fundamental human rights, in accordance with EU and OECD standards, as well as digital diplomacy activities in the area of policies or regulations concerning artificial intelligence\u201D (p 6)
Additional material on fundamental rights (see, eg, p 23)`,"Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`Fairness
\u201Cdiversity, non-discrimination and fairness\u201D (p 63)
Equality
\u201CArtificial intelligence is redefining many professions due to process optimisation and automation, and as a result machines replace humans in doing standard and repeatable tasks on an unprecedented scale. This risks aggravating problems in socially and economically excluded regions, increasing unemployment, as well as exacerbating various forms of inequality and discrimination.\u201D`,"General principles on AI":["Trust. AI systems should not be used so as to undermine society\u2019s trust. ","R&D. Sufficient resources should be invested in AI R&D.","Human rights-centred. AI systems should be compatible with human rights. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Transparency (explainability). AI systems should be sufficiently explainable.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Environmental wellbeing. The use of AI should not harm the environment. ","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Bias testing. AI systems should be tested for bias. ","Interoperability. AI systems should be able to work with other systems. ","Opportunity. The opportunities of AI should be harnessed.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,"],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24268","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"Note Poland\u2019s aspiration: \u201CPoland is the European leader in education in AI and other digital technologies at secondary school level\u201D (p 45)",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Poland: Policy for the Development of Artificial Intelligence in Poland from 2020","Translation Comments":""},id:"i-z5-nxrhEvU",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-z5-nxrhEvU",name:"Poland: Policy for the Development of Artificial Intelligence in Poland from 2020",index:122,createdAt:"2024-05-28T23:21:18.902Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-z5-nxrhEvU"},{values:{"Category of creator":["OECD"],"Policy creator":["Luxembourg"],"Policy Name":"AI: A Strategic Vision for Luxembourg","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Very little is said about education, but what is said is about the promise of EdTech: \u201CIn the domain of education, AI could help in defining and generating personalized teaching/learning methods and tools, especially in the field of differentiated education.\u201D Worth noting. ","Relevance Type":["Policy makes fleeting reference to AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["AI_EN_0.pdf"],"Key quotes on AI in education principles":`\u201CWhile AI is not radically new, especially for Luxembourg\u2019s researchers, it is on the threshold of being accessible and applicable across industries and throughout society: digital health, finance, mobility, logistics, clean technologies, space and beyond \u2013 not to mention education, environment and art\u201D (p 8)
\u201CIn the domain of education, AI could help in defining and generating personalized teaching/learning methods and tools, especially in the field of differentiated education\u201D (p 14)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":"\u201CAs a diverse, innovative nation, we will decide what impact this technology will have on human rights, on people\u2019s lives and on our democratic values.\u201D (p 4)","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24335","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Luxembourg: AI: A Strategic Vision for Luxembourg","Translation Comments":""},id:"i-5t3qlI4mpu",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-5t3qlI4mpu",name:"Luxembourg: AI: A Strategic Vision for Luxembourg",index:123,createdAt:"2024-05-28T23:15:53.248Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-5t3qlI4mpu"},{values:{"Category of creator":["OECD"],"Policy creator":["Switzerland"],"Policy Name":"Guidelines on AI","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a pretty standard AI framework. Included in case of interest. Could be applied to AI in education. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["_Artificial Intelligence_ \u2013 Adoption of Guidelines for the Federal Government.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"\u201CPut people at the centre: The dignity and well-being of every individual, as well as the public interest, must be at the forefront of the development and use of AI systems. Particular attention is paid to the protection of fundamental rights in the use of AI.\u201D (p 1)","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Human rights-centred. AI systems should be compatible with human rights. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26987","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":5,Title:"Switzerland: Guidelines on AI","Translation Comments":"N/A - English"},id:"i-ptJWDz_6mV",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-ptJWDz_6mV",name:"Switzerland: Guidelines on AI",index:130,createdAt:"2024-05-28T23:11:48.516Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-ptJWDz_6mV"},{values:{"Category of creator":["OECD"],"Policy creator":["Czech Republic"],"Policy Name":"National AI Strategy of the Czech Republic","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This is one of the most EdTech-oriented strategies I have seen so far. See extracts below. 
`,"Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["NAIS_eng_web.pdf"],"Key quotes on AI in education principles":`Its strategic goals relating to AI in education are very opportunity-oriented:
\u201Crecommend universities to use AI for university management\u201D; (p 26)
\u201CImplementation of pilot projects for the management of higher education institutions and teaching methods at all levels of education using the principles of management of complex systems using AI\u201D (p 26)
\u201CFinancially support pilot projects for the management of higher education institutions and teaching methods at all levels of education using the principles of management of complex systems using AI\u201D. (p 27)
\u201CCompleting the transformation of education, including fully functional AI teaching in English in most relevant schools and the transformation of content and form of teaching with regard to the ongoing changes in the labour market and society\u201D (p 27)
One of the really interesting concrete initiatives for implementation:
\u201CSupport programme for the implementation of AI in education, including the use of tools for managing the transformation of education based on artificial intelligence\u201D (p 28)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":`Long-term objective (until 2035):
\u201CWe are going to prevent discrimination, manipulation and misuse of AI, we are going to set the rules for decision-making of algorithms about people in everyday life. We want artificial intelligence to serve all the people of Europe.\u201D (p 3)
\u201CA significant role in development will also be played by clear legislation, ensuring the protection of fundamental rights and security as well as legal certainty for investors (Chapter 6).\u201D (p 7)
\u201CSecuring standards primarily in the areas of security, personal data protection and the protection of fundamental rights in research, development and use of AI.\u201D (p 36)`,"Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`\u201CEnsuring equal opportunities and benefits brought about by economic development for the entire society ... the creation of an administrative and legislative framework for AI that avoids any form of discrimination or disadvantage, with a strong emphasis on rights and privacy;\u201D (p 8)
Assuming that by avoiding disadvantage, they mean ensuring substantive equality \u2014 i.e., the law is acting to ensure that people are equal (which is an outcome \u2014 i.e., within the province of equity)
\u201CPotential threats include deepening the problems in socially excluded regions, temporarily increasing structural and frictional unemployment, or deepening the various forms of inequality and discrimination\u201D (p 30)`,"General principles on AI":["Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Human rights-centred. AI systems should be compatible with human rights. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","R&D. Sufficient resources should be invested in AI R&D.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24171","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"Note: for procurement, it is actually doing the opposite to using procurement to drive compliance with standards. It talks about: \u201CRemoving legal barriers to AI development, including public law and, for example, public procurement.\u201D (p 36)","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Czech Republic: National AI Strategy of the Czech Republic","Translation Comments":"N/A - English"},id:"i-Qau2vIXd3P",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-Qau2vIXd3P",name:"Czech Republic: National AI Strategy of the Czech Republic",index:131,createdAt:"2024-05-28T21:30:35.552Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-Qau2vIXd3P"},{values:{"Category of creator":["OECD"],"Policy creator":["South Korea"],"Policy Name":"Human-Centred National Guidelines for AI Ethics","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a good general framework that could easily be applied to EdTech. Attached. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["The National Guidelines for AI Ethics _ The National Guidelines for AI Ethics _ INTRODUCTION _ \uC778\uACF5\uC9C0\uB2A5 \uC724\uB9AC \uC18C\uD1B5\uCC44\uB110.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`Under Principle 1 - Safeguarding Human Right
\u201CAI should be developed and utilized in a way that respects equal human rights and guarantees diverse democratic values and rights stipulated in international human rights laws and similar standards. 

AI should not be developed or utilized in a way that violates human rights and freedom\u201D (p 2)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`Under Principle 6 - Solidarity
\u201CDiverse stakeholders should be provided with equitable participation opportunities throughout the entire AI system lifecycle\u201D (p 3)
Under Principle 3 - Respect for Diversity
\u201CThe socially disadvantaged and vulnerable should be guaranteed access to AI technologies and services Efforts should be made to ensure equal distribution of AI benefits to all people rather than to certain groups\u201D (p 3) 
\u201CThroughout every stage of AI development and utilization the diversity and representativeness of the AI users should be ensured and bias and discrimination based on personal characteristics such as gender age disability region race religion and nationality should be minimized Commercialized AI systems should be generally applicable to all individuals\u201D (p 3)`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Human rights-centred. AI systems should be compatible with human rights. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27065","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":5,Title:"South Korea: Human-Centred National Guidelines for AI Ethics","Translation Comments":"N/A - English"},id:"i-RIW2LAshak",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-RIW2LAshak",name:"South Korea: Human-Centred National Guidelines for AI Ethics",index:404,createdAt:"2024-05-28T21:06:14.668Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-RIW2LAshak"},{values:{"Category of creator":["OECD"],"Policy creator":["South Korea"],"Policy Name":"National Strategy for AI","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is very little here about EdTech \u2014 just a few fleeting references. But in addition to these references, there is a general governance framework. This just scrapes through. ","Relevance Type":["Policy contains case studies on AI in education","Policy makes fleeting reference to AI in education","Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["Korea_National_Strategy_for_Artificial_Intelligence_2019.pdf"],"Key quotes on AI in education principles":`The key opportunities identified:
\u2018AI-powered English assistant teacher\u2019.
Also talks about \u2018[e]xpanding practical educational platforms for better accessibility to vocational training and providing various contents through a smart training platform (opened in Oct. 2019)\u2019 (p 46). 
However, I am not sure what it means by \u2018smart training platform\u2019 \u2014 thin on details`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"image.png","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["R&D. Sufficient resources should be invested in AI R&D.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26497","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"There is not much to say \u2014 it is just outlining the kinds of values it intends to explore. Up to this point, it had not built a robust AI ethics framework. ","Notable Case Studes - Examples of AI in Education":"\u2018AI-powered English assistant teacher\u2019 using technology assists English teacher classes through conversations and quizzes in English (checking speaking ability by students\u2019 (p 13)","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"South Korea: National Strategy for AI","Translation Comments":""},id:"i-LVovi9GBwR",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-LVovi9GBwR",name:"South Korea: National Strategy for AI",index:136,createdAt:"2024-05-28T21:05:37.383Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-LVovi9GBwR"},{values:{"Category of creator":["OECD"],"Policy creator":["Japan"],"Policy Name":"Governance Guidelines for Implementation of AI Principles","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Note that this document is an official translation. It was prepared by the Expert Group. As it happens, there is some really useful material in here. Could be applied to EdTech. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["20210709_9.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`A few questions asked in \u201CPractical Examples for Gap Analysis between AI Governance Goals and Current State: 
Did the AI developer give due consideration when designing the data set so that it would not entrench/impair any unfair discrimination based on certain social attributes?
Example: Did the AI system developer consider the possibility that unfair discrimination based on certain social attributes may be reproduced as a result of prioritizing the reproducibility of the real world?
Example: Did the AI developer ensure not to use any data set that could entrench/impair unfair discrimination based on certain social attributes, even at the cost of the reproducibility of the real world?\u201D (p 70)`,"General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27170","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":2,Title:"Japan: Governance Guidelines for Implementation of AI Principles","Translation Comments":""},id:"i-cdhpUfOZAa",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-cdhpUfOZAa",name:"Japan: Governance Guidelines for Implementation of AI Principles",index:144,createdAt:"2024-05-28T02:41:31.068Z",updatedAt:"2024-06-03T07:24:49.496Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-cdhpUfOZAa"},{values:{"Category of creator":["OECD"],"Policy creator":["Japan"],"Policy Name":"Integrated Innovation Strategy Promotion Council","Year of Commencement or Creation":"2022",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Note that the document is translated with DeepL. There is some recognition that AI could be used to enhance education (although the focus is on how to educate Japan for AI). ","Relevance Type":["Policy makes fleeting reference to AI in education","Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["AI Japan en.pdf"],"Key quotes on AI in education principles":"\u201CThere are high expectations for AI in many areas, including telemedicine and A I diagnostic support for improved access to medical care and personalized medicine, expanded access to education and personalized support, flood and other disaster forecasting, including for use in developing countries, and technology to enable resource recycling throughout economic activities.\u201D (p 29)","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CThere are high expectations for AI in many areas, including telemedicine and A I diagnostic support for improved access to medical care and personalized medicine, expanded access to education and personalized support, flood and other disaster forecasting, including for use in developing countries, and technology to enable resource recycling throughout economic activities.\u201D (p 29)","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Interoperability. AI systems should be able to work with other systems. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","R&D. Sufficient resources should be invested in AI R&D.","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25312","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`Interoperability:
\u201CFor example, establishing interoperability of Japan's digital data platform with data platforms such as India Stack can help them access and scale their operations in larger markets\u201D (p 25)
Procurement:
A little vague \u2014 details lost in translation \u2014 but this could be relevant: \u201CIt is essential to establish a trust infrastructure for government procurement in the United States and a common trust infrastructure in the EU. The U.S. has already established a trust infrastructure in the field of government procurement and the EU has established a common trust infrastructure, and Japan has also started related studies.\u201D (p 64)`,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Japan: Integrated Innovation Strategy Promotion Council","Translation Comments":"Translation Completed (DeepL)"},id:"i-kCIhlFwLkT",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-kCIhlFwLkT",name:"Japan: Integrated Innovation Strategy Promotion Council",index:145,createdAt:"2024-05-28T02:34:17.490Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-kCIhlFwLkT"},{values:{"Category of creator":["OECD"],"Policy creator":["United States"],"Policy Name":"AI Bill of Rights Blueprint","Year of Commencement or Creation":"2022",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`There are some interesting and broadly relevant ideas in this blueprint for an AI Bill of Rights. https://www.whitehouse.gov/ostp/ai-bill-of-rights/
`,"Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education","Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["Managing bias. The risk of bias should be managed with care. ","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Human rights-centred. The technology must be consistent with human rights. ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities."],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Educates. It helps officials or others understand the opportunities and risks of AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Blueprint-for-an-AI-Bill-of-Rights.pdf"],"Key quotes on AI in education principles":`\u201CBut there is much more work to do to protect the public from algorithmic discrimination to use and design automated systems in an equitable way... Ensuring equity should also go beyond existing guardrails to consider the holistic impact that automated systems make on underserved communities and to institute proactive protections that support these communities.
A predictive model marketed as being able to predict whether students are likely to drop out of school was used by more than 500 universities across the country. The model was found to use race directly as a predictor, and also shown to have large disparities by race; Black students were as many as four times as likely as their otherwise similar white peers to be deemed at high risk of dropping out. These risk scores are used by advisors to guide students towards or away from majors, and some worry that they are being used to guide Black students away from math and science subjects.\u201D (p 24)
\u201CThe National Disabled Law Students Association expressed concerns that individuals with disabilities were more likely to be flagged as potentially suspicious by remote proctoring AI systems because of their disability-specific access needs such as needing longer breaks or using screen readers or dictation software.\u201D (p 25) 
\u201CCompanies collect student data such as demographic information, free or reduced lunch status, whether they've used drugs, or whether they've expressed interest in LGBTQI+ groups, and then use that data to forecast student success.76 Parents and education experts have expressed concern about collection of such sensitive data without express parental consent, the lack of transparency in how such data is being used, and the potential for resulting discriminatory impacts.\u201D (p 37)

\u201CA school board\u2019s attempt to surveil public school students\u2014undertaken without adequate community input\u2014sparked a state-wide biometrics moratorium.79 Reacting to a plan in the city of Lockport, New York, the state\u2019s legislature banned the use of facial recognition systems and other \u201Cbiometric identifying technology\u201D in schools until July 1, 2022.80 The law additionally requires that a report on the privacy, civil rights, and civil liberties implications of the use of such technologies be issued before biometric identification technologies can be used in New York schools.\u201D (p 39)
\u201CEducation-related concerning uses included the increased use of remote proctoring systems, student location and facial recognition tracking, teacher evaluation systems, robot teachers, and more... Various panelists raised the limitations of existing privacy law as a key concern, pointing out that students should be able to reinvent themselves and require privacy of their student records and education-related data in order to do so. The overarching concerns of surveillance in these domains included concerns about the chilling effects of surveillance on student expression...\u201D (p 57)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as the objective or justification of the policy (the primary objective or justification)","Key quote on human rights":`\u201CCivil liberties and civil rights must not be limited by the threat of surveillance or harassment facilitated or aided by an automated system.\u201D (p 34)

\u201CSchool audio surveillance systems monitor student conversations to detect potential "stress indicators" as a warning of potential violence. Online proctoring systems claim to detect if a student is cheating on an exam using biometric markers. These systems have the potential to limit student freedom to express a range of emotions at school and may inappropriately flag students with disabilities who need accommodations or use screen readers or dictation software as cheating.\u201D (p 37)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`\u201CYou should not face discrimination by algorithms and systems should be used and designed in an equitable way.\u201D (p 5)
\u201CProactive assessment of equity in design. Those responsible for the development, use, or oversight of automated systems should conduct proactive equity assessments in the design phase of the technology research and development or during its acquisition to review potential input data, associated historical context, accessibility for people with disabilities, and societal goals to identify potential discrimination and effects on equity resulting from the introduction of the technology.\u201D (p 26)`,"General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Human rights-centred. AI systems should be compatible with human rights. ","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Inclusive development. AI systems should be developed inclusively. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society."],"Link (OECD or Other)":"https://www.whitehouse.gov/ostp/ai-bill-of-rights/","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":27,Title:"United States: AI Bill of Rights Blueprint","Translation Comments":"N/A - English"},id:"i-ibWXq2I11E",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-ibWXq2I11E",name:"United States: AI Bill of Rights Blueprint",index:400,createdAt:"2024-05-27T10:35:27.349Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-ibWXq2I11E"},{values:{"Category of creator":["OECD"],"Policy creator":["United States"],"Policy Name":"State Department Guidance on Products or Services with Surveillance Capabilities","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is an initiative that could (and should) be considered when developing EdTech for schools. One could imagine numerous surveillance technologies (e.g., attendance monitoring) that should be screened by reference to these principles \u2014 or something like them \u2014 prior to deployment. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A Other]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Guides impact assessment. It helps officials anticipate or evaluate the impact of AI","Educates. It helps officials or others understand the opportunities and risks of AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["DRL-Industry-Guidance-Project-FINAL-1-pager-508-1.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as the objective or justification of the policy (the primary objective or justification)","Key quote on human rights":`This is all about \u201CHuman Rights Due Diligence\u201D:
The U.S. Department of State is committed to the promotion and protection of human rights. In that spirit, U.S. businesses should carefully review this voluntary guidance and consider whether to participate in, or continue to participate in, transactions if they identify a risk that the end-user will likely misuse the product or service to carry out human rights violations or abuses. (p 1)
Human Rights Due Diligence (hereinafer \u201Cdue diligence\u201D): For the purpose of this document, \u201Cdue diligence\u201D is defined as the process by which a business  works to  identify,  anticipate,  prevent, mitigate,  and account for how it addresses actual or potential adverse impacts on the human rights of individuals. This includes impacts that it may cause or contribute to, or to which it is otherwise directly linked.  In accordance with the UN Guiding Principles, among the factors that should be considered where impacts are directly linked include the business\u2019s leverage over the entity concerned, how crucial the relationship is to the business, the severity of the abuse, and whether terminating the relationship with the entity would have adverse human rights consequences. (p 5)`,"Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"N/A","General principles on AI":["Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Respect for laws [NEW]. AI should respect existing law.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Human rights-centred. AI systems should be compatible with human rights. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Freedom of speech and assembly [NEW]. AI systems should not abrogate freedom of speech or assembly. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26986","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"Procurement \u2014 \u201CIn sales where the ultimate end use may not be known but the product or service in question presents a human rights risk, require end-user license agreement with human rights safeguards language, and require re-sellers to conduct their own human rights due diligence in cases of resale\u201D (11)","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":["Will Cesta"],"Relevant?":"Yes","Series #":41,Title:"United States: State Department Guidance on Products or Services with Surveillance Capabilities","Translation Comments":""},id:"i-ronKCeda9b",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-ronKCeda9b",name:"United States: State Department Guidance on Products or Services with Surveillance Capabilities",index:398,createdAt:"2024-05-27T09:32:13.420Z",updatedAt:"2024-06-05T22:45:06.600Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-ronKCeda9b"},{values:{"Category of creator":["OECD"],"Policy creator":["United States"],"Policy Name":"Government by Algorithm: AI in Federal Administrative Agencies","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a brilliant report\u2014David Engstrom as lead. It is included for its broad principles, but there is very little on education in here. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Government by Algorithm.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"This is not really focused on civil/human rights. It talks about other legal rights, but there are only a handful of fleeting references to the others. ","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`Uses the languages of discrimination throughout \u2014 eg:

\u201CSecond, the rise of AI decision tools will increasingly challenge conventional principles of antidiscrimination law\u201D
\u201CFormal blindness can be functional discrimination.\u201D
\u201CThe administrative state\u2019s growing adoption of AI tools risks compounding biases against vulnerable groups. If biases go unchecked, agency tools will only deepen existing inequities and also likely run afoul of antidiscrimination law\u201D`,"General principles on AI":["Respect for laws [NEW]. AI should respect existing law.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Environmental wellbeing. The use of AI should not harm the environment. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Opportunity. The opportunities of AI should be harnessed."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26961","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`The content on procurement is not clear-cut \u2014 not \u201Cyep, sets standards to influence development\u201D. It explores interesting related ideas, though:

\u201CIn sum, usability may militate in favor of internal capacity building. Privately produced, procurement-generated tools may boast the most cutting-edge analytics, but may also be less tailored to the task at hand, be less attuned to legal requirements and an agency\u2019s bureaucratic realities, and do not necessarily come with ongoing and regular engagement between technologists and agency enforcement staff. In contrast, in-house production may strain agency budgets, but will yield governance tools that are, on average, better tailored to subtle governance tasks, more law- and policy?compliant, more attuned to complex organizational dynamics, and less subject to information leakage and conflicts of interest that can reduce a tool\u2019s efficacy and raise significant distributive concerns\u201D`,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":["Will Cesta"],"Relevant?":"Yes","Series #":14,Title:"United States: Government by Algorithm: AI in Federal Administrative Agencies","Translation Comments":""},id:"i-Wliu2lS19z",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-Wliu2lS19z",name:"United States: Government by Algorithm: AI in Federal Administrative Agencies",index:373,createdAt:"2024-05-27T09:25:44.010Z",updatedAt:"2024-06-06T00:01:48.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-Wliu2lS19z"},{values:{"Category of creator":["OECD"],"Policy creator":["United States"],"Policy Name":"Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is important to our project because it joins the links between \u2018racial equity\u2019/\u2019support for underserved communities\u2019 with AI: \u201Cpromote equity in science and root out bias in the design and use of new technologies, such as artificial intelligence\u201D. See also: \u201C(b) When designing, developing, acquiring, and using artificial intelligence and automated systems in the Federal Government, agencies shall do so, consistent with applicable law, in a manner that advances equity.\u201D These are short statements, but hugely important given that they are coming from the global leader in AI and apply \u2014 as executive law \u2014 to the public service in the US. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":[],"Governance practices employed":["[N/A]"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government _ The White House.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201Cand promote equity and human rights around the world through our foreign policy and foreign assistance.\u201D

Also speaks a lot about human rights. `,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`\u201C; promote equity in science and root out bias in the design and use of new technologies, such as artificial intelligence\u201D
\u201CWhen designing, developing, acquiring, and using artificial intelligence and automated systems in the Federal Government, agencies shall do so, consistent with applicable law, in a manner that advances equity.\u201D`,"General principles on AI":["Respect for laws [NEW]. AI should respect existing law.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27439","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":["Will Cesta"],"Relevant?":"Yes","Series #":3,Title:"United States: Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government","Translation Comments":""},id:"i-d8BRcO2fJK",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-d8BRcO2fJK",name:"United States: Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government",index:161,createdAt:"2024-05-27T09:12:44.160Z",updatedAt:"2024-06-05T23:47:42.455Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-d8BRcO2fJK"},{values:{"Category of creator":["OECD"],"Policy creator":["United States"],"Policy Name":"Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`The US expressly deals with AI in education in its recent Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. It makes reference to important imminent developments (such as a toolkit). 

  (d)  To help ensure the responsible development and deployment of AI in the education sector, the Secretary of Education shall, within 365 days of the date of this order, develop resources, policies, and guidance regarding AI.  These resources shall address safe, responsible, and nondiscriminatory uses of AI in education, including the impact AI systems have on vulnerable and underserved communities, and shall be developed in consultation with stakeholders as appropriate.  They shall also include the development of an \u201CAI toolkit\u201D for education leaders implementing recommendations from the Department of Education\u2019s AI and the Future of Teaching and Learning report, including appropriate human review of AI decisions, designing AI systems to enhance trust and safety and align with privacy-related laws and regulations in the educational context, and developing education-specific guardrails.`,"Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":["Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Trust. Organisations seeking to incorporate AI into educational settings must build trust."],"Governance practices employed":["Binds. It creates binding obligations in relation to AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence _ The White House.pdf"],"Key quotes on AI in education principles":`Avoidance of harm in education:
\u201CSuch protections are especially important in critical fields like healthcare, financial services, education, housing, law, and transportation, where mistakes by or misuse of AI could harm patients, cost consumers or small businesses, or jeopardize safety or rights.\u201D
The key extract is as follows:
\u201CTo help ensure the responsible development and deployment of AI in the education sector, the Secretary of Education shall, within 365 days of the date of this order, develop resources, policies, and guidance regarding AI. These resources shall address safe, responsible, and nondiscriminatory uses of AI in education, including the impact AI systems have on vulnerable and underserved communities, and shall be developed in consultation with stakeholders as appropriate. They shall also include the development of an \u201CAI toolkit\u201D for education leaders implementing recommendations from the Department of Education\u2019s AI and the Future of Teaching and Learning report, including appropriate human review of AI decisions, designing AI systems to enhance trust and safety and align with privacy-related laws and regulations in the educational context, and developing education-specific guardrails.\u201D`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201CAmericans\u2019 privacy and civil liberties must be protected as AI continues advancing.\u201D
\u201C(d) Artificial Intelligence policies must be consistent with my Administration\u2019s dedication to advancing equity and civil rights.\u201D
Note also the AI Bill of Rights blueprint`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`\u201C(d) Artificial Intelligence policies must be consistent with my Administration\u2019s dedication to advancing equity and civil rights. My Administration cannot \u2014 and will not \u2014 tolerate the use of AI to disadvantage those who are already too often denied equal opportunity and justice. From hiring to housing to healthcare, we have seen what happens when AI use deepens discrimination and bias, rather than improving quality of life. Artificial Intelligence systems deployed irresponsibly have reproduced and intensified existing inequities, caused new types of harmful discrimination, and exacerbated online and physical harms. My Administration will build on the important steps that have already been taken \u2014 such as issuing the Blueprint for an AI Bill of Rights, the AI Risk Management Framework, and Executive Order 14091 of February 16, 2023 (Further Advancing Racial Equity and Support for Underserved Communities Through the Federal Government) \u2014 in seeking to ensure that AI complies with all Federal laws and to promote robust technical evaluations, careful oversight, engagement with affected communities, and rigorous regulation.\u201D (p 2-3)
Note also the comments specific to education:
\u201CTo help ensure the responsible development and deployment of AI in the education sector, the Secretary of Education shall, within 365 days of the date of this order, develop resources, policies, and guidance regarding AI. These resources shall address safe, responsible, and nondiscriminatory uses of AI in education, including the impact AI systems have on vulnerable and underserved communities, and shall be developed in consultation with stakeholders as appropriate. They shall also include the development of an \u201CAI toolkit\u201D for education leaders implementing recommendations from the Department of Education\u2019s AI and the Future of Teaching and Learning report, including appropriate human review of AI decisions, designing AI systems to enhance trust and safety and align with privacy-related laws and regulations in the educational context, and developing education-specific guardrails.\u201D`,"General principles on AI":["Augmentation, not replacement. AI systems should augment, not displace, workers.","Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power.","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D.","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Interoperability. AI systems should be able to work with other systems. ","Environmental wellbeing. The use of AI should not harm the environment. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27577","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"There is so much here that it is worth reading the policy attached \u2014 focus on the opening principles (especially p 1-4, leading up to the definitions)","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"Memorable point: \u201CIn the end, AI reflects the principles of the people who build it, the people who use it, and the data upon which it is built. I firmly believe that the power of our ideals; the foundations of our society; and the creativity, diversity, and decency of our people are the reasons that America thrived in past eras of rapid change. They are the reasons we will succeed again in this moment. We are more than capable of harnessing AI for justice, security, and opportunity for all.\u201D",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":2,Title:"United States: Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence","Translation Comments":""},id:"i-qEBK7OMRGa",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-qEBK7OMRGa",name:"United States: Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence",index:160,createdAt:"2024-05-27T09:07:40.068Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-qEBK7OMRGa"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Singapore"],"Policy Name":"Proposed Model AI Governance Framework for Generative AI","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This framework builds on the general Model AI Governance Framework released in 2019-2020. It is built on 9 core principles. It is easy to see how this could be adapted to educational contexts, particularly as the emerging EdTech is (largely) driven by genAI. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Proposed_MGF_Gen_AI_2024.pdf"],"Key quotes on AI in education principles":"\u201CAI should serve the public in impactful ways. Today, AI powers many public services, such as adaptive learning systems in schools and health management systems in hospitals. This unlocks new value propositions, creates efficiencies and improves user experience.\u201D (p 20)","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CThe aim is to establish a global Digital Commons \u2013 a place with common rules-of-the-road and equal opportunities for all citizens to flourish, regardless of their geographical location.\u201D (p 20) ","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","R&D. Sufficient resources should be invested in AI R&D.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Environmental wellbeing. The use of AI should not harm the environment. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Transparency (explainability). AI systems should be sufficiently explainable.","Bias testing. AI systems should be tested for bias. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27638","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":33,Title:"Singapore: Proposed Model AI Governance Framework for Generative AI","Translation Comments":"N/A - English"},id:"i-cEsc8uQgVt",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-cEsc8uQgVt",name:"Singapore: Proposed Model AI Governance Framework for Generative AI",index:365,createdAt:"2024-05-27T01:40:32.338Z",updatedAt:"2024-06-05T21:37:17.815Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-cEsc8uQgVt"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Singapore"],"Policy Name":"Model AI Governance Framework","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a solid governance framework for AI generally. Some parts of it could be applied to educational settings. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["SGModelAIGovFramework2.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"\u201CHuman rights alignment: Ensure that the design, development and implementation of technologies do not infringe internationally recognised human rights.\u201D (p 65)","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`Under \u201C6. Human Centricity and Well-being\u201D
\u201Ca. To aim for an equitable distribution of the benefits of data practices and avoid data practices that disproportionately disadvantage vulnerable groups.\u201D (p 65)

Under \u201CDifferent datasets for training, testing, and validation\u201D
\u201CWhere applicable, the model could also be checked for systematic bias by testing it on different demographic groups to observe whether any groups are being systematically advantaged or disadvantaged.\u201D (p 40)

\u201CEnsure that algorithmic decisions do not create discriminatory or unjust impacts across different demographic lines (e.g. race, sex, etc.).\u201D (p 64)`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24428","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":32,Title:"Singapore: Model AI Governance Framework","Translation Comments":"N/A - English"},id:"i-eQMFUuu1hw",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-eQMFUuu1hw",name:"Singapore: Model AI Governance Framework",index:364,createdAt:"2024-05-27T01:40:13.108Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-eQMFUuu1hw"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Singapore"],"Policy Name":"ASEAN Guide on AI Governance and Ethics","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a highly relevant framework that could \u2014 in part \u2014 be applied to educational settings. It offers a concrete guide (sort of like the UK and Canada) from p 17 (i.e., impact assessment). See also Annex A: AI Risk Impact Assessment template (p 60). ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["ASEAN-Guide-on-AI-Governance-and-Ethics_beautified_201223_v2.pdf"],"Key quotes on AI in education principles":"\u201CTo mitigate discrimination, it is important that the design, development, and deployment of AI systems align with fairness and equity principles. In addition, the datasets used to train the AI systems should be diverse and representative. Appropriate measures should be taken to mitigate potential biases during data collection and pre-processing, training, and inference. For example, the ASEAN Guide on AI Governance and Ethics 12 training and test dataset for an AI system used in the education sector should be adequately representative of the student population by including students of different genders and ethnicities.\u201D (p 12)","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`\u201CDeployers should have safeguards in place to ensure that algorithmic decisions do not further exacerbate or amplify existing discriminatory or unjust impacts across different demographics and the design, development, and deployment of AI systems should not result in unfair biasness or discrimination. An example of such safeguards would include human interventions and checks on the algorithms and its outputs. Deployers of AI systems should conduct regular testing of such systems to confirm if there is bias and where bias is confirmed, make the necessary adjustments to rectify imbalances to ensure equity.\u201D (p 12)

\u201CIf not properly managed, an AI system\u2019s outputs used to make decisions with significant impact on individuals could perpetuate existing discriminatory or unjust impacts to specific demographics. To mitigate discrimination, it is important that the design, development, and deployment of AI systems align with fairness and equity principles.\u201D (p 12)

\u201CPropagation of embedded biases: Generative AI systems have the ability to capture and reflect the biases present in the training dataset. If not properly addressed, these biases can be inherited and result in biased or toxic output that reinforces biased or discriminatory stereotypes. For example, image generation systems prompted with \u201CAfrican worker\u201D may generate images of individuals in tattered clothing and rudimentary tools, while simultaneously generating images of wealthy individuals when prompted with \u201CEuropean worker\u201D28 . This highlights the risk of propagation of biases from foundation models to downstream models trained from them, which perpetuates such biases and stereotypes.\u201D (p 56)

\u201CWhen designing and developing AI systems, deployers and developers also need to bear in mind the principles of human-centricity, fairness and equity, transparency and explainability, safety and security, robustness and reliability, accountability and integrity, and privacy and data governance.\u201D (p 29)`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Augmentation, not replacement. AI systems should augment, not displace, workers.","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Environmental wellbeing. The use of AI should not harm the environment. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Interoperability. AI systems should be able to work with other systems. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27645","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":26,Title:"Singapore: ASEAN Guide on AI Governance and Ethics","Translation Comments":"N/A - English"},id:"i-FgCTrbGUmb",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-FgCTrbGUmb",name:"Singapore: ASEAN Guide on AI Governance and Ethics",index:361,createdAt:"2024-05-27T01:38:48.336Z",updatedAt:"2025-04-24T03:57:09.712Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-FgCTrbGUmb"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Singapore"],"Policy Name":"Transforming education through technology masterplan 2030","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This is one of the most relevant documents encountered yet. It is a dedicated EdTech plan. Worth reading here:
EdTech Masterplan 2030 | MOE
Also attached as a PDF, but it\u2019s worth following the links. `,"Relevance Type":["Policy is about AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["EdTech Masterplan 2030 _ MOE.pdf"],"Key quotes on AI in education principles":`Opportunities:
Provide AI-enabled, resource-rich Singapore Student Learning Space (SLS) for greater customisation of learning
AI-enabled features in SLS to customise learning pathways to individual student\u2019s needs, for example, the Adaptive Learning System.
Richer variety of learning resources in the SLS to enable finer customisation and to support self-directed learning.
Provide digital tools and platforms to enhance feedback and assessment
AI-enabled tools to provide immediate and customised feedback to students, for example, through Learning Feedback Assistants.
Training:
Greater emphasis on e-Pedagogy and use of EdTech in both NIE pre-service teacher training and in-service teacher professional development
Provide resources and professional development opportunities for teachers on data literacy and cyber wellness.
Partner Centre of Teaching and Learning Excellence (CTLE) to study and share effective and innovative use of EdTech
`,"Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["[N/A]"],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27663","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"Singapore Student Learning Space (SLS) Info-Site (moe.edu.sg) \u2014 AI-enabled Student Learning Space ","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":21,Title:"Singapore: Transforming education through technology masterplan 2030","Translation Comments":""},id:"i-cYzSrNlIt4",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-cYzSrNlIt4",name:"Singapore: Transforming education through technology masterplan 2030",index:356,createdAt:"2024-05-27T01:37:05.956Z",updatedAt:"2024-06-03T23:13:10.878Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-cYzSrNlIt4"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Singapore"],"Policy Name":"Public Sector AI Playbook","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is an interesting document\u2014could something like this be handed out to users of these systems? Lots of examples / case studies. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Develops tools. It provides tools and place them in the hands of businesses or governments","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["public-sector-ai-playbook.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D.","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27660","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":16,Title:"Singapore: Public Sector AI Playbook","Translation Comments":"N/A - English"},id:"i-eofU-tnKpc",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-eofU-tnKpc",name:"Singapore: Public Sector AI Playbook",index:351,createdAt:"2024-05-27T01:36:11.891Z",updatedAt:"2024-06-06T03:10:26.217Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-eofU-tnKpc"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Singapore"],"Policy Name":"National AI Strategy 2.0","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is one of very few national strategies that sees the relationship between AI and education as being more about educating people to \u2018do AI\u2019. It sees AI as a tool to be deployed in many domains, including education. There is not a lot of detail in this report\u2014that is broken out in its dedicated education policy. ","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["nais2023.pdf"],"Key quotes on AI in education principles":"\u201CSmart Nation Priorities, where AI assists our national development, and unlocks new value propositions for social impact. These include Healthcare, Education & Manpower, Trust & Safety, and Public Service Delivery\u201D (p 18)","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"N/A","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"N/A","General principles on AI":["Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Opportunity. The opportunities of AI should be harnessed."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27628","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":2,Title:"Singapore: National AI Strategy 2.0","Translation Comments":"Official Translation Obtained"},id:"i-XSShfibeDy",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-XSShfibeDy",name:"Singapore: National AI Strategy 2.0",index:348,createdAt:"2024-05-27T01:35:50.952Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-XSShfibeDy"},{values:{"Category of creator":["OECD"],"Policy creator":["Austria"],"Policy Name":"AI Mission Austria 2030","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is a brief line here about AI in education: \u2018AI can help learners and educators to make learning more effective and exciting.\u2019 The other content about education concerns education for AI. However, there are some broadly relevant governance ideas here. This is not a high-priority plan, but worth noting. ","Relevance Type":["Policy makes fleeting reference to AI in education","Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":"","Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Communicates a stance. It expresses a hope for the future of AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["aimat_ua (1).pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24233","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Austria: AI Mission Austria 2030","Translation Comments":"N/A - English"},id:"i-il2x7bQckP",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-il2x7bQckP",name:"Austria: AI Mission Austria 2030",index:163,createdAt:"2024-05-27T01:14:37.198Z",updatedAt:"2024-06-02T23:37:28.020Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-il2x7bQckP"},{values:{"Category of creator":["OECD"],"Policy creator":["Norway"],"Policy Name":"Report No 22 ","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"I have translated this report on data as a resource. I had low expectations, but there is actually some interesting stuff on data sharing in primary and secondary education that could be adapted to data collected by AI applications. I have translated a copy of the report. See 5.2.3.","Relevance Type":["Policy makes fleeting reference to AI in education","Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary"],"Principles on AI in education":["Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations."],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Educates. It helps officials or others understand the opportunities and risks of AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["request.pdf"],"Key quotes on AI in education principles":`5.2.3 Research and education data
\u201CDisclosure must take place within the framework of a good level of privacy and with the necessary considerations for security, intellectual property rights and trade secrets. In order to achieve the main goal of more sharing and reuse of data, the appropriate use of licences on the data is of great importance. On behalf of the Ministry of Education and Research, the Research Council of Norway has therefore appointed a committee to investigate rights and licensing issues in connection with the sharing of research data, with the aim of ensuring that the results of publicly funded research contribute to value creation and benefit the general public. The results of the committee's work will be presented in the summer of 2021. 
On behalf of the Ministry of Education and Research, Unit (the Norwegian Directorate for ICT and Joint Services in Higher Education and Research) is carrying out a pilot project on the sharing of data on education, research and integration. Examples of education data are data from primary and secondary education. The goal is to establish an infrastructure for making data available in the knowledge sector that facilitates both efficient information management ("order in one's own house") and an infrastructure for reuse. The pilot project is based on the concept study Future sharing of data in the knowledge sector, which was carried out in the period January 2019 to January 2020.38 The pre-project will detail and possibly adjust the recommended concept, and it will form the basis for deciding on a possible realisation of the concept through a main project or a programme consisting of several projects.\u201D`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":`\u201CData must be shared and used in such a way that fundamental rights and freedoms are respected, and Norwegian societal values are preserved.\u201D (1.2) 

\u201CThe Digital Services Act (DSA) can be seen as a revision of the E-Commerce Directive. Since the E-Commerce Directive came into force in 2000, the digital landscape has changed significantly through the emergence of new digital platforms. The DSA will improve the ability to remove illegal content online and better protect users' fundamental rights, including freedom of expression.\u201D 7.1.2

\u201CThe Government's policy will also promote a balanced data economy that safeguards Norwegian societal values and respects the fundamental rights and freedoms of the individual\u201D (8)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`\u201CRisk of discrimination and erroneous conclusions 
The use of profiling based on algorithms and artificial intelligence can provide better and more personalised services, but it can also increase the risk of unlawful discrimination. When services are more individualised, consumers are at risk of being subjected to price discrimination. Algorithm-based advertising systems can also be designed in such a way that, for example, housing rental and job ads are only shown to certain groups of people, so that others are effectively excluded and potentially discriminated against.\u201D (7.2.1)

\u201CAn important issue is the work to promote a level playing field between multinational companies and Norwegian players.\u201D (2) 

Under \u201CBoks 5.9 Open Data Licenses\u201D in 5.3 
\u201COpen Standard Data Licences is a general agreement between a data provider and those who will use the data. The agreement contains very few restrictions and ensures a level playing field for all users. The licences facilitate the combination of data from multiple sources and room for manoeuvre to process data and offer services and new data products in the market. Examples of open data licenses are Creative Commons Attribution 4.0 (CC BY 4.0) and Norwegian License for Public Data (NLOD).\u201D (5.3)

\u201CIn December 2020, the European Commission presented the Digital Services Act and the Digital Markets Act. These are intended to fulfil two main objectives: To create a secure digital area where the rights of all users of digital services are protected, and to ensure a level playing field for promoting innovation, growth and competition both in the EU/EEA and globally.\u201D (7.1.2)`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27303","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":5,Title:"Norway: Report No 22 ","Translation Comments":"Translation Completed (Google Translate)"},id:"i-RecXqYep6s",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-RecXqYep6s",name:"Norway: Report No 22 ",index:333,createdAt:"2024-05-27T00:52:42.234Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-RecXqYep6s"},{values:{"Category of creator":["OECD"],"Policy creator":["Norway"],"Policy Name":"National Strategy for AI","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"For the most part, this strategy talks about education for AI rather than AI in education. However, it also talks about the deployment of AI for training purposes (see p 45). This is a great case study, and led to a concrete recommendation: \u201Cconsider a digital platform for continuing and further education programs\u2019. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education","Policy makes fleeting reference to AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Plans further action. It sets out a strategy on AI","Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Communicates a stance. It expresses a hope for the future of AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["Norway_National_Strategy_for_Artificial_Intelligence_2020.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":`\u201CNorwegian society is characterised by trust and respect for fundamental values such as human rights and privacy. This is something we perhaps take for granted in Norway, but leading the way in developing human-friendly and trustworthy artificial intelligence may prove a key advantage in today's global competition.\u201D (p2) 

\u201CNorwegian society is characterised by trust and respect for fundamental values such as human rights and privacy. The Government wants Norway to lead the way in 6 developing and using AI with respect for individual rights and freedoms. This can become a key advantage in today's global competition.\u201D (p 5-6)

\u201CThe Government will encourage development and use of artificial intelligence in Norway to be based on ethical principles and to respect human rights and democracy\u201D (p 61)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`\u201CAI systems must facilitate inclusion, diversity and equal treatment When developing and using AI, it is especially important to ensure that AI contribute to inclusion and equality, and that discrimination be avoided. Datasets that are used to train AI systems can contain historical bias, be incomplete or incorrect. Identifiable and discriminatory bias should, if possible, be removed in the collection phase. Bias can be counteracted by putting in place oversight processes to analyse and correct the system\u2019s decisions in light of the purpose.\u201D (p 59)

\u201CEthical considerations should be built into algorithms during development. Among other things, it will be important to assess whether an algorithm may lead to discrimination and whether it is sufficiently robust to withstand manipulation. Ethical evaluations may also call for considering potential environmental impacts and whether a system contributes to achieving the UN Sustainable Development Goals.\u201D (p 60)

\u201CAutomated administrative proceedings can also enhance implementation of rights and obligations; for example, by automatically making decisions that grant benefits when the conditions are met. This can particularly benefit the most disadvantaged in society.\u201D (p 27)`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","R&D. Sufficient resources should be invested in AI R&D.","Human rights-centred. AI systems should be compatible with human rights. ","Transparency (explainability). AI systems should be sufficiently explainable.","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Interoperability. AI systems should be able to work with other systems. ","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality)."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26464","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Norway: National Strategy for AI","Translation Comments":"N/A - English"},id:"i-TH30MMf_2H",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-TH30MMf_2H",name:"Norway: National Strategy for AI",index:164,createdAt:"2024-05-27T00:51:22.656Z",updatedAt:"2024-06-03T07:18:00.486Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-TH30MMf_2H"},{values:{"Category of creator":["OECD"],"Policy creator":["United States"],"Policy Name":"Artificial Intelligence and the Future of Teaching and Learning: Insights and Recommendations","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This document was prepared by the Office of Educational Technology to \u2018share knowledge\u2019 about artificial intelligence. It pursues the answers to two overarching questions: (1) \u2018What is our collective vision of a desirable and achievable educational system that leverages automation to advance learning while protecting and centering human agency?\u2019; and (2) How and on what timeline will we be ready with necessary guidelines and guardrails, as well as convincing evidence of positive impacts, so that constituents can ethically and equitably implement this vision widely?\u2019 It advances a handful of interesting and relevant principles. ","Relevance Type":["Policy is about AI in education","Policy contains case studies on AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary"],"Principles on AI in education":["Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Managing bias. The risk of bias should be managed with care. ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.","Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Transparency (transparency to government). The extent to which AI is used in educational settings should be clear to the government. ","Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.","Trust. Organisations seeking to incorporate AI into educational settings must build trust.","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["Artificial Intelligence and the Future of Teaching and Learning (1).pdf"],"Key quotes on AI in education principles":`
Contestability:
\u201CThe Blueprint for an AI Bill of Rights similarly calls for \u201Caccess to timely human consideration and remedy by a fallback and escalation process if an automated system fails, it produces an error, or you would like to appeal or contest its impacts\u2026\u201D Building on this consensus, we call upon all constituents to adopt \u201Chumans in the loop\u201D as a key criterion for educational use of AI.\u201D (53)
Replacement:
\u201CSome teachers worry that they may be replaced\u2014to the contrary, the Department firmly rejects the idea that AI could replace teachers.\u201D (p 3)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":`\u201CPolicies should not hinder innovation and improvement, nor should they be burdensome to implement. Society needs an education-focused AI policy that protects civil rights and promotes democratic values in the building, deployment, and governance of automated systems to be used across the many decentralized levels of the American educational system.\u201D
Endorses the AI Bill of Rights blueprint numerous times`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`Risk of inequity:
\u201CYet, the broad equity challenges of avoiding algorithmic discrimination while increasing community and cultural responsiveness must be approached within the four foundations we earlier outlined: human in the loop, equity, safety and effectiveness, and evaluation of AI models. We cannot expect AI models to respect cultural responsiveness. The Department is particularly concerned that equity is something that engaged educators and other responsive adults are in the best position to address and something that is never solely addressable as a computational problem.\u201D (p 34)
\u201CTo what extent are teachers able to exercise voice and decision-making to improve equity, reduce bias, and increase cultural responsiveness in the use of AI-enabled tools and systems?\u201D (p 34)
\u201COur call for attending to equity considerations as we evaluate AI models requires information about how discriminatory bias may arise in particular AI systems and what developers have done to address it. This can only be achieved with transparency for how the tools use datasets to achieve outcomes and what data they have available or that a teacher could include in her judgement but are not available to the system (IEP status is offered as an example above).\u201D (p 35)
Increasing equity:
\u201CFrom neurotypical to neurodiverse learners. AI models could help in including neurodiverse learners (students who access, process, and interact with the world in less common ways than \u201Cneurotypical\u201D students) who could benefit from different learning paths and from forms of display and input that fit their strengths. Constituents want AI models that can support learning for neurodiverse learners and learners with disabilities. Thus, they want AI models that can work with multiple paths to learning and multiple modalities of interaction. Such models should be tested for efficacy, to guard against the possibility that some students could be assigned a \u201Cpersonalized\u201D but inadequate learning resource. In addition, some systems for neurodiverse students are presently underutilized, so designs that support intended use will also be important.\u201D (p 21)
\u201CIn support of equitable learning, especially for those most affected by the pandemic, AI could shift edtech from a current deficit-based model to a strengths-based alternative. In addition to finding student weaknesses and assigning fixes, edtech could make recommendations based on strengths that students bring to learning and how adapting to the whole student\u2014a cognitive, social, and self-regulating person\u2014could enable more powerful learning. Adapting to the whole student should include supporting students with disabilities as well as English learners. With regard to equity, we must remain highly attuned to the challenges of bias (which are inherent to how AI systems are developed) and take firm action to ensure fairness.\u201D (p 52)
Monitoring:
\u201CHow strong are the processes or systems for monitoring student use of AI for barriers, bias, or other undesirable consequences of AI use by learners? How are emergent issues addressed?\u201D (p 23)
Pedagogical optimisation:
\u201CThus, our key recommendation is to tease out the strengths and limitations of AI models inside forthcoming edtech products and to focus on AI models that align closely to desired visions of learning. AI is now advancing rapidly, and we should differentiate between products that have simple AI-like features inside and products that have more sophisticated AI models.\u201D (p 24)
Teacher training:
\u201CWe anticipate teachers will need training and support to understand how and when they will need to exercise human judgement.\u201D (p 32)
Understanding:
\u201CIn education, decision makers will need more than notice\u2014they will need to understand how AI models work in a range of general educational use cases, so they can better anticipate limitations, problems, and risks. AI models in edtech will be approximations of reality and, thus, constituents can always ask these questions: How precise are the AI models? Do they accurately capture what is most important? How well do the recommendations made by an AI model fit educational goals? What are the broader implications of using AI models at scale in educational processes?\u201D
Etc \u2014 lots of information in here`,"General principles on AI":["[N/A]"],"Link (OECD or Other)":"","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"This is very EdTech-focused. Broad principles are mostly linked specifically to the educational context. ","Notable Case Studes - Examples of AI in Education":`\u201CExamples of AI supporting learning principles in this section include the following: AI-based tutoring for students as they solve math problems (based on cognitive learning theories), adapting to learners with special needs (based on the Universal Design for Learning framework and related theories), and AI support for effective student teamwork (based on theories in the field called \u201CComputer Supported Collaborative Learning\u201D).\u201D (p 18) \u2014 more to be found
`,"Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"United States: Artificial Intelligence and the Future of Teaching and Learning: Insights and Recommendations","Translation Comments":""},id:"i-RitrSNR6M4",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-RitrSNR6M4",name:"United States: Artificial Intelligence and the Future of Teaching and Learning: Insights and Recommendations",index:169,createdAt:"2024-05-26T22:24:56.599Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-RitrSNR6M4"},{values:{"Category of creator":["IO"],"Policy creator":["European Union"],"Policy Name":"European Commission, Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and learning for Educators","Year of Commencement or Creation":"2022",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This document, taking into account the EU regulatory framework on AI generally, endeavours to \u2018provide awareness and practical guidance for educators who are increasingly confronted with the use of AI in their teaching and practice\u2019. 
The document is principally concerned with school environments, though much of what it says is relevant to education generally. This is one of the most directly relevant policy initiatives. 
Focus on Action 6. `,"Relevance Type":["Policy is about AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Managing bias. The risk of bias should be managed with care. ","Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ","Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology.","Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Academic integrity. Students should be supported to use AI tools ethically in their work, which extends to appropriate attribution.","Information. Information about the technology in use should be readily available. ","Trust. Organisations seeking to incorporate AI into educational settings must build trust.","Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.","Human rights-centred. The technology must be consistent with human rights. "],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["European Commission (1).pdf"],"Key quotes on AI in education principles":`Summary of ethical considerations:
\u201CHuman agency relates to an individual\u2019s capability to become a competent member of society. A person with agency can determine their life choices and be responsible for their actions. Agency underpins widely used concepts such as autonomy, self-determination, and responsibility. 
Fairness relates to everyone being treated fairly in the social organisation. Clear processes are required so that all users have equal access to opportunity. These include equity, inclusion, non-discrimination, and fair distribution of rights and responsibilities. 
Humanity addresses consideration for the people, their identity, integrity, and dignity. We need to consider the well-being, safety, social cohesion, meaningful contact, and respect that is necessary for a meaningful human connection. That connection implies, for example, that we approach people with respect of their intrinsic value and not as a data object or a means-to-an-end. It is at the essence of the human-centric approach to AI. 
Justified choice relates to the use of knowledge, facts, and data to justify necessary or appropriate collective choices by multiple stakeholders in the school environment. It requires transparency and is based on participatory and collaborative models of decision-making as well as explainability. These ethical considerations are intrinsically valuable and worth striving for in education. They guide educators and school leaders in their decisions about the use of AI systems in education. The key ethical requirements introduced below can help ensure that AI systems used in education and training are trustworthy and address relevant concerns.\u201D (p 18)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":"\u201CWe shall also strongly benefit from the views and experience of our pupils, their families, and all stakeholders in the field of education about the use and impact of AI in their daily work and how to make it further beneficial while avoiding risks and negative effects to human rights and our fundamental EU values.\u201D (p 7)","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`
\u201CFairness relates to everyone being treated fairly in the social organisation. Clear processes are required so that all users have equal access to opportunity. These include equity, inclusion, non-discrimination, and fair distribution of rights and responsibilities.\u201D (p 18)

The two aspects:
\u201CAI can result in new forms of inequalities or discrimination and exacerbate existing ones. However, if properly designed and used, it can also offer opportunities to improve access and inclusion - in everyday life, in work, and in education. There is also significant potential for AI to provide educational resources for young people with disabilities and special needs. For example, AI-based solutions such as real-time live captioning can assist those with impaired hearing, while audio description can make access easier and more effective for people with low levels of vision\u201D (p 12)
Note their case study on \u201Cproviding individualised interventions for special needs\u201D:
\u201CA school is considering how AI systems can help reduce barriers for students with special educational needs. The school is currently trialling an AI system to detect student support demands early on and provide tailored instructional support. By detecting patterns of corresponding characteristics from measures such as learning performance, standardised tests attention span or reading speed, the system suggests probabilities of specific diagnoses and related recommendations for interventions.\u201D (p 23)
Note that it focuses on the language of \u201Cfairness\u201D. Its guidance questions on using AI in education ethically are:
Is the system accessible by everyone in the same way without any barriers? 
Does the system provide appropriate interaction modes for learners with disabilities or special education needs? Is the AI system designed to treat learners respectfully adapting to their individual needs? 
Is the user interface appropriate and accessible for the age level of the learners? Has the usability and user-experience been tested for the target age group? 
Are there procedures in place to ensure that AI use will not lead to discrimination or unfair behaviour for all users? 
Does the AI system documentation or its training process provide insight into potential bias in the data? 
Are procedures in place to detect and deal with bias or perceived inequalities that may arise? (p 20)`,"General principles on AI":["[N/A]"],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26885","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"This is education-focused. ","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":2,Title:"European Union: European Commission, Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and learning for Educators","Translation Comments":"N/A - English"},id:"i-BzC3TE7vsZ",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-BzC3TE7vsZ",name:"European Union: European Commission, Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and learning for Educators",index:170,createdAt:"2024-05-26T22:20:47.390Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-BzC3TE7vsZ"},{values:{"Category of creator":["OECD"],"Policy creator":["New Zealand"],"Policy Name":"Algorithm Charter for Aotearoa New Zealand","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is effectively a broad framework for classifying risk and thinking about governance of algorithms generally. It is not education-focused, but this kind of document \u2014 optimised for educational contexts \u2014 could be given to schools by the Department of Education. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Algorithm-Charter-2020_Final-English-1 (1).pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"\u201CEnsure that privacy, ethics and human rights are safeguarded by: Regularly peer reviewing algorithms to assess for unintended consequences and act on this information.\u201D (p 3)","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`\u201CSimple algorithms can be used to standardise business processes to ensure scarce resources are distributed equitably.\u201D (p 1)
Consideration for M\u0101ori persons under \u201CPartnership\u201D - \u201CDeliver clear public benefit through Treaty commitments by: Embedding a Te Ao M\u0101ori perspective in the development and use of algorithms consistent with the principles of the Treaty of Waitangi.\u201D (p 3)`,"General principles on AI":["Bias testing. AI systems should be tested for bias. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25730","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"New Zealand: Algorithm Charter for Aotearoa New Zealand","Translation Comments":""},id:"i-0TFl3ja1DB",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-0TFl3ja1DB",name:"New Zealand: Algorithm Charter for Aotearoa New Zealand",index:173,createdAt:"2024-05-26T22:03:43.964Z",updatedAt:"2024-06-04T22:38:42.129Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-0TFl3ja1DB"},{values:{"Category of creator":["OECD"],"Policy creator":["Estonia"],"Policy Name":"Estonian Catalogue of Public Sector Information Systems","Year of Commencement or Creation":"2018",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This policy is not education-oriented, but is a good example of the kind of database that could be built for EdTech. Note: Will need to translate before using. 
Infos\xFCsteemid - Riigi infos\xFCsteemi halduss\xFCsteem RIHA`,"Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A Other]"],"Governance practices employed":["[N/A]"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26751","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"The reason for including this policy is that it provides a good example of a system that could be used to highlight which AI systems are in use, particularly in government schools. ",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":8,Title:"Estonia: Estonian Catalogue of Public Sector Information Systems","Translation Comments":"Translation Needed"},id:"i-8iMFNRIMnV",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-8iMFNRIMnV",name:"Estonia: Estonian Catalogue of Public Sector Information Systems",index:305,createdAt:"2024-05-26T10:02:45.078Z",updatedAt:"2024-06-04T23:04:30.755Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-8iMFNRIMnV"},{values:{"Category of creator":["OECD"],"Policy creator":["Estonia"],"Policy Name":"AI Use Cases in the Public Sector","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`The policy here is logging instances in which this technology is used. It seems like something that could be applied to EdTech \u2014 specifically, we are talking about the principle of \u201Cmonitoring\u201D. 

See Original source. Translated examples:

School Kratt
The aim of the project was to investigate the feasibility of applying logs for the use of digital learning assets to automatically create models for measuring learning outcomes using machine learning methods. Such models make it possible to collect more systematic information about the learner's development automatically, without interfering with the study, and thus provide input for better planning and automatic personalization of further learning. As part of the project: a visual prototype was created to demonstrate the results of measuring learning outcomes, the first models were trained using machine learning, and a primary methodology for data science was created.

Text-to-speech in language exams and tests
Audio files of instructions for the listening parts of language exams are usually recorded in the studio. However, in recent years, language technology has developed so rapidly, and speech synthesis at such a good level that instead of reading instructions, they can be quickly and easily created using a computer program. This saves time and money, and examiners do not even realize that the instructions are actually read by a machine instead of a human.

Marakratt
As part of the project, a proof-of-concept solution for the student was created for a kratt supporting individual learning paths. The project experimented with the use of machine learning to create models for recommending learning material. Prototype-like models were also created to help automate the personalisation of learning assets and activities used in learning, based on the interests, knowledge and abilities of the learners.

Personal learning path
In the case of personalised learning, there is a transition from a teacher-centred learning process to a learner-centred one, and the learner can make choices based on his or her goals, pace that suits him or her, tools and interests. Based on the available data, the aim is to develop solutions that would make it possible to give feedback to the Estonian learner and teacher about the learning process and go further: to show what the learner has done, as well as why he or she did it and what are the possible gaps in his or her knowledge or skills.`,"Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Tracks. It sets out to boost understanding specifically of where and how AI is being used"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["AI Usage Cases Estonia.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"N/A","Does the policy reflect the principle of equity/equality?":"N/A","Key quote on equity/equality":"N/A","General principles on AI":["Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26828","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":3,Title:"Estonia: AI Use Cases in the Public Sector","Translation Comments":"Translation Completed (Google Translate)"},id:"i-BvDC6gzHEo",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-BvDC6gzHEo",name:"Estonia: AI Use Cases in the Public Sector",index:300,createdAt:"2024-05-26T10:02:12.522Z",updatedAt:"2024-06-04T23:03:11.475Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-BvDC6gzHEo"},{values:{"Category of creator":["OECD"],"Policy creator":["Italy"],"Policy Name":"AI Strategic Programme","Year of Commencement or Creation":"2022",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Like most national AI strategies, Italy talks about education in the context of AI skill. But it also recognises that AI \u2018can constitute a powerful instrument for a fruitful transformation of the national education system to develop personalized learning plans while ensuring fairness and trustworthiness\u2019 (p 17). There are also some useful general governance ideas expressed. ","Relevance Type":["Policy makes fleeting reference to AI in education","Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["Italy_Artificial_Intelligence_Strategic_Programme_2022-2024.pdf"],"Key quotes on AI in education principles":`Education-specific comments
\u201CEducation system. As artificial intelligence is transforming every aspect of our lives we need to educate all people to this technology through a new education and training plan to understand, reinforce, integrate and disseminate AI technology. AI should be an important topic at all education levels. At the same time, it can constitute a powerful instrument for a fruitful transformation of the national education system to develop personalized learning plans while ensuring fairness and trustworthiness.\u201D (p 17).

General guiding principles:
Italy\u2019s AI is a European AI. In line with the EU Coordinated Plan on Artificial Intelligence, the Italian Strategic Programme stems from the awareness that only through common and coordinated actions Europe will be able to compete globally and work towards strategic autonomy. Therefore, this programme reflects the four sets of proposals put forward by the 2021 EU Coordinated Plan on AI. First, it sets enabling conditions for AI\u2019s development and uptake by focusing on cooperation, data and computing infrastructure. Second, it leverages on existing Italian HPC and data-management infrastructure. Third, it aims at nurturing talents and adheres to the joint effort for improving and adopting the harmonised set of rules for AI proposed by the AI ACT. Fourth, it identifies priority sectors where to build strategic leadership. 
Italy will be a global research and innovation hub of AI. To guarantee future economic growth and strategic autonomy, it is essential for Italy to boost its AI research and development ecosystem and leapfrog at the forefront of AI developments. Accordingly, this strategic programme will invest in frontier research and applications to develop AI methodologies and techniques of tomorrow. 
Italy\u2019s AI will be human-centred, trustworthy and sustainable. Technologies must not promote economic growth per se, but inclusive and sustainable growth, in line with the principles contained in Article 3 of the Italian Constitution and the United Nations Sustainable Development Goals. This means that AI development must be centred around economic and social inclusion, human rights as well as environ?mental sustainability. AI must be designed and implemented in a responsible and transparent manner, based on trust and robustness so that it can be safely adopted in every sector and be capable of respon?ding to societal challenges. To this aim, Italy adheres to the \u201CEthics Guidelines for trustworthy AI- Guidance and implementation program\u201D defined by the High Level Expert Group on AI. 
Italian companies will become leaders of AI-based research, development and innovation. The digital transformation of our entrepreneurial ecosystem is a must, if Italy wants to keep up with the most deve?loped and innovative nations. To that end, this programme fosters the development, implementation and adoption of AI solutions. Public-private partnerships will be instrumental in finding appropriate synergies between research bodies and enterprises with the aim of increasing Italy\u2019s technology transfer capabilities and thus competitiveness. 
Italy\u2019s public administrations will govern with AI and will govern AI. The use and impact of AI in the public sector revolves around the dual dimensions of governance \u2018with and of\u2019 AI. On the one hand, Italy\u2019s Government will improve its internal processes and policies thanks to a responsible use of data and AI technology. On the other hand, the Government is committed to governing AI and mitigating its potential risks, especially to safeguard human rights and ensure an ethical deployment of AI.
Note: The \u201Cgeneral principles\u201D identified are from a crude summary.`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201CThe use and impact of AI in the public sector revolves around the dual dimensions of governance \u2018with and of\u2019 AI. On the one hand, Italy\u2019s Government will improve its internal processes and policies thanks to a responsible use of data and AI technology. On the other hand, the Government is committed to governing AI and mitigating its potential risks, especially to safeguard human rights and ensure an ethical deployment of AI.\u201D (p 14)
\u201CTechnologies must not promote economic growth per se, but inclusive and sustainable growth, in line with the principles contained in Article 3 of the Italian Constitution and the United Nations Sustainable Development Goals. This means that AI development must be centred around economic and social inclusion, human rights as well as environmental sustainability. AI must be designed and implemented in a responsible and transparent manner, based on trust and robustness so that it can be safely adopted in every sector and be capable of responding to societal challenges. To this aim, Italy adheres to the \u201CEthics Guidelines for trustworthy AI- Guidance and implementation program\u201D defined by the High Level Expert Group on AI.\u201D (p 14)`,"Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"N/A","General principles on AI":["Human rights-centred. AI systems should be compatible with human rights. ","Opportunity. The opportunities of AI should be harnessed.","R&D. Sufficient resources should be invested in AI R&D.","Environmental wellbeing. The use of AI should not harm the environment. ","Inclusive development. AI systems should be developed inclusively. ","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Interoperability. AI systems should be able to work with other systems. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27222","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Italy: AI Strategic Programme","Translation Comments":"Official Translation Obtained"},id:"i-s-WMQjjj_P",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-s-WMQjjj_P",name:"Italy: AI Strategic Programme",index:176,createdAt:"2024-05-24T04:29:45.220Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-s-WMQjjj_P"},{values:{"Category of creator":["OECD"],"Policy creator":["Netherlands"],"Policy Name":"Non-Discrimination by Design","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`These guidelines could be useful in educational settings.  It\u2019s a practical checklist of sorts. 
New guidelines aim to correct discriminatory algorithms | Vrije Universiteit Brussel (vub.be)`,"Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Non-discriminatie by design.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as the objective or justification of the policy (the primary objective or justification)","Key quote on human rights":"\u201CThe guideline is a result of the Dutch government\u2019s commitment to human rights as a starting point for the use of AI and is in line with the recently adopted motion by politicians Jesse Klaver and Lilianne Ploumen on the new governance culture, in which the country\u2019s parliament stated that \u201Cracism must be ended as soon as possible, not least by stopping the use of discriminatory algorithms\u201D.\u201D ","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`\u201CAlgorithms work with data, but the data that organisations hold is often incomplete and biased. An algorithm that learns from today\u2019s world will learn that men are more likely to be invited for an interview for a managerial position than women; an algorithm trained on the police database, which has an overrepresentation of data from neighbourhoods with many residents with an immigrant background, will conclude that crime is concentrated in those neighbourhoods. Organisations should therefore always check the data is balanced, complete and up to date.\u201D (no pinpoint \u2014 website)

\u201CThe control of algorithms should not only be about whether the system explicitly makes decisions based on discriminatory grounds such as race, orientation, beliefs or age. Even if automatic decision-making systems do not take these factors into account directly, they may do so indirectly. If a predictive policing system uses postcode areas, for example, it can lead to indirect discrimination, because it can advise the police to do a lot of surveillance in particular areas. The risk of self-fulfilling prophecies is high. \u201C`,"General principles on AI":["Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Bias testing. AI systems should be tested for bias. ","Human rights-centred. AI systems should be compatible with human rights. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27116","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":11,Title:"Netherlands: Non-Discrimination by Design","Translation Comments":"Translation Needed"},id:"i-oeQINs-uuL",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-oeQINs-uuL",name:"Netherlands: Non-Discrimination by Design",index:181,createdAt:"2024-05-24T00:14:03.083Z",updatedAt:"2024-06-03T07:20:22.021Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-oeQINs-uuL"},{values:{"Category of creator":["OECD"],"Policy creator":["United Kingdom"],"Policy Name":"AI Procurement-In-A-Box","Year of Commencement or Creation":"2018",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is another useful \u2018tool\u2019 intended to drive norms and standards. It does this at the procurement level. It could be applied to EdTech. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["WEF_AI_Procurement_in_a_Box_AI_Government_Procurement_Guidelines_2020.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information in reference to AI in general","Key quote on human rights":`Under \u201Cexample of human rights assessment from Google Cloud\u201D
\u201CGoogle Cloud launched a Celebrity Recognition tool to a select set of media and entertainment customers to help them identify and label celebrities in professionally produced content, such as movies and sporting events. From the beginning of the product development process, they engaged in a human rights impact assessment (HRIA) and internal AI principles reviews. In partnership with BSR, a human rights non-profit organization, and using the UN\u2019s Guiding Principles on Business and Human Rights as a framework, the team considered potential impacts throughout numerous dimensions including privacy, discrimination, freedom of expression and many others. Aspects such as consultation with potentially affected stakeholders, dialogue with independent expert resources and paying particular attention to those at heightened risk of vulnerability or marginalization were part of the methodology\u201D (p 16)

\u201CAssemble multidisciplinary teams that specialize in designing, procuring, evaluating and operationalizing AI systems. These multidisciplinary teams should include expertise in: policy from the domain (e.g. justice) in which the AI solution will be applied, machine learning/ data science, data engineering, technology (software and hardware), procurement, ethics and human rights.\u201D (p 21) `,"Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CEmployment decisions have high stakes with critical consequences for individuals, organizations and society. Algorithms can make predictions in ways that disadvantage certain groups. Hence, concerns about AI algorithms bias and discrimination are particularly heightened, further complicated by labour and anti-discrimination laws.\u201D (p 8)","General principles on AI":["Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27022","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":`Guidelines - What are the key considerations when starting a procurement process? (p 11-12) 
Use procurement processes that focus not on prescribing a specific solution but rather on outlining problems and opportunities, and allow room for iteration.
Define the public benefit of using AI while assessing risks.
Align your procurement with relevant existing governmental strategies and contribute to their further improvement.
Incorporate potentially relevant legislation and codes of practice in your RFP.
Articulate the technical and administrative feasibility of accessing relevant data.
Highlight the technical and ethical limitations of intended uses of data to avoid issues such as historical data bias.
Work with a diverse, multidisciplinary team
Focus throughout the procurement process on mechanisms of algorithmic accountability and of transparency norms.
Implement a process for the continued engagement of the AI provider with the acquiring entity for knowledge transfer and long-term risk assessment.
Create the conditions for a level and fair playing field among AI solution providers.`,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":27,Title:"United Kingdom: AI Procurement-In-A-Box","Translation Comments":"N/A - English"},id:"i-wH9XyF1SnK",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-wH9XyF1SnK",name:"United Kingdom: AI Procurement-In-A-Box",index:299,createdAt:"2024-05-24T00:08:54.179Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-wH9XyF1SnK"},{values:{"Category of creator":["OECD"],"Policy creator":["United Kingdom"],"Policy Name":"Welsh Language Technology Action Plan","Year of Commencement or Creation":"2018",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is a very good example of an optimistic vision for education \u2014 an example of how technology can help students. ","Relevance Type":["Policy contains case studies on AI in education"],"What kinds of education, if any, are contemplated by the policy?":"","Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["welsh-language-technology-and-digital-media-action-plan.pdf"],"Key quotes on AI in education principles":"\u201CThe Welsh language to be the user interface (UI) language of devices in Welsh-medium education and for Welsh-speaking students and staff in colleges and universities in Wales.\u201D (p 13)","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Opportunity. The opportunities of AI should be harnessed."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26880","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"The initiative is using AI to enable greater use of the Welsh language, including in educational settings. ","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":25,Title:"United Kingdom: Welsh Language Technology Action Plan","Translation Comments":""},id:"i-0oQBY0gmWD",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-0oQBY0gmWD",name:"United Kingdom: Welsh Language Technology Action Plan",index:297,createdAt:"2024-05-24T00:08:34.228Z",updatedAt:"2024-06-03T03:55:15.425Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-0oQBY0gmWD"},{values:{"Category of creator":["OECD"],"Policy creator":["United Kingdom"],"Policy Name":"UK Government\u2019s Guidelines for AI Procurement","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This extends on the Procurement-In-A-Box content dealt with earlier. This is the specific document that emerged out of a project with the World Economic Forum. Could definitely be applied to EdTech procurement, at least in government schools. 
Guidelines for AI procurement - GOV.UK (www.gov.uk)
`,"Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)","Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically","Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Guidelines for AI procurement - GOV.UK.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":`\u201CExplain in your procurement documentation that the public benefit is a main driver of your decision-making process when assessing proposals. Consider the human and socio-economic impact and benefits of your AI system in line with Social Value guidance. Public benefit goals must be relevant to what you are procuring (and not generic in nature) and must comply with the principles of non-discrimination, equal treatment and proportionality.\u201D (p 8-9)

\u201CHave suppliers highlighted and/or addressed any issues of bias within the data? Do they clearly explain why their strategies are appropriate and proportionate? Do they have a plan for addressing any issues that you may have missed and underline the importance of an agile project delivery?\u201D (p 11)

\u201CAs part of the evaluation process, also review the specialist skills, qualifications and diversity of the team that will develop and deploy the AI system. This can also help to anticipate or detect unfair bias in the system.\u201D (p 20)`,"General principles on AI":["Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Inclusive development. AI systems should be developed inclusively. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24808","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":23,Title:"United Kingdom: UK Government\u2019s Guidelines for AI Procurement","Translation Comments":"N/A - English"},id:"i-gEpPiSpPhW",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-gEpPiSpPhW",name:"United Kingdom: UK Government\u2019s Guidelines for AI Procurement",index:295,createdAt:"2024-05-24T00:08:08.619Z",updatedAt:"2024-06-05T21:37:17.815Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-gEpPiSpPhW"},{values:{"Category of creator":["OECD"],"Policy creator":["United Kingdom"],"Policy Name":"Foundation Model Taskforce","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This is a hugely relevant project on the \u201Copportunity\u201D side. As the UK government argued, building a government-owned foundation model could, in education, \u2018transform teachers\u2019 day-to-day work, freeing up their time to focus on delivering excellent teaching\u2019.
Initial \xA3100 million for expert taskforce to help UK build and adopt next generation of safe AI - GOV.UK (www.gov.uk)`,"Relevance Type":["Policy makes fleeting reference to AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["To build capacity \u2014 to en","Develops tools. It provides tools and place them in the hands of businesses or governments"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:"","Key quotes on AI in education principles":"\u201CIn education it could transform teachers\u2019 day-to-day work, freeing up their time to focus on delivering excellent teaching.\u201D","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["R&D. Sufficient resources should be invested in AI R&D.","Opportunity. The opportunities of AI should be harnessed.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27548","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`Opportunity
\u201CThis technology is also predicted to raise global GDP by 7 percent over a decade, making its adoption a vital opportunity to grow the UK economy.\u201D
\u201CDeveloped responsibly, cutting-edge AI can have a transformative impact in nearly every industry. It can revolutionise the way we develop new medical treatments, tackle climate change and improve our public services, all while growing and future-proofing our economy.\u201D
Etc
Trust
\u201CTo support businesses and public trust in these systems and drive their adoption, the Taskforce will work with the sector towards developing the safety and reliability of foundation models, both at a scientific and commercial level.\u201D`,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":13,Title:"United Kingdom: Foundation Model Taskforce","Translation Comments":""},id:"i-xGK8RQmKFx",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-xGK8RQmKFx",name:"United Kingdom: Foundation Model Taskforce",index:285,createdAt:"2024-05-24T00:07:26.088Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-xGK8RQmKFx"},{values:{"Category of creator":["OECD"],"Policy creator":["United Kingdom"],"Policy Name":"National AI Strategy","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Like most national strategies reviewed, this focuses on AI education rather than EdTech governance. However, it does express some general governance norms (see p 50) that could be applied to EdTech.","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":"","Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["National_AI_Strategy_-_PDF_version.pdf"],"Key quotes on AI in education principles":"This is not focused on \u2018EdTech\u2019 \u2014 more focused on building capacity for education, like most national strategies. ","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information in reference to AI in general","Key quote on human rights":`\u201CWe will collaborate with key actors and partners on the global stage to promote the responsible development and deployment of AI. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. Through our science partnerships and wider development and diplomacy work, we will seek to engage early with countries on AI governance, to promote open society values and defend human rights\u201D (p 50)
\u201CThis is not to say that AI is currently unregulated. The UK already regulates many aspects of the development and use of AI through \u2018cross-sector\u2019 legislation and different regulators. For example, there is coverage in areas like data protection (Information Commissioner\u2019s Office), competition (Competition & Markets Authority), human rights and equality (Equality & Human Rights Commission). As well as through \u2018sector-specific\u2019 legislation and regulators, for example financial services (Financial Conduct Authority) and medical products (Medicines and Healthcare products Regulatory Agency).\u201D (p 51)
\u201CThe UK is already working with like-minded partners to ensure that shared values on human rights, democratic principles and the rule of law shape AI regulation and governance frameworks, whether binding or non-binding, and that an inclusive multi-stakeholder approach is taken throughout these processes.\u201D (p 55)`,"Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CFor example, concerns around fairness relate to algorithmic bias and discrimination issues under the Equality Act, the use of personal data (including sensitive personal data) and sector-specific notions of fairness such as the Financial Conduct Authority\u2019s Fair Treatment of Customers guidance.\u201D (p 55)","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27177","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`There are lots of fleeting references. 

Interoperability (extracted because many do not mention it):
\u201CGrowing the UK\u2019s contribution to the development of global AI technical standards, to translate UK R&D for trustworthy AI into robust, technical specifications and processes that can support our AI governance model, ensure global interoperability and minimise the costs of regulatory compliance;\u201D (p 50)
\u201CUK Defence has a strong record of collaboration with international partners and allies. Key collaborations include engagement with NATO allies to lead AI integration and interoperability across the Alliance, and supporting the AI Partnership for Defence, a 14-nation coalition providing values based global leadership for defence AI.\u201D (p 55)
\u201CWe want global technical standards for AI to benefit UK citizens, businesses, and the economy by: \u2022 Supporting R&D and Innovation. Technical standards should provide clear definitions and processes for innovators and businesses, lowering costs and project complexity and improving product consistency and interoperability, supporting market uptake.\u201D (p 57)
On procurement:
\u201CPublic Sector as exemplar for AI procurement & ethics\u201D (p 14)
Then they note:
\u201CNational Statistics Data Science Campus; the Crown Commercial Service\u2019s public sector AI procurement portal; and support for the Department for International Trade attracting AI related Foreign Direct Investment into the UK.\u201D
Artificial Intelligence (AI) - CCS (crowncommercial.gov.uk)
`,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"United Kingdom: National AI Strategy","Translation Comments":""},id:"i-M57ryB1BR9",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-M57ryB1BR9",name:"United Kingdom: National AI Strategy",index:182,createdAt:"2024-05-24T00:06:30.998Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-M57ryB1BR9"},{values:{"Category of creator":["OECD"],"Policy creator":["Ireland"],"Policy Name":"National AI Strategy","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`There is a focus here on \u2018AI education\u2019, but that is not the only thing. They also recognise that AI can advance Ireland\u2019s objectives in areas including education\u2014that it can be a force for good in this space. 

This is an excellent document\u2014both for its general guidance on AI governance and commentary on the opportunities at hand (including increasing access to education). `,"Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["national-ai-strategy.pdf"],"Key quotes on AI in education principles":`Preparedness to embrace AI in education
\u201CConsider how AI can be incorporated into future policy for digital learning\u201D (p 11)
\u201CFor example, AI applications can advance our objectives in areas such as climate action, public health, education, housing, urban development, preservation of cultural heritage, food security, human rights, crisis response and disaster management, amongst others\u201D (p 7)
AI for social inclusion: 
\u201CAI FOR SOCIAL INCLUSION While there is a risk that AI could result in new forms of inequalities, it may also offer opportunities to improve access and inclusion - in work, in education, in everyday life, and in making human connections. For example, robots incorporating AI and smart home assistants are being used to assist in providing health and social care.13 There is also significant potential for AI to provide educational resources for people with disabilities and special needs.14 The development of AI-based semantic technologies to extract digital content can render navigation and access easier and more effective for people with low levels of vision. In addition, AI-based innovations like real-time live captioning can assist those with impaired hearing.\u201D (p 18)
Translation in learning:
\u201Cresearchers at Lero, the SFI Research Centre for Software, are working with Microsoft to develop AI-based \u201Cchatbots\u201D to provide opportunities for young refugees to access and avail of high-quality educational resources in their own languages\u201D (p 18)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":`\u201CA human rights-based approach to AI is increasingly supported by multilateral standard-setting organisations, such as the United Nations (UN), the UN Educational, Scientific and Cultural Organisation (UNESCO), the Organisation for Economic Cooperation and Development (OECD) and the Council of Europe.23 Human rights are protected by law and as such should underpin ethics guidance for AI.\u201D (p 25)
\u201CDeploying AI in certain public service areas - for example policing - will require particular attention from an ethical and human rights perspective. In driving public service adoption of AI, the GovTech Delivery Board will consider appropriate safeguards \u2013 including the potential use of impact assessments - to ensure that the use of AI within the Public Service is consistent with ethical principles and with human rights obligations.\u201D (p 25)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`Risk of AI augmenting/being a source of inequity:
\u201CWhile AI will lead to some displacement, as with other previous disruptive technological advances, it will also lead to the creation of new jobs and higher productivity and incomes. The policy challenge is to ensure that these gains are shared equitably.\u201D (p 11)
\u201CAI-based systems have the potential to exacerbate existing structural inequities and marginalisation of vulnerable groups. For instance, AI-based facial recognition technology that has been trained disproportionately on lighter skin tones may be significantly less accurate in relation to people of colour and can thus exhibit higher false positive rates for this population.\u201D (p 21)
\u201CBeneficial AI innovation also relies on strong data governance, which ensures privacy, equity, transparency, and inclusivity. The proposal for an EU Data Governance Act is an important initiative in this respect.\u201D (p 61)
Social inclusion:
\u201CWhile there is a risk that AI could result in new forms of inequalities, it may also offer opportunities to improve access and inclusion - in work, in education, in everyday life, and in making human connections. For example, robots incorporating AI and smart home assistants are being used to assist in providing health and social care.1\u201D (p 18)
This sounds like substantive equality to me
\u201CThere is also significant potential for AI to provide educational resources for people with disabilities and special needs.14 The development of AI-based semantic technologies to extract digital content can render navigation and access easier and more effective for people with low levels of vision. In addition, AI-based innovations like real-time live captioning can assist those with impaired hearing.\u201D (p 18)`,"General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Bias testing. AI systems should be tested for bias. ","Human rights-centred. AI systems should be compatible with human rights. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Environmental wellbeing. The use of AI should not harm the environment. ","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Inclusive development. AI systems should be developed inclusively. ","R&D. Sufficient resources should be invested in AI R&D.","Opportunity. The opportunities of AI should be harnessed.","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27106S","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`On the principle that impact assessments should be undertaken:
\u201CImpact assessments are an important tool to identify and mitigate any potential risks of adverse impacts of AI. These impact assessments can be carried out voluntarily under an ethics-based approach, but they can also be incorporated under a binding legal framework. EU law already requires Impact Assessments in specific sectors, such as Data Protection Impact Assessments (DPIAs) under the GDPR. The Assessment List for Trustworthy AI (ALTAI), specifically refers to the need to perform a fundamental rights impact assessment for AI systems and provides examples of relevant questions for this purpose.25 The Council of Europe also recommends that Governments should conduct human rights impact assessments in the area of AI.\u201D (p 25)
\u201CCertification schemes or codes of conduct (whether voluntary or mandatory) are another way of building trust in AI systems and providing a pathway to compliance. Certification can provide independent and effective assurance that the protection and security of personal data involved in the training, testing, and application of AI algorithms, models and systems accords with international and Irish standards. This can be used to drive efficient, responsible, accountable and ethical AI data processing of personal data. For example, the Code of Conduct and Certification mechanisms under the General Data Protection Regulation (GDPR) are a means by which compliance with that Regulation can be verified.\u201D (p 27)
\u201CThis can be especially helpful and advantageous where the outcomes of AI usage in data processing operations may lead to decisions that have impact or a risk to individuals. It is possible these risks can be significant in some cases and that this could lead to bias, discrimination or a limitation of rights. The Top Team on Standards will examine ways to support the development of certification schemes and codes of conduct to address particular aspects of AI processing or different stages of AI development and operations in areas such as:
explainability and transparency 
determination or demonstration of fairness 
estimations of bias in training data 
mechanisms to effectively audit AI systems 
securing AI datastores and training sets 
data minimisation and anonymisation techniques that provide for effective outputs or AI \u201Cdecisions\u201D 
effective support for GDPR rights in AI systems 
design principles for AI systems that ensure effective data protection\u201D  (p 27)`,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Ireland: National AI Strategy","Translation Comments":"N/A - English"},id:"i-F_yviDxDMK",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-F_yviDxDMK",name:"Ireland: National AI Strategy",index:184,createdAt:"2024-05-23T22:28:41.075Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-F_yviDxDMK"},{values:{"Category of creator":["OECD"],"Policy creator":["Netherlands"],"Policy Name":"Vision on Generative AI","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`This vision statement / issues paper deals expressly with education. 

There are some interesting comments on unequal access to technology \u2014 \u201CSmaller companies, educational institutions, teachers, students, and socio-economically vulnerable groups may be disadvantaged, which can increase social inequalities within a society as well as between societies worldwide\u201D (p 14). Also note strong intention to regulate: \u201CIt is important that the government facilitates a support structure that manages the development of AI for education\u201D (p 20). `,"Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ","Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Trust. Organisations seeking to incorporate AI into educational settings must build trust.","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Information. Information about the technology in use should be readily available. ","Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. ","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ","Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ","Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.","Human rights-centred. The technology must be consistent with human rights. ","Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Transparency (transparency to government). The extent to which AI is used in educational settings should be clear to the government. ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["Government-wide+vision+on+generative+AI+of+the+Netherlands.pdf"],"Key quotes on AI in education principles":`Note on above \u2014 the general principles it discusses are intended to apply to education (among other things), so there is some overlap between \u201Ceducation principles\u201D and \u201Cgeneral principles\u201D. However, quotes are placed in the \u201Cgeneral\u201D box if general, and \u201Ceducation\u201D box if education-specific. 

Investment
\u201CIt is important that the government facilitates a support structure that manages the development of AI for education. With funding from the National Growth Fund, the Ministries of Economic Affairs and Climate Policy and Education, Culture and Science are investing substantially in the National Education Lab AI (NOLAI) for a period of ten years. Teachers, scientists, and companies collaborate to responsibly develop and evaluate advanced digital innovations, such as AI, in primary education.7 For instance, AI is being utilised to develop a centralised teacher dashboard and to offer customised assistance to students in their learning\u201D (p 20)
Section titled \u201CGenerative AI as a learning tool\u201D
\u201CGenerative AI models can be used to analyse huge amounts of data quickly. Generative AI can therefore be used, for example, to explain complex texts, interpret key topics and draw conclusions. Users can therefore also use generative AI as a learning tool. 
We see this role, for example, in the field of language and translation, Generative AI models are capable of translating large amounts of text with high accuracy. The technology can be used to translate content, making relevant information available to a wider audience. This can be helpful for language learning and for translating websites or educational materials, including those related to government. 
Generative AI can therefore play an important role as a learning tool in education. For instance, this technology can assist students in generating summaries, clarifying learning material, and composing practice questions. Generative AI models can create personalised feedback, recommendations, and interventions by analysing users\u2019 learning patterns to tailor teaching to personal learning needs.11 
Teachers can use generative AI to design teaching methods or improve teaching materials. 
Furthermore, generative AI enables the prediction of future student performance based on past student data, which can help identify students who may require additional support.12 
The function of a learning tool is exemplified by the use of digital search engines, which are utilised by the majority of individuals in their daily lives. Generative AI has already been integrated into search engines by companies like Google and Microsoft, significantly improving their functionality. 
Finally, generative AI applications like ChatGPT are capable of explaining concepts in a variety of ways. The tool can be utilised for academic or professional purposes, as well as for everyday topics such as explaining the operation of a fuse box or how to save energy. Due to the interactive nature of applications like ChatGPT, users can request customised or more detailed explanations.\u201D (p 10)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`The key passage is as follows (on p 20):
\u201Cii Laws and regulations in the Netherlands and the EU
Different legal frameworks apply to the development and application of generative AI. The following discusses how the development of generative AI relates to fundamental rights with a particular focus on the European AI Act.
Fundamental rights 
The use and development of generative AI could potentially affect the realisation of fundamental rights. The fundamental rights affected by generative AI are the prohibition of discrimination and the right to privacy and data protection. 
The prohibition of discrimination and the principle of equality are included in Article 1 of the Constitution. The prohibition of discrimination is enshrined in Article 14 of the European Convention on Human Rights (ECHR) and Article 26 of the International Covenant on Civil and Political Rights (ICCPR). As previously noted in chapter 3b, generative AI can inadvertently perpetuate bias or discrimination. Bias can enter generative AI systems in various ways, including through developer and training data. As only a handful of AI developers shape generative AI and applications, (unconscious) bias may inadvertently be introduced into the models. In addition, training data may contain bias and enter the model, spreading and amplifying this bias widely.8 
The use and development of generative AI may raise concerns regarding the protection of privacy and data. The right to privacy is set out in Article 10 of the Constitution. In addition, the right to privacy is protected by Article 8 of the European Convention on Human Rights (Right to respect private and family life) and Article 17 of the International Covenant on Civil and Political Rights.\u201D`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`Concerns about concentrations of power and related access concerns: 
\u201CThe development of generative AI depends on a handful of large companies. This can result in unequal access to technology and disproportionate opportunities to take advantage of it. Smaller companies, educational institutions, teachers, students, and socio-economically vulnerable groups may be disadvantaged, which can increase social inequalities within a society as well as between societies worldwide. Finally, market power is often the prelude to exerting social and political influence.\u201D (p 14)
\u201CGenerative AI for greater equality\u201D
\u201CGenerative AI should help promote equality and bridge (socio-economic) gaps, both within and between countries. This is in line with several of the Sustainable Development Goals (SDGs).
This requires, firstly, monitoring the impact of automation on wage and employment trends, especially where increasing income and wealth inequality. AI may cause wages for different jobs to diverge more, as was the case with previous automation.34 
Secondly, policies and initiatives that promote economic equality, such as education and retraining programmes, social safety nets, and inclusive AI development that ensures a more balanced distribution of opportunities, can help counter economic inequality and reduce the digital divide. It is important to ensure that our social safety net is well-equipped for the socio-economic transitions that generative AI is expected to trigger in the mid to long term. 
Finally, equity requires fair conditions for all parties involved in model development and training. It is important to note that human \u2018labellers\u2019 who assist in improving AI models should receive fair compensation and working conditions. Unfortunately, this is not always the case.\u201D (p 26)
`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Augmentation, not replacement. AI systems should augment, not displace, workers.","Bias testing. AI systems should be tested for bias. ","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27627","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`Procurement:
\u201CContracted generative AI applications should also comply with the General Government Terms and Conditions for IT Contracts 2022 and departmental procurement conditions (if they prevail).\u201D (p 40)
\u201CDrafting, developing or refining (intergovernmental) procurement conditions with a view to generative AI.\u201D (p 42)
\u201CIt encourages the use of open source by applying the \u2018open source unless\u2019 principle in procurement and development.\u201D (p 25)
\u201CThe Dutch government has a commendable role in the responsible and safe development, procurement, and deployment of generative AI.\u201D (p 40)
Augmentation:
\u201CIt may be undesirable to replace certain forms of human contact with AI-driven processes\u201D (p 26)
Impact assessment content\u201D:
\u201CGovernment leading by example 
The government is actively promoting the acquisition of knowledge and skills. This allows us to take full advantage of the opportunities provided by generative AI. Adequate commitment to knowledge and skills also benefits one\u2019s grasp of technology, promotes social equity, and encourages participation. As a government, we will set a positive example. ...
As a government, we recognise the importance of innovation and experimentation in harnessing generative AI for public values. All generative AI applications must comply with relevant laws and regulations.22 To determine whether a specific form of generative AI deployment is feasible, a risk analysis should be conducted for each unique case before use. These are a Data Protection Impact Assessment (DPIA) and an algorithm impact assessment (such as an Impact Assessment Fundamental Rights and Algorithms (IAMA)), which identifies risks and mitigation measures. The results of this should be submitted to the (departmental) Chief Information Officer and the Data Protection Officer for advice before deployment. The above points apply when using or (re)developing an open-source generative AI application. In the context of the \u2018Wet open overheid\u2019 (Open Government Act) (Woo) and encouraging transparency, the policy guideline \u201Copen (source), unless\u201D applies.23 Non-contracted generative AI applications\u201D (p 40)`,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":`It seems to have built \u201CDutch open language models\u201D
\u201CDutch open language models 
\u201CWe encourage the development of Dutch and European LLM\u2019s compliant to public values. Financing GPT NL is one example. We are also exploring the possibility of joining the Alliance for Languages Technologies European Digital Infrastructure Consortium (ALT-EDIC), among others\u201D; (p 14)`,'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":10,Title:"Netherlands: Vision on Generative AI","Translation Comments":""},id:"i-SxcvRiVWW4",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-SxcvRiVWW4",name:"Netherlands: Vision on Generative AI",index:195,createdAt:"2024-05-23T10:22:00.655Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-SxcvRiVWW4"},{values:{"Category of creator":["OECD"],"Policy creator":["Netherlands"],"Policy Name":"Amsterdam\u2019s Register","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`The idea of an AI register could be applied to educational settings (which is one of the transparency norms).
Algorithm Register`,"Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Tracks. It sets out to boost understanding specifically of where and how AI is being used"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:"","Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information in reference to AI in general","Key quote on human rights":"\u201CAlgorithms used in public services must adhere to the same rules and principles as all other public services provided by the municipality. That means they must treat people equally, not limit their freedom, be transparent and open to democratic control and be at the service of the people of Amsterdam; not the other way around.\u201D (https://algoritmeregister.amsterdam.nl/en/more-information/) ","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Inclusive development. AI systems should be developed inclusively. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26889","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`The Algorithm Register encourages users to: 
access the published algorithms for their own interests; and
provide feedback and participate in \u201Cbuilding human-centered algorithms in Amsterdam\u201D. 
It also provides open access to some of the algorithms used by the City of Amsterdam. `,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":4,Title:"Netherlands: Amsterdam\u2019s Register","Translation Comments":"N/A - English"},id:"i-5BdsrZQR69",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-5BdsrZQR69",name:"Netherlands: Amsterdam\u2019s Register",index:189,createdAt:"2024-05-23T10:20:52.902Z",updatedAt:"2024-06-06T03:10:06.114Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-5BdsrZQR69"},{values:{"Category of creator":["OECD"],"Policy creator":["Netherlands"],"Policy Name":"Algorithm Supervision Body","Year of Commencement or Creation":"2022",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"Translated with DeepL. This is highly relevant in a general sense \u2014 it is about approaches to regulating algorithms. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A Other]"],"Governance practices employed":["To help officials anticipate the impact of AI by offering them systematic frameworks and tools","[N/A]"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["advies-privacy-company-inrichting-algoritmetoezicht en.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"Numerous references to human rights, including requirement of a \u201Cmandatory human rights impact assessment\u201D by the ministry. ","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about the risk of AI augmenting inequities/inequalities","Key quote on equity/equality":"Talks about \u201Cnon-discrimination\u201D throughout","General principles on AI":["Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ","Human rights-centred. AI systems should be compatible with human rights. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27438","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":["Will Cesta"],"Relevant?":"Yes","Series #":3,Title:"Netherlands: Algorithm Supervision Body","Translation Comments":"Translation Completed (DeepL)"},id:"i-dwqYhbrrRP",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-dwqYhbrrRP",name:"Netherlands: Algorithm Supervision Body",index:188,createdAt:"2024-05-23T10:20:45.245Z",updatedAt:"2024-06-05T23:05:44.633Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-dwqYhbrrRP"},{values:{"Category of creator":["OECD"],"Policy creator":["Canada"],"Policy Name":"Canada\u2019s Digital Charter","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is not \u2018about\u2019 AI in education, but the norms it expresses could be applied to AI in education. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Seeks information. It gathers inputs on public sentiment about AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Canada Charter.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":`Mentions concepts related to human rights in its 10 principles: 
\u201CFree from Hate and Violent Extremism\u201D (Principle 9) 
\u201CSafety and Security\u201D (Principle 2) `,"Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`Mentions a concept related to equity in its 10 principles: 
\u201CA Level Playing Field\u201D (Principle 6) `,"General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Interoperability. AI systems should be able to work with other systems. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress."],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24508","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":5,Title:"Canada: Canada\u2019s Digital Charter","Translation Comments":"N/A - English"},id:"i-npZS-xFGnW",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-npZS-xFGnW",name:"Canada: Canada\u2019s Digital Charter",index:201,createdAt:"2024-05-23T08:40:26.962Z",updatedAt:"2024-06-03T07:18:49.846Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-npZS-xFGnW"},{values:{"Category of creator":["OECD"],"Policy creator":["Canada"],"Policy Name":"Algorithmic Impact Assessment","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This is one of the most important and interesting initiatives, and one that could definitely be applied to AI in education. It is a concrete tool designed to help officials assess and mitigate risk. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Algorithmic Impact Assessment Tool - Canada.ca.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`\u201CThe impacts of automating an administrative decision are classified into 4 levels, ranging from Level I (little impact) to Level IV (very high impact). The AIA is intended to identify risks and assess impacts in a broad range of areas, including: 
the rights of individuals or communities 
the health or well-being of individuals or communities 
the economic interests of individuals, entities, or communities 
the ongoing sustainability of an ecosystem\u201D (p 5-6)`,"Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`\u201CA broad range of information about an automation project is required to fully answer the questions in the risk and mitigation areas of the AIA. Prior to starting the AIA, it is useful to have information about: 
the administrative decision that the automated decision system will inform, contribute to, or make, the context in which the system will be used, and the way the system will assist or replace the judgement of a human decision-maker 
the clients subject to the decision, including evidence of any vulnerability (for example, socioeconomic, demographic, geographic)\u201D (p8-9)`,"General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Bias testing. AI systems should be tested for bias. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24387","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":3,Title:"Canada: Algorithmic Impact Assessment","Translation Comments":"N/A - English"},id:"i-d273os6Vd3",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-d273os6Vd3",name:"Canada: Algorithmic Impact Assessment",index:199,createdAt:"2024-05-23T08:40:00.447Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-d273os6Vd3"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Indonesia"],"Policy Name":"National AI Strategy","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':`Note: Translated using DeepL. There is a fair bit of content worth looking into here, including an application map in education (p 127). 
There is a governance section, but my feeling is that this is very opportunity-oriented. Nothing is said about risk in the education context, but some general AI risk principles are included. `,"Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["Indonesia en.pdf"],"Key quotes on AI in education principles":`The big picture here is that: (a) results in schools are bad, (b) university is inaccessible, but: 
Artificial Intelligence can be utilized to increase the scale and reach of quality education services with special attention to rural communities, people with disabilities, and children with special needs. Artificial Intelligence can be applied to personalize content and learning experiences that take into account various modes of interaction according to learner characteristics. Artificial Intelligence can also help manage information on learning outcomes and their scaling up as feedback to the system in order to produce adaptive and automated delivery of learning experiences (p 97-98)
Artificial Intelligence can be utilized to improve the efficiency of teachers' administrative tasks beyond the preparation and delivery of learning content. This includes preparing general teaching plans, evaluating learning outcomes, ensuring academic integrity, and evaluating educator performance. Automation of these administrative tasks can help teachers focus more on preparing and delivering quality learning content. (p 98)
There are three (3) perspectives in the application of Artificial Intelligence for education, namely student/learner-facing (learning-facing), teacher/teaching (teacher-facing) and managers and administrators at all levels (system-facing) as users [Zawacki-Richter et al. 2019].
They go on to say:
Education services that are currently class-based will shift to learner-based education. Furthermore, education can lead to Precision Learning which takes the term from the health field. In Precision Learning, learning in addition to taking into account the cognitive, affective, and psycho-motor aspects of students, also takes into account the behavior or daily habits of students. Then with the amount of data that can be taken from students through gadgets, computers and students' digital footprints, there will be a lot of information obtained from individual students. Formal learning in schools will slowly shift from school to out of school which is currently recognized by the government with the existence of home schooling with a standardized evaluation system. Artificial Intelligence will play a major role in the changes in education in the future. Various applications of Artificial Intelligence in Education are shown in Figure 7-4, including Intelligent Online Education, Smart Course Content with AR/VR, Virtual Laboratory, Adaptive Learning System, Adaptive Assessment System, Adaptive Classification System, Serious Game in Education, and Precision Learning System. (p 126)
What can be done?
Development of various multimedia content, educational games, and adaptive assessment for learning as a fun experience rather than learning as a burden.
 The development of integrated education data, coordinated learning materials, integrated question banks and the use of smart evaluation methods to realize an open education system (stakeholders working together) rather than a closed education system (stakeholders acting individually). 
Development of an adaptive assessment system and an intelligent student classification system to make teachers a facilitator of learning rather than a transmitter of knowledge. 
Development of a precision learning system to realize a learner-centered and personalized approach rather than a one-size fits all pedagogical approach (p 127)
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"\u201CArtificial Intelligence that is intended to generate public trust and be accountable must fulfil the element of safety, meaning that the Artificial Intelligence developed can be tested and is suitable for use without threatening the safety and protection of human rights.\u201D (p 41)","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`\u201CArtificial Intelligence can be utilized to increase the scale and reach of quality education services with special attention to rural communities, people with disabilities, and children with special needs. Artificial Intelligence can be applied to personalize content and learning experiences that take into account various modes of interaction according to learner characteristics. Artificial Intelligence can also help manage information on learning outcomes and their scaling. (p 97)\u201D
More general comments:
To achieve trustworthy Artificial Intelligence, there must be a focus on inclusion and diversity throughout the lifecycle of the Artificial Intelligence system, which must be user-centered and designed in a way that allows everyone to use the Artificial Intelligence product or service. (p 40)`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Human rights-centred. AI systems should be compatible with human rights. ","Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26968","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`Note: Indonesia is not signing up to the \u201Caugmentation, not replacement\u201D team:
During a Kompas100 CEO Forum event in Jakarta on Thursday (28/11/2019), the President of the Republic of Indonesia, Joko Widodo, ordered government agencies to eliminate two ranks of civil servants by 2020 and replace their roles with Artificial Intelligence, in an effort to cut bureaucracy that hampers investment. President Jokowi's statement was reinforced by an analysis by an international organization (Deloitte, 2019) that sheds light on how Artificial Intelligence can benefit the government (p 122)
Procurement:
Not sure whether this is a dodgy translation...?
Create a policy that prioritizes products made by the nation's children in government procurement to reduce dependence on imported products and at the same time to increase TKDN. (p 27)
Sets \u201Cpublic trust\u201D as one of the goals (p 39)`,"Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Indonesia: National AI Strategy","Translation Comments":"Translation Completed (DeepL)"},id:"i-r3DyNRPcd4",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-r3DyNRPcd4",name:"Indonesia: National AI Strategy",index:206,createdAt:"2024-05-23T02:26:03.418Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-r3DyNRPcd4"},{values:{"Category of creator":["OECD"],"Policy creator":["Latvia"],"Policy Name":"Latvia\u2019s National AI Strategy","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This policy recognises that AI has a role to play in education, and refers to some general regulatory principles that could be applied to education.","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary","Tertiary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["Latvia (translated).pdf"],"Key quotes on AI in education principles":`The main section on AI in education \u2014 as distinct from AI education \u2014 is:
AI as a tool can be used to improve general education. Basically, three educational support functions that AI can perform can be highlighted88: 
1. Smart content \u2013 A technology that can create a synopsis from the contents of a book or prepare a test for testing knowledge. For example, Cram10189 or Netex learning90 tools. 
2. Smart training systems (virtual learning assistant) \u2013 personalized electronic training tailored to the needs, learning style, preferences of the pupil or student. For example, the Carnegie Lerning91 tool. 
3. Virtual learning environment as an aid to learning information. For example, the Victoryxr92 tool. AI systems could also be used as a virtual teaching assistant to test and aggregate learners' knowledge. Analysts at Technavio predict that between 2018 and 2022, the size of the AI market in the U.S. education sector will grow by 48%.93 (p 22)
It does not go much further. `,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":`It talks about human rights a fair bit in the context of its governance ambitions, for example:
AI systems should be designed in a way that respects the rule of law, human rights, democratic values and diversity and should include appropriate safeguards, such as ensuring human intervention where necessary, to ensure fairness. (p 22)
As set out in the Charter, CEPEJ believes that the application of AI in the area of justice can help improve efficiency and quality and must be implemented responsibly, with respect for fundamental rights, as guaranteed in particular by the European Convention on Human Rights and the Council of Europe Convention for the Protection of Personal Data with regard to Automatic Processing of Personal Data. (p 41)`,"Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":`Nothing education-specific.
The closest thing I can find \u2014 noting that this is a DeepL translation \u2014 is:
the main requirements for AI-systems are sustainable and inclusive development, human orientation and fairness, transparency and explainability of actions, security, responsibility. (p 22)
`,"General principles on AI":["Bias testing. AI systems should be tested for bias. ","Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Human rights-centred. AI systems should be compatible with human rights. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Inclusive development. AI systems should be developed inclusively. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (explainability). AI systems should be sufficiently explainable.","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","R&D. Sufficient resources should be invested in AI R&D.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Opportunity. The opportunities of AI should be harnessed.","Interoperability. AI systems should be able to work with other systems. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26933","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":`\u201CAs set out in the Charter, CEPEJ believes that the application of AI in the area of justice can help improve efficiency and quality and must be implemented responsibly, with respect for fundamental rights, as guaranteed in particular by the European Convention on Human Rights and the Council of Europe Convention for the Protection of Personal Data with regard to Automatic Processing of Personal Data.\u201D (p 22) 
Etc, etc [cites a range of principles developed]
It seems to implicitly accept these principles (although notes that \u201Cexplainability\u201D is complex):
\u201CIt is these basic principles that must also be taken into account when developing AI solutions in Latvia and planning their further development.\u201D (p 24)`,"Notable Case Studes - Examples of AI in Education":`They mention a few use cases:
1. Smart content \u2013 A technology that can create a synopsis from the contents of a book or prepare a test for testing knowledge. For example, Cram10189 or Netex learning90 tools. 
2. Smart training systems (virtual learning assistant) \u2013 personalized electronic training tailored to the needs, learning style, preferences of the pupil or student. For example, the Carnegie Lerning91 tool. 
3. Virtual learning environment as an aid to learning information. For example, the Victoryxr92 tool. AI systems could also be used as a virtual teaching assistant to test and aggregate learners' knowledge. Analysts at Technavio predict that between 2018 and 2022, the size of the AI market in the U.S. education sector will grow by 48%.93 (p 22)
`,"Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Latvia: Latvia\u2019s National AI Strategy","Translation Comments":""},id:"i-YejprgjJnB",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-YejprgjJnB",name:"Latvia: Latvia\u2019s National AI Strategy",index:211,createdAt:"2024-05-23T01:16:13.693Z",updatedAt:"2024-06-05T21:39:18.055Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-YejprgjJnB"},{values:{"Category of creator":["OECD"],"Policy creator":["Slovenia"],"Policy Name":"National AI Programme of Slovenia","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This policy seems to be on the robust end of the spectrum. The document attached addresses numerous relevant areas, particularly \u201CEnsuring an appropriate legal and ethical framework\u201D, which may prove generally relevant (see p 58 of the document attached). Note that the document attached was translated with DeepL\u2014 this is not an official translation. Definitely worth further investigation. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education","Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ","Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ","Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["Slovenia.pdf"],"Key quotes on AI in education principles":"\u201CThe use of AI in education will enable fairer access to education for more vulnerable groups and people with special needs, as the use of AI solutions allows educational resources and methods to be adapted to each individual according to their needs and preferences. It is particularly important that teachers at all levels of education know and understand AI solutions so well that they actively use them as a tool to facilitate their work by bringing them closer to students' needs, making the necessary analyses, facilitating assessment and, ultimately, upgrading their own professional development.\u201D (p 31)","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":`\u201CSlovenia stands for AI, which as a tool must primarily serve a person to ensure the quality of his life, thus joining EU countries with a vision of human-centric development and introduction of AI for his good and for the benefit of society. Ensuring public acceptance of AI is key to this, and this must be based on the confidence that AI deployment will actually produce positive impacts on individuals' lives. To do this, we must provide an appropriate legal and ethical framework that preserves and guarantees the acquisition and continued respect of human rights and fundamental freedoms, thereby guaranteeing the civil, political, economic, social and cultural rights of every individual, regardless of the level of introduction of new solutions.\u201D (p 8)

\u201CThe development and introduction of AI into society must be based on respect for human rights and fundamental freedoms as enshrined in the Constitution of the Republic of Slovenia, the EU Charter of Fundamental Rights, the Universal Declaration of Human Rights and other fundamental international instruments in the field of human rights. It must respect the fundamental values of Slovenian society, the rule of law and democracy and ensure economic and political stability\u201D (p 13)

\u201CSlovenia's efforts are also in line with the OECD Principles on Artificial Intelligence, which promote artificial intelligence that is innovative and trustworthy and respects human rights and democratic values.\u201D (p 13)
\u201CTaking into account the basic direction of the Programme for the development and deployment of trustworthy and human-centric AI, it is necessary to provide public and private sector actors with appropriate education and awareness raising on the ethical and legal aspects of the development and use of AI, including a focus on different human rights risks.\u201D (p 41)

\u201CSafety authorities shall only introduce AIs in the performance of their duties if this is necessary from the point of view of effectiveness and efficiency and the solutions do not endanger human rights and fundamental freedoms, are ethical, lawful and proportionate. In the area of freedom, security and justice, as in some other areas (e.g. procedures and decisions in healthcare), humans must have control over the use of AI and must therefore be given the right and be able to request review and review of decisions taken using AI. Responsibility for final decisions must lie with a clearly identifiable decision-maker. Systems operating in this field must be transparent and offer not only assessments or proposals but also their explanations wherever AI techniques allow it (the issue of transparency and explainability of AI methods).\u201D (p 52) 

\u201CThe speed of AI deployment and its impacts on society largely depend on people's trust that solutions are safe, robust and actually help improve their lives and ensure freedom, human rights and democratic processes.\u201D (p 55) 

\u201CEthical principles should therefore be reflected in the relevant legal regime of IMs. Although there is no legal vacuum in the field of AI with regard to the protection of human rights, regulation is necessary for the effective enforcement of already applicable sectoral norms, for example, anti-discrimination (international, EU and national) law.\u201D (p 58)

\u201CSlovenia will strengthen cooperation at the international level in the field of research, development and innovation; Education; scientific and economic diplomacy; regulation and regulation of the development, implementation and use of AI in accordance with respect for human rights and fundamental freedoms; developing an appropriate legal and ethical framework; international development cooperation and strengthening North-South cooperation and supporting sustainable development and achieving the SDGs.\u201D (p 61)

\u201CSupport education and awareness raising among businesses and the public sector on providing a legal and ethical framework for the development, deployment and use of AI, including human rights compliance issues.\u201D (p 64)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`\u201CAI shall pay particular attention to the protection of privacy and personal data and non-discrimination, and generally to ensure that the development and use of AI is based on ethical guidelines68 and criteria that ensure this, such as human performance and control, technical robustness and security, privacy and data management, transparency, diversity, non-discrimination and equity, social and environmental well-being and clear accountability.\u201D (p 58)

\u201CThe use of AI in education will enable fairer access to education for more vulnerable groups and people with special needs, as the use of AI solutions allows educational resources and methods to be adapted to each individual according to their needs and preferences. It is particularly important that teachers at all levels of education know and understand AI solutions so well that they actively use them as a tool to facilitate their work by bringing them closer to students' needs, making the necessary analyses, facilitating assessment and, ultimately, upgrading their own professional development.\u201D (p 31)

\u201CSupport digital training and literacy programmes for the widest population, including vulnerable groups, and in particular people with special needs, for the acquisition of digital competences and user skills in the field of AI (general lifelong learning, adult computer literacy).\u201D (p 51)

\u201CSupport lifelong education to AI also for more vulnerable groups and people with special needs 45 will help reduce the risk of social and digital exclusion, which could be exacerbated by the uptake of AI in certain areas of society\u201D (p 31)
`,"General principles on AI":["Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Bias testing. AI systems should be tested for bias. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Environmental wellbeing. The use of AI should not harm the environment. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Human rights-centred. AI systems should be compatible with human rights. ","Inclusive development. AI systems should be developed inclusively. ","Interoperability. AI systems should be able to work with other systems. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-14677","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Slovenia: National AI Programme of Slovenia","Translation Comments":"Translation Completed (DeepL)"},id:"i-Xg_AS09rrG",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-Xg_AS09rrG",name:"Slovenia: National AI Programme of Slovenia",index:215,createdAt:"2024-05-22T23:45:56.061Z",updatedAt:"2024-06-06T02:14:24.932Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-Xg_AS09rrG"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["United Arab Emirates"],"Policy Name":"UAE National Strategy for AI","Year of Commencement or Creation":"2018",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"As with many of the AI strategies reviewed, this one is focused on AI as a tool for economic growth, and sees education principally as a method of learning to \u2018do\u2019 AI \u2014 its focus on the safe and effective use of AI in education is less pronounced. However, there are a few areas of potential relevance \u2014 see Objective 4 (Adopt AI Across Customer Service to Improve Lives and Government) and Objective 8 (Ensure Strong Governance and Effective Regulation). ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["United_Arab_Emirates_National_Strategy_for_Artificial_Intelligence_2017-2031.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"No","Key quote on human rights":"","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"\u201CThe UAE also faces significant social and economic challenges, where the outcomes for the population are poor compared to other countries. For example, high rates of obesity and heart disease, high rates of traffic fatalities, poor air quality and poor education outcomes. Using AI to better respond to these challenges has huge potential benefits. There is a role for Government in supercharging this \u2013 providing the focus, resources and drive to solve these challenges.\u201D (p 30)","General principles on AI":["Opportunity. The opportunities of AI should be harnessed.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","R&D. Sufficient resources should be invested in AI R&D.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25387","Analysis Complete":!0,"Draft Analysis Complete":!0,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":"",Title:"United Arab Emirates: UAE National Strategy for AI","Translation Comments":"N/A - English"},id:"i-hGDvWnUmlp",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-hGDvWnUmlp",name:"United Arab Emirates: UAE National Strategy for AI",index:219,createdAt:"2024-05-22T23:30:52.519Z",updatedAt:"2024-06-05T21:37:17.815Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-hGDvWnUmlp"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Serbia"],"Policy Name":"Strategy for the Development of AI in the Republic of Serbia for the Period 2020-2025","Year of Commencement or Creation":"2020",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This plan discusses the \u201Cdevelopment of education geared to the needs of modern society and economy conditioned by the advancement of artificial intelligence\u201D \u2014 education for AI \u2014 but does not actually deal with AI in education directly. However, it is concerned with general principles that are applicable to education. Specifically, Objective 5 (from page 41) focuses on \u2018Ethical and safe application of artificial intelligence\u2019. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Divides focus relatively evenly between risk and opportunity",File:["Serbia_Strategy_for_Development_of_Artificial_Intelligence_in_Republic_of_Serbia_2020-2025.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"\u201C. In this sense, the development of an ethical framework should enable the protection of basic human rights and common values,\u201D (p 43)","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`There is an entire section on: \u201CProtection from discrimination in the implementation of artificial intelligence\u201D (p 42)

\u201CThe data used for training algorithms can be based on past discrimination (e.g. women have been higher risk taxpayers in the past and the algorithm forecasts the same situation in the future), there can be unbalanced data (e.g. significantly more data for men than for women causing the algorithm to favor men afterwards), or the responsible person fails at including all relevant data sources in the training. In addition, individuals who are subject to the decisions made by the AI model must have the right to an explanation and the right to transparency in connection with the algorithm. That is why it is necessary to enable: prevention of discrimination, enable early understanding and interpretation of the model and enable explanation of the decision.\u201D`,"General principles on AI":["Inclusive development. AI systems should be developed inclusively. ","Human rights-centred. AI systems should be compatible with human rights. ","Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.","Respect for laws [NEW]. AI should respect existing law.","R&D. Sufficient resources should be invested in AI R&D.","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Bias testing. AI systems should be tested for bias. ","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Opportunity. The opportunities of AI should be harnessed.","Interoperability. AI systems should be able to work with other systems. ","Trust. AI systems should not be used so as to undermine society\u2019s trust. ","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26466","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":["Will Cesta"],"Relevant?":"Yes","Series #":1,Title:"Serbia: Strategy for the Development of AI in the Republic of Serbia for the Period 2020-2025","Translation Comments":""},id:"i-XFPq4O1wP8",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-XFPq4O1wP8",name:"Serbia: Strategy for the Development of AI in the Republic of Serbia for the Period 2020-2025",index:230,createdAt:"2024-05-22T21:36:10.291Z",updatedAt:"2024-06-05T23:35:51.831Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-XFPq4O1wP8"},{values:{"Category of creator":["Non-OECD"],"Policy creator":["Vietnam"],"Policy Name":"National Strategy on R&D and Application of AI","Year of Commencement or Creation":"2021",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"There is a clear intention here for the government of Viet Nam to drive the adoption of AI in education. The policy is very \u2018opportunity-oriented\u2019\u2014very little is said about risk management. Still, there is clearly a governmental intervention concerned with AI in education \u2014 not merely education for AI capacity \u2014 so it is worth including this. ","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["Does Not Specify"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Plans further action. It sets out a strategy on AI"],"Opportunity and risk orientation":"Opportunity-focused (says significantly more about opportunities than risks)",File:["National Strategy On R&D and Application of Artificial Intelligence.pdf"],"Key quotes on AI in education principles":"\u201CPromote and carry out AI applications in the education sector: predict the work demand of the market; identify the student assessment criteria, support students to identify their job strengths upon graduation; automate the professional process of teachers; identify the criteria for achieving learning goals; personalize learning, improve learning efficiency with the help of teachers and virtual tutors to support students' awareness.\u201D (p 18)","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 One or two fleeting references, but not significant to the policy","Key quote on human rights":"\u201CDevelop and supplement additional legal documents on privacy protection, human rights, security related to the development and application of AI and on ensuring network security for AI-related activities.\u201D (p 5)","Does the policy reflect the principle of equity/equality?":"No","Key quote on equity/equality":"","General principles on AI":["R&D. Sufficient resources should be invested in AI R&D.","Opportunity. The opportunities of AI should be harnessed."],"Link (OECD or Other)":"https://en.baochinhphu.vn/national-strategy-on-rd-and-application-of-artificial-intelligence-11140663.htm","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":1,Title:"Vietnam: National Strategy on R&D and Application of AI","Translation Comments":"Translation Needed"},id:"i-hVLihd7Ntd",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-hVLihd7Ntd",name:"Vietnam: National Strategy on R&D and Application of AI",index:13,createdAt:"2024-05-22T21:13:42.079Z",updatedAt:"2024-06-05T21:38:16.468Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-hVLihd7Ntd"},{values:{"Category of creator":["OECD"],"Policy creator":["Australia"],"Policy Name":"Humans rights and technology discussion paper","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This paper certainly engages with the topic of education, but it is not exclusively focused on the safe and effective use of AI in education\u2014it is identifying human rights risks. However, the content is broadly relevant, so it is worth including.","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["techrights_2019_discussionpaper_0.pdf"],"Key quotes on AI in education principles":`\u201CNew technologies can improve the availability and accessibility of education. Lack of access to technology can exacerbate inequality, based on factors such as age, disability, Indigenous status, and rural or remote location.\u201D (p 18)
`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as the objective or justification of the policy (the primary objective or justification)","Key quote on human rights":`\u201CBut we also saw how artificial intelligence (AI) and other new technologies can threaten our human rights. Time and again people told us, \u2018I\u2019m starting to realise that my personal information can be used against me\u2019.\u201D (p 7)

Also note its reference to the Convention on the Rights of Persons with Disabilities, which provides for: 
\u201Cequality in education, including taking appropriate measures facilitating and delivering education in the most appropriate modes and means of communication\u201D (quoted on p 150)`,"Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`\u201CThe ultimate goal should be AI that benefits humanity by contributing to a more responsible and equitable society. By inviting multi-stakeholder input, considering risks, and setting rights-respecting standards, Australia has the opportunity to be among the norm-setters on the world stage.\u201D

(Another source quoted on p 133)`,"General principles on AI":["[N/A]"],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26833","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":9,Title:"Australia: Humans rights and technology discussion paper","Translation Comments":"N/A - English"},id:"i-0I94x5PNst",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-0I94x5PNst",name:"Australia: Humans rights and technology discussion paper",index:237,createdAt:"2024-05-21T09:52:27.091Z",updatedAt:"2024-06-04T22:33:52.017Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-0I94x5PNst"},{values:{"Category of creator":["OECD"],"Policy creator":["Australia"],"Policy Name":"AI Ethics Framework ","Year of Commencement or Creation":"2019",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"In principle, these principles apply to any form of AI deployed in Australia, including AI in education. ","Relevance Type":["Policy expresses principles or ideas that could inform the governance of AI in education"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"],"Governance practices employed":["Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Australia\u2019s AI Ethics Principles _ Australia\u2019s Artificial Intelligence Ethics Framework _ Department of Industry Science and Resources.pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"\u201CHuman rights risks need to be carefully considered, as AI systems can equally enable and hamper such fundamental rights. It\u2019s permissible to interfere with certain human rights where it\u2019s reasonable, necessary and proportionate.\u201D (no pinpoint)","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about AI as a tool for promoting equitable/equal access","Key quote on equity/equality":"\u201CThis principle aims to ensure that AI systems are fair and that they enable inclusion throughout their entire lifecycle. AI systems should be user-centric and designed in a way that allows all people interacting with it to access the related products or services. This includes both appropriate consultation with stakeholders, who may be affected by the AI system throughout its lifecycle, and ensuring people receive equitable access and treatment. This is particularly important given concerns about the potential for AI to perpetuate societal injustices and have a disparate impact on vulnerable and underrepresented groups including, but not limited to, groups relating to age, disability, race, sex, intersex status, gender identity and sexual orientation. Measures should be taken to ensure the AI produced decisions are compliant with anti-discrimination laws.\u201D","General principles on AI":["Transparency (explainability). AI systems should be sufficiently explainable.","Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ","Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ","Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ","Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.","Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.","Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ","Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ","Contestability. Users of AI systems should have the opportunity to contest outputs. ","Environmental wellbeing. The use of AI should not harm the environment. ","Inclusive development. AI systems should be developed inclusively. "],"Link (OECD or Other)":"https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics-principles","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":6,Title:"Australia: AI Ethics Framework ","Translation Comments":"N/A - English"},id:"i-X2pIeYByF8",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-X2pIeYByF8",name:"Australia: AI Ethics Framework ",index:5,createdAt:"2024-05-18T00:05:19.692Z",updatedAt:"2024-06-02T22:43:23.722Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-X2pIeYByF8"},{values:{"Category of creator":["OECD"],"Policy creator":["Australia"],"Policy Name":"Australian Framework for Generative AI in Schools","Year of Commencement or Creation":"2023",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"The Australian Framework for Generative AI in Schools is the most relevant Australian policy to the topic of \u2018governance of AI in education\u2019.","Relevance Type":["Policy is about AI in education"],"What kinds of education, if any, are contemplated by the policy?":["Primary","Secondary"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.","Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.","Critical thinking. Use of the tools should not come at the cost of critical thinking.  ","Academic integrity. Students should be supported to use AI tools ethically in their work, which extends to appropriate attribution.","Understanding of strengths and limitations. Schools deploying AI should \u2014 through systematic instruction \u2014 teach students about the technology\u2019s strengths and limitations. ","Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ","Managing bias. The risk of bias should be managed with care. ","Promoting diversity. Technology should be used to expose users to diverse perspectives. ","Human rights-centred. The technology must be consistent with human rights. ","Transparency (transparency to user). It should be clear to users \u2014 including students and schools \u2014 of an AI system in educational settings that they are using an AI system. ","Information. Information about the technology in use should be readily available. ","Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ","Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ","Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.","Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ","Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.","Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.","Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ","Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.","Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ","Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ","Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ","Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems."],"Governance practices employed":["Educates. It helps officials or others understand the opportunities and risks of AI","Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["Australian Framework for Generative AI in Schools (2).pdf"],"Key quotes on AI in education principles":"","Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as an objective or justification of the policy (one of several objectives or justifications)","Key quote on human rights":"\u201Cgenerative AI tools are used in ways that respect human and worker rights, including individual autonomy and dignity.\u201D (p 6)","Does the policy reflect the principle of equity/equality?":"Yes \u2014 it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access","Key quote on equity/equality":`4.1 Accessibility and inclusivity: generative AI tools are used in ways that enhance opportunities, and are inclusive, accessible, and equitable for people with disability and from diverse backgrounds. 4.2 Equity and access: regional, rural and remote communities are considered when implementing generative AI.(p 7)

The Framework aims to ensure that generative AI tools are used in ways that are fair, accessible and inclusive of all Australian school communities. (p 4)`,"General principles on AI":["[N/A]"],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27568","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":8,Title:"Australia: Australian Framework for Generative AI in Schools","Translation Comments":"N/A - English"},id:"i-kTVWc1qdJN",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-kTVWc1qdJN",name:"Australia: Australian Framework for Generative AI in Schools",index:6,createdAt:"2024-05-18T00:05:19.692Z",updatedAt:"2024-06-04T22:34:11.566Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-kTVWc1qdJN"},{values:{"Category of creator":["OECD"],"Policy creator":["Australia"],"Policy Name":"Safe and Responsible AI in Australia: Interim Response","Year of Commencement or Creation":"2024",'Reasons for inclusion in / exclusion from our "Approaches to Governing AI in Education" table':"This consultation process yielded some relevant material and expresses norms concerned with opportunities (eg, \u2018offering personalised learning experiences\u2019).","Relevance Type":["Policy has an AI in education component"],"What kinds of education, if any, are contemplated by the policy?":["[N/A]"],"Principles on AI in education":["Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative\u2014educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."],"Governance practices employed":["Seeks information. It gathers inputs on public sentiment about AI"],"Opportunity and risk orientation":"Risk-focused (says significantly more about risk than opportunities)",File:["safe-and-responsible-ai-in-australia-governments-interim-response (1).pdf"],"Key quotes on AI in education principles":`\u201CAI has the potential to improve educational outcomes for children. It can offer personalised learning experiences which address their unique needs or help them to collaborate and develop critical thinking and problem-solving skills\u201D (p 9)

Note that they pointed out that AI in education is considered \u201Chigh-risk\u201D (p 14)`,"Does the policy reflect the principle of human rights compatibility?":"Yes \u2014 as background information directly linked to the policy\u2019s goals/aims/purpose","Key quote on human rights":"\u201CBut harms may also manifest at a systemic level, with outputs potentially compromising political and social cohesion, stability of labour markets and human rights.\u201D (p 10)","Does the policy reflect the principle of equity/equality?":"One or two fleeting references, but not significant to the policy","Key quote on equity/equality":"","General principles on AI":["[N/A]"],"Link (OECD or Other)":"https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27593","Analysis Complete":!0,"Draft Analysis Complete":!1,"Key quotes on general AI principles":"","Notable Case Studes - Examples of AI in Education":"","Other Points of Interest":"",'Reasons for non-inclusion (other than "Irrelevant")':"","Record Entered By":"","Relevant?":"Yes","Series #":16,Title:"Australia: Safe and Responsible AI in Australia: Interim Response","Translation Comments":"N/A - English"},id:"i-IPrCsM4tqD",href:"https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-IPrCsM4tqD",name:"Australia: Safe and Responsible AI in Australia: Interim Response",index:9,createdAt:"2024-05-18T00:05:19.692Z",updatedAt:"2024-06-04T22:34:03.751Z",browserLink:"https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-IPrCsM4tqD"}]};var yn=class i{dataSources;constructor(){this.dataSources={tableA:this.validateTableData(Wu),tableB:this.validateTableData(Uu)}}validateTableData(n){return!n.columns||!n.rows?(console.error("Invalid table data structure",n),{columns:[],rows:[]}):n}getData(n="tableB"){return I(this.dataSources[n])}getTableAData(){return this.getData("tableA")}getTableBData(){return this.getData("tableB")}static \u0275fac=function(e){return new(e||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})},gn=class{aiPrinciplesSignal=te([{principle:"Accountability",count:9,description:"It should always be clear who is accountable for the use of AI in educational settings"},{principle:"Privacy and data protection",count:13,description:"AI systems used in educational settings should not create privacy or data security vulnerabilities"},{principle:"Transparency (explainability)",count:10,description:"AI systems used in education should be sufficiently explainable"},{principle:"Teacher training",count:18,description:"Teachers should be trained to ensure that AI is used well in educational settings"},{principle:"Equity/equality (increasing)",count:12,description:"This technology should be used as a means of reducing existing educational inequities"},{principle:"Harm avoidance",count:10,description:"AI systems used in schools should not harm the wellbeing or safety of any member"},{principle:"Academic integrity",count:3,description:"Students should be supported to use AI tools ethically in their work"},{principle:"Human rights-centred",count:10,description:"The technology must be consistent with human rights"},{principle:"Augmentation, not replacement",count:7,description:"AI systems should not be used in educational settings as a replacement for teachers"},{principle:"Managing bias",count:10,description:"The risk of bias should be managed with care"}]);aiPrinciples=this.aiPrinciplesSignal.asReadonly()};var La=class i{dataService=l(gn);static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-dashboards"]],decls:0,vars:0,template:function(e,t){},dependencies:[je,_t,wt,qa,fn,Na,io],encapsulation:2})};var Di=class{applyChanges(n,e,t,o,a){n.forEachOperation((s,r,c)=>{let d,p;if(s.previousIndex==null){let v=t(s,r,c);d=e.createEmbeddedView(v.templateRef,v.context,v.index),p=ti.INSERTED}else c==null?(e.remove(r),p=ti.REMOVED):(d=e.get(r),e.move(d,c),p=ti.MOVED);a&&a({context:d?.context,operation:p,record:s})})}detach(){}};var uy=[[["caption"]],[["colgroup"],["col"]],"*"],hy=["caption","colgroup, col","*"];function py(i,n){i&1&&T(0,2)}function my(i,n){i&1&&(u(0,"thead",0),ke(1,1),h(),u(2,"tbody",0),ke(3,2)(4,3),h(),u(5,"tfoot",0),ke(6,4),h())}function fy(i,n){i&1&&ke(0,1)(1,2)(2,3)(3,4)}var ht=new A("CDK_TABLE");var Ba=(()=>{class i{template=l(Pe);constructor(){}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","cdkCellDef",""]]})}return i})(),ja=(()=>{class i{template=l(Pe);constructor(){}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","cdkHeaderCellDef",""]]})}return i})(),Xu=(()=>{class i{template=l(Pe);constructor(){}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","cdkFooterCellDef",""]]})}return i})(),bn=(()=>{class i{_table=l(ht,{optional:!0});_hasStickyChanged=!1;get name(){return this._name}set name(e){this._setNameInput(e)}_name;get sticky(){return this._sticky}set sticky(e){e!==this._sticky&&(this._sticky=e,this._hasStickyChanged=!0)}_sticky=!1;get stickyEnd(){return this._stickyEnd}set stickyEnd(e){e!==this._stickyEnd&&(this._stickyEnd=e,this._hasStickyChanged=!0)}_stickyEnd=!1;cell;headerCell;footerCell;cssClassFriendlyName;_columnCssClassName;constructor(){}hasStickyChanged(){let e=this._hasStickyChanged;return this.resetStickyChanged(),e}resetStickyChanged(){this._hasStickyChanged=!1}_updateColumnCssClassName(){this._columnCssClassName=[`cdk-column-${this.cssClassFriendlyName}`]}_setNameInput(e){e&&(this._name=e,this.cssClassFriendlyName=e.replace(/[^a-z0-9_-]/gi,"-"),this._updateColumnCssClassName())}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","cdkColumnDef",""]],contentQueries:function(t,o,a){if(t&1&&(se(a,Ba,5),se(a,ja,5),se(a,Xu,5)),t&2){let s;B(s=j())&&(o.cell=s.first),B(s=j())&&(o.headerCell=s.first),B(s=j())&&(o.footerCell=s.first)}},inputs:{name:[0,"cdkColumnDef","name"],sticky:[2,"sticky","sticky",K],stickyEnd:[2,"stickyEnd","stickyEnd",K]},features:[de([{provide:"MAT_SORT_HEADER_COLUMN_DEF",useExisting:i}])]})}return i})(),Ka=class{constructor(n,e){e.nativeElement.classList.add(...n._columnCssClassName)}},Ju=(()=>{class i extends Ka{constructor(){super(l(bn),l(R))}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["cdk-header-cell"],["th","cdk-header-cell",""]],hostAttrs:["role","columnheader",1,"cdk-header-cell"],features:[H]})}return i})();var $u=(()=>{class i extends Ka{constructor(){let e=l(bn),t=l(R);super(e,t);let o=e._table?._getCellRole();o&&t.nativeElement.setAttribute("role",o)}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["cdk-cell"],["td","cdk-cell",""]],hostAttrs:[1,"cdk-cell"],features:[H]})}return i})();var fl=(()=>{class i{template=l(Pe);_differs=l(Wt);columns;_columnsDiffer;constructor(){}ngOnChanges(e){if(!this._columnsDiffer){let t=e.columns&&e.columns.currentValue||[];this._columnsDiffer=this._differs.find(t).create(),this._columnsDiffer.diff(t)}}getColumnsDiff(){return this._columnsDiffer.diff(this.columns)}extractCellTemplate(e){return this instanceof go?e.headerCell.template:this instanceof yl?e.footerCell.template:e.cell.template}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,features:[we]})}return i})(),go=(()=>{class i extends fl{_table=l(ht,{optional:!0});_hasStickyChanged=!1;get sticky(){return this._sticky}set sticky(e){e!==this._sticky&&(this._sticky=e,this._hasStickyChanged=!0)}_sticky=!1;constructor(){super(l(Pe),l(Wt))}ngOnChanges(e){super.ngOnChanges(e)}hasStickyChanged(){let e=this._hasStickyChanged;return this.resetStickyChanged(),e}resetStickyChanged(){this._hasStickyChanged=!1}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","cdkHeaderRowDef",""]],inputs:{columns:[0,"cdkHeaderRowDef","columns"],sticky:[2,"cdkHeaderRowDefSticky","sticky",K]},features:[H,we]})}return i})(),yl=(()=>{class i extends fl{_table=l(ht,{optional:!0});_hasStickyChanged=!1;get sticky(){return this._sticky}set sticky(e){e!==this._sticky&&(this._sticky=e,this._hasStickyChanged=!0)}_sticky=!1;constructor(){super(l(Pe),l(Wt))}ngOnChanges(e){super.ngOnChanges(e)}hasStickyChanged(){let e=this._hasStickyChanged;return this.resetStickyChanged(),e}resetStickyChanged(){this._hasStickyChanged=!1}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","cdkFooterRowDef",""]],inputs:{columns:[0,"cdkFooterRowDef","columns"],sticky:[2,"cdkFooterRowDefSticky","sticky",K]},features:[H,we]})}return i})(),Va=(()=>{class i extends fl{_table=l(ht,{optional:!0});when;constructor(){super(l(Pe),l(Wt))}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","cdkRowDef",""]],inputs:{columns:[0,"cdkRowDefColumns","columns"],when:[0,"cdkRowDefWhen","when"]},features:[H]})}return i})(),Ei=(()=>{class i{_viewContainer=l(Fe);cells;context;static mostRecentCellOutlet=null;constructor(){i.mostRecentCellOutlet=this}ngOnDestroy(){i.mostRecentCellOutlet===this&&(i.mostRecentCellOutlet=null)}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","cdkCellOutlet",""]]})}return i})(),gl=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["cdk-header-row"],["tr","cdk-header-row",""]],hostAttrs:["role","row",1,"cdk-header-row"],decls:1,vars:0,consts:[["cdkCellOutlet",""]],template:function(t,o){t&1&&ke(0,0)},dependencies:[Ei],encapsulation:2})}return i})();var bl=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["cdk-row"],["tr","cdk-row",""]],hostAttrs:["role","row",1,"cdk-row"],decls:1,vars:0,consts:[["cdkCellOutlet",""]],template:function(t,o){t&1&&ke(0,0)},dependencies:[Ei],encapsulation:2})}return i})(),Qu=(()=>{class i{templateRef=l(Pe);_contentClassName="cdk-no-data-row";constructor(){}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["ng-template","cdkNoDataRow",""]]})}return i})(),Hu=["top","bottom","left","right"],ml=class{_isNativeHtmlTable;_stickCellCss;_isBrowser;_needsPositionStickyOnElement;direction;_positionListener;_tableInjector;_elemSizeCache=new WeakMap;_resizeObserver=globalThis?.ResizeObserver?new globalThis.ResizeObserver(n=>this._updateCachedSizes(n)):null;_updatedStickyColumnsParamsToReplay=[];_stickyColumnsReplayTimeout=null;_cachedCellWidths=[];_borderCellCss;_destroyed=!1;constructor(n,e,t=!0,o=!0,a,s,r){this._isNativeHtmlTable=n,this._stickCellCss=e,this._isBrowser=t,this._needsPositionStickyOnElement=o,this.direction=a,this._positionListener=s,this._tableInjector=r,this._borderCellCss={top:`${e}-border-elem-top`,bottom:`${e}-border-elem-bottom`,left:`${e}-border-elem-left`,right:`${e}-border-elem-right`}}clearStickyPositioning(n,e){(e.includes("left")||e.includes("right"))&&this._removeFromStickyColumnReplayQueue(n);let t=[];for(let o of n)o.nodeType===o.ELEMENT_NODE&&t.push(o,...Array.from(o.children));ve({write:()=>{for(let o of t)this._removeStickyStyle(o,e)}},{injector:this._tableInjector})}updateStickyColumns(n,e,t,o=!0,a=!0){if(!n.length||!this._isBrowser||!(e.some(ae=>ae)||t.some(ae=>ae))){this._positionListener?.stickyColumnsUpdated({sizes:[]}),this._positionListener?.stickyEndColumnsUpdated({sizes:[]});return}let s=n[0],r=s.children.length,c=this.direction==="rtl",d=c?"right":"left",p=c?"left":"right",v=e.lastIndexOf(!0),C=t.indexOf(!0),P,L,W;a&&this._updateStickyColumnReplayQueue({rows:[...n],stickyStartStates:[...e],stickyEndStates:[...t]}),ve({earlyRead:()=>{P=this._getCellWidths(s,o),L=this._getStickyStartColumnPositions(P,e),W=this._getStickyEndColumnPositions(P,t)},write:()=>{for(let ae of n)for(let ye=0;ye<r;ye++){let et=ae.children[ye];e[ye]&&this._addStickyStyle(et,d,L[ye],ye===v),t[ye]&&this._addStickyStyle(et,p,W[ye],ye===C)}this._positionListener&&P.some(ae=>!!ae)&&(this._positionListener.stickyColumnsUpdated({sizes:v===-1?[]:P.slice(0,v+1).map((ae,ye)=>e[ye]?ae:null)}),this._positionListener.stickyEndColumnsUpdated({sizes:C===-1?[]:P.slice(C).map((ae,ye)=>t[ye+C]?ae:null).reverse()}))}},{injector:this._tableInjector})}stickRows(n,e,t){if(!this._isBrowser)return;let o=t==="bottom"?n.slice().reverse():n,a=t==="bottom"?e.slice().reverse():e,s=[],r=[],c=[];ve({earlyRead:()=>{for(let d=0,p=0;d<o.length;d++){if(!a[d])continue;s[d]=p;let v=o[d];c[d]=this._isNativeHtmlTable?Array.from(v.children):[v];let C=this._retrieveElementSize(v).height;p+=C,r[d]=C}},write:()=>{let d=a.lastIndexOf(!0);for(let p=0;p<o.length;p++){if(!a[p])continue;let v=s[p],C=p===d;for(let P of c[p])this._addStickyStyle(P,t,v,C)}t==="top"?this._positionListener?.stickyHeaderRowsUpdated({sizes:r,offsets:s,elements:c}):this._positionListener?.stickyFooterRowsUpdated({sizes:r,offsets:s,elements:c})}},{injector:this._tableInjector})}updateStickyFooterContainer(n,e){this._isNativeHtmlTable&&ve({write:()=>{let t=n.querySelector("tfoot");t&&(e.some(o=>!o)?this._removeStickyStyle(t,["bottom"]):this._addStickyStyle(t,"bottom",0,!1))}},{injector:this._tableInjector})}destroy(){this._stickyColumnsReplayTimeout&&clearTimeout(this._stickyColumnsReplayTimeout),this._resizeObserver?.disconnect(),this._destroyed=!0}_removeStickyStyle(n,e){if(!n.classList.contains(this._stickCellCss))return;for(let o of e)n.style[o]="",n.classList.remove(this._borderCellCss[o]);Hu.some(o=>e.indexOf(o)===-1&&n.style[o])?n.style.zIndex=this._getCalculatedZIndex(n):(n.style.zIndex="",this._needsPositionStickyOnElement&&(n.style.position=""),n.classList.remove(this._stickCellCss))}_addStickyStyle(n,e,t,o){n.classList.add(this._stickCellCss),o&&n.classList.add(this._borderCellCss[e]),n.style[e]=`${t}px`,n.style.zIndex=this._getCalculatedZIndex(n),this._needsPositionStickyOnElement&&(n.style.cssText+="position: -webkit-sticky; position: sticky; ")}_getCalculatedZIndex(n){let e={top:100,bottom:10,left:1,right:1},t=0;for(let o of Hu)n.style[o]&&(t+=e[o]);return t?`${t}`:""}_getCellWidths(n,e=!0){if(!e&&this._cachedCellWidths.length)return this._cachedCellWidths;let t=[],o=n.children;for(let a=0;a<o.length;a++){let s=o[a];t.push(this._retrieveElementSize(s).width)}return this._cachedCellWidths=t,t}_getStickyStartColumnPositions(n,e){let t=[],o=0;for(let a=0;a<n.length;a++)e[a]&&(t[a]=o,o+=n[a]);return t}_getStickyEndColumnPositions(n,e){let t=[],o=0;for(let a=n.length;a>0;a--)e[a]&&(t[a]=o,o+=n[a]);return t}_retrieveElementSize(n){let e=this._elemSizeCache.get(n);if(e)return e;let t=n.getBoundingClientRect(),o={width:t.width,height:t.height};return this._resizeObserver&&(this._elemSizeCache.set(n,o),this._resizeObserver.observe(n,{box:"border-box"})),o}_updateStickyColumnReplayQueue(n){this._removeFromStickyColumnReplayQueue(n.rows),this._stickyColumnsReplayTimeout||this._updatedStickyColumnsParamsToReplay.push(n)}_removeFromStickyColumnReplayQueue(n){let e=new Set(n);for(let t of this._updatedStickyColumnsParamsToReplay)t.rows=t.rows.filter(o=>!e.has(o));this._updatedStickyColumnsParamsToReplay=this._updatedStickyColumnsParamsToReplay.filter(t=>!!t.rows.length)}_updateCachedSizes(n){let e=!1;for(let t of n){let o=t.borderBoxSize?.length?{width:t.borderBoxSize[0].inlineSize,height:t.borderBoxSize[0].blockSize}:{width:t.contentRect.width,height:t.contentRect.height};o.width!==this._elemSizeCache.get(t.target)?.width&&yy(t.target)&&(e=!0),this._elemSizeCache.set(t.target,o)}e&&this._updatedStickyColumnsParamsToReplay.length&&(this._stickyColumnsReplayTimeout&&clearTimeout(this._stickyColumnsReplayTimeout),this._stickyColumnsReplayTimeout=setTimeout(()=>{if(!this._destroyed){for(let t of this._updatedStickyColumnsParamsToReplay)this.updateStickyColumns(t.rows,t.stickyStartStates,t.stickyEndStates,!0,!1);this._updatedStickyColumnsParamsToReplay=[],this._stickyColumnsReplayTimeout=null}},0))}};function yy(i){return["cdk-cell","cdk-header-cell","cdk-footer-cell"].some(n=>i.classList.contains(n))}var za=new A("CDK_SPL");var vl=(()=>{class i{viewContainer=l(Fe);elementRef=l(R);constructor(){let e=l(ht);e._rowOutlet=this,e._outletAssigned()}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","rowOutlet",""]]})}return i})(),Al=(()=>{class i{viewContainer=l(Fe);elementRef=l(R);constructor(){let e=l(ht);e._headerRowOutlet=this,e._outletAssigned()}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","headerRowOutlet",""]]})}return i})(),Il=(()=>{class i{viewContainer=l(Fe);elementRef=l(R);constructor(){let e=l(ht);e._footerRowOutlet=this,e._outletAssigned()}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","footerRowOutlet",""]]})}return i})(),_l=(()=>{class i{viewContainer=l(Fe);elementRef=l(R);constructor(){let e=l(ht);e._noDataRowOutlet=this,e._outletAssigned()}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","noDataRowOutlet",""]]})}return i})(),wl=(()=>{class i{_differs=l(Wt);_changeDetectorRef=l(me);_elementRef=l(R);_dir=l(dt,{optional:!0});_platform=l(oe);_viewRepeater=l(dn);_viewportRuler=l(Ct);_stickyPositioningListener=l(za,{optional:!0,skipSelf:!0});_document=l(D);_data;_onDestroy=new S;_renderRows;_renderChangeSubscription;_columnDefsByName=new Map;_rowDefs;_headerRowDefs;_footerRowDefs;_dataDiffer;_defaultRowDef;_customColumnDefs=new Set;_customRowDefs=new Set;_customHeaderRowDefs=new Set;_customFooterRowDefs=new Set;_customNoDataRow;_headerRowDefChanged=!0;_footerRowDefChanged=!0;_stickyColumnStylesNeedReset=!0;_forceRecalculateCellWidths=!0;_cachedRenderRowsMap=new Map;_isNativeHtmlTable;_stickyStyler;stickyCssClass="cdk-table-sticky";needsPositionStickyOnElement=!0;_isServer;_isShowingNoDataRow=!1;_hasAllOutlets=!1;_hasInitialized=!1;_getCellRole(){if(this._cellRoleInternal===void 0){let e=this._elementRef.nativeElement.getAttribute("role");return e==="grid"||e==="treegrid"?"gridcell":"cell"}return this._cellRoleInternal}_cellRoleInternal=void 0;get trackBy(){return this._trackByFn}set trackBy(e){this._trackByFn=e}_trackByFn;get dataSource(){return this._dataSource}set dataSource(e){this._dataSource!==e&&this._switchDataSource(e)}_dataSource;get multiTemplateDataRows(){return this._multiTemplateDataRows}set multiTemplateDataRows(e){this._multiTemplateDataRows=e,this._rowOutlet&&this._rowOutlet.viewContainer.length&&(this._forceRenderDataRows(),this.updateStickyColumnStyles())}_multiTemplateDataRows=!1;get fixedLayout(){return this._fixedLayout}set fixedLayout(e){this._fixedLayout=e,this._forceRecalculateCellWidths=!0,this._stickyColumnStylesNeedReset=!0}_fixedLayout=!1;contentChanged=new Z;viewChange=new Ee({start:0,end:Number.MAX_VALUE});_rowOutlet;_headerRowOutlet;_footerRowOutlet;_noDataRowOutlet;_contentColumnDefs;_contentRowDefs;_contentHeaderRowDefs;_contentFooterRowDefs;_noDataRow;_injector=l(V);constructor(){l(new Vt("role"),{optional:!0})||this._elementRef.nativeElement.setAttribute("role","table"),this._isServer=!this._platform.isBrowser,this._isNativeHtmlTable=this._elementRef.nativeElement.nodeName==="TABLE",this._dataDiffer=this._differs.find([]).create((t,o)=>this.trackBy?this.trackBy(o.dataIndex,o.data):o)}ngOnInit(){this._setupStickyStyler(),this._viewportRuler.change().pipe(pe(this._onDestroy)).subscribe(()=>{this._forceRecalculateCellWidths=!0})}ngAfterContentInit(){this._hasInitialized=!0}ngAfterContentChecked(){this._canRender()&&this._render()}ngOnDestroy(){this._stickyStyler?.destroy(),[this._rowOutlet?.viewContainer,this._headerRowOutlet?.viewContainer,this._footerRowOutlet?.viewContainer,this._cachedRenderRowsMap,this._customColumnDefs,this._customRowDefs,this._customHeaderRowDefs,this._customFooterRowDefs,this._columnDefsByName].forEach(e=>{e?.clear()}),this._headerRowDefs=[],this._footerRowDefs=[],this._defaultRowDef=null,this._onDestroy.next(),this._onDestroy.complete(),wa(this.dataSource)&&this.dataSource.disconnect(this)}renderRows(){this._renderRows=this._getAllRenderRows();let e=this._dataDiffer.diff(this._renderRows);if(!e){this._updateNoDataRow(),this.contentChanged.next();return}let t=this._rowOutlet.viewContainer;this._viewRepeater.applyChanges(e,t,(o,a,s)=>this._getEmbeddedViewArgs(o.item,s),o=>o.item.data,o=>{o.operation===ti.INSERTED&&o.context&&this._renderCellTemplateForItem(o.record.item.rowDef,o.context)}),this._updateRowIndexContext(),e.forEachIdentityChange(o=>{let a=t.get(o.currentIndex);a.context.$implicit=o.item.data}),this._updateNoDataRow(),this.contentChanged.next(),this.updateStickyColumnStyles()}addColumnDef(e){this._customColumnDefs.add(e)}removeColumnDef(e){this._customColumnDefs.delete(e)}addRowDef(e){this._customRowDefs.add(e)}removeRowDef(e){this._customRowDefs.delete(e)}addHeaderRowDef(e){this._customHeaderRowDefs.add(e),this._headerRowDefChanged=!0}removeHeaderRowDef(e){this._customHeaderRowDefs.delete(e),this._headerRowDefChanged=!0}addFooterRowDef(e){this._customFooterRowDefs.add(e),this._footerRowDefChanged=!0}removeFooterRowDef(e){this._customFooterRowDefs.delete(e),this._footerRowDefChanged=!0}setNoDataRow(e){this._customNoDataRow=e}updateStickyHeaderRowStyles(){let e=this._getRenderedRows(this._headerRowOutlet);if(this._isNativeHtmlTable){let o=Yu(this._headerRowOutlet,"thead");o&&(o.style.display=e.length?"":"none")}let t=this._headerRowDefs.map(o=>o.sticky);this._stickyStyler.clearStickyPositioning(e,["top"]),this._stickyStyler.stickRows(e,t,"top"),this._headerRowDefs.forEach(o=>o.resetStickyChanged())}updateStickyFooterRowStyles(){let e=this._getRenderedRows(this._footerRowOutlet);if(this._isNativeHtmlTable){let o=Yu(this._footerRowOutlet,"tfoot");o&&(o.style.display=e.length?"":"none")}let t=this._footerRowDefs.map(o=>o.sticky);this._stickyStyler.clearStickyPositioning(e,["bottom"]),this._stickyStyler.stickRows(e,t,"bottom"),this._stickyStyler.updateStickyFooterContainer(this._elementRef.nativeElement,t),this._footerRowDefs.forEach(o=>o.resetStickyChanged())}updateStickyColumnStyles(){let e=this._getRenderedRows(this._headerRowOutlet),t=this._getRenderedRows(this._rowOutlet),o=this._getRenderedRows(this._footerRowOutlet);(this._isNativeHtmlTable&&!this._fixedLayout||this._stickyColumnStylesNeedReset)&&(this._stickyStyler.clearStickyPositioning([...e,...t,...o],["left","right"]),this._stickyColumnStylesNeedReset=!1),e.forEach((a,s)=>{this._addStickyColumnStyles([a],this._headerRowDefs[s])}),this._rowDefs.forEach(a=>{let s=[];for(let r=0;r<t.length;r++)this._renderRows[r].rowDef===a&&s.push(t[r]);this._addStickyColumnStyles(s,a)}),o.forEach((a,s)=>{this._addStickyColumnStyles([a],this._footerRowDefs[s])}),Array.from(this._columnDefsByName.values()).forEach(a=>a.resetStickyChanged())}_outletAssigned(){!this._hasAllOutlets&&this._rowOutlet&&this._headerRowOutlet&&this._footerRowOutlet&&this._noDataRowOutlet&&(this._hasAllOutlets=!0,this._canRender()&&this._render())}_canRender(){return this._hasAllOutlets&&this._hasInitialized}_render(){this._cacheRowDefs(),this._cacheColumnDefs(),!this._headerRowDefs.length&&!this._footerRowDefs.length&&this._rowDefs.length;let t=this._renderUpdatedColumns()||this._headerRowDefChanged||this._footerRowDefChanged;this._stickyColumnStylesNeedReset=this._stickyColumnStylesNeedReset||t,this._forceRecalculateCellWidths=t,this._headerRowDefChanged&&(this._forceRenderHeaderRows(),this._headerRowDefChanged=!1),this._footerRowDefChanged&&(this._forceRenderFooterRows(),this._footerRowDefChanged=!1),this.dataSource&&this._rowDefs.length>0&&!this._renderChangeSubscription?this._observeRenderChanges():this._stickyColumnStylesNeedReset&&this.updateStickyColumnStyles(),this._checkStickyStates()}_getAllRenderRows(){let e=[],t=this._cachedRenderRowsMap;if(this._cachedRenderRowsMap=new Map,!this._data)return e;for(let o=0;o<this._data.length;o++){let a=this._data[o],s=this._getRenderRowsForData(a,o,t.get(a));this._cachedRenderRowsMap.has(a)||this._cachedRenderRowsMap.set(a,new WeakMap);for(let r=0;r<s.length;r++){let c=s[r],d=this._cachedRenderRowsMap.get(c.data);d.has(c.rowDef)?d.get(c.rowDef).push(c):d.set(c.rowDef,[c]),e.push(c)}}return e}_getRenderRowsForData(e,t,o){return this._getRowDefs(e,t).map(s=>{let r=o&&o.has(s)?o.get(s):[];if(r.length){let c=r.shift();return c.dataIndex=t,c}else return{data:e,rowDef:s,dataIndex:t}})}_cacheColumnDefs(){this._columnDefsByName.clear(),Ga(this._getOwnDefs(this._contentColumnDefs),this._customColumnDefs).forEach(t=>{this._columnDefsByName.has(t.name),this._columnDefsByName.set(t.name,t)})}_cacheRowDefs(){this._headerRowDefs=Ga(this._getOwnDefs(this._contentHeaderRowDefs),this._customHeaderRowDefs),this._footerRowDefs=Ga(this._getOwnDefs(this._contentFooterRowDefs),this._customFooterRowDefs),this._rowDefs=Ga(this._getOwnDefs(this._contentRowDefs),this._customRowDefs);let e=this._rowDefs.filter(t=>!t.when);!this.multiTemplateDataRows&&e.length>1,this._defaultRowDef=e[0]}_renderUpdatedColumns(){let e=(s,r)=>{let c=!!r.getColumnsDiff();return s||c},t=this._rowDefs.reduce(e,!1);t&&this._forceRenderDataRows();let o=this._headerRowDefs.reduce(e,!1);o&&this._forceRenderHeaderRows();let a=this._footerRowDefs.reduce(e,!1);return a&&this._forceRenderFooterRows(),t||o||a}_switchDataSource(e){this._data=[],wa(this.dataSource)&&this.dataSource.disconnect(this),this._renderChangeSubscription&&(this._renderChangeSubscription.unsubscribe(),this._renderChangeSubscription=null),e||(this._dataDiffer&&this._dataDiffer.diff([]),this._rowOutlet&&this._rowOutlet.viewContainer.clear()),this._dataSource=e}_observeRenderChanges(){if(!this.dataSource)return;let e;wa(this.dataSource)?e=this.dataSource.connect(this):_n(this.dataSource)?e=this.dataSource:Array.isArray(this.dataSource)&&(e=I(this.dataSource)),this._renderChangeSubscription=e.pipe(pe(this._onDestroy)).subscribe(t=>{this._data=t||[],this.renderRows()})}_forceRenderHeaderRows(){this._headerRowOutlet.viewContainer.length>0&&this._headerRowOutlet.viewContainer.clear(),this._headerRowDefs.forEach((e,t)=>this._renderRow(this._headerRowOutlet,e,t)),this.updateStickyHeaderRowStyles()}_forceRenderFooterRows(){this._footerRowOutlet.viewContainer.length>0&&this._footerRowOutlet.viewContainer.clear(),this._footerRowDefs.forEach((e,t)=>this._renderRow(this._footerRowOutlet,e,t)),this.updateStickyFooterRowStyles()}_addStickyColumnStyles(e,t){let o=Array.from(t?.columns||[]).map(r=>{let c=this._columnDefsByName.get(r);return c}),a=o.map(r=>r.sticky),s=o.map(r=>r.stickyEnd);this._stickyStyler.updateStickyColumns(e,a,s,!this._fixedLayout||this._forceRecalculateCellWidths)}_getRenderedRows(e){let t=[];for(let o=0;o<e.viewContainer.length;o++){let a=e.viewContainer.get(o);t.push(a.rootNodes[0])}return t}_getRowDefs(e,t){if(this._rowDefs.length==1)return[this._rowDefs[0]];let o=[];if(this.multiTemplateDataRows)o=this._rowDefs.filter(a=>!a.when||a.when(t,e));else{let a=this._rowDefs.find(s=>s.when&&s.when(t,e))||this._defaultRowDef;a&&o.push(a)}return o.length,o}_getEmbeddedViewArgs(e,t){let o=e.rowDef,a={$implicit:e.data};return{templateRef:o.template,context:a,index:t}}_renderRow(e,t,o,a={}){let s=e.viewContainer.createEmbeddedView(t.template,a,o);return this._renderCellTemplateForItem(t,a),s}_renderCellTemplateForItem(e,t){for(let o of this._getCellTemplates(e))Ei.mostRecentCellOutlet&&Ei.mostRecentCellOutlet._viewContainer.createEmbeddedView(o,t);this._changeDetectorRef.markForCheck()}_updateRowIndexContext(){let e=this._rowOutlet.viewContainer;for(let t=0,o=e.length;t<o;t++){let s=e.get(t).context;s.count=o,s.first=t===0,s.last=t===o-1,s.even=t%2===0,s.odd=!s.even,this.multiTemplateDataRows?(s.dataIndex=this._renderRows[t].dataIndex,s.renderIndex=t):s.index=this._renderRows[t].dataIndex}}_getCellTemplates(e){return!e||!e.columns?[]:Array.from(e.columns,t=>{let o=this._columnDefsByName.get(t);return e.extractCellTemplate(o)})}_forceRenderDataRows(){this._dataDiffer.diff([]),this._rowOutlet.viewContainer.clear(),this.renderRows()}_checkStickyStates(){let e=(t,o)=>t||o.hasStickyChanged();this._headerRowDefs.reduce(e,!1)&&this.updateStickyHeaderRowStyles(),this._footerRowDefs.reduce(e,!1)&&this.updateStickyFooterRowStyles(),Array.from(this._columnDefsByName.values()).reduce(e,!1)&&(this._stickyColumnStylesNeedReset=!0,this.updateStickyColumnStyles())}_setupStickyStyler(){let e=this._dir?this._dir.value:"ltr";this._stickyStyler=new ml(this._isNativeHtmlTable,this.stickyCssClass,this._platform.isBrowser,this.needsPositionStickyOnElement,e,this._stickyPositioningListener,this._injector),(this._dir?this._dir.change:I()).pipe(pe(this._onDestroy)).subscribe(t=>{this._stickyStyler.direction=t,this.updateStickyColumnStyles()})}_getOwnDefs(e){return e.filter(t=>!t._table||t._table===this)}_updateNoDataRow(){let e=this._customNoDataRow||this._noDataRow;if(!e)return;let t=this._rowOutlet.viewContainer.length===0;if(t===this._isShowingNoDataRow)return;let o=this._noDataRowOutlet.viewContainer;if(t){let a=o.createEmbeddedView(e.templateRef),s=a.rootNodes[0];a.rootNodes.length===1&&s?.nodeType===this._document.ELEMENT_NODE&&(s.setAttribute("role","row"),s.classList.add(e._contentClassName))}else o.clear();this._isShowingNoDataRow=t,this._changeDetectorRef.markForCheck()}static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["cdk-table"],["table","cdk-table",""]],contentQueries:function(t,o,a){if(t&1&&(se(a,Qu,5),se(a,bn,5),se(a,Va,5),se(a,go,5),se(a,yl,5)),t&2){let s;B(s=j())&&(o._noDataRow=s.first),B(s=j())&&(o._contentColumnDefs=s),B(s=j())&&(o._contentRowDefs=s),B(s=j())&&(o._contentHeaderRowDefs=s),B(s=j())&&(o._contentFooterRowDefs=s)}},hostAttrs:[1,"cdk-table"],hostVars:2,hostBindings:function(t,o){t&2&&N("cdk-table-fixed-layout",o.fixedLayout)},inputs:{trackBy:"trackBy",dataSource:"dataSource",multiTemplateDataRows:[2,"multiTemplateDataRows","multiTemplateDataRows",K],fixedLayout:[2,"fixedLayout","fixedLayout",K]},outputs:{contentChanged:"contentChanged"},exportAs:["cdkTable"],features:[de([{provide:ht,useExisting:i},{provide:dn,useClass:Di},{provide:za,useValue:null}])],ngContentSelectors:hy,decls:5,vars:2,consts:[["role","rowgroup"],["headerRowOutlet",""],["rowOutlet",""],["noDataRowOutlet",""],["footerRowOutlet",""]],template:function(t,o){t&1&&(Y(uy),T(0),T(1,1),J(2,py,1,0),J(3,my,7,0)(4,fy,4,0)),t&2&&(f(2),$(o._isServer?2:-1),f(),$(o._isNativeHtmlTable?3:4))},dependencies:[Al,vl,_l,Il],styles:[`.cdk-table-fixed-layout{table-layout:fixed}
`],encapsulation:2})}return i})();function Ga(i,n){return i.concat(Array.from(n))}function Yu(i,n){let e=n.toUpperCase(),t=i.viewContainer.element.nativeElement;for(;t;){let o=t.nodeType===1?t.nodeName:null;if(o===e)return t;if(o==="TABLE")break;t=t.parentNode}return null}var eh=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[po]})}return i})();var gy=[[["caption"]],[["colgroup"],["col"]],"*"],by=["caption","colgroup, col","*"];function vy(i,n){i&1&&T(0,2)}function Ay(i,n){i&1&&(u(0,"thead",0),ke(1,1),h(),u(2,"tbody",2),ke(3,3)(4,4),h(),u(5,"tfoot",0),ke(6,5),h())}function Iy(i,n){i&1&&ke(0,1)(1,3)(2,4)(3,5)}var Wa=(()=>{class i extends wl{stickyCssClass="mat-mdc-table-sticky";needsPositionStickyOnElement=!1;static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275cmp=y({type:i,selectors:[["mat-table"],["table","mat-table",""]],hostAttrs:[1,"mat-mdc-table","mdc-data-table__table"],hostVars:2,hostBindings:function(t,o){t&2&&N("mdc-table-fixed-layout",o.fixedLayout)},exportAs:["matTable"],features:[de([{provide:wl,useExisting:i},{provide:ht,useExisting:i},{provide:dn,useClass:Di},{provide:za,useValue:null}]),H],ngContentSelectors:by,decls:5,vars:2,consts:[["role","rowgroup"],["headerRowOutlet",""],["role","rowgroup",1,"mdc-data-table__content"],["rowOutlet",""],["noDataRowOutlet",""],["footerRowOutlet",""]],template:function(t,o){t&1&&(Y(gy),T(0),T(1,1),J(2,vy,1,0),J(3,Ay,7,0)(4,Iy,4,0)),t&2&&(f(2),$(o._isServer?2:-1),f(),$(o._isNativeHtmlTable?3:4))},dependencies:[Al,vl,_l,Il],styles:[`.mat-mdc-table-sticky{position:sticky !important}mat-table{display:block}mat-header-row{min-height:var(--mat-table-header-container-height, 56px)}mat-row{min-height:var(--mat-table-row-item-container-height, 52px)}mat-footer-row{min-height:var(--mat-table-footer-container-height, 52px)}mat-row,mat-header-row,mat-footer-row{display:flex;border-width:0;border-bottom-width:1px;border-style:solid;align-items:center;box-sizing:border-box}mat-cell:first-of-type,mat-header-cell:first-of-type,mat-footer-cell:first-of-type{padding-left:24px}[dir=rtl] mat-cell:first-of-type:not(:only-of-type),[dir=rtl] mat-header-cell:first-of-type:not(:only-of-type),[dir=rtl] mat-footer-cell:first-of-type:not(:only-of-type){padding-left:0;padding-right:24px}mat-cell:last-of-type,mat-header-cell:last-of-type,mat-footer-cell:last-of-type{padding-right:24px}[dir=rtl] mat-cell:last-of-type:not(:only-of-type),[dir=rtl] mat-header-cell:last-of-type:not(:only-of-type),[dir=rtl] mat-footer-cell:last-of-type:not(:only-of-type){padding-right:0;padding-left:24px}mat-cell,mat-header-cell,mat-footer-cell{flex:1;display:flex;align-items:center;overflow:hidden;word-wrap:break-word;min-height:inherit}.mat-mdc-table{min-width:100%;border:0;border-spacing:0;table-layout:auto;white-space:normal;background-color:var(--mat-table-background-color, var(--mat-sys-surface))}.mdc-data-table__cell{box-sizing:border-box;overflow:hidden;text-align:left;text-overflow:ellipsis}[dir=rtl] .mdc-data-table__cell{text-align:right}.mdc-data-table__cell,.mdc-data-table__header-cell{padding:0 16px}.mat-mdc-header-row{-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;height:var(--mat-table-header-container-height, 56px);color:var(--mat-table-header-headline-color, var(--mat-sys-on-surface, rgba(0, 0, 0, 0.87)));font-family:var(--mat-table-header-headline-font, var(--mat-sys-title-small-font, Roboto, sans-serif));line-height:var(--mat-table-header-headline-line-height, var(--mat-sys-title-small-line-height));font-size:var(--mat-table-header-headline-size, var(--mat-sys-title-small-size, 14px));font-weight:var(--mat-table-header-headline-weight, var(--mat-sys-title-small-weight, 500))}.mat-mdc-row{height:var(--mat-table-row-item-container-height, 52px);color:var(--mat-table-row-item-label-text-color, var(--mat-sys-on-surface, rgba(0, 0, 0, 0.87)))}.mat-mdc-row,.mdc-data-table__content{-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;font-family:var(--mat-table-row-item-label-text-font, var(--mat-sys-body-medium-font, Roboto, sans-serif));line-height:var(--mat-table-row-item-label-text-line-height, var(--mat-sys-body-medium-line-height));font-size:var(--mat-table-row-item-label-text-size, var(--mat-sys-body-medium-size, 14px));font-weight:var(--mat-table-row-item-label-text-weight, var(--mat-sys-body-medium-weight))}.mat-mdc-footer-row{-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;height:var(--mat-table-footer-container-height, 52px);color:var(--mat-table-row-item-label-text-color, var(--mat-sys-on-surface, rgba(0, 0, 0, 0.87)));font-family:var(--mat-table-footer-supporting-text-font, var(--mat-sys-body-medium-font, Roboto, sans-serif));line-height:var(--mat-table-footer-supporting-text-line-height, var(--mat-sys-body-medium-line-height));font-size:var(--mat-table-footer-supporting-text-size, var(--mat-sys-body-medium-size, 14px));font-weight:var(--mat-table-footer-supporting-text-weight, var(--mat-sys-body-medium-weight));letter-spacing:var(--mat-table-footer-supporting-text-tracking, var(--mat-sys-body-medium-tracking))}.mat-mdc-header-cell{border-bottom-color:var(--mat-table-row-item-outline-color, var(--mat-sys-outline, rgba(0, 0, 0, 0.12)));border-bottom-width:var(--mat-table-row-item-outline-width, 1px);border-bottom-style:solid;letter-spacing:var(--mat-table-header-headline-tracking, var(--mat-sys-title-small-tracking));font-weight:inherit;line-height:inherit;box-sizing:border-box;text-overflow:ellipsis;overflow:hidden;outline:none;text-align:left}[dir=rtl] .mat-mdc-header-cell{text-align:right}.mdc-data-table__row:last-child>.mat-mdc-header-cell{border-bottom:none}.mat-mdc-cell{border-bottom-color:var(--mat-table-row-item-outline-color, var(--mat-sys-outline, rgba(0, 0, 0, 0.12)));border-bottom-width:var(--mat-table-row-item-outline-width, 1px);border-bottom-style:solid;letter-spacing:var(--mat-table-row-item-label-text-tracking, var(--mat-sys-body-medium-tracking));line-height:inherit}.mdc-data-table__row:last-child>.mat-mdc-cell{border-bottom:none}.mat-mdc-footer-cell{letter-spacing:var(--mat-table-row-item-label-text-tracking, var(--mat-sys-body-medium-tracking))}mat-row.mat-mdc-row,mat-header-row.mat-mdc-header-row,mat-footer-row.mat-mdc-footer-row{border-bottom:none}.mat-mdc-table tbody,.mat-mdc-table tfoot,.mat-mdc-table thead,.mat-mdc-cell,.mat-mdc-footer-cell,.mat-mdc-header-row,.mat-mdc-row,.mat-mdc-footer-row,.mat-mdc-table .mat-mdc-header-cell{background:inherit}.mat-mdc-table mat-header-row.mat-mdc-header-row,.mat-mdc-table mat-row.mat-mdc-row,.mat-mdc-table mat-footer-row.mat-mdc-footer-cell{height:unset}mat-header-cell.mat-mdc-header-cell,mat-cell.mat-mdc-cell,mat-footer-cell.mat-mdc-footer-cell{align-self:stretch}
`],encapsulation:2})}return i})(),Ua=(()=>{class i extends Ba{static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275dir=_({type:i,selectors:[["","matCellDef",""]],features:[de([{provide:Ba,useExisting:i}]),H]})}return i})(),Ha=(()=>{class i extends ja{static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275dir=_({type:i,selectors:[["","matHeaderCellDef",""]],features:[de([{provide:ja,useExisting:i}]),H]})}return i})();var Ya=(()=>{class i extends bn{get name(){return this._name}set name(e){this._setNameInput(e)}_updateColumnCssClassName(){super._updateColumnCssClassName(),this._columnCssClassName.push(`mat-column-${this.cssClassFriendlyName}`)}static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275dir=_({type:i,selectors:[["","matColumnDef",""]],inputs:{name:[0,"matColumnDef","name"]},features:[de([{provide:bn,useExisting:i},{provide:"MAT_SORT_HEADER_COLUMN_DEF",useExisting:i}]),H]})}return i})(),Za=(()=>{class i extends Ju{static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275dir=_({type:i,selectors:[["mat-header-cell"],["th","mat-header-cell",""]],hostAttrs:["role","columnheader",1,"mat-mdc-header-cell","mdc-data-table__header-cell"],features:[H]})}return i})();var Xa=(()=>{class i extends $u{static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275dir=_({type:i,selectors:[["mat-cell"],["td","mat-cell",""]],hostAttrs:[1,"mat-mdc-cell","mdc-data-table__cell"],features:[H]})}return i})();var Ja=(()=>{class i extends go{static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275dir=_({type:i,selectors:[["","matHeaderRowDef",""]],inputs:{columns:[0,"matHeaderRowDef","columns"],sticky:[2,"matHeaderRowDefSticky","sticky",K]},features:[de([{provide:go,useExisting:i}]),H]})}return i})();var $a=(()=>{class i extends Va{static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275dir=_({type:i,selectors:[["","matRowDef",""]],inputs:{columns:[0,"matRowDefColumns","columns"],when:[0,"matRowDefWhen","when"]},features:[de([{provide:Va,useExisting:i}]),H]})}return i})(),Qa=(()=>{class i extends gl{static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275cmp=y({type:i,selectors:[["mat-header-row"],["tr","mat-header-row",""]],hostAttrs:["role","row",1,"mat-mdc-header-row","mdc-data-table__header-row"],exportAs:["matHeaderRow"],features:[de([{provide:gl,useExisting:i}]),H],decls:1,vars:0,consts:[["cdkCellOutlet",""]],template:function(t,o){t&1&&ke(0,0)},dependencies:[Ei],encapsulation:2})}return i})();var es=(()=>{class i extends bl{static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275cmp=y({type:i,selectors:[["mat-row"],["tr","mat-row",""]],hostAttrs:["role","row",1,"mat-mdc-row","mdc-data-table__row"],exportAs:["matRow"],features:[de([{provide:bl,useExisting:i}]),H],decls:1,vars:0,consts:[["cdkCellOutlet",""]],template:function(t,o){t&1&&ke(0,0)},dependencies:[Ei],encapsulation:2})}return i})();var vn=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[z,eh,z]})}return i})();var ih=new A("");var nh=new A("");var _y={"[class.ng-untouched]":"isUntouched","[class.ng-touched]":"isTouched","[class.ng-pristine]":"isPristine","[class.ng-dirty]":"isDirty","[class.ng-valid]":"isValid","[class.ng-invalid]":"isInvalid","[class.ng-pending]":"isPending"},dD=ge(b({},_y),{"[class.ng-submitted]":"isSubmitted"});var oh=(()=>{class i{isErrorState(e,t){return!!(e&&e.invalid&&(e.touched||t&&t.submitted))}static \u0275fac=function(t){return new(t||i)};static \u0275prov=g({token:i,factory:i.\u0275fac,providedIn:"root"})}return i})();var wy=new A("mat-chips-default-options",{providedIn:"root",factory:()=>({separatorKeyCodes:[13]})});var ah=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({providers:[oh,{provide:wy,useValue:{separatorKeyCodes:[13]}}],imports:[z,ii,z]})}return i})();var ts=class i{static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-data"]],decls:1,vars:0,template:function(e,t){e&1&&ie(0,"router-outlet")},dependencies:[je,vn,_t,ah,io,mi],encapsulation:2})};var sh=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[z,z]})}return i})();var rh=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[z]})}return i})();var Cy=["*"],ky=`.mdc-list{margin:0;padding:8px 0;list-style-type:none}.mdc-list:focus{outline:none}.mdc-list-item{display:flex;position:relative;justify-content:flex-start;overflow:hidden;padding:0;align-items:stretch;cursor:pointer;padding-left:16px;padding-right:16px;background-color:var(--mat-list-list-item-container-color, transparent);border-radius:var(--mat-list-list-item-container-shape, var(--mat-sys-corner-none))}.mdc-list-item.mdc-list-item--selected{background-color:var(--mat-list-list-item-selected-container-color)}.mdc-list-item:focus{outline:0}.mdc-list-item.mdc-list-item--disabled{cursor:auto}.mdc-list-item.mdc-list-item--with-one-line{height:var(--mat-list-list-item-one-line-container-height, 48px)}.mdc-list-item.mdc-list-item--with-one-line .mdc-list-item__start{align-self:center;margin-top:0}.mdc-list-item.mdc-list-item--with-one-line .mdc-list-item__end{align-self:center;margin-top:0}.mdc-list-item.mdc-list-item--with-two-lines{height:var(--mat-list-list-item-two-line-container-height, 64px)}.mdc-list-item.mdc-list-item--with-two-lines .mdc-list-item__start{align-self:flex-start;margin-top:16px}.mdc-list-item.mdc-list-item--with-two-lines .mdc-list-item__end{align-self:center;margin-top:0}.mdc-list-item.mdc-list-item--with-three-lines{height:var(--mat-list-list-item-three-line-container-height, 88px)}.mdc-list-item.mdc-list-item--with-three-lines .mdc-list-item__start{align-self:flex-start;margin-top:16px}.mdc-list-item.mdc-list-item--with-three-lines .mdc-list-item__end{align-self:flex-start;margin-top:16px}.mdc-list-item.mdc-list-item--selected::before,.mdc-list-item.mdc-list-item--selected:focus::before,.mdc-list-item:not(.mdc-list-item--selected):focus::before{position:absolute;box-sizing:border-box;width:100%;height:100%;top:0;left:0;content:"";pointer-events:none}a.mdc-list-item{color:inherit;text-decoration:none}.mdc-list-item__start{fill:currentColor;flex-shrink:0;pointer-events:none}.mdc-list-item--with-leading-icon .mdc-list-item__start{color:var(--mat-list-list-item-leading-icon-color, var(--mat-sys-on-surface-variant));width:var(--mat-list-list-item-leading-icon-size, 24px);height:var(--mat-list-list-item-leading-icon-size, 24px);margin-left:16px;margin-right:32px}[dir=rtl] .mdc-list-item--with-leading-icon .mdc-list-item__start{margin-left:32px;margin-right:16px}.mdc-list-item--with-leading-icon:hover .mdc-list-item__start{color:var(--mat-list-list-item-hover-leading-icon-color)}.mdc-list-item--with-leading-avatar .mdc-list-item__start{width:var(--mat-list-list-item-leading-avatar-size, 40px);height:var(--mat-list-list-item-leading-avatar-size, 40px);margin-left:16px;margin-right:16px;border-radius:50%}.mdc-list-item--with-leading-avatar .mdc-list-item__start,[dir=rtl] .mdc-list-item--with-leading-avatar .mdc-list-item__start{margin-left:16px;margin-right:16px;border-radius:50%}.mdc-list-item__end{flex-shrink:0;pointer-events:none}.mdc-list-item--with-trailing-meta .mdc-list-item__end{font-family:var(--mat-list-list-item-trailing-supporting-text-font, var(--mat-sys-label-small-font));line-height:var(--mat-list-list-item-trailing-supporting-text-line-height, var(--mat-sys-label-small-line-height));font-size:var(--mat-list-list-item-trailing-supporting-text-size, var(--mat-sys-label-small-size));font-weight:var(--mat-list-list-item-trailing-supporting-text-weight, var(--mat-sys-label-small-weight));letter-spacing:var(--mat-list-list-item-trailing-supporting-text-tracking, var(--mat-sys-label-small-tracking))}.mdc-list-item--with-trailing-icon .mdc-list-item__end{color:var(--mat-list-list-item-trailing-icon-color, var(--mat-sys-on-surface-variant));width:var(--mat-list-list-item-trailing-icon-size, 24px);height:var(--mat-list-list-item-trailing-icon-size, 24px)}.mdc-list-item--with-trailing-icon:hover .mdc-list-item__end{color:var(--mat-list-list-item-hover-trailing-icon-color)}.mdc-list-item.mdc-list-item--with-trailing-meta .mdc-list-item__end{color:var(--mat-list-list-item-trailing-supporting-text-color, var(--mat-sys-on-surface-variant))}.mdc-list-item--selected.mdc-list-item--with-trailing-icon .mdc-list-item__end{color:var(--mat-list-list-item-selected-trailing-icon-color, var(--mat-sys-primary))}.mdc-list-item__content{text-overflow:ellipsis;white-space:nowrap;overflow:hidden;align-self:center;flex:1;pointer-events:none}.mdc-list-item--with-two-lines .mdc-list-item__content,.mdc-list-item--with-three-lines .mdc-list-item__content{align-self:stretch}.mdc-list-item__primary-text{text-overflow:ellipsis;white-space:nowrap;overflow:hidden;color:var(--mat-list-list-item-label-text-color, var(--mat-sys-on-surface));font-family:var(--mat-list-list-item-label-text-font, var(--mat-sys-body-large-font));line-height:var(--mat-list-list-item-label-text-line-height, var(--mat-sys-body-large-line-height));font-size:var(--mat-list-list-item-label-text-size, var(--mat-sys-body-large-size));font-weight:var(--mat-list-list-item-label-text-weight, var(--mat-sys-body-large-weight));letter-spacing:var(--mat-list-list-item-label-text-tracking, var(--mat-sys-body-large-tracking))}.mdc-list-item:hover .mdc-list-item__primary-text{color:var(--mat-list-list-item-hover-label-text-color, var(--mat-sys-on-surface))}.mdc-list-item:focus .mdc-list-item__primary-text{color:var(--mat-list-list-item-focus-label-text-color, var(--mat-sys-on-surface))}.mdc-list-item--with-two-lines .mdc-list-item__primary-text,.mdc-list-item--with-three-lines .mdc-list-item__primary-text{display:block;margin-top:0;line-height:normal;margin-bottom:-20px}.mdc-list-item--with-two-lines .mdc-list-item__primary-text::before,.mdc-list-item--with-three-lines .mdc-list-item__primary-text::before{display:inline-block;width:0;height:28px;content:"";vertical-align:0}.mdc-list-item--with-two-lines .mdc-list-item__primary-text::after,.mdc-list-item--with-three-lines .mdc-list-item__primary-text::after{display:inline-block;width:0;height:20px;content:"";vertical-align:-20px}.mdc-list-item__secondary-text{text-overflow:ellipsis;white-space:nowrap;overflow:hidden;display:block;margin-top:0;color:var(--mat-list-list-item-supporting-text-color, var(--mat-sys-on-surface-variant));font-family:var(--mat-list-list-item-supporting-text-font, var(--mat-sys-body-medium-font));line-height:var(--mat-list-list-item-supporting-text-line-height, var(--mat-sys-body-medium-line-height));font-size:var(--mat-list-list-item-supporting-text-size, var(--mat-sys-body-medium-size));font-weight:var(--mat-list-list-item-supporting-text-weight, var(--mat-sys-body-medium-weight));letter-spacing:var(--mat-list-list-item-supporting-text-tracking, var(--mat-sys-body-medium-tracking))}.mdc-list-item__secondary-text::before{display:inline-block;width:0;height:20px;content:"";vertical-align:0}.mdc-list-item--with-three-lines .mdc-list-item__secondary-text{white-space:normal;line-height:20px}.mdc-list-item--with-overline .mdc-list-item__secondary-text{white-space:nowrap;line-height:auto}.mdc-list-item--with-leading-radio.mdc-list-item,.mdc-list-item--with-leading-checkbox.mdc-list-item,.mdc-list-item--with-leading-icon.mdc-list-item,.mdc-list-item--with-leading-avatar.mdc-list-item{padding-left:0;padding-right:16px}[dir=rtl] .mdc-list-item--with-leading-radio.mdc-list-item,[dir=rtl] .mdc-list-item--with-leading-checkbox.mdc-list-item,[dir=rtl] .mdc-list-item--with-leading-icon.mdc-list-item,[dir=rtl] .mdc-list-item--with-leading-avatar.mdc-list-item{padding-left:16px;padding-right:0}.mdc-list-item--with-leading-radio.mdc-list-item--with-two-lines .mdc-list-item__primary-text,.mdc-list-item--with-leading-checkbox.mdc-list-item--with-two-lines .mdc-list-item__primary-text,.mdc-list-item--with-leading-icon.mdc-list-item--with-two-lines .mdc-list-item__primary-text,.mdc-list-item--with-leading-avatar.mdc-list-item--with-two-lines .mdc-list-item__primary-text{display:block;margin-top:0;line-height:normal;margin-bottom:-20px}.mdc-list-item--with-leading-radio.mdc-list-item--with-two-lines .mdc-list-item__primary-text::before,.mdc-list-item--with-leading-checkbox.mdc-list-item--with-two-lines .mdc-list-item__primary-text::before,.mdc-list-item--with-leading-icon.mdc-list-item--with-two-lines .mdc-list-item__primary-text::before,.mdc-list-item--with-leading-avatar.mdc-list-item--with-two-lines .mdc-list-item__primary-text::before{display:inline-block;width:0;height:32px;content:"";vertical-align:0}.mdc-list-item--with-leading-radio.mdc-list-item--with-two-lines .mdc-list-item__primary-text::after,.mdc-list-item--with-leading-checkbox.mdc-list-item--with-two-lines .mdc-list-item__primary-text::after,.mdc-list-item--with-leading-icon.mdc-list-item--with-two-lines .mdc-list-item__primary-text::after,.mdc-list-item--with-leading-avatar.mdc-list-item--with-two-lines .mdc-list-item__primary-text::after{display:inline-block;width:0;height:20px;content:"";vertical-align:-20px}.mdc-list-item--with-leading-radio.mdc-list-item--with-two-lines.mdc-list-item--with-trailing-meta .mdc-list-item__end,.mdc-list-item--with-leading-checkbox.mdc-list-item--with-two-lines.mdc-list-item--with-trailing-meta .mdc-list-item__end,.mdc-list-item--with-leading-icon.mdc-list-item--with-two-lines.mdc-list-item--with-trailing-meta .mdc-list-item__end,.mdc-list-item--with-leading-avatar.mdc-list-item--with-two-lines.mdc-list-item--with-trailing-meta .mdc-list-item__end{display:block;margin-top:0;line-height:normal}.mdc-list-item--with-leading-radio.mdc-list-item--with-two-lines.mdc-list-item--with-trailing-meta .mdc-list-item__end::before,.mdc-list-item--with-leading-checkbox.mdc-list-item--with-two-lines.mdc-list-item--with-trailing-meta .mdc-list-item__end::before,.mdc-list-item--with-leading-icon.mdc-list-item--with-two-lines.mdc-list-item--with-trailing-meta .mdc-list-item__end::before,.mdc-list-item--with-leading-avatar.mdc-list-item--with-two-lines.mdc-list-item--with-trailing-meta .mdc-list-item__end::before{display:inline-block;width:0;height:32px;content:"";vertical-align:0}.mdc-list-item--with-trailing-icon.mdc-list-item,[dir=rtl] .mdc-list-item--with-trailing-icon.mdc-list-item{padding-left:0;padding-right:0}.mdc-list-item--with-trailing-icon .mdc-list-item__end{margin-left:16px;margin-right:16px}.mdc-list-item--with-trailing-meta.mdc-list-item{padding-left:16px;padding-right:0}[dir=rtl] .mdc-list-item--with-trailing-meta.mdc-list-item{padding-left:0;padding-right:16px}.mdc-list-item--with-trailing-meta .mdc-list-item__end{-webkit-user-select:none;user-select:none;margin-left:28px;margin-right:16px}[dir=rtl] .mdc-list-item--with-trailing-meta .mdc-list-item__end{margin-left:16px;margin-right:28px}.mdc-list-item--with-trailing-meta.mdc-list-item--with-three-lines .mdc-list-item__end,.mdc-list-item--with-trailing-meta.mdc-list-item--with-two-lines .mdc-list-item__end{display:block;line-height:normal;align-self:flex-start;margin-top:0}.mdc-list-item--with-trailing-meta.mdc-list-item--with-three-lines .mdc-list-item__end::before,.mdc-list-item--with-trailing-meta.mdc-list-item--with-two-lines .mdc-list-item__end::before{display:inline-block;width:0;height:28px;content:"";vertical-align:0}.mdc-list-item--with-leading-radio .mdc-list-item__start,.mdc-list-item--with-leading-checkbox .mdc-list-item__start{margin-left:8px;margin-right:24px}[dir=rtl] .mdc-list-item--with-leading-radio .mdc-list-item__start,[dir=rtl] .mdc-list-item--with-leading-checkbox .mdc-list-item__start{margin-left:24px;margin-right:8px}.mdc-list-item--with-leading-radio.mdc-list-item--with-two-lines .mdc-list-item__start,.mdc-list-item--with-leading-checkbox.mdc-list-item--with-two-lines .mdc-list-item__start{align-self:flex-start;margin-top:8px}.mdc-list-item--with-trailing-radio.mdc-list-item,.mdc-list-item--with-trailing-checkbox.mdc-list-item{padding-left:16px;padding-right:0}[dir=rtl] .mdc-list-item--with-trailing-radio.mdc-list-item,[dir=rtl] .mdc-list-item--with-trailing-checkbox.mdc-list-item{padding-left:0;padding-right:16px}.mdc-list-item--with-trailing-radio.mdc-list-item--with-leading-icon,.mdc-list-item--with-trailing-radio.mdc-list-item--with-leading-avatar,.mdc-list-item--with-trailing-checkbox.mdc-list-item--with-leading-icon,.mdc-list-item--with-trailing-checkbox.mdc-list-item--with-leading-avatar{padding-left:0}[dir=rtl] .mdc-list-item--with-trailing-radio.mdc-list-item--with-leading-icon,[dir=rtl] .mdc-list-item--with-trailing-radio.mdc-list-item--with-leading-avatar,[dir=rtl] .mdc-list-item--with-trailing-checkbox.mdc-list-item--with-leading-icon,[dir=rtl] .mdc-list-item--with-trailing-checkbox.mdc-list-item--with-leading-avatar{padding-right:0}.mdc-list-item--with-trailing-radio .mdc-list-item__end,.mdc-list-item--with-trailing-checkbox .mdc-list-item__end{margin-left:24px;margin-right:8px}[dir=rtl] .mdc-list-item--with-trailing-radio .mdc-list-item__end,[dir=rtl] .mdc-list-item--with-trailing-checkbox .mdc-list-item__end{margin-left:8px;margin-right:24px}.mdc-list-item--with-trailing-radio.mdc-list-item--with-three-lines .mdc-list-item__end,.mdc-list-item--with-trailing-checkbox.mdc-list-item--with-three-lines .mdc-list-item__end{align-self:flex-start;margin-top:8px}.mdc-list-group__subheader{margin:.75rem 16px}.mdc-list-item--disabled .mdc-list-item__start,.mdc-list-item--disabled .mdc-list-item__content,.mdc-list-item--disabled .mdc-list-item__end{opacity:1}.mdc-list-item--disabled .mdc-list-item__primary-text,.mdc-list-item--disabled .mdc-list-item__secondary-text{opacity:var(--mat-list-list-item-disabled-label-text-opacity, 0.3)}.mdc-list-item--disabled.mdc-list-item--with-leading-icon .mdc-list-item__start{color:var(--mat-list-list-item-disabled-leading-icon-color, var(--mat-sys-on-surface));opacity:var(--mat-list-list-item-disabled-leading-icon-opacity, 0.38)}.mdc-list-item--disabled.mdc-list-item--with-trailing-icon .mdc-list-item__end{color:var(--mat-list-list-item-disabled-trailing-icon-color, var(--mat-sys-on-surface));opacity:var(--mat-list-list-item-disabled-trailing-icon-opacity, 0.38)}.mat-mdc-list-item.mat-mdc-list-item-both-leading-and-trailing,[dir=rtl] .mat-mdc-list-item.mat-mdc-list-item-both-leading-and-trailing{padding-left:0;padding-right:0}.mdc-list-item.mdc-list-item--disabled .mdc-list-item__primary-text{color:var(--mat-list-list-item-disabled-label-text-color, var(--mat-sys-on-surface))}.mdc-list-item:hover::before{background-color:var(--mat-list-list-item-hover-state-layer-color, var(--mat-sys-on-surface));opacity:var(--mat-list-list-item-hover-state-layer-opacity, var(--mat-sys-hover-state-layer-opacity))}.mdc-list-item.mdc-list-item--disabled::before{background-color:var(--mat-list-list-item-disabled-state-layer-color, var(--mat-sys-on-surface));opacity:var(--mat-list-list-item-disabled-state-layer-opacity, var(--mat-sys-focus-state-layer-opacity))}.mdc-list-item:focus::before{background-color:var(--mat-list-list-item-focus-state-layer-color, var(--mat-sys-on-surface));opacity:var(--mat-list-list-item-focus-state-layer-opacity, var(--mat-sys-focus-state-layer-opacity))}.mdc-list-item--disabled .mdc-radio,.mdc-list-item--disabled .mdc-checkbox{opacity:var(--mat-list-list-item-disabled-label-text-opacity, 0.3)}.mdc-list-item--with-leading-avatar .mat-mdc-list-item-avatar{border-radius:var(--mat-list-list-item-leading-avatar-shape, var(--mat-sys-corner-full));background-color:var(--mat-list-list-item-leading-avatar-color, var(--mat-sys-primary-container))}.mat-mdc-list-item-icon{font-size:var(--mat-list-list-item-leading-icon-size, 24px)}@media(forced-colors: active){a.mdc-list-item--activated::after{content:"";position:absolute;top:50%;right:16px;transform:translateY(-50%);width:10px;height:0;border-bottom:solid 10px;border-radius:10px}a.mdc-list-item--activated [dir=rtl]::after{right:auto;left:16px}}.mat-mdc-list-base{display:block}.mat-mdc-list-base .mdc-list-item__start,.mat-mdc-list-base .mdc-list-item__end,.mat-mdc-list-base .mdc-list-item__content{pointer-events:auto}.mat-mdc-list-item,.mat-mdc-list-option{width:100%;box-sizing:border-box;-webkit-tap-highlight-color:rgba(0,0,0,0)}.mat-mdc-list-item:not(.mat-mdc-list-item-interactive),.mat-mdc-list-option:not(.mat-mdc-list-item-interactive){cursor:default}.mat-mdc-list-item .mat-divider-inset,.mat-mdc-list-option .mat-divider-inset{position:absolute;left:0;right:0;bottom:0}.mat-mdc-list-item .mat-mdc-list-item-avatar~.mat-divider-inset,.mat-mdc-list-option .mat-mdc-list-item-avatar~.mat-divider-inset{margin-left:72px}[dir=rtl] .mat-mdc-list-item .mat-mdc-list-item-avatar~.mat-divider-inset,[dir=rtl] .mat-mdc-list-option .mat-mdc-list-item-avatar~.mat-divider-inset{margin-right:72px}.mat-mdc-list-item-interactive::before{top:0;left:0;right:0;bottom:0;position:absolute;content:"";opacity:0;pointer-events:none;border-radius:inherit}.mat-mdc-list-item>.mat-focus-indicator{top:0;left:0;right:0;bottom:0;position:absolute;pointer-events:none}.mat-mdc-list-item:focus>.mat-focus-indicator::before{content:""}.mat-mdc-list-item.mdc-list-item--with-three-lines .mat-mdc-list-item-line.mdc-list-item__secondary-text{white-space:nowrap;line-height:normal}.mat-mdc-list-item.mdc-list-item--with-three-lines .mat-mdc-list-item-unscoped-content.mdc-list-item__secondary-text{display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2}mat-action-list button{background:none;color:inherit;border:none;font:inherit;outline:inherit;-webkit-tap-highlight-color:rgba(0,0,0,0);text-align:start}mat-action-list button::-moz-focus-inner{border:0}.mdc-list-item--with-leading-icon .mdc-list-item__start{margin-inline-start:var(--mat-list-list-item-leading-icon-start-space, 16px);margin-inline-end:var(--mat-list-list-item-leading-icon-end-space, 16px)}.mat-mdc-nav-list .mat-mdc-list-item{border-radius:var(--mat-list-active-indicator-shape, var(--mat-sys-corner-full));--mat-focus-indicator-border-radius: var(--mat-list-active-indicator-shape, var(--mat-sys-corner-full))}.mat-mdc-nav-list .mat-mdc-list-item.mdc-list-item--activated{background-color:var(--mat-list-active-indicator-color, var(--mat-sys-secondary-container))}
`,Dy=["unscopedContent"],Ey=["text"],xy=[[["","matListItemAvatar",""],["","matListItemIcon",""]],[["","matListItemTitle",""]],[["","matListItemLine",""]],"*",[["","matListItemMeta",""]],[["mat-divider"]]],Ty=["[matListItemAvatar],[matListItemIcon]","[matListItemTitle]","[matListItemLine]","*","[matListItemMeta]","mat-divider"];var Ry=new A("ListOption"),kl=(()=>{class i{_elementRef=l(R);constructor(){}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","matListItemTitle",""]],hostAttrs:[1,"mat-mdc-list-item-title","mdc-list-item__primary-text"]})}return i})(),Sy=(()=>{class i{_elementRef=l(R);constructor(){}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","matListItemLine",""]],hostAttrs:[1,"mat-mdc-list-item-line","mdc-list-item__secondary-text"]})}return i})(),Oy=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","matListItemMeta",""]],hostAttrs:[1,"mat-mdc-list-item-meta","mdc-list-item__end"]})}return i})(),lh=(()=>{class i{_listOption=l(Ry,{optional:!0});constructor(){}_isAlignedAtStart(){return!this._listOption||this._listOption?._getTogglePosition()==="after"}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,hostVars:4,hostBindings:function(t,o){t&2&&N("mdc-list-item__start",o._isAlignedAtStart())("mdc-list-item__end",!o._isAlignedAtStart())}})}return i})(),Py=(()=>{class i extends lh{static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275dir=_({type:i,selectors:[["","matListItemAvatar",""]],hostAttrs:[1,"mat-mdc-list-item-avatar"],features:[H]})}return i})(),Dl=(()=>{class i extends lh{static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275dir=_({type:i,selectors:[["","matListItemIcon",""]],hostAttrs:[1,"mat-mdc-list-item-icon"],features:[H]})}return i})(),qy=new A("MAT_LIST_CONFIG"),Cl=(()=>{class i{_isNonInteractive=!0;get disableRipple(){return this._disableRipple}set disableRipple(e){this._disableRipple=Qe(e)}_disableRipple=!1;get disabled(){return this._disabled()}set disabled(e){this._disabled.set(Qe(e))}_disabled=te(!1);_defaultOptions=l(qy,{optional:!0});static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,hostVars:1,hostBindings:function(t,o){t&2&&X("aria-disabled",o.disabled)},inputs:{disableRipple:"disableRipple",disabled:"disabled"}})}return i})(),Fy=(()=>{class i{_elementRef=l(R);_ngZone=l(F);_listBase=l(Cl,{optional:!0});_platform=l(oe);_hostElement;_isButtonElement;_noopAnimations=Le();_avatars;_icons;set lines(e){this._explicitLines=Ft(e,null),this._updateItemLines(!1)}_explicitLines=null;get disableRipple(){return this.disabled||this._disableRipple||this._noopAnimations||!!this._listBase?.disableRipple}set disableRipple(e){this._disableRipple=Qe(e)}_disableRipple=!1;get disabled(){return this._disabled()||!!this._listBase?.disabled}set disabled(e){this._disabled.set(Qe(e))}_disabled=te(!1);_subscriptions=new De;_rippleRenderer=null;_hasUnscopedTextContent=!1;rippleConfig;get rippleDisabled(){return this.disableRipple||!!this.rippleConfig.disabled}constructor(){l(Te).load(ei);let e=l(co,{optional:!0});this.rippleConfig=e||{},this._hostElement=this._elementRef.nativeElement,this._isButtonElement=this._hostElement.nodeName.toLowerCase()==="button",this._listBase&&!this._listBase._isNonInteractive&&this._initInteractiveListItem(),this._isButtonElement&&!this._hostElement.hasAttribute("type")&&this._hostElement.setAttribute("type","button")}ngAfterViewInit(){this._monitorProjectedLinesAndTitle(),this._updateItemLines(!0)}ngOnDestroy(){this._subscriptions.unsubscribe(),this._rippleRenderer!==null&&this._rippleRenderer._removeTriggerEvents()}_hasIconOrAvatar(){return!!(this._avatars.length||this._icons.length)}_initInteractiveListItem(){this._hostElement.classList.add("mat-mdc-list-item-interactive"),this._rippleRenderer=new Ii(this,this._ngZone,this._hostElement,this._platform,l(V)),this._rippleRenderer.setupTriggerEvents(this._hostElement)}_monitorProjectedLinesAndTitle(){this._ngZone.runOutsideAngular(()=>{this._subscriptions.add(Nt(this._lines.changes,this._titles.changes).subscribe(()=>this._updateItemLines(!1)))})}_updateItemLines(e){if(!this._lines||!this._titles||!this._unscopedContent)return;e&&this._checkDomForUnscopedTextContent();let t=this._explicitLines??this._inferLinesFromContent(),o=this._unscopedContent.nativeElement;if(this._hostElement.classList.toggle("mat-mdc-list-item-single-line",t<=1),this._hostElement.classList.toggle("mdc-list-item--with-one-line",t<=1),this._hostElement.classList.toggle("mdc-list-item--with-two-lines",t===2),this._hostElement.classList.toggle("mdc-list-item--with-three-lines",t===3),this._hasUnscopedTextContent){let a=this._titles.length===0&&t===1;o.classList.toggle("mdc-list-item__primary-text",a),o.classList.toggle("mdc-list-item__secondary-text",!a)}else o.classList.remove("mdc-list-item__primary-text"),o.classList.remove("mdc-list-item__secondary-text")}_inferLinesFromContent(){let e=this._titles.length+this._lines.length;return this._hasUnscopedTextContent&&(e+=1),e}_checkDomForUnscopedTextContent(){this._hasUnscopedTextContent=Array.from(this._unscopedContent.nativeElement.childNodes).filter(e=>e.nodeType!==e.COMMENT_NODE).some(e=>!!(e.textContent&&e.textContent.trim()))}static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,contentQueries:function(t,o,a){if(t&1&&(se(a,Py,4),se(a,Dl,4)),t&2){let s;B(s=j())&&(o._avatars=s),B(s=j())&&(o._icons=s)}},hostVars:4,hostBindings:function(t,o){t&2&&(X("aria-disabled",o.disabled)("disabled",o._isButtonElement&&o.disabled||null),N("mdc-list-item--disabled",o.disabled))},inputs:{lines:"lines",disableRipple:"disableRipple",disabled:"disabled"}})}return i})();var ch=(()=>{class i extends Fy{_lines;_titles;_meta;_unscopedContent;_itemText;get activated(){return this._activated}set activated(e){this._activated=Qe(e)}_activated=!1;_getAriaCurrent(){return this._hostElement.nodeName==="A"&&this._activated?"page":null}_hasBothLeadingAndTrailing(){return this._meta.length!==0&&(this._avatars.length!==0||this._icons.length!==0)}static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275cmp=y({type:i,selectors:[["mat-list-item"],["a","mat-list-item",""],["button","mat-list-item",""]],contentQueries:function(t,o,a){if(t&1&&(se(a,Sy,5),se(a,kl,5),se(a,Oy,5)),t&2){let s;B(s=j())&&(o._lines=s),B(s=j())&&(o._titles=s),B(s=j())&&(o._meta=s)}},viewQuery:function(t,o){if(t&1&&(xe(Dy,5),xe(Ey,5)),t&2){let a;B(a=j())&&(o._unscopedContent=a.first),B(a=j())&&(o._itemText=a.first)}},hostAttrs:[1,"mat-mdc-list-item","mdc-list-item"],hostVars:13,hostBindings:function(t,o){t&2&&(X("aria-current",o._getAriaCurrent()),N("mdc-list-item--activated",o.activated)("mdc-list-item--with-leading-avatar",o._avatars.length!==0)("mdc-list-item--with-leading-icon",o._icons.length!==0)("mdc-list-item--with-trailing-meta",o._meta.length!==0)("mat-mdc-list-item-both-leading-and-trailing",o._hasBothLeadingAndTrailing())("_mat-animation-noopable",o._noopAnimations))},inputs:{activated:"activated"},exportAs:["matListItem"],features:[H],ngContentSelectors:Ty,decls:10,vars:0,consts:[["unscopedContent",""],[1,"mdc-list-item__content"],[1,"mat-mdc-list-item-unscoped-content",3,"cdkObserveContent"],[1,"mat-focus-indicator"]],template:function(t,o){if(t&1){let a=Ie();Y(xy),T(0),u(1,"span",1),T(2,1),T(3,2),u(4,"span",2,0),he("cdkObserveContent",function(){return re(a),le(o._updateItemLines(!0))}),T(6,3),h()(),T(7,4),T(8,5),ie(9,"div",3)}},dependencies:[Zd],encapsulation:2,changeDetection:0})}return i})();var dh=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["","mat-subheader",""],["","matSubheader",""]],hostAttrs:[1,"mat-mdc-subheader","mdc-list-group__subheader"]})}return i})();var uh=(()=>{class i extends Cl{_isNonInteractive=!1;static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275cmp=y({type:i,selectors:[["mat-nav-list"]],hostAttrs:["role","navigation",1,"mat-mdc-nav-list","mat-mdc-list-base","mdc-list"],exportAs:["matNavList"],features:[de([{provide:Cl,useExisting:i}]),H],ngContentSelectors:Cy,decls:1,vars:0,template:function(t,o){t&1&&(Y(),T(0))},styles:[ky],encapsulation:2,changeDetection:0})}return i})();var is=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[Xd,z,ii,rh,sh]})}return i})();var Ny=(i,n)=>n.principle;function Ly(i,n){if(i&1&&(u(0,"mat-card")(1,"mat-card-header")(2,"mat-card-title"),m(3),h(),u(4,"mat-card-subtitle"),m(5),h()(),u(6,"mat-card-content")(7,"p"),m(8),h(),ie(9,"mat-progress-bar",2),h()()),i&2){let e=n.$implicit,t=k();f(3),St(e.principle),f(2),mt("Referenced in ",e.count," policies"),f(3),St(e.description),f(),M("value",e.count/t.maxCount*100)}}var ns=class i{dataService=l(gn);maxCount=Math.max(...this.dataService.aiPrinciples().map(n=>n.count));static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-ai-principles"]],decls:6,vars:0,consts:[[1,"principles-container"],[1,"principles-grid"],["mode","determinate","color","primary",3,"value"]],template:function(e,t){e&1&&(u(0,"div",0)(1,"h1"),m(2,"AI in Education Principles"),h(),u(3,"div",1),Bt(4,Ly,10,4,"mat-card",null,Ny),h()()),e&2&&(f(4),jt(t.dataService.aiPrinciples()))},dependencies:[je,_t,nn,an,sn,ou,on,is,wt,Na,Vu],styles:[".principles-container[_ngcontent-%COMP%]{max-width:1200px;margin:0 auto;padding:20px}.principles-grid[_ngcontent-%COMP%]{display:grid;grid-template-columns:repeat(auto-fill,minmax(350px,1fr));gap:20px;margin-top:20px}mat-card[_ngcontent-%COMP%]{height:100%}mat-card-content[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{margin-bottom:16px;min-height:3em}h1[_ngcontent-%COMP%]{color:#333;margin-bottom:20px}"]})};var os=class i{static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-all-policies"]],decls:2,vars:0,template:function(e,t){e&1&&(Q(0,"p"),m(1,"all-policies works!"),ne())},encapsulation:2})};var as=class i{static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-relevant-policies"]],decls:2,vars:0,template:function(e,t){e&1&&(Q(0,"p"),m(1,"relevant-policies works!"),ne())},encapsulation:2})};var ss=class i{static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-creation-year"]],decls:2,vars:0,template:function(e,t){e&1&&(Q(0,"p"),m(1,"creation-year works!"),ne())},encapsulation:2})};var rs=class i{static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-governance-practices"]],decls:2,vars:0,template:function(e,t){e&1&&(Q(0,"p"),m(1,"governance-practices works!"),ne())},encapsulation:2})};var ls=class i{static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-opportunity-risk"]],decls:2,vars:0,template:function(e,t){e&1&&(Q(0,"p"),m(1,"opportunity-risk works!"),ne())},encapsulation:2})};var cs=class i{static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-principles"]],decls:2,vars:0,template:function(e,t){e&1&&(Q(0,"p"),m(1,"principles works!"),ne())},encapsulation:2})};var ds=class i{static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-essential-reading"]],decls:2,vars:0,template:function(e,t){e&1&&(Q(0,"p"),m(1,"essential-reading works!"),ne())},encapsulation:2})};var us=class i{static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-relevance-assessment"]],decls:2,vars:0,template:function(e,t){e&1&&(Q(0,"p"),m(1,"relevance-assessment works!"),ne())},encapsulation:2})};var hs=class i{static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-lookup-tables"]],decls:2,vars:0,template:function(e,t){e&1&&(Q(0,"p"),m(1,"lookup-tables works!"),ne())},encapsulation:2})};var Gy=["determinateSpinner"];function Ky(i,n){if(i&1&&(Tt(),u(0,"svg",11),ie(1,"circle",12),h()),i&2){let e=k();X("viewBox",e._viewBox()),f(),Be("stroke-dasharray",e._strokeCircumference(),"px")("stroke-dashoffset",e._strokeCircumference()/2,"px")("stroke-width",e._circleStrokeWidth(),"%"),X("r",e._circleRadius())}}var zy=new A("mat-progress-spinner-default-options",{providedIn:"root",factory:By});function By(){return{diameter:hh}}var hh=100,jy=10,ps=(()=>{class i{_elementRef=l(R);_noopAnimations;get color(){return this._color||this._defaultColor}set color(e){this._color=e}_color;_defaultColor="primary";_determinateCircle;constructor(){let e=l(zy),t=ro(),o=this._elementRef.nativeElement;this._noopAnimations=t==="di-disabled"&&!!e&&!e._forceAnimations,this.mode=o.nodeName.toLowerCase()==="mat-spinner"?"indeterminate":"determinate",!this._noopAnimations&&t==="reduced-motion"&&o.classList.add("mat-progress-spinner-reduced-motion"),e&&(e.color&&(this.color=this._defaultColor=e.color),e.diameter&&(this.diameter=e.diameter),e.strokeWidth&&(this.strokeWidth=e.strokeWidth))}mode;get value(){return this.mode==="determinate"?this._value:0}set value(e){this._value=Math.max(0,Math.min(100,e||0))}_value=0;get diameter(){return this._diameter}set diameter(e){this._diameter=e||0}_diameter=hh;get strokeWidth(){return this._strokeWidth??this.diameter/10}set strokeWidth(e){this._strokeWidth=e||0}_strokeWidth;_circleRadius(){return(this.diameter-jy)/2}_viewBox(){let e=this._circleRadius()*2+this.strokeWidth;return`0 0 ${e} ${e}`}_strokeCircumference(){return 2*Math.PI*this._circleRadius()}_strokeDashOffset(){return this.mode==="determinate"?this._strokeCircumference()*(100-this._value)/100:null}_circleStrokeWidth(){return this.strokeWidth/this.diameter*100}static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["mat-progress-spinner"],["mat-spinner"]],viewQuery:function(t,o){if(t&1&&xe(Gy,5),t&2){let a;B(a=j())&&(o._determinateCircle=a.first)}},hostAttrs:["role","progressbar","tabindex","-1",1,"mat-mdc-progress-spinner","mdc-circular-progress"],hostVars:18,hostBindings:function(t,o){t&2&&(X("aria-valuemin",0)("aria-valuemax",100)("aria-valuenow",o.mode==="determinate"?o.value:null)("mode",o.mode),Me("mat-"+o.color),Be("width",o.diameter,"px")("height",o.diameter,"px")("--mat-progress-spinner-size",o.diameter+"px")("--mat-progress-spinner-active-indicator-width",o.diameter+"px"),N("_mat-animation-noopable",o._noopAnimations)("mdc-circular-progress--indeterminate",o.mode==="indeterminate"))},inputs:{color:"color",mode:"mode",value:[2,"value","value",Ye],diameter:[2,"diameter","diameter",Ye],strokeWidth:[2,"strokeWidth","strokeWidth",Ye]},exportAs:["matProgressSpinner"],decls:14,vars:11,consts:[["circle",""],["determinateSpinner",""],["aria-hidden","true",1,"mdc-circular-progress__determinate-container"],["xmlns","http://www.w3.org/2000/svg","focusable","false",1,"mdc-circular-progress__determinate-circle-graphic"],["cx","50%","cy","50%",1,"mdc-circular-progress__determinate-circle"],["aria-hidden","true",1,"mdc-circular-progress__indeterminate-container"],[1,"mdc-circular-progress__spinner-layer"],[1,"mdc-circular-progress__circle-clipper","mdc-circular-progress__circle-left"],[3,"ngTemplateOutlet"],[1,"mdc-circular-progress__gap-patch"],[1,"mdc-circular-progress__circle-clipper","mdc-circular-progress__circle-right"],["xmlns","http://www.w3.org/2000/svg","focusable","false",1,"mdc-circular-progress__indeterminate-circle-graphic"],["cx","50%","cy","50%"]],template:function(t,o){if(t&1&&(st(0,Ky,2,8,"ng-template",null,0,Ns),u(2,"div",2,1),Tt(),u(4,"svg",3),ie(5,"circle",4),h()(),Cn(),u(6,"div",5)(7,"div",6)(8,"div",7),ke(9,8),h(),u(10,"div",9),ke(11,8),h(),u(12,"div",10),ke(13,8),h()()()),t&2){let a=Rt(1);f(4),X("viewBox",o._viewBox()),f(),Be("stroke-dasharray",o._strokeCircumference(),"px")("stroke-dashoffset",o._strokeDashOffset(),"px")("stroke-width",o._circleStrokeWidth(),"%"),X("r",o._circleRadius()),f(4),M("ngTemplateOutlet",a),f(2),M("ngTemplateOutlet",a),f(2),M("ngTemplateOutlet",a)}},dependencies:[Bs],styles:[`.mat-mdc-progress-spinner{--mat-progress-spinner-animation-multiplier: 1;display:block;overflow:hidden;line-height:0;position:relative;direction:ltr;transition:opacity 250ms cubic-bezier(0.4, 0, 0.6, 1)}.mat-mdc-progress-spinner circle{stroke-width:var(--mat-progress-spinner-active-indicator-width, 4px)}.mat-mdc-progress-spinner._mat-animation-noopable,.mat-mdc-progress-spinner._mat-animation-noopable .mdc-circular-progress__determinate-circle{transition:none !important}.mat-mdc-progress-spinner._mat-animation-noopable .mdc-circular-progress__indeterminate-circle-graphic,.mat-mdc-progress-spinner._mat-animation-noopable .mdc-circular-progress__spinner-layer,.mat-mdc-progress-spinner._mat-animation-noopable .mdc-circular-progress__indeterminate-container{animation:none !important}.mat-mdc-progress-spinner._mat-animation-noopable .mdc-circular-progress__indeterminate-container circle{stroke-dasharray:0 !important}@media(forced-colors: active){.mat-mdc-progress-spinner .mdc-circular-progress__indeterminate-circle-graphic,.mat-mdc-progress-spinner .mdc-circular-progress__determinate-circle{stroke:currentColor;stroke:CanvasText}}.mat-progress-spinner-reduced-motion{--mat-progress-spinner-animation-multiplier: 1.25}.mdc-circular-progress__determinate-container,.mdc-circular-progress__indeterminate-circle-graphic,.mdc-circular-progress__indeterminate-container,.mdc-circular-progress__spinner-layer{position:absolute;width:100%;height:100%}.mdc-circular-progress__determinate-container{transform:rotate(-90deg)}.mdc-circular-progress--indeterminate .mdc-circular-progress__determinate-container{opacity:0}.mdc-circular-progress__indeterminate-container{font-size:0;letter-spacing:0;white-space:nowrap;opacity:0}.mdc-circular-progress--indeterminate .mdc-circular-progress__indeterminate-container{opacity:1;animation:mdc-circular-progress-container-rotate calc(1568.2352941176ms*var(--mat-progress-spinner-animation-multiplier)) linear infinite}.mdc-circular-progress__determinate-circle-graphic,.mdc-circular-progress__indeterminate-circle-graphic{fill:rgba(0,0,0,0)}.mat-mdc-progress-spinner .mdc-circular-progress__determinate-circle,.mat-mdc-progress-spinner .mdc-circular-progress__indeterminate-circle-graphic{stroke:var(--mat-progress-spinner-active-indicator-color, var(--mat-sys-primary))}@media(forced-colors: active){.mat-mdc-progress-spinner .mdc-circular-progress__determinate-circle,.mat-mdc-progress-spinner .mdc-circular-progress__indeterminate-circle-graphic{stroke:CanvasText}}.mdc-circular-progress__determinate-circle{transition:stroke-dashoffset 500ms cubic-bezier(0, 0, 0.2, 1)}.mdc-circular-progress__gap-patch{position:absolute;top:0;left:47.5%;box-sizing:border-box;width:5%;height:100%;overflow:hidden}.mdc-circular-progress__gap-patch .mdc-circular-progress__indeterminate-circle-graphic{left:-900%;width:2000%;transform:rotate(180deg)}.mdc-circular-progress__circle-clipper .mdc-circular-progress__indeterminate-circle-graphic{width:200%}.mdc-circular-progress__circle-right .mdc-circular-progress__indeterminate-circle-graphic{left:-100%}.mdc-circular-progress--indeterminate .mdc-circular-progress__circle-left .mdc-circular-progress__indeterminate-circle-graphic{animation:mdc-circular-progress-left-spin calc(1333ms*var(--mat-progress-spinner-animation-multiplier)) cubic-bezier(0.4, 0, 0.2, 1) infinite both}.mdc-circular-progress--indeterminate .mdc-circular-progress__circle-right .mdc-circular-progress__indeterminate-circle-graphic{animation:mdc-circular-progress-right-spin calc(1333ms*var(--mat-progress-spinner-animation-multiplier)) cubic-bezier(0.4, 0, 0.2, 1) infinite both}.mdc-circular-progress__circle-clipper{display:inline-flex;position:relative;width:50%;height:100%;overflow:hidden}.mdc-circular-progress--indeterminate .mdc-circular-progress__spinner-layer{animation:mdc-circular-progress-spinner-layer-rotate calc(5332ms*var(--mat-progress-spinner-animation-multiplier)) cubic-bezier(0.4, 0, 0.2, 1) infinite both}@keyframes mdc-circular-progress-container-rotate{to{transform:rotate(360deg)}}@keyframes mdc-circular-progress-spinner-layer-rotate{12.5%{transform:rotate(135deg)}25%{transform:rotate(270deg)}37.5%{transform:rotate(405deg)}50%{transform:rotate(540deg)}62.5%{transform:rotate(675deg)}75%{transform:rotate(810deg)}87.5%{transform:rotate(945deg)}100%{transform:rotate(1080deg)}}@keyframes mdc-circular-progress-left-spin{from{transform:rotate(265deg)}50%{transform:rotate(130deg)}to{transform:rotate(265deg)}}@keyframes mdc-circular-progress-right-spin{from{transform:rotate(-265deg)}50%{transform:rotate(-130deg)}to{transform:rotate(-265deg)}}
`],encapsulation:2,changeDetection:0})}return i})();var ms=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[z]})}return i})();var Vy=["mat-internal-form-field",""],Wy=["*"],mh=(()=>{class i{labelPosition;static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["div","mat-internal-form-field",""]],hostAttrs:[1,"mdc-form-field","mat-internal-form-field"],hostVars:2,hostBindings:function(t,o){t&2&&N("mdc-form-field--align-end",o.labelPosition==="before")},inputs:{labelPosition:"labelPosition"},attrs:Vy,ngContentSelectors:Wy,decls:1,vars:0,template:function(t,o){t&1&&(Y(),T(0))},styles:[`.mat-internal-form-field{-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;display:inline-flex;align-items:center;vertical-align:middle}.mat-internal-form-field>label{margin-left:0;margin-right:auto;padding-left:4px;padding-right:0;order:0}[dir=rtl] .mat-internal-form-field>label{margin-left:auto;margin-right:0;padding-left:0;padding-right:4px}.mdc-form-field--align-end>label{margin-left:auto;margin-right:0;padding-left:0;padding-right:4px;order:-1}[dir=rtl] .mdc-form-field--align-end .mdc-form-field--align-end label{margin-left:0;margin-right:auto;padding-left:4px;padding-right:0}
`],encapsulation:2,changeDetection:0})}return i})();var Uy=["input"],Hy=["label"],Yy=["*"],Zy=new A("mat-checkbox-default-options",{providedIn:"root",factory:yh});function yh(){return{color:"accent",clickAction:"check-indeterminate",disabledInteractive:!1}}var Se=(function(i){return i[i.Init=0]="Init",i[i.Checked=1]="Checked",i[i.Unchecked=2]="Unchecked",i[i.Indeterminate=3]="Indeterminate",i})(Se||{}),El=class{source;checked},fh=yh(),bo=(()=>{class i{_elementRef=l(R);_changeDetectorRef=l(me);_ngZone=l(F);_animationsDisabled=Le();_options=l(Zy,{optional:!0});focus(){this._inputElement.nativeElement.focus()}_createChangeEvent(e){let t=new El;return t.source=this,t.checked=e,t}_getAnimationTargetElement(){return this._inputElement?.nativeElement}_animationClasses={uncheckedToChecked:"mdc-checkbox--anim-unchecked-checked",uncheckedToIndeterminate:"mdc-checkbox--anim-unchecked-indeterminate",checkedToUnchecked:"mdc-checkbox--anim-checked-unchecked",checkedToIndeterminate:"mdc-checkbox--anim-checked-indeterminate",indeterminateToChecked:"mdc-checkbox--anim-indeterminate-checked",indeterminateToUnchecked:"mdc-checkbox--anim-indeterminate-unchecked"};ariaLabel="";ariaLabelledby=null;ariaDescribedby;ariaExpanded;ariaControls;ariaOwns;_uniqueId;id;get inputId(){return`${this.id||this._uniqueId}-input`}required;labelPosition="after";name=null;change=new Z;indeterminateChange=new Z;value;disableRipple;_inputElement;_labelElement;tabIndex;color;disabledInteractive;_onTouched=()=>{};_currentAnimationClass="";_currentCheckState=Se.Init;_controlValueAccessorChangeFn=()=>{};_validatorChangeFn=()=>{};constructor(){l(Te).load(ei);let e=l(new Vt("tabindex"),{optional:!0});this._options=this._options||fh,this.color=this._options.color||fh.color,this.tabIndex=e==null?0:parseInt(e)||0,this.id=this._uniqueId=l(vi).getId("mat-mdc-checkbox-"),this.disabledInteractive=this._options?.disabledInteractive??!1}ngOnChanges(e){e.required&&this._validatorChangeFn()}ngAfterViewInit(){this._syncIndeterminate(this.indeterminate)}get checked(){return this._checked}set checked(e){e!=this.checked&&(this._checked=e,this._changeDetectorRef.markForCheck())}_checked=!1;get disabled(){return this._disabled}set disabled(e){e!==this.disabled&&(this._disabled=e,this._changeDetectorRef.markForCheck())}_disabled=!1;get indeterminate(){return this._indeterminate()}set indeterminate(e){let t=e!=this._indeterminate();this._indeterminate.set(e),t&&(e?this._transitionCheckState(Se.Indeterminate):this._transitionCheckState(this.checked?Se.Checked:Se.Unchecked),this.indeterminateChange.emit(e)),this._syncIndeterminate(e)}_indeterminate=te(!1);_isRippleDisabled(){return this.disableRipple||this.disabled}_onLabelTextChange(){this._changeDetectorRef.detectChanges()}writeValue(e){this.checked=!!e}registerOnChange(e){this._controlValueAccessorChangeFn=e}registerOnTouched(e){this._onTouched=e}setDisabledState(e){this.disabled=e}validate(e){return this.required&&e.value!==!0?{required:!0}:null}registerOnValidatorChange(e){this._validatorChangeFn=e}_transitionCheckState(e){let t=this._currentCheckState,o=this._getAnimationTargetElement();if(!(t===e||!o)&&(this._currentAnimationClass&&o.classList.remove(this._currentAnimationClass),this._currentAnimationClass=this._getAnimationClassForCheckStateTransition(t,e),this._currentCheckState=e,this._currentAnimationClass.length>0)){o.classList.add(this._currentAnimationClass);let a=this._currentAnimationClass;this._ngZone.runOutsideAngular(()=>{setTimeout(()=>{o.classList.remove(a)},1e3)})}}_emitChangeEvent(){this._controlValueAccessorChangeFn(this.checked),this.change.emit(this._createChangeEvent(this.checked)),this._inputElement&&(this._inputElement.nativeElement.checked=this.checked)}toggle(){this.checked=!this.checked,this._controlValueAccessorChangeFn(this.checked)}_handleInputClick(){let e=this._options?.clickAction;!this.disabled&&e!=="noop"?(this.indeterminate&&e!=="check"&&Promise.resolve().then(()=>{this._indeterminate.set(!1),this.indeterminateChange.emit(!1)}),this._checked=!this._checked,this._transitionCheckState(this._checked?Se.Checked:Se.Unchecked),this._emitChangeEvent()):(this.disabled&&this.disabledInteractive||!this.disabled&&e==="noop")&&(this._inputElement.nativeElement.checked=this.checked,this._inputElement.nativeElement.indeterminate=this.indeterminate)}_onInteractionEvent(e){e.stopPropagation()}_onBlur(){Promise.resolve().then(()=>{this._onTouched(),this._changeDetectorRef.markForCheck()})}_getAnimationClassForCheckStateTransition(e,t){if(this._animationsDisabled)return"";switch(e){case Se.Init:if(t===Se.Checked)return this._animationClasses.uncheckedToChecked;if(t==Se.Indeterminate)return this._checked?this._animationClasses.checkedToIndeterminate:this._animationClasses.uncheckedToIndeterminate;break;case Se.Unchecked:return t===Se.Checked?this._animationClasses.uncheckedToChecked:this._animationClasses.uncheckedToIndeterminate;case Se.Checked:return t===Se.Unchecked?this._animationClasses.checkedToUnchecked:this._animationClasses.checkedToIndeterminate;case Se.Indeterminate:return t===Se.Checked?this._animationClasses.indeterminateToChecked:this._animationClasses.indeterminateToUnchecked}return""}_syncIndeterminate(e){let t=this._inputElement;t&&(t.nativeElement.indeterminate=e)}_onInputClick(){this._handleInputClick()}_onTouchTargetClick(){this._handleInputClick(),this.disabled||this._inputElement.nativeElement.focus()}_preventBubblingFromLabel(e){e.target&&this._labelElement.nativeElement.contains(e.target)&&e.stopPropagation()}static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["mat-checkbox"]],viewQuery:function(t,o){if(t&1&&(xe(Uy,5),xe(Hy,5)),t&2){let a;B(a=j())&&(o._inputElement=a.first),B(a=j())&&(o._labelElement=a.first)}},hostAttrs:[1,"mat-mdc-checkbox"],hostVars:16,hostBindings:function(t,o){t&2&&(Rn("id",o.id),X("tabindex",null)("aria-label",null)("aria-labelledby",null),Me(o.color?"mat-"+o.color:"mat-accent"),N("_mat-animation-noopable",o._animationsDisabled)("mdc-checkbox--disabled",o.disabled)("mat-mdc-checkbox-disabled",o.disabled)("mat-mdc-checkbox-checked",o.checked)("mat-mdc-checkbox-disabled-interactive",o.disabledInteractive))},inputs:{ariaLabel:[0,"aria-label","ariaLabel"],ariaLabelledby:[0,"aria-labelledby","ariaLabelledby"],ariaDescribedby:[0,"aria-describedby","ariaDescribedby"],ariaExpanded:[2,"aria-expanded","ariaExpanded",K],ariaControls:[0,"aria-controls","ariaControls"],ariaOwns:[0,"aria-owns","ariaOwns"],id:"id",required:[2,"required","required",K],labelPosition:"labelPosition",name:"name",value:"value",disableRipple:[2,"disableRipple","disableRipple",K],tabIndex:[2,"tabIndex","tabIndex",e=>e==null?void 0:Ye(e)],color:"color",disabledInteractive:[2,"disabledInteractive","disabledInteractive",K],checked:[2,"checked","checked",K],disabled:[2,"disabled","disabled",K],indeterminate:[2,"indeterminate","indeterminate",K]},outputs:{change:"change",indeterminateChange:"indeterminateChange"},exportAs:["matCheckbox"],features:[de([{provide:ih,useExisting:Ti(()=>i),multi:!0},{provide:nh,useExisting:i,multi:!0}]),we],ngContentSelectors:Yy,decls:15,vars:23,consts:[["checkbox",""],["input",""],["label",""],["mat-internal-form-field","",3,"click","labelPosition"],[1,"mdc-checkbox"],[1,"mat-mdc-checkbox-touch-target",3,"click"],["type","checkbox",1,"mdc-checkbox__native-control",3,"blur","click","change","checked","indeterminate","disabled","id","required","tabIndex"],[1,"mdc-checkbox__ripple"],[1,"mdc-checkbox__background"],["focusable","false","viewBox","0 0 24 24","aria-hidden","true",1,"mdc-checkbox__checkmark"],["fill","none","d","M1.73,12.91 8.1,19.28 22.79,4.59",1,"mdc-checkbox__checkmark-path"],[1,"mdc-checkbox__mixedmark"],["mat-ripple","",1,"mat-mdc-checkbox-ripple","mat-focus-indicator",3,"matRippleTrigger","matRippleDisabled","matRippleCentered"],[1,"mdc-label",3,"for"]],template:function(t,o){if(t&1){let a=Ie();Y(),u(0,"div",3),he("click",function(r){return re(a),le(o._preventBubblingFromLabel(r))}),u(1,"div",4,0)(3,"div",5),he("click",function(){return re(a),le(o._onTouchTargetClick())}),h(),u(4,"input",6,1),he("blur",function(){return re(a),le(o._onBlur())})("click",function(){return re(a),le(o._onInputClick())})("change",function(r){return re(a),le(o._onInteractionEvent(r))}),h(),ie(6,"div",7),u(7,"div",8),Tt(),u(8,"svg",9),ie(9,"path",10),h(),Cn(),ie(10,"div",11),h(),ie(11,"div",12),h(),u(12,"label",13,2),T(14),h()()}if(t&2){let a=Rt(2);M("labelPosition",o.labelPosition),f(4),N("mdc-checkbox--selected",o.checked),M("checked",o.checked)("indeterminate",o.indeterminate)("disabled",o.disabled&&!o.disabledInteractive)("id",o.inputId)("required",o.required)("tabIndex",o.disabled&&!o.disabledInteractive?-1:o.tabIndex),X("aria-label",o.ariaLabel||null)("aria-labelledby",o.ariaLabelledby)("aria-describedby",o.ariaDescribedby)("aria-checked",o.indeterminate?"mixed":null)("aria-controls",o.ariaControls)("aria-disabled",o.disabled&&o.disabledInteractive?!0:null)("aria-expanded",o.ariaExpanded)("aria-owns",o.ariaOwns)("name",o.name)("value",o.value),f(7),M("matRippleTrigger",a)("matRippleDisabled",o.disableRipple||o.disabled)("matRippleCentered",!0),f(),M("for",o.inputId)}},dependencies:[_a,mh],styles:[`.mdc-checkbox{display:inline-block;position:relative;flex:0 0 18px;box-sizing:content-box;width:18px;height:18px;line-height:0;white-space:nowrap;cursor:pointer;vertical-align:bottom;padding:calc((var(--mat-checkbox-state-layer-size, 40px) - 18px)/2);margin:calc((var(--mat-checkbox-state-layer-size, 40px) - var(--mat-checkbox-state-layer-size, 40px))/2)}.mdc-checkbox:hover>.mdc-checkbox__ripple{opacity:var(--mat-checkbox-unselected-hover-state-layer-opacity, var(--mat-sys-hover-state-layer-opacity));background-color:var(--mat-checkbox-unselected-hover-state-layer-color, var(--mat-sys-on-surface))}.mdc-checkbox:hover>.mat-mdc-checkbox-ripple>.mat-ripple-element{background-color:var(--mat-checkbox-unselected-hover-state-layer-color, var(--mat-sys-on-surface))}.mdc-checkbox .mdc-checkbox__native-control:focus+.mdc-checkbox__ripple{opacity:var(--mat-checkbox-unselected-focus-state-layer-opacity, var(--mat-sys-focus-state-layer-opacity));background-color:var(--mat-checkbox-unselected-focus-state-layer-color, var(--mat-sys-on-surface))}.mdc-checkbox .mdc-checkbox__native-control:focus~.mat-mdc-checkbox-ripple .mat-ripple-element{background-color:var(--mat-checkbox-unselected-focus-state-layer-color, var(--mat-sys-on-surface))}.mdc-checkbox:active>.mdc-checkbox__native-control+.mdc-checkbox__ripple{opacity:var(--mat-checkbox-unselected-pressed-state-layer-opacity, var(--mat-sys-pressed-state-layer-opacity));background-color:var(--mat-checkbox-unselected-pressed-state-layer-color, var(--mat-sys-primary))}.mdc-checkbox:active>.mdc-checkbox__native-control~.mat-mdc-checkbox-ripple .mat-ripple-element{background-color:var(--mat-checkbox-unselected-pressed-state-layer-color, var(--mat-sys-primary))}.mdc-checkbox:hover .mdc-checkbox__native-control:checked+.mdc-checkbox__ripple{opacity:var(--mat-checkbox-selected-hover-state-layer-opacity, var(--mat-sys-hover-state-layer-opacity));background-color:var(--mat-checkbox-selected-hover-state-layer-color, var(--mat-sys-primary))}.mdc-checkbox:hover .mdc-checkbox__native-control:checked~.mat-mdc-checkbox-ripple .mat-ripple-element{background-color:var(--mat-checkbox-selected-hover-state-layer-color, var(--mat-sys-primary))}.mdc-checkbox .mdc-checkbox__native-control:focus:checked+.mdc-checkbox__ripple{opacity:var(--mat-checkbox-selected-focus-state-layer-opacity, var(--mat-sys-focus-state-layer-opacity));background-color:var(--mat-checkbox-selected-focus-state-layer-color, var(--mat-sys-primary))}.mdc-checkbox .mdc-checkbox__native-control:focus:checked~.mat-mdc-checkbox-ripple .mat-ripple-element{background-color:var(--mat-checkbox-selected-focus-state-layer-color, var(--mat-sys-primary))}.mdc-checkbox:active>.mdc-checkbox__native-control:checked+.mdc-checkbox__ripple{opacity:var(--mat-checkbox-selected-pressed-state-layer-opacity, var(--mat-sys-pressed-state-layer-opacity));background-color:var(--mat-checkbox-selected-pressed-state-layer-color, var(--mat-sys-on-surface))}.mdc-checkbox:active>.mdc-checkbox__native-control:checked~.mat-mdc-checkbox-ripple .mat-ripple-element{background-color:var(--mat-checkbox-selected-pressed-state-layer-color, var(--mat-sys-on-surface))}.mdc-checkbox--disabled.mat-mdc-checkbox-disabled-interactive .mdc-checkbox .mdc-checkbox__native-control~.mat-mdc-checkbox-ripple .mat-ripple-element,.mdc-checkbox--disabled.mat-mdc-checkbox-disabled-interactive .mdc-checkbox .mdc-checkbox__native-control+.mdc-checkbox__ripple{background-color:var(--mat-checkbox-unselected-hover-state-layer-color, var(--mat-sys-on-surface))}.mdc-checkbox .mdc-checkbox__native-control{position:absolute;margin:0;padding:0;opacity:0;cursor:inherit;z-index:1;width:var(--mat-checkbox-state-layer-size, 40px);height:var(--mat-checkbox-state-layer-size, 40px);top:calc((var(--mat-checkbox-state-layer-size, 40px) - var(--mat-checkbox-state-layer-size, 40px))/2);right:calc((var(--mat-checkbox-state-layer-size, 40px) - var(--mat-checkbox-state-layer-size, 40px))/2);left:calc((var(--mat-checkbox-state-layer-size, 40px) - var(--mat-checkbox-state-layer-size, 40px))/2)}.mdc-checkbox--disabled{cursor:default;pointer-events:none}@media(forced-colors: active){.mdc-checkbox--disabled{opacity:.5}}.mdc-checkbox__background{display:inline-flex;position:absolute;align-items:center;justify-content:center;box-sizing:border-box;width:18px;height:18px;border:2px solid currentColor;border-radius:2px;background-color:rgba(0,0,0,0);pointer-events:none;will-change:background-color,border-color;transition:background-color 90ms cubic-bezier(0.4, 0, 0.6, 1),border-color 90ms cubic-bezier(0.4, 0, 0.6, 1);-webkit-print-color-adjust:exact;color-adjust:exact;border-color:var(--mat-checkbox-unselected-icon-color, var(--mat-sys-on-surface-variant));top:calc((var(--mat-checkbox-state-layer-size, 40px) - 18px)/2);left:calc((var(--mat-checkbox-state-layer-size, 40px) - 18px)/2)}.mdc-checkbox__native-control:enabled:checked~.mdc-checkbox__background,.mdc-checkbox__native-control:enabled:indeterminate~.mdc-checkbox__background{border-color:var(--mat-checkbox-selected-icon-color, var(--mat-sys-primary));background-color:var(--mat-checkbox-selected-icon-color, var(--mat-sys-primary))}.mdc-checkbox--disabled .mdc-checkbox__background{border-color:var(--mat-checkbox-disabled-unselected-icon-color, color-mix(in srgb, var(--mat-sys-on-surface) 38%, transparent))}.mdc-checkbox__native-control:disabled:checked~.mdc-checkbox__background,.mdc-checkbox__native-control:disabled:indeterminate~.mdc-checkbox__background{background-color:var(--mat-checkbox-disabled-selected-icon-color, color-mix(in srgb, var(--mat-sys-on-surface) 38%, transparent));border-color:rgba(0,0,0,0)}.mdc-checkbox:hover>.mdc-checkbox__native-control:not(:checked)~.mdc-checkbox__background,.mdc-checkbox:hover>.mdc-checkbox__native-control:not(:indeterminate)~.mdc-checkbox__background{border-color:var(--mat-checkbox-unselected-hover-icon-color, var(--mat-sys-on-surface));background-color:rgba(0,0,0,0)}.mdc-checkbox:hover>.mdc-checkbox__native-control:checked~.mdc-checkbox__background,.mdc-checkbox:hover>.mdc-checkbox__native-control:indeterminate~.mdc-checkbox__background{border-color:var(--mat-checkbox-selected-hover-icon-color, var(--mat-sys-primary));background-color:var(--mat-checkbox-selected-hover-icon-color, var(--mat-sys-primary))}.mdc-checkbox__native-control:focus:focus:not(:checked)~.mdc-checkbox__background,.mdc-checkbox__native-control:focus:focus:not(:indeterminate)~.mdc-checkbox__background{border-color:var(--mat-checkbox-unselected-focus-icon-color, var(--mat-sys-on-surface))}.mdc-checkbox__native-control:focus:focus:checked~.mdc-checkbox__background,.mdc-checkbox__native-control:focus:focus:indeterminate~.mdc-checkbox__background{border-color:var(--mat-checkbox-selected-focus-icon-color, var(--mat-sys-primary));background-color:var(--mat-checkbox-selected-focus-icon-color, var(--mat-sys-primary))}.mdc-checkbox--disabled.mat-mdc-checkbox-disabled-interactive .mdc-checkbox:hover>.mdc-checkbox__native-control~.mdc-checkbox__background,.mdc-checkbox--disabled.mat-mdc-checkbox-disabled-interactive .mdc-checkbox .mdc-checkbox__native-control:focus~.mdc-checkbox__background,.mdc-checkbox--disabled.mat-mdc-checkbox-disabled-interactive .mdc-checkbox__background{border-color:var(--mat-checkbox-disabled-unselected-icon-color, color-mix(in srgb, var(--mat-sys-on-surface) 38%, transparent))}.mdc-checkbox--disabled.mat-mdc-checkbox-disabled-interactive .mdc-checkbox__native-control:checked~.mdc-checkbox__background,.mdc-checkbox--disabled.mat-mdc-checkbox-disabled-interactive .mdc-checkbox__native-control:indeterminate~.mdc-checkbox__background{background-color:var(--mat-checkbox-disabled-selected-icon-color, color-mix(in srgb, var(--mat-sys-on-surface) 38%, transparent));border-color:rgba(0,0,0,0)}.mdc-checkbox__checkmark{position:absolute;top:0;right:0;bottom:0;left:0;width:100%;opacity:0;transition:opacity 180ms cubic-bezier(0.4, 0, 0.6, 1);color:var(--mat-checkbox-selected-checkmark-color, var(--mat-sys-on-primary))}@media(forced-colors: active){.mdc-checkbox__checkmark{color:CanvasText}}.mdc-checkbox--disabled .mdc-checkbox__checkmark,.mdc-checkbox--disabled.mat-mdc-checkbox-disabled-interactive .mdc-checkbox__checkmark{color:var(--mat-checkbox-disabled-selected-checkmark-color, var(--mat-sys-surface))}@media(forced-colors: active){.mdc-checkbox--disabled .mdc-checkbox__checkmark,.mdc-checkbox--disabled.mat-mdc-checkbox-disabled-interactive .mdc-checkbox__checkmark{color:CanvasText}}.mdc-checkbox__checkmark-path{transition:stroke-dashoffset 180ms cubic-bezier(0.4, 0, 0.6, 1);stroke:currentColor;stroke-width:3.12px;stroke-dashoffset:29.7833385;stroke-dasharray:29.7833385}.mdc-checkbox__mixedmark{width:100%;height:0;transform:scaleX(0) rotate(0deg);border-width:1px;border-style:solid;opacity:0;transition:opacity 90ms cubic-bezier(0.4, 0, 0.6, 1),transform 90ms cubic-bezier(0.4, 0, 0.6, 1);border-color:var(--mat-checkbox-selected-checkmark-color, var(--mat-sys-on-primary))}@media(forced-colors: active){.mdc-checkbox__mixedmark{margin:0 1px}}.mdc-checkbox--disabled .mdc-checkbox__mixedmark,.mdc-checkbox--disabled.mat-mdc-checkbox-disabled-interactive .mdc-checkbox__mixedmark{border-color:var(--mat-checkbox-disabled-selected-checkmark-color, var(--mat-sys-surface))}.mdc-checkbox--anim-unchecked-checked .mdc-checkbox__background,.mdc-checkbox--anim-unchecked-indeterminate .mdc-checkbox__background,.mdc-checkbox--anim-checked-unchecked .mdc-checkbox__background,.mdc-checkbox--anim-indeterminate-unchecked .mdc-checkbox__background{animation-duration:180ms;animation-timing-function:linear}.mdc-checkbox--anim-unchecked-checked .mdc-checkbox__checkmark-path{animation:mdc-checkbox-unchecked-checked-checkmark-path 180ms linear;transition:none}.mdc-checkbox--anim-unchecked-indeterminate .mdc-checkbox__mixedmark{animation:mdc-checkbox-unchecked-indeterminate-mixedmark 90ms linear;transition:none}.mdc-checkbox--anim-checked-unchecked .mdc-checkbox__checkmark-path{animation:mdc-checkbox-checked-unchecked-checkmark-path 90ms linear;transition:none}.mdc-checkbox--anim-checked-indeterminate .mdc-checkbox__checkmark{animation:mdc-checkbox-checked-indeterminate-checkmark 90ms linear;transition:none}.mdc-checkbox--anim-checked-indeterminate .mdc-checkbox__mixedmark{animation:mdc-checkbox-checked-indeterminate-mixedmark 90ms linear;transition:none}.mdc-checkbox--anim-indeterminate-checked .mdc-checkbox__checkmark{animation:mdc-checkbox-indeterminate-checked-checkmark 500ms linear;transition:none}.mdc-checkbox--anim-indeterminate-checked .mdc-checkbox__mixedmark{animation:mdc-checkbox-indeterminate-checked-mixedmark 500ms linear;transition:none}.mdc-checkbox--anim-indeterminate-unchecked .mdc-checkbox__mixedmark{animation:mdc-checkbox-indeterminate-unchecked-mixedmark 300ms linear;transition:none}.mdc-checkbox__native-control:checked~.mdc-checkbox__background,.mdc-checkbox__native-control:indeterminate~.mdc-checkbox__background{transition:border-color 90ms cubic-bezier(0, 0, 0.2, 1),background-color 90ms cubic-bezier(0, 0, 0.2, 1)}.mdc-checkbox__native-control:checked~.mdc-checkbox__background>.mdc-checkbox__checkmark>.mdc-checkbox__checkmark-path,.mdc-checkbox__native-control:indeterminate~.mdc-checkbox__background>.mdc-checkbox__checkmark>.mdc-checkbox__checkmark-path{stroke-dashoffset:0}.mdc-checkbox__native-control:checked~.mdc-checkbox__background>.mdc-checkbox__checkmark{transition:opacity 180ms cubic-bezier(0, 0, 0.2, 1),transform 180ms cubic-bezier(0, 0, 0.2, 1);opacity:1}.mdc-checkbox__native-control:checked~.mdc-checkbox__background>.mdc-checkbox__mixedmark{transform:scaleX(1) rotate(-45deg)}.mdc-checkbox__native-control:indeterminate~.mdc-checkbox__background>.mdc-checkbox__checkmark{transform:rotate(45deg);opacity:0;transition:opacity 90ms cubic-bezier(0.4, 0, 0.6, 1),transform 90ms cubic-bezier(0.4, 0, 0.6, 1)}.mdc-checkbox__native-control:indeterminate~.mdc-checkbox__background>.mdc-checkbox__mixedmark{transform:scaleX(1) rotate(0deg);opacity:1}@keyframes mdc-checkbox-unchecked-checked-checkmark-path{0%,50%{stroke-dashoffset:29.7833385}50%{animation-timing-function:cubic-bezier(0, 0, 0.2, 1)}100%{stroke-dashoffset:0}}@keyframes mdc-checkbox-unchecked-indeterminate-mixedmark{0%,68.2%{transform:scaleX(0)}68.2%{animation-timing-function:cubic-bezier(0, 0, 0, 1)}100%{transform:scaleX(1)}}@keyframes mdc-checkbox-checked-unchecked-checkmark-path{from{animation-timing-function:cubic-bezier(0.4, 0, 1, 1);opacity:1;stroke-dashoffset:0}to{opacity:0;stroke-dashoffset:-29.7833385}}@keyframes mdc-checkbox-checked-indeterminate-checkmark{from{animation-timing-function:cubic-bezier(0, 0, 0.2, 1);transform:rotate(0deg);opacity:1}to{transform:rotate(45deg);opacity:0}}@keyframes mdc-checkbox-indeterminate-checked-checkmark{from{animation-timing-function:cubic-bezier(0.14, 0, 0, 1);transform:rotate(45deg);opacity:0}to{transform:rotate(360deg);opacity:1}}@keyframes mdc-checkbox-checked-indeterminate-mixedmark{from{animation-timing-function:cubic-bezier(0, 0, 0.2, 1);transform:rotate(-45deg);opacity:0}to{transform:rotate(0deg);opacity:1}}@keyframes mdc-checkbox-indeterminate-checked-mixedmark{from{animation-timing-function:cubic-bezier(0.14, 0, 0, 1);transform:rotate(0deg);opacity:1}to{transform:rotate(315deg);opacity:0}}@keyframes mdc-checkbox-indeterminate-unchecked-mixedmark{0%{animation-timing-function:linear;transform:scaleX(1);opacity:1}32.8%,100%{transform:scaleX(0);opacity:0}}.mat-mdc-checkbox{display:inline-block;position:relative;-webkit-tap-highlight-color:rgba(0,0,0,0)}.mat-mdc-checkbox._mat-animation-noopable>.mat-internal-form-field>.mdc-checkbox>.mat-mdc-checkbox-touch-target,.mat-mdc-checkbox._mat-animation-noopable>.mat-internal-form-field>.mdc-checkbox>.mdc-checkbox__native-control,.mat-mdc-checkbox._mat-animation-noopable>.mat-internal-form-field>.mdc-checkbox>.mdc-checkbox__ripple,.mat-mdc-checkbox._mat-animation-noopable>.mat-internal-form-field>.mdc-checkbox>.mat-mdc-checkbox-ripple::before,.mat-mdc-checkbox._mat-animation-noopable>.mat-internal-form-field>.mdc-checkbox>.mdc-checkbox__background,.mat-mdc-checkbox._mat-animation-noopable>.mat-internal-form-field>.mdc-checkbox>.mdc-checkbox__background>.mdc-checkbox__checkmark,.mat-mdc-checkbox._mat-animation-noopable>.mat-internal-form-field>.mdc-checkbox>.mdc-checkbox__background>.mdc-checkbox__checkmark>.mdc-checkbox__checkmark-path,.mat-mdc-checkbox._mat-animation-noopable>.mat-internal-form-field>.mdc-checkbox>.mdc-checkbox__background>.mdc-checkbox__mixedmark{transition:none !important;animation:none !important}.mat-mdc-checkbox label{cursor:pointer}.mat-mdc-checkbox .mat-internal-form-field{color:var(--mat-checkbox-label-text-color, var(--mat-sys-on-surface));font-family:var(--mat-checkbox-label-text-font, var(--mat-sys-body-medium-font));line-height:var(--mat-checkbox-label-text-line-height, var(--mat-sys-body-medium-line-height));font-size:var(--mat-checkbox-label-text-size, var(--mat-sys-body-medium-size));letter-spacing:var(--mat-checkbox-label-text-tracking, var(--mat-sys-body-medium-tracking));font-weight:var(--mat-checkbox-label-text-weight, var(--mat-sys-body-medium-weight))}.mat-mdc-checkbox.mat-mdc-checkbox-disabled.mat-mdc-checkbox-disabled-interactive{pointer-events:auto}.mat-mdc-checkbox.mat-mdc-checkbox-disabled.mat-mdc-checkbox-disabled-interactive input{cursor:default}.mat-mdc-checkbox.mat-mdc-checkbox-disabled label{cursor:default;color:var(--mat-checkbox-disabled-label-color, color-mix(in srgb, var(--mat-sys-on-surface) 38%, transparent))}.mat-mdc-checkbox label:empty{display:none}.mat-mdc-checkbox .mdc-checkbox__ripple{opacity:0}.mat-mdc-checkbox .mat-mdc-checkbox-ripple,.mdc-checkbox__ripple{top:0;left:0;right:0;bottom:0;position:absolute;border-radius:50%;pointer-events:none}.mat-mdc-checkbox .mat-mdc-checkbox-ripple:not(:empty),.mdc-checkbox__ripple:not(:empty){transform:translateZ(0)}.mat-mdc-checkbox-ripple .mat-ripple-element{opacity:.1}.mat-mdc-checkbox-touch-target{position:absolute;top:50%;left:50%;height:var(--mat-checkbox-touch-target-size, 48px);width:var(--mat-checkbox-touch-target-size, 48px);transform:translate(-50%, -50%);display:var(--mat-checkbox-touch-target-display, block)}.mat-mdc-checkbox .mat-mdc-checkbox-ripple::before{border-radius:50%}.mdc-checkbox__native-control:focus~.mat-focus-indicator::before{content:""}
`],encapsulation:2,changeDetection:0})}return i})(),fs=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[bo,z,z]})}return i})();var Xy=()=>[],bh=(i,n)=>n.id;function Jy(i,n){i&1&&(u(0,"div",1),ie(1,"mat-spinner"),u(2,"p"),m(3,"Loading policy data..."),h()())}function $y(i,n){if(i&1){let e=Ie();u(0,"div",2)(1,"p"),m(2),h(),u(3,"button",4),he("click",function(){re(e);let o=k();return le(o.loadData())}),m(4,"Retry"),h()()}if(i&2){let e=k();f(2),St(e.error())}}function Qy(i,n){if(i&1){let e=Ie();u(0,"mat-checkbox",18),he("change",function(){let o=re(e).$implicit,a=k(2);return le(a.toggleColumn(o.id))}),m(1),h()}if(i&2){let e=n.$implicit,t=k(2);M("checked",!t.hiddenColumnIds().has(e.id)),f(),mt(" ",e.name," ")}}function eg(i,n){if(i&1){let e=Ie();u(0,"th",21)(1,"div",22)(2,"span"),m(3),h(),u(4,"button",23),he("click",function(){re(e);let o=k().$implicit,a=k(2);return le(a.toggleColumn(o.id))}),u(5,"mat-icon"),m(6,"close"),h()()()()}if(i&2){let e=k().$implicit;f(3),St(e.name)}}function tg(i,n){if(i&1&&m(0),i&2){let e=k().$implicit,t=k().$implicit,o=k(2);mt(" ",o.formatCellValue(o.getCellValue(e,t.name),t)," ")}}function ig(i,n){if(i&1&&(u(0,"a",25),m(1," View Link "),h()),i&2){let e=k().$implicit,t=k().$implicit,o=k(2);M("href",o.getCellValue(e,t.name),Co)}}function ng(i,n){i&1&&(u(0,"span"),m(1,"-"),h())}function og(i,n){if(i&1&&(u(0,"td",24),J(1,tg,1,1),J(2,ig,2,1,"a",25),J(3,ng,2,0,"span"),h()),i&2){let e=n.$implicit,t=k().$implicit,o=k(2);f(),$(o.isLink(t)?-1:1),f(),$(o.isLink(t)&&o.getCellValue(e,t.name)?2:-1),f(),$(o.isLink(t)&&!o.getCellValue(e,t.name)?3:-1)}}function ag(i,n){if(i&1&&(qi(0,14),st(1,eg,7,1,"th",19)(2,og,4,3,"td",20),Fi()),i&2){let e=n.$implicit;M("matColumnDef",e.name)}}function sg(i,n){i&1&&ie(0,"tr",26)}function rg(i,n){i&1&&ie(0,"tr",27)}function lg(i,n){if(i&1){let e=Ie();u(0,"div",3)(1,"div",5)(2,"div",6)(3,"h3"),m(4),h(),u(5,"div",7)(6,"button",8),he("click",function(){re(e);let o=k();return le(o.toggleAllColumns(!0))}),m(7,"Show All"),h(),u(8,"button",8),he("click",function(){re(e);let o=k();return le(o.toggleAllColumns(!1))}),m(9,"Hide All"),h()()(),u(10,"details",9)(11,"summary"),m(12,"Customize Columns"),h(),u(13,"div",10),Bt(14,Qy,2,2,"mat-checkbox",11,bh),h()()(),u(16,"div",12)(17,"table",13),Bt(18,ag,3,1,"ng-container",14,bh),st(20,sg,1,0,"tr",15)(21,rg,1,0,"tr",16),h()(),u(22,"div",17)(23,"p"),m(24),h()()()}if(i&2){let e,t=k();f(4),Mi("Columns (",t.visibleColumns().length,"/",t.data().columns.length,")"),f(10),jt(t.data().columns),f(3),M("dataSource",((e=t.data())==null?null:e.rows)||Ni(8,Xy)),f(),jt(t.visibleColumns()),f(2),M("matHeaderRowDef",t.displayedColumns())("matHeaderRowDefSticky",!0),f(),M("matRowDefColumns",t.displayedColumns()),f(3),Mi("Showing ",t.data().rows.length," rows with ",t.visibleColumns().length," columns")}}var ys=class i{policyDataService=l(yn);data=te(null);hiddenColumnIds=te(new Set);loading=te(!0);error=te(null);visibleColumns=ri(()=>{let n=this.data(),e=this.hiddenColumnIds();return n?n.columns.filter(t=>!e.has(t.id)):[]});ngOnInit(){this.loadData()}loadData(){this.loading.set(!0),this.error.set(null),this.policyDataService.getData().subscribe({next:n=>{this.data.set(n),this.loading.set(!1)},error:n=>{this.error.set("Failed to load data"),this.loading.set(!1),console.error("Error loading data:",n)}})}toggleColumn(n){let e=new Set(this.hiddenColumnIds());e.has(n)?e.delete(n):e.add(n),this.hiddenColumnIds.set(e)}toggleAllColumns(n){if(n)this.hiddenColumnIds.set(new Set);else{let e=new Set(this.data()?.columns.map(t=>t.id)||[]);this.hiddenColumnIds.set(e)}}getCellValue(n,e){return n.values[e]}formatCellValue(n,e){return n==null?"-":e.format.isArray&&Array.isArray(n)?n.join(", "):e.format.type==="checkbox"?n?"\u2713":"\u2717":e.format.type==="number"&&typeof n=="number"?n.toLocaleString():String(n)}displayedColumns=ri(()=>this.visibleColumns().map(n=>n.name));isLink(n){return n.format.type==="link"}isCheckbox(n){return n.format.type==="checkbox"}trackByColumnId(n,e){return e.id}trackByRowId(n,e){return e.id}static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-policy-analysis"]],decls:6,vars:3,consts:[[1,"policy-analysis-container"],[1,"loading-state"],[1,"error-state"],[1,"table-section"],["mat-raised-button","",3,"click"],[1,"table-controls"],[1,"control-group"],[1,"button-group"],["mat-button","",3,"click"],[1,"column-selector"],[1,"column-grid"],[3,"checked"],[1,"table-wrapper"],["mat-table","",1,"mat-elevation-z2",3,"dataSource"],[3,"matColumnDef"],["mat-header-row","",4,"matHeaderRowDef","matHeaderRowDefSticky"],["mat-row","",4,"matRowDef","matRowDefColumns"],[1,"table-summary"],[3,"change","checked"],["mat-header-cell","",4,"matHeaderCellDef"],["mat-cell","",4,"matCellDef"],["mat-header-cell",""],[1,"header-content"],["mat-icon-button","","title","Hide this column",3,"click"],["mat-cell",""],["target","_blank","rel","noopener noreferrer","mat-button","","color","primary",3,"href"],["mat-header-row",""],["mat-row",""]],template:function(e,t){e&1&&(u(0,"div",0)(1,"h2"),m(2,"Table B.Policy Analysis Data"),h(),J(3,Jy,4,0,"div",1),J(4,$y,5,1,"div",2),J(5,lg,25,9,"div",3),h()),e&2&&(f(3),$(t.loading()?3:-1),f(),$(t.error()&&!t.loading()?4:-1),f(),$(t.data()&&!t.loading()?5:-1))},dependencies:[je,ms,ps,fn,Ma,yo,fs,bo,wt,rn,vn,Wa,Ha,Ja,Ya,Ua,$a,Za,Xa,Qa,es],styles:[".policy-analysis-container[_ngcontent-%COMP%]{padding:1.5rem;max-width:100%;height:100%;display:flex;flex-direction:column}h2[_ngcontent-%COMP%]{margin:0 0 1.5rem;color:#333;font-size:1.75rem}.loading-state[_ngcontent-%COMP%], .error-state[_ngcontent-%COMP%]{display:flex;flex-direction:column;align-items:center;justify-content:center;padding:3rem;text-align:center}.spinner[_ngcontent-%COMP%]{width:48px;height:48px;border:4px solid #f3f3f3;border-top:4px solid #7d8489;border-radius:50%;animation:_ngcontent-%COMP%_spin 1s linear infinite;margin-bottom:1rem}@keyframes _ngcontent-%COMP%_spin{0%{transform:rotate(0)}to{transform:rotate(360deg)}}.error-state[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{color:#e74c3c;margin-bottom:1rem}.table-section[_ngcontent-%COMP%]{flex:1;display:flex;flex-direction:column;gap:1rem}.table-controls[_ngcontent-%COMP%]{background:#f8f9fa;padding:1rem;border-radius:8px;border:1px solid #dee2e6}.control-group[_ngcontent-%COMP%]{display:flex;justify-content:space-between;align-items:center;margin-bottom:.5rem}.control-group[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%]{margin:0;font-size:1rem;color:#495057}.button-group[_ngcontent-%COMP%]{display:flex;gap:.5rem}.btn[_ngcontent-%COMP%]{padding:.375rem .75rem;border:1px solid #dee2e6;background:#fff;border-radius:4px;cursor:pointer;font-size:.875rem;transition:all .2s}.btn[_ngcontent-%COMP%]:hover{background:#e9ecef;border-color:#adb5bd}.btn-sm[_ngcontent-%COMP%]{padding:.25rem .5rem;font-size:.813rem}.column-selector[_ngcontent-%COMP%]{margin-top:.5rem}.column-selector[_ngcontent-%COMP%]   summary[_ngcontent-%COMP%]{cursor:pointer;padding:.5rem;background:#fff;border-radius:4px;-webkit-user-select:none;user-select:none;font-weight:500}.column-selector[_ngcontent-%COMP%]   summary[_ngcontent-%COMP%]:hover{background:#e9ecef}.column-grid[_ngcontent-%COMP%]{display:grid;grid-template-columns:repeat(auto-fill,minmax(250px,1fr));gap:.5rem;padding:1rem;max-height:300px;overflow-y:auto}.column-option[_ngcontent-%COMP%]{display:flex;align-items:center;gap:.5rem;padding:.25rem;cursor:pointer;border-radius:4px}.column-option[_ngcontent-%COMP%]:hover{background:#f8f9fa}.column-option[_ngcontent-%COMP%]   input[_ngcontent-%COMP%]{cursor:pointer}.table-wrapper[_ngcontent-%COMP%]{flex:1;overflow:auto;border:1px solid #dee2e6;border-radius:8px;background:#fff}.mat-mdc-table[_ngcontent-%COMP%]{font-size:.813rem!important;line-height:1.2!important}.mat-mdc-header-cell[_ngcontent-%COMP%]{padding:.25rem .5rem!important;height:auto!important;min-height:32px!important;font-size:.813rem!important;font-weight:600!important;border-bottom:1px solid #dee2e6!important;border-right:1px solid #dee2e6!important;white-space:nowrap!important;background:#f8f9fa!important}.mat-mdc-cell[_ngcontent-%COMP%]{padding:.25rem .5rem!important;height:auto!important;min-height:32px!important;font-size:.813rem!important;border-bottom:1px solid #e9ecef!important;border-right:1px solid #e9ecef!important;max-width:200px!important;overflow:hidden!important;text-overflow:ellipsis!important;white-space:nowrap!important}.mat-mdc-row[_ngcontent-%COMP%], .mat-mdc-header-row[_ngcontent-%COMP%]{height:auto!important;min-height:32px!important}.header-content[_ngcontent-%COMP%]{display:flex;align-items:center;justify-content:space-between;gap:.25rem}.header-content[_ngcontent-%COMP%]   button[_ngcontent-%COMP%]{width:20px!important;height:20px!important;line-height:1!important}.header-content[_ngcontent-%COMP%]   .mat-icon[_ngcontent-%COMP%]{font-size:16px!important;width:16px!important;height:16px!important}.mat-mdc-row[_ngcontent-%COMP%]:hover{background:#f8f9fa!important}.mat-mdc-cell[_ngcontent-%COMP%]   a[_ngcontent-%COMP%]{font-size:.75rem!important;padding:.125rem .25rem!important;min-width:auto!important;height:auto!important;line-height:1.2!important}.mat-mdc-table[_ngcontent-%COMP%]   .mat-mdc-header-row[_ngcontent-%COMP%], .mat-mdc-table[_ngcontent-%COMP%]   .mat-mdc-row[_ngcontent-%COMP%]{border-bottom:none!important}.table-summary[_ngcontent-%COMP%]{padding:.5rem;background:#f8f9fa;border-radius:4px;text-align:center;font-size:.813rem;color:#6c757d;margin-top:.5rem}@media (max-width: 768px){.mat-mdc-header-cell[_ngcontent-%COMP%], .mat-mdc-cell[_ngcontent-%COMP%]{padding:.125rem .25rem!important;font-size:.75rem!important;min-height:28px!important}.mat-mdc-row[_ngcontent-%COMP%], .mat-mdc-header-row[_ngcontent-%COMP%]{min-height:28px!important}.header-content[_ngcontent-%COMP%]   button[_ngcontent-%COMP%]{width:18px!important;height:18px!important}.header-content[_ngcontent-%COMP%]   .mat-icon[_ngcontent-%COMP%]{font-size:14px!important;width:14px!important;height:14px!important}}.table-section[_ngcontent-%COMP%]{flex:1;display:flex;flex-direction:column;gap:.5rem}.table-controls[_ngcontent-%COMP%]{background:#f8f9fa;padding:.5rem;border-radius:4px;border:1px solid #dee2e6}.control-group[_ngcontent-%COMP%]{display:flex;justify-content:space-between;align-items:center;margin-bottom:.25rem}.control-group[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%]{margin:0;font-size:.875rem;color:#495057}.button-group[_ngcontent-%COMP%]{display:flex;gap:.25rem}.column-selector[_ngcontent-%COMP%]   summary[_ngcontent-%COMP%]{cursor:pointer;padding:.25rem;background:#fff;border-radius:4px;-webkit-user-select:none;user-select:none;font-weight:500;font-size:.875rem}.column-grid[_ngcontent-%COMP%]{display:grid;grid-template-columns:repeat(auto-fill,minmax(200px,1fr));gap:.25rem;padding:.5rem;max-height:200px;overflow-y:auto}.header-content[_ngcontent-%COMP%]   button[_ngcontent-%COMP%]{width:16px!important;height:16px!important;line-height:1!important;background:#825151!important;color:#000!important;border-radius:2px!important;min-width:16px!important}.header-content[_ngcontent-%COMP%]   button[_ngcontent-%COMP%]:hover{background:#9f9a9a!important}.header-content[_ngcontent-%COMP%]   .mat-icon[_ngcontent-%COMP%]{font-size:10px!important;width:10px!important;height:10px!important;font-weight:700!important}.policy-analysis-container[_ngcontent-%COMP%]{padding:1rem;max-width:100%;height:100vh;display:flex;flex-direction:column;overflow:hidden}.table-section[_ngcontent-%COMP%]{flex:1;display:flex;flex-direction:column;gap:.5rem;min-height:0}.table-wrapper[_ngcontent-%COMP%]{flex:1;overflow:auto;border:1px solid #dee2e6;border-radius:4px;background:#fff;min-width:800px}.column-grid[_ngcontent-%COMP%]{display:grid;grid-template-columns:repeat(auto-fill,minmax(200px,1fr));gap:.25rem;padding:.5rem;max-height:150px;overflow-y:auto}"]})};var cg=()=>[],vh=(i,n)=>n.id;function dg(i,n){i&1&&(u(0,"div",1),ie(1,"mat-spinner"),u(2,"p"),m(3,"Loading policy data..."),h()())}function ug(i,n){if(i&1){let e=Ie();u(0,"div",2)(1,"p"),m(2),h(),u(3,"button",4),he("click",function(){re(e);let o=k();return le(o.loadData())}),m(4,"Retry"),h()()}if(i&2){let e=k();f(2),St(e.error())}}function hg(i,n){if(i&1){let e=Ie();u(0,"mat-checkbox",18),he("change",function(){let o=re(e).$implicit,a=k(2);return le(a.toggleColumn(o.id))}),m(1),h()}if(i&2){let e=n.$implicit,t=k(2);M("checked",!t.hiddenColumnIds().has(e.id)),f(),mt(" ",e.name," ")}}function pg(i,n){if(i&1){let e=Ie();u(0,"th",21)(1,"div",22)(2,"span"),m(3),h(),u(4,"button",23),he("click",function(){re(e);let o=k().$implicit,a=k(2);return le(a.toggleColumn(o.id))}),u(5,"mat-icon"),m(6,"close"),h()()()()}if(i&2){let e=k().$implicit;f(3),St(e.name)}}function mg(i,n){if(i&1&&m(0),i&2){let e=k().$implicit,t=k().$implicit,o=k(2);mt(" ",o.formatCellValue(o.getCellValue(e,t.name),t)," ")}}function fg(i,n){if(i&1&&(u(0,"a",25),m(1," View Link "),h()),i&2){let e=k().$implicit,t=k().$implicit,o=k(2);M("href",o.getCellValue(e,t.name),Co)}}function yg(i,n){i&1&&(u(0,"span"),m(1,"-"),h())}function gg(i,n){if(i&1&&(u(0,"td",24),J(1,mg,1,1),J(2,fg,2,1,"a",25),J(3,yg,2,0,"span"),h()),i&2){let e=n.$implicit,t=k().$implicit,o=k(2);f(),$(o.isLink(t)?-1:1),f(),$(o.isLink(t)&&o.getCellValue(e,t.name)?2:-1),f(),$(o.isLink(t)&&!o.getCellValue(e,t.name)?3:-1)}}function bg(i,n){if(i&1&&(qi(0,14),st(1,pg,7,1,"th",19)(2,gg,4,3,"td",20),Fi()),i&2){let e=n.$implicit;M("matColumnDef",e.name)}}function vg(i,n){i&1&&ie(0,"tr",26)}function Ag(i,n){i&1&&ie(0,"tr",27)}function Ig(i,n){if(i&1){let e=Ie();u(0,"div",3)(1,"div",5)(2,"div",6)(3,"h3"),m(4),h(),u(5,"div",7)(6,"button",8),he("click",function(){re(e);let o=k();return le(o.toggleAllColumns(!0))}),m(7,"Show All"),h(),u(8,"button",8),he("click",function(){re(e);let o=k();return le(o.toggleAllColumns(!1))}),m(9,"Hide All"),h()()(),u(10,"details",9)(11,"summary"),m(12,"Customize Columns"),h(),u(13,"div",10),Bt(14,hg,2,2,"mat-checkbox",11,vh),h()()(),u(16,"div",12)(17,"table",13),Bt(18,bg,3,1,"ng-container",14,vh),st(20,vg,1,0,"tr",15)(21,Ag,1,0,"tr",16),h()(),u(22,"div",17)(23,"p"),m(24),h()()()}if(i&2){let e,t=k();f(4),Mi("Columns (",t.visibleColumns().length,"/",t.data().columns.length,")"),f(10),jt(t.data().columns),f(3),M("dataSource",((e=t.data())==null?null:e.rows)||Ni(8,cg)),f(),jt(t.visibleColumns()),f(2),M("matHeaderRowDef",t.displayedColumns())("matHeaderRowDefSticky",!0),f(),M("matRowDefColumns",t.displayedColumns()),f(3),Mi("Showing ",t.data().rows.length," rows with ",t.visibleColumns().length," columns")}}var gs=class i{policyDataService=l(yn);data=te(null);hiddenColumnIds=te(new Set);loading=te(!0);error=te(null);visibleColumns=ri(()=>{let n=this.data(),e=this.hiddenColumnIds();return n?n.columns.filter(t=>!e.has(t.id)):[]});ngOnInit(){this.loadData()}loadData(){this.loading.set(!0),this.error.set(null),this.policyDataService.getData("tableA").subscribe({next:n=>{console.log("Table A Data loaded:",n),this.data.set(n),this.loading.set(!1)},error:n=>{this.error.set("Failed to load data"),this.loading.set(!1),console.error("Error loading data:",n)}})}toggleColumn(n){let e=new Set(this.hiddenColumnIds());e.has(n)?e.delete(n):e.add(n),this.hiddenColumnIds.set(e)}toggleAllColumns(n){if(n)this.hiddenColumnIds.set(new Set);else{let e=new Set(this.data()?.columns.map(t=>t.id)||[]);this.hiddenColumnIds.set(e)}}getCellValue(n,e){return n.values[e]}formatCellValue(n,e){return n==null?"-":e.format?.isArray&&Array.isArray(n)?n.join(", "):e.format?.type==="number"&&typeof n=="number"?n.toLocaleString():String(n)}displayedColumns=ri(()=>this.visibleColumns().map(n=>n.name));isCheckbox(n){return n.format.type==="checkbox"}isLink(n){return n.format.type==="link"||n.format.type==="url"}trackByColumnId(n,e){return e.id}trackByRowId(n,e){return e.id}static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-table-a"]],decls:6,vars:3,consts:[[1,"policy-analysis-container"],[1,"loading-state"],[1,"error-state"],[1,"table-section"],["mat-raised-button","",3,"click"],[1,"table-controls"],[1,"control-group"],[1,"button-group"],["mat-button","",3,"click"],[1,"column-selector"],[1,"column-grid"],[3,"checked"],[1,"table-wrapper"],["mat-table","",1,"mat-elevation-z2",3,"dataSource"],[3,"matColumnDef"],["mat-header-row","",4,"matHeaderRowDef","matHeaderRowDefSticky"],["mat-row","",4,"matRowDef","matRowDefColumns"],[1,"table-summary"],[3,"change","checked"],["mat-header-cell","",4,"matHeaderCellDef"],["mat-cell","",4,"matCellDef"],["mat-header-cell",""],[1,"header-content"],["mat-icon-button","","title","Hide this column",3,"click"],["mat-cell",""],["target","_blank","rel","noopener noreferrer","mat-button","","color","primary",3,"href"],["mat-header-row",""],["mat-row",""]],template:function(e,t){e&1&&(u(0,"div",0)(1,"h2"),m(2,"Table A: All Potentially Relevant AI Policies Reviewed"),h(),J(3,dg,4,0,"div",1),J(4,ug,5,1,"div",2),J(5,Ig,25,9,"div",3),h()),e&2&&(f(3),$(t.loading()?3:-1),f(),$(t.error()&&!t.loading()?4:-1),f(),$(t.data()&&!t.loading()?5:-1))},dependencies:[je,vn,Wa,Ha,Ja,Ya,Ua,$a,Za,Xa,Qa,es,ms,ps,fn,Ma,yo,fs,bo,wt,rn],styles:[".policy-analysis-container[_ngcontent-%COMP%]{padding:1.5rem;max-width:100%;height:100%;display:flex;flex-direction:column}h2[_ngcontent-%COMP%]{margin:0 0 1.5rem;color:#333;font-size:1.75rem}.loading-state[_ngcontent-%COMP%], .error-state[_ngcontent-%COMP%]{display:flex;flex-direction:column;align-items:center;justify-content:center;padding:3rem;text-align:center}.spinner[_ngcontent-%COMP%]{width:48px;height:48px;border:4px solid #f3f3f3;border-top:4px solid #7d8489;border-radius:50%;animation:_ngcontent-%COMP%_spin 1s linear infinite;margin-bottom:1rem}@keyframes _ngcontent-%COMP%_spin{0%{transform:rotate(0)}to{transform:rotate(360deg)}}.error-state[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{color:#e74c3c;margin-bottom:1rem}.table-section[_ngcontent-%COMP%]{flex:1;display:flex;flex-direction:column;gap:1rem}.table-controls[_ngcontent-%COMP%]{background:#f8f9fa;padding:1rem;border-radius:8px;border:1px solid #dee2e6}.control-group[_ngcontent-%COMP%]{display:flex;justify-content:space-between;align-items:center;margin-bottom:.5rem}.control-group[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%]{margin:0;font-size:1rem;color:#495057}.button-group[_ngcontent-%COMP%]{display:flex;gap:.5rem}.btn[_ngcontent-%COMP%]{padding:.375rem .75rem;border:1px solid #dee2e6;background:#fff;border-radius:4px;cursor:pointer;font-size:.875rem;transition:all .2s}.btn[_ngcontent-%COMP%]:hover{background:#e9ecef;border-color:#adb5bd}.btn-sm[_ngcontent-%COMP%]{padding:.25rem .5rem;font-size:.813rem}.column-selector[_ngcontent-%COMP%]{margin-top:.5rem}.column-selector[_ngcontent-%COMP%]   summary[_ngcontent-%COMP%]{cursor:pointer;padding:.5rem;background:#fff;border-radius:4px;-webkit-user-select:none;user-select:none;font-weight:500}.column-selector[_ngcontent-%COMP%]   summary[_ngcontent-%COMP%]:hover{background:#e9ecef}.column-grid[_ngcontent-%COMP%]{display:grid;grid-template-columns:repeat(auto-fill,minmax(250px,1fr));gap:.5rem;padding:1rem;max-height:300px;overflow-y:auto}.column-option[_ngcontent-%COMP%]{display:flex;align-items:center;gap:.5rem;padding:.25rem;cursor:pointer;border-radius:4px}.column-option[_ngcontent-%COMP%]:hover{background:#f8f9fa}.column-option[_ngcontent-%COMP%]   input[_ngcontent-%COMP%]{cursor:pointer}.table-wrapper[_ngcontent-%COMP%]{flex:1;overflow:auto;border:1px solid #dee2e6;border-radius:8px;background:#fff}.mat-mdc-table[_ngcontent-%COMP%]{font-size:.813rem!important;line-height:1.2!important}.mat-mdc-header-cell[_ngcontent-%COMP%]{padding:.25rem .5rem!important;height:auto!important;min-height:32px!important;font-size:.813rem!important;font-weight:600!important;border-bottom:1px solid #dee2e6!important;border-right:1px solid #dee2e6!important;white-space:nowrap!important;background:#f8f9fa!important}.mat-mdc-cell[_ngcontent-%COMP%]{padding:.25rem .5rem!important;height:auto!important;min-height:32px!important;font-size:.813rem!important;border-bottom:1px solid #e9ecef!important;border-right:1px solid #e9ecef!important;max-width:200px!important;overflow:hidden!important;text-overflow:ellipsis!important;white-space:nowrap!important}.mat-mdc-row[_ngcontent-%COMP%], .mat-mdc-header-row[_ngcontent-%COMP%]{height:auto!important;min-height:32px!important}.header-content[_ngcontent-%COMP%]{display:flex;align-items:center;justify-content:space-between;gap:.25rem}.header-content[_ngcontent-%COMP%]   button[_ngcontent-%COMP%]{width:20px!important;height:20px!important;line-height:1!important}.header-content[_ngcontent-%COMP%]   .mat-icon[_ngcontent-%COMP%]{font-size:16px!important;width:16px!important;height:16px!important}.mat-mdc-row[_ngcontent-%COMP%]:hover{background:#f8f9fa!important}.mat-mdc-cell[_ngcontent-%COMP%]   a[_ngcontent-%COMP%]{font-size:.75rem!important;padding:.125rem .25rem!important;min-width:auto!important;height:auto!important;line-height:1.2!important}.mat-mdc-table[_ngcontent-%COMP%]   .mat-mdc-header-row[_ngcontent-%COMP%], .mat-mdc-table[_ngcontent-%COMP%]   .mat-mdc-row[_ngcontent-%COMP%]{border-bottom:none!important}.table-summary[_ngcontent-%COMP%]{padding:.5rem;background:#f8f9fa;border-radius:4px;text-align:center;font-size:.813rem;color:#6c757d;margin-top:.5rem}@media (max-width: 768px){.mat-mdc-header-cell[_ngcontent-%COMP%], .mat-mdc-cell[_ngcontent-%COMP%]{padding:.125rem .25rem!important;font-size:.75rem!important;min-height:28px!important}.mat-mdc-row[_ngcontent-%COMP%], .mat-mdc-header-row[_ngcontent-%COMP%]{min-height:28px!important}.header-content[_ngcontent-%COMP%]   button[_ngcontent-%COMP%]{width:18px!important;height:18px!important}.header-content[_ngcontent-%COMP%]   .mat-icon[_ngcontent-%COMP%]{font-size:14px!important;width:14px!important;height:14px!important}}.table-section[_ngcontent-%COMP%]{flex:1;display:flex;flex-direction:column;gap:.5rem}.table-controls[_ngcontent-%COMP%]{background:#f8f9fa;padding:.5rem;border-radius:4px;border:1px solid #dee2e6}.control-group[_ngcontent-%COMP%]{display:flex;justify-content:space-between;align-items:center;margin-bottom:.25rem}.control-group[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%]{margin:0;font-size:.875rem;color:#495057}.button-group[_ngcontent-%COMP%]{display:flex;gap:.25rem}.column-selector[_ngcontent-%COMP%]   summary[_ngcontent-%COMP%]{cursor:pointer;padding:.25rem;background:#fff;border-radius:4px;-webkit-user-select:none;user-select:none;font-weight:500;font-size:.875rem}.column-grid[_ngcontent-%COMP%]{display:grid;grid-template-columns:repeat(auto-fill,minmax(200px,1fr));gap:.25rem;padding:.5rem;max-height:200px;overflow-y:auto}.header-content[_ngcontent-%COMP%]   button[_ngcontent-%COMP%]{width:16px!important;height:16px!important;line-height:1!important;background:#825151!important;color:#000!important;border-radius:2px!important;min-width:16px!important}.header-content[_ngcontent-%COMP%]   button[_ngcontent-%COMP%]:hover{background:#9f9a9a!important}.header-content[_ngcontent-%COMP%]   .mat-icon[_ngcontent-%COMP%]{font-size:10px!important;width:10px!important;height:10px!important;font-weight:700!important}.policy-analysis-container[_ngcontent-%COMP%]{padding:1rem;max-width:100%;height:100vh;display:flex;flex-direction:column;overflow:hidden}.table-section[_ngcontent-%COMP%]{flex:1;display:flex;flex-direction:column;gap:.5rem;min-height:0}.table-wrapper[_ngcontent-%COMP%]{flex:1;overflow:auto;border:1px solid #dee2e6;border-radius:4px;background:#fff;min-width:800px}.column-grid[_ngcontent-%COMP%]{display:grid;grid-template-columns:repeat(auto-fill,minmax(200px,1fr));gap:.25rem;padding:.5rem;max-height:150px;overflow-y:auto}"]})};var Ah=[{path:"",component:ya},{path:"tips",component:ga},{path:"dashboards",component:La,children:[{path:"all-policies",component:os},{path:"relevant-policies",component:as},{path:"creation-year",component:ss},{path:"governance-practices",component:rs},{path:"opportunity-risk",component:ls},{path:"principles",component:cs},{path:"essential-reading",component:ds}]},{path:"data",component:ts,children:[{path:"relevance-assessment",component:us},{path:"lookup-tables",component:hs},{path:"all-potentially-relevant-ai-policies-reviewed",component:gs},{path:"policy-analysis",component:ys},{path:"",redirectTo:"relevance-assessment",pathMatch:"full"}]},{path:"ai-principles",component:ns}];var Ih={providers:[lc(),Mr(Ah),Md()]};var As=["*"],_g=["content"],wg=[[["mat-drawer"]],[["mat-drawer-content"]],"*"],Cg=["mat-drawer","mat-drawer-content","*"];function kg(i,n){if(i&1){let e=Ie();u(0,"div",1),he("click",function(){re(e);let o=k();return le(o._onBackdropClicked())}),h()}if(i&2){let e=k();N("mat-drawer-shown",e._isShowingBackdrop())}}function Dg(i,n){i&1&&(u(0,"mat-drawer-content"),T(1,2),h())}var Eg=[[["mat-sidenav"]],[["mat-sidenav-content"]],"*"],xg=["mat-sidenav","mat-sidenav-content","*"];function Tg(i,n){if(i&1){let e=Ie();u(0,"div",1),he("click",function(){re(e);let o=k();return le(o._onBackdropClicked())}),h()}if(i&2){let e=k();N("mat-drawer-shown",e._isShowingBackdrop())}}function Rg(i,n){i&1&&(u(0,"mat-sidenav-content"),T(1,2),h())}var Sg=`.mat-drawer-container{position:relative;z-index:1;color:var(--mat-sidenav-content-text-color, var(--mat-sys-on-background));background-color:var(--mat-sidenav-content-background-color, var(--mat-sys-background));box-sizing:border-box;display:block;overflow:hidden}.mat-drawer-container[fullscreen]{top:0;left:0;right:0;bottom:0;position:absolute}.mat-drawer-container[fullscreen].mat-drawer-container-has-open{overflow:hidden}.mat-drawer-container.mat-drawer-container-explicit-backdrop .mat-drawer-side{z-index:3}.mat-drawer-container.ng-animate-disabled .mat-drawer-backdrop,.mat-drawer-container.ng-animate-disabled .mat-drawer-content,.ng-animate-disabled .mat-drawer-container .mat-drawer-backdrop,.ng-animate-disabled .mat-drawer-container .mat-drawer-content{transition:none}.mat-drawer-backdrop{top:0;left:0;right:0;bottom:0;position:absolute;display:block;z-index:3;visibility:hidden}.mat-drawer-backdrop.mat-drawer-shown{visibility:visible;background-color:var(--mat-sidenav-scrim-color, color-mix(in srgb, var(--mat-sys-neutral-variant20) 40%, transparent))}.mat-drawer-transition .mat-drawer-backdrop{transition-duration:400ms;transition-timing-function:cubic-bezier(0.25, 0.8, 0.25, 1);transition-property:background-color,visibility}@media(forced-colors: active){.mat-drawer-backdrop{opacity:.5}}.mat-drawer-content{position:relative;z-index:1;display:block;height:100%;overflow:auto}.mat-drawer-content.mat-drawer-content-hidden{opacity:0}.mat-drawer-transition .mat-drawer-content{transition-duration:400ms;transition-timing-function:cubic-bezier(0.25, 0.8, 0.25, 1);transition-property:transform,margin-left,margin-right}.mat-drawer{position:relative;z-index:4;color:var(--mat-sidenav-container-text-color, var(--mat-sys-on-surface-variant));box-shadow:var(--mat-sidenav-container-elevation-shadow, none);background-color:var(--mat-sidenav-container-background-color, var(--mat-sys-surface));border-top-right-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-bottom-right-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));width:var(--mat-sidenav-container-width, 360px);display:block;position:absolute;top:0;bottom:0;z-index:3;outline:0;box-sizing:border-box;overflow-y:auto;transform:translate3d(-100%, 0, 0)}@media(forced-colors: active){.mat-drawer,[dir=rtl] .mat-drawer.mat-drawer-end{border-right:solid 1px currentColor}}@media(forced-colors: active){[dir=rtl] .mat-drawer,.mat-drawer.mat-drawer-end{border-left:solid 1px currentColor;border-right:none}}.mat-drawer.mat-drawer-side{z-index:2}.mat-drawer.mat-drawer-end{right:0;transform:translate3d(100%, 0, 0);border-top-left-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-bottom-left-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-top-right-radius:0;border-bottom-right-radius:0}[dir=rtl] .mat-drawer{border-top-left-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-bottom-left-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-top-right-radius:0;border-bottom-right-radius:0;transform:translate3d(100%, 0, 0)}[dir=rtl] .mat-drawer.mat-drawer-end{border-top-right-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-bottom-right-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-top-left-radius:0;border-bottom-left-radius:0;left:0;right:auto;transform:translate3d(-100%, 0, 0)}.mat-drawer-transition .mat-drawer{transition:transform 400ms cubic-bezier(0.25, 0.8, 0.25, 1)}.mat-drawer:not(.mat-drawer-opened):not(.mat-drawer-animating){visibility:hidden;box-shadow:none}.mat-drawer:not(.mat-drawer-opened):not(.mat-drawer-animating) .mat-drawer-inner-container{display:none}.mat-drawer.mat-drawer-opened.mat-drawer-opened{transform:none}.mat-drawer-side{box-shadow:none;border-right-color:var(--mat-sidenav-container-divider-color, transparent);border-right-width:1px;border-right-style:solid}.mat-drawer-side.mat-drawer-end{border-left-color:var(--mat-sidenav-container-divider-color, transparent);border-left-width:1px;border-left-style:solid;border-right:none}[dir=rtl] .mat-drawer-side{border-left-color:var(--mat-sidenav-container-divider-color, transparent);border-left-width:1px;border-left-style:solid;border-right:none}[dir=rtl] .mat-drawer-side.mat-drawer-end{border-right-color:var(--mat-sidenav-container-divider-color, transparent);border-right-width:1px;border-right-style:solid;border-left:none}.mat-drawer-inner-container{width:100%;height:100%;overflow:auto}.mat-sidenav-fixed{position:fixed}
`;var Og=new A("MAT_DRAWER_DEFAULT_AUTOSIZE",{providedIn:"root",factory:Pg}),Rl=new A("MAT_DRAWER_CONTAINER");function Pg(){return!1}var bs=(()=>{class i extends un{_platform=l(oe);_changeDetectorRef=l(me);_container=l(Tl);constructor(){let e=l(R),t=l(wi),o=l(F);super(e,t,o)}ngAfterContentInit(){this._container._contentMarginChanges.subscribe(()=>{this._changeDetectorRef.markForCheck()})}_shouldBeHidden(){if(this._platform.isBrowser)return!1;let{start:e,end:t}=this._container;return e!=null&&e.mode!=="over"&&e.opened||t!=null&&t.mode!=="over"&&t.opened}static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["mat-drawer-content"]],hostAttrs:[1,"mat-drawer-content"],hostVars:6,hostBindings:function(t,o){t&2&&(Be("margin-left",o._container._contentMargins.left,"px")("margin-right",o._container._contentMargins.right,"px"),N("mat-drawer-content-hidden",o._shouldBeHidden()))},features:[de([{provide:un,useExisting:i}]),H],ngContentSelectors:As,decls:1,vars:0,template:function(t,o){t&1&&(Y(),T(0))},encapsulation:2,changeDetection:0})}return i})(),xl=(()=>{class i{_elementRef=l(R);_focusTrapFactory=l(Wr);_focusMonitor=l(Jt);_platform=l(oe);_ngZone=l(F);_renderer=l(Ce);_interactivityChecker=l(pa);_doc=l(D);_container=l(Rl,{optional:!0});_focusTrap=null;_elementFocusedBeforeDrawerWasOpened=null;_eventCleanups;_isAttached;_anchor;get position(){return this._position}set position(e){e=e==="end"?"end":"start",e!==this._position&&(this._isAttached&&this._updatePositionInParent(e),this._position=e,this.onPositionChanged.emit())}_position="start";get mode(){return this._mode}set mode(e){this._mode=e,this._updateFocusTrapState(),this._modeChanged.next()}_mode="over";get disableClose(){return this._disableClose}set disableClose(e){this._disableClose=Qe(e)}_disableClose=!1;get autoFocus(){let e=this._autoFocus;return e??(this.mode==="side"?"dialog":"first-tabbable")}set autoFocus(e){(e==="true"||e==="false"||e==null)&&(e=Qe(e)),this._autoFocus=e}_autoFocus;get opened(){return this._opened()}set opened(e){this.toggle(Qe(e))}_opened=te(!1);_openedVia;_animationStarted=new S;_animationEnd=new S;openedChange=new Z(!0);_openedStream=this.openedChange.pipe(ue(e=>e),q(()=>{}));openedStart=this._animationStarted.pipe(ue(()=>this.opened),Ds(void 0));_closedStream=this.openedChange.pipe(ue(e=>!e),q(()=>{}));closedStart=this._animationStarted.pipe(ue(()=>!this.opened),Ds(void 0));_destroyed=new S;onPositionChanged=new Z;_content;_modeChanged=new S;_injector=l(V);_changeDetectorRef=l(me);constructor(){this.openedChange.pipe(pe(this._destroyed)).subscribe(e=>{e?(this._elementFocusedBeforeDrawerWasOpened=this._doc.activeElement,this._takeFocus()):this._isFocusWithinDrawer()&&this._restoreFocus(this._openedVia||"program")}),this._ngZone.runOutsideAngular(()=>{let e=this._elementRef.nativeElement;Fl(e,"keydown").pipe(ue(t=>t.keyCode===27&&!this.disableClose&&!tn(t)),pe(this._destroyed)).subscribe(t=>this._ngZone.run(()=>{this.close(),t.stopPropagation(),t.preventDefault()})),this._eventCleanups=[this._renderer.listen(e,"transitionrun",this._handleTransitionEvent),this._renderer.listen(e,"transitionend",this._handleTransitionEvent),this._renderer.listen(e,"transitioncancel",this._handleTransitionEvent)]}),this._animationEnd.subscribe(()=>{this.openedChange.emit(this.opened)})}_forceFocus(e,t){this._interactivityChecker.isFocusable(e)||(e.tabIndex=-1,this._ngZone.runOutsideAngular(()=>{let o=()=>{a(),s(),e.removeAttribute("tabindex")},a=this._renderer.listen(e,"blur",o),s=this._renderer.listen(e,"mousedown",o)})),e.focus(t)}_focusByCssSelector(e,t){let o=this._elementRef.nativeElement.querySelector(e);o&&this._forceFocus(o,t)}_takeFocus(){if(!this._focusTrap)return;let e=this._elementRef.nativeElement;switch(this.autoFocus){case!1:case"dialog":return;case!0:case"first-tabbable":ve(()=>{!this._focusTrap.focusInitialElement()&&typeof e.focus=="function"&&e.focus()},{injector:this._injector});break;case"first-heading":this._focusByCssSelector('h1, h2, h3, h4, h5, h6, [role="heading"]');break;default:this._focusByCssSelector(this.autoFocus);break}}_restoreFocus(e){this.autoFocus!=="dialog"&&(this._elementFocusedBeforeDrawerWasOpened?this._focusMonitor.focusVia(this._elementFocusedBeforeDrawerWasOpened,e):this._elementRef.nativeElement.blur(),this._elementFocusedBeforeDrawerWasOpened=null)}_isFocusWithinDrawer(){let e=this._doc.activeElement;return!!e&&this._elementRef.nativeElement.contains(e)}ngAfterViewInit(){this._isAttached=!0,this._position==="end"&&this._updatePositionInParent("end"),this._platform.isBrowser&&(this._focusTrap=this._focusTrapFactory.create(this._elementRef.nativeElement),this._updateFocusTrapState())}ngOnDestroy(){this._eventCleanups.forEach(e=>e()),this._focusTrap?.destroy(),this._anchor?.remove(),this._anchor=null,this._animationStarted.complete(),this._animationEnd.complete(),this._modeChanged.complete(),this._destroyed.next(),this._destroyed.complete()}open(e){return this.toggle(!0,e)}close(){return this.toggle(!1)}_closeViaBackdropClick(){return this._setOpen(!1,!0,"mouse")}toggle(e=!this.opened,t){e&&t&&(this._openedVia=t);let o=this._setOpen(e,!e&&this._isFocusWithinDrawer(),this._openedVia||"program");return e||(this._openedVia=null),o}_setOpen(e,t,o){return e===this.opened?Promise.resolve(e?"open":"close"):(this._opened.set(e),this._container?._transitionsEnabled?this._setIsAnimating(!0):setTimeout(()=>{this._animationStarted.next(),this._animationEnd.next()}),this._elementRef.nativeElement.classList.toggle("mat-drawer-opened",e),!e&&t&&this._restoreFocus(o),this._changeDetectorRef.markForCheck(),this._updateFocusTrapState(),new Promise(a=>{this.openedChange.pipe(Ke(1)).subscribe(s=>a(s?"open":"close"))}))}_setIsAnimating(e){this._elementRef.nativeElement.classList.toggle("mat-drawer-animating",e)}_getWidth(){return this._elementRef.nativeElement.offsetWidth||0}_updateFocusTrapState(){this._focusTrap&&(this._focusTrap.enabled=!!this._container?.hasBackdrop&&this.opened)}_updatePositionInParent(e){if(!this._platform.isBrowser)return;let t=this._elementRef.nativeElement,o=t.parentNode;e==="end"?(this._anchor||(this._anchor=this._doc.createComment("mat-drawer-anchor"),o.insertBefore(this._anchor,t)),o.appendChild(t)):this._anchor&&this._anchor.parentNode.insertBefore(t,this._anchor)}_handleTransitionEvent=e=>{let t=this._elementRef.nativeElement;e.target===t&&this._ngZone.run(()=>{e.type==="transitionrun"?this._animationStarted.next(e):(e.type==="transitionend"&&this._setIsAnimating(!1),this._animationEnd.next(e))})};static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["mat-drawer"]],viewQuery:function(t,o){if(t&1&&xe(_g,5),t&2){let a;B(a=j())&&(o._content=a.first)}},hostAttrs:[1,"mat-drawer"],hostVars:12,hostBindings:function(t,o){t&2&&(X("align",null)("tabIndex",o.mode!=="side"?"-1":null),Be("visibility",!o._container&&!o.opened?"hidden":null),N("mat-drawer-end",o.position==="end")("mat-drawer-over",o.mode==="over")("mat-drawer-push",o.mode==="push")("mat-drawer-side",o.mode==="side"))},inputs:{position:"position",mode:"mode",disableClose:"disableClose",autoFocus:"autoFocus",opened:"opened"},outputs:{openedChange:"openedChange",_openedStream:"opened",openedStart:"openedStart",_closedStream:"closed",closedStart:"closedStart",onPositionChanged:"positionChanged"},exportAs:["matDrawer"],ngContentSelectors:As,decls:3,vars:0,consts:[["content",""],["cdkScrollable","",1,"mat-drawer-inner-container"]],template:function(t,o){t&1&&(Y(),u(0,"div",1,0),T(2),h())},dependencies:[un],encapsulation:2,changeDetection:0})}return i})(),Tl=(()=>{class i{_dir=l(dt,{optional:!0});_element=l(R);_ngZone=l(F);_changeDetectorRef=l(me);_animationDisabled=Le();_transitionsEnabled=!1;_allDrawers;_drawers=new zt;_content;_userContent;get start(){return this._start}get end(){return this._end}get autosize(){return this._autosize}set autosize(e){this._autosize=Qe(e)}_autosize=l(Og);get hasBackdrop(){return this._drawerHasBackdrop(this._start)||this._drawerHasBackdrop(this._end)}set hasBackdrop(e){this._backdropOverride=e==null?null:Qe(e)}_backdropOverride;backdropClick=new Z;_start;_end;_left;_right;_destroyed=new S;_doCheckSubject=new S;_contentMargins={left:null,right:null};_contentMarginChanges=new S;get scrollable(){return this._userContent||this._content}_injector=l(V);constructor(){let e=l(oe),t=l(Ct);this._dir?.change.pipe(pe(this._destroyed)).subscribe(()=>{this._validateDrawers(),this.updateContentMargins()}),t.change().pipe(pe(this._destroyed)).subscribe(()=>this.updateContentMargins()),!this._animationDisabled&&e.isBrowser&&this._ngZone.runOutsideAngular(()=>{setTimeout(()=>{this._element.nativeElement.classList.add("mat-drawer-transition"),this._transitionsEnabled=!0},200)})}ngAfterContentInit(){this._allDrawers.changes.pipe(tt(this._allDrawers),pe(this._destroyed)).subscribe(e=>{this._drawers.reset(e.filter(t=>!t._container||t._container===this)),this._drawers.notifyOnChanges()}),this._drawers.changes.pipe(tt(null)).subscribe(()=>{this._validateDrawers(),this._drawers.forEach(e=>{this._watchDrawerToggle(e),this._watchDrawerPosition(e),this._watchDrawerMode(e)}),(!this._drawers.length||this._isDrawerOpen(this._start)||this._isDrawerOpen(this._end))&&this.updateContentMargins(),this._changeDetectorRef.markForCheck()}),this._ngZone.runOutsideAngular(()=>{this._doCheckSubject.pipe(Lt(10),pe(this._destroyed)).subscribe(()=>this.updateContentMargins())})}ngOnDestroy(){this._contentMarginChanges.complete(),this._doCheckSubject.complete(),this._drawers.destroy(),this._destroyed.next(),this._destroyed.complete()}open(){this._drawers.forEach(e=>e.open())}close(){this._drawers.forEach(e=>e.close())}updateContentMargins(){let e=0,t=0;if(this._left&&this._left.opened){if(this._left.mode=="side")e+=this._left._getWidth();else if(this._left.mode=="push"){let o=this._left._getWidth();e+=o,t-=o}}if(this._right&&this._right.opened){if(this._right.mode=="side")t+=this._right._getWidth();else if(this._right.mode=="push"){let o=this._right._getWidth();t+=o,e-=o}}e=e||null,t=t||null,(e!==this._contentMargins.left||t!==this._contentMargins.right)&&(this._contentMargins={left:e,right:t},this._ngZone.run(()=>this._contentMarginChanges.next(this._contentMargins)))}ngDoCheck(){this._autosize&&this._isPushed()&&this._ngZone.runOutsideAngular(()=>this._doCheckSubject.next())}_watchDrawerToggle(e){e._animationStarted.pipe(pe(this._drawers.changes)).subscribe(()=>{this.updateContentMargins(),this._changeDetectorRef.markForCheck()}),e.mode!=="side"&&e.openedChange.pipe(pe(this._drawers.changes)).subscribe(()=>this._setContainerClass(e.opened))}_watchDrawerPosition(e){e.onPositionChanged.pipe(pe(this._drawers.changes)).subscribe(()=>{ve({read:()=>this._validateDrawers()},{injector:this._injector})})}_watchDrawerMode(e){e._modeChanged.pipe(pe(Nt(this._drawers.changes,this._destroyed))).subscribe(()=>{this.updateContentMargins(),this._changeDetectorRef.markForCheck()})}_setContainerClass(e){let t=this._element.nativeElement.classList,o="mat-drawer-container-has-open";e?t.add(o):t.remove(o)}_validateDrawers(){this._start=this._end=null,this._drawers.forEach(e=>{e.position=="end"?(this._end!=null,this._end=e):(this._start!=null,this._start=e)}),this._right=this._left=null,this._dir&&this._dir.value==="rtl"?(this._left=this._end,this._right=this._start):(this._left=this._start,this._right=this._end)}_isPushed(){return this._isDrawerOpen(this._start)&&this._start.mode!="over"||this._isDrawerOpen(this._end)&&this._end.mode!="over"}_onBackdropClicked(){this.backdropClick.emit(),this._closeModalDrawersViaBackdrop()}_closeModalDrawersViaBackdrop(){[this._start,this._end].filter(e=>e&&!e.disableClose&&this._drawerHasBackdrop(e)).forEach(e=>e._closeViaBackdropClick())}_isShowingBackdrop(){return this._isDrawerOpen(this._start)&&this._drawerHasBackdrop(this._start)||this._isDrawerOpen(this._end)&&this._drawerHasBackdrop(this._end)}_isDrawerOpen(e){return e!=null&&e.opened}_drawerHasBackdrop(e){return this._backdropOverride==null?!!e&&e.mode!=="side":this._backdropOverride}static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["mat-drawer-container"]],contentQueries:function(t,o,a){if(t&1&&(se(a,bs,5),se(a,xl,5)),t&2){let s;B(s=j())&&(o._content=s.first),B(s=j())&&(o._allDrawers=s)}},viewQuery:function(t,o){if(t&1&&xe(bs,5),t&2){let a;B(a=j())&&(o._userContent=a.first)}},hostAttrs:[1,"mat-drawer-container"],hostVars:2,hostBindings:function(t,o){t&2&&N("mat-drawer-container-explicit-backdrop",o._backdropOverride)},inputs:{autosize:"autosize",hasBackdrop:"hasBackdrop"},outputs:{backdropClick:"backdropClick"},exportAs:["matDrawerContainer"],features:[de([{provide:Rl,useExisting:i}])],ngContentSelectors:Cg,decls:4,vars:2,consts:[[1,"mat-drawer-backdrop",3,"mat-drawer-shown"],[1,"mat-drawer-backdrop",3,"click"]],template:function(t,o){t&1&&(Y(wg),J(0,kg,1,2,"div",0),T(1),T(2,1),J(3,Dg,2,0,"mat-drawer-content")),t&2&&($(o.hasBackdrop?0:-1),f(3),$(o._content?-1:3))},dependencies:[bs],styles:[`.mat-drawer-container{position:relative;z-index:1;color:var(--mat-sidenav-content-text-color, var(--mat-sys-on-background));background-color:var(--mat-sidenav-content-background-color, var(--mat-sys-background));box-sizing:border-box;display:block;overflow:hidden}.mat-drawer-container[fullscreen]{top:0;left:0;right:0;bottom:0;position:absolute}.mat-drawer-container[fullscreen].mat-drawer-container-has-open{overflow:hidden}.mat-drawer-container.mat-drawer-container-explicit-backdrop .mat-drawer-side{z-index:3}.mat-drawer-container.ng-animate-disabled .mat-drawer-backdrop,.mat-drawer-container.ng-animate-disabled .mat-drawer-content,.ng-animate-disabled .mat-drawer-container .mat-drawer-backdrop,.ng-animate-disabled .mat-drawer-container .mat-drawer-content{transition:none}.mat-drawer-backdrop{top:0;left:0;right:0;bottom:0;position:absolute;display:block;z-index:3;visibility:hidden}.mat-drawer-backdrop.mat-drawer-shown{visibility:visible;background-color:var(--mat-sidenav-scrim-color, color-mix(in srgb, var(--mat-sys-neutral-variant20) 40%, transparent))}.mat-drawer-transition .mat-drawer-backdrop{transition-duration:400ms;transition-timing-function:cubic-bezier(0.25, 0.8, 0.25, 1);transition-property:background-color,visibility}@media(forced-colors: active){.mat-drawer-backdrop{opacity:.5}}.mat-drawer-content{position:relative;z-index:1;display:block;height:100%;overflow:auto}.mat-drawer-content.mat-drawer-content-hidden{opacity:0}.mat-drawer-transition .mat-drawer-content{transition-duration:400ms;transition-timing-function:cubic-bezier(0.25, 0.8, 0.25, 1);transition-property:transform,margin-left,margin-right}.mat-drawer{position:relative;z-index:4;color:var(--mat-sidenav-container-text-color, var(--mat-sys-on-surface-variant));box-shadow:var(--mat-sidenav-container-elevation-shadow, none);background-color:var(--mat-sidenav-container-background-color, var(--mat-sys-surface));border-top-right-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-bottom-right-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));width:var(--mat-sidenav-container-width, 360px);display:block;position:absolute;top:0;bottom:0;z-index:3;outline:0;box-sizing:border-box;overflow-y:auto;transform:translate3d(-100%, 0, 0)}@media(forced-colors: active){.mat-drawer,[dir=rtl] .mat-drawer.mat-drawer-end{border-right:solid 1px currentColor}}@media(forced-colors: active){[dir=rtl] .mat-drawer,.mat-drawer.mat-drawer-end{border-left:solid 1px currentColor;border-right:none}}.mat-drawer.mat-drawer-side{z-index:2}.mat-drawer.mat-drawer-end{right:0;transform:translate3d(100%, 0, 0);border-top-left-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-bottom-left-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-top-right-radius:0;border-bottom-right-radius:0}[dir=rtl] .mat-drawer{border-top-left-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-bottom-left-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-top-right-radius:0;border-bottom-right-radius:0;transform:translate3d(100%, 0, 0)}[dir=rtl] .mat-drawer.mat-drawer-end{border-top-right-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-bottom-right-radius:var(--mat-sidenav-container-shape, var(--mat-sys-corner-large));border-top-left-radius:0;border-bottom-left-radius:0;left:0;right:auto;transform:translate3d(-100%, 0, 0)}.mat-drawer-transition .mat-drawer{transition:transform 400ms cubic-bezier(0.25, 0.8, 0.25, 1)}.mat-drawer:not(.mat-drawer-opened):not(.mat-drawer-animating){visibility:hidden;box-shadow:none}.mat-drawer:not(.mat-drawer-opened):not(.mat-drawer-animating) .mat-drawer-inner-container{display:none}.mat-drawer.mat-drawer-opened.mat-drawer-opened{transform:none}.mat-drawer-side{box-shadow:none;border-right-color:var(--mat-sidenav-container-divider-color, transparent);border-right-width:1px;border-right-style:solid}.mat-drawer-side.mat-drawer-end{border-left-color:var(--mat-sidenav-container-divider-color, transparent);border-left-width:1px;border-left-style:solid;border-right:none}[dir=rtl] .mat-drawer-side{border-left-color:var(--mat-sidenav-container-divider-color, transparent);border-left-width:1px;border-left-style:solid;border-right:none}[dir=rtl] .mat-drawer-side.mat-drawer-end{border-right-color:var(--mat-sidenav-container-divider-color, transparent);border-right-width:1px;border-right-style:solid;border-left:none}.mat-drawer-inner-container{width:100%;height:100%;overflow:auto}.mat-sidenav-fixed{position:fixed}
`],encapsulation:2,changeDetection:0})}return i})(),vs=(()=>{class i extends bs{static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275cmp=y({type:i,selectors:[["mat-sidenav-content"]],hostAttrs:[1,"mat-drawer-content","mat-sidenav-content"],features:[de([{provide:un,useExisting:i}]),H],ngContentSelectors:As,decls:1,vars:0,template:function(t,o){t&1&&(Y(),T(0))},encapsulation:2,changeDetection:0})}return i})(),Sl=(()=>{class i extends xl{get fixedInViewport(){return this._fixedInViewport}set fixedInViewport(e){this._fixedInViewport=Qe(e)}_fixedInViewport=!1;get fixedTopGap(){return this._fixedTopGap}set fixedTopGap(e){this._fixedTopGap=Ft(e)}_fixedTopGap=0;get fixedBottomGap(){return this._fixedBottomGap}set fixedBottomGap(e){this._fixedBottomGap=Ft(e)}_fixedBottomGap=0;static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275cmp=y({type:i,selectors:[["mat-sidenav"]],hostAttrs:[1,"mat-drawer","mat-sidenav"],hostVars:16,hostBindings:function(t,o){t&2&&(X("tabIndex",o.mode!=="side"?"-1":null)("align",null),Be("top",o.fixedInViewport?o.fixedTopGap:null,"px")("bottom",o.fixedInViewport?o.fixedBottomGap:null,"px"),N("mat-drawer-end",o.position==="end")("mat-drawer-over",o.mode==="over")("mat-drawer-push",o.mode==="push")("mat-drawer-side",o.mode==="side")("mat-sidenav-fixed",o.fixedInViewport))},inputs:{fixedInViewport:"fixedInViewport",fixedTopGap:"fixedTopGap",fixedBottomGap:"fixedBottomGap"},exportAs:["matSidenav"],features:[de([{provide:xl,useExisting:i}]),H],ngContentSelectors:As,decls:3,vars:0,consts:[["content",""],["cdkScrollable","",1,"mat-drawer-inner-container"]],template:function(t,o){t&1&&(Y(),u(0,"div",1,0),T(2),h())},dependencies:[un],encapsulation:2,changeDetection:0})}return i})(),_h=(()=>{class i extends Tl{_allDrawers=void 0;_content=void 0;static \u0275fac=(()=>{let e;return function(o){return(e||(e=ce(i)))(o||i)}})();static \u0275cmp=y({type:i,selectors:[["mat-sidenav-container"]],contentQueries:function(t,o,a){if(t&1&&(se(a,vs,5),se(a,Sl,5)),t&2){let s;B(s=j())&&(o._content=s.first),B(s=j())&&(o._allDrawers=s)}},hostAttrs:[1,"mat-drawer-container","mat-sidenav-container"],hostVars:2,hostBindings:function(t,o){t&2&&N("mat-drawer-container-explicit-backdrop",o._backdropOverride)},exportAs:["matSidenavContainer"],features:[de([{provide:Rl,useExisting:i},{provide:Tl,useExisting:i}]),H],ngContentSelectors:xg,decls:4,vars:2,consts:[[1,"mat-drawer-backdrop",3,"mat-drawer-shown"],[1,"mat-drawer-backdrop",3,"click"]],template:function(t,o){t&1&&(Y(Eg),J(0,Tg,1,2,"div",0),T(1),T(2,1),J(3,Rg,2,0,"mat-sidenav-content")),t&2&&($(o.hasBackdrop?0:-1),f(3),$(o._content?-1:3))},dependencies:[vs],styles:[Sg],encapsulation:2,changeDetection:0})}return i})(),wh=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[z,_i,_i,z]})}return i})();var Fg=["*",[["mat-toolbar-row"]]],Mg=["*","mat-toolbar-row"],Ng=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275dir=_({type:i,selectors:[["mat-toolbar-row"]],hostAttrs:[1,"mat-toolbar-row"],exportAs:["matToolbarRow"]})}return i})(),Ch=(()=>{class i{_elementRef=l(R);_platform=l(oe);_document=l(D);color;_toolbarRows;constructor(){}ngAfterViewInit(){this._platform.isBrowser&&(this._checkToolbarMixedModes(),this._toolbarRows.changes.subscribe(()=>this._checkToolbarMixedModes()))}_checkToolbarMixedModes(){this._toolbarRows.length}static \u0275fac=function(t){return new(t||i)};static \u0275cmp=y({type:i,selectors:[["mat-toolbar"]],contentQueries:function(t,o,a){if(t&1&&se(a,Ng,5),t&2){let s;B(s=j())&&(o._toolbarRows=s)}},hostAttrs:[1,"mat-toolbar"],hostVars:6,hostBindings:function(t,o){t&2&&(Me(o.color?"mat-"+o.color:""),N("mat-toolbar-multiple-rows",o._toolbarRows.length>0)("mat-toolbar-single-row",o._toolbarRows.length===0))},inputs:{color:"color"},exportAs:["matToolbar"],ngContentSelectors:Mg,decls:2,vars:0,template:function(t,o){t&1&&(Y(Fg),T(0),T(1,1))},styles:[`.mat-toolbar{background:var(--mat-toolbar-container-background-color, var(--mat-sys-surface));color:var(--mat-toolbar-container-text-color, var(--mat-sys-on-surface))}.mat-toolbar,.mat-toolbar h1,.mat-toolbar h2,.mat-toolbar h3,.mat-toolbar h4,.mat-toolbar h5,.mat-toolbar h6{font-family:var(--mat-toolbar-title-text-font, var(--mat-sys-title-large-font));font-size:var(--mat-toolbar-title-text-size, var(--mat-sys-title-large-size));line-height:var(--mat-toolbar-title-text-line-height, var(--mat-sys-title-large-line-height));font-weight:var(--mat-toolbar-title-text-weight, var(--mat-sys-title-large-weight));letter-spacing:var(--mat-toolbar-title-text-tracking, var(--mat-sys-title-large-tracking));margin:0}@media(forced-colors: active){.mat-toolbar{outline:solid 1px}}.mat-toolbar .mat-form-field-underline,.mat-toolbar .mat-form-field-ripple,.mat-toolbar .mat-focused .mat-form-field-ripple{background-color:currentColor}.mat-toolbar .mat-form-field-label,.mat-toolbar .mat-focused .mat-form-field-label,.mat-toolbar .mat-select-value,.mat-toolbar .mat-select-arrow,.mat-toolbar .mat-form-field.mat-focused .mat-select-arrow{color:inherit}.mat-toolbar .mat-input-element{caret-color:currentColor}.mat-toolbar .mat-mdc-button-base.mat-mdc-button-base.mat-unthemed{--mat-button-text-label-text-color: var(--mat-toolbar-container-text-color, var(--mat-sys-on-surface));--mat-button-outlined-label-text-color: var(--mat-toolbar-container-text-color, var(--mat-sys-on-surface))}.mat-toolbar-row,.mat-toolbar-single-row{display:flex;box-sizing:border-box;padding:0 16px;width:100%;flex-direction:row;align-items:center;white-space:nowrap;height:var(--mat-toolbar-standard-height, 64px)}@media(max-width: 599px){.mat-toolbar-row,.mat-toolbar-single-row{height:var(--mat-toolbar-mobile-height, 56px)}}.mat-toolbar-multiple-rows{display:flex;box-sizing:border-box;flex-direction:column;width:100%;min-height:var(--mat-toolbar-standard-height, 64px)}@media(max-width: 599px){.mat-toolbar-multiple-rows{min-height:var(--mat-toolbar-mobile-height, 56px)}}
`],encapsulation:2,changeDetection:0})}return i})();var kh=(()=>{class i{static \u0275fac=function(t){return new(t||i)};static \u0275mod=x({type:i});static \u0275inj=E({imports:[z,z]})}return i})();var Gg=()=>({exact:!0}),Is=class i{title="Education and AI Policy Commons";router=l($e);navigateToWelcome(){this.router.navigate(["/"])}static \u0275fac=function(e){return new(e||i)};static \u0275cmp=y({type:i,selectors:[["app-root"]],decls:57,vars:19,consts:[["welcomeMenu","matMenu"],["dashboardMenu","matMenu"],["dataMenu","matMenu"],["mode","side","opened",""],["mat-subheader",""],["tabindex","0","role","button","aria-haspopup","true",1,"welcome-menu-trigger",3,"matMenuTriggerFor"],["matListItemIcon",""],["matListItemTitle",""],["mat-menu-item","",3,"routerLink","routerLinkActive","routerLinkActiveOptions"],["mat-menu-item","","routerLinkActive","active",3,"routerLink"],[1,"dashboard-menu-trigger",3,"matMenuTriggerFor"],["mat-menu-item","",3,"routerLink"],["tabindex","0","role","button","aria-haspopup","true",1,"data-menu-trigger",3,"matMenuTriggerFor"],["color","primary"]],template:function(e,t){if(e&1&&(u(0,"mat-sidenav-container")(1,"mat-sidenav",3)(2,"mat-nav-list")(3,"h3",4),m(4,"Navigation"),h(),u(5,"mat-list-item",5)(6,"mat-icon",6),m(7,"home"),h(),u(8,"span",7),m(9,"Welcome"),h()(),u(10,"mat-menu",null,0)(12,"button",8),m(13," Welcome Page "),h(),u(14,"button",9),m(15," Tips "),h()(),u(16,"mat-list-item",10)(17,"mat-icon",6),m(18,"dashboard"),h(),u(19,"span",7),m(20,"Dashboards"),h()(),u(21,"mat-menu",null,1)(23,"button",11),m(24,"All Policies Assessed"),h(),u(25,"button",11),m(26,"Policies Marked as Relevant"),h(),u(27,"button",11),m(28,"Year of Creation or Commencement"),h(),u(29,"button",11),m(30,"Governance Practices"),h(),u(31,"button",11),m(32,"Opportunity and Risk Focus"),h(),u(33,"button",11),m(34,"Principles Expressed"),h(),u(35,"button",11),m(36,"Essential Reading"),h()(),u(37,"mat-list-item",12)(38,"mat-icon",6),m(39,"storage"),h(),u(40,"span",7),m(41,"Data"),h()(),u(42,"mat-menu",null,2)(44,"button",9),m(45," Relevance Assessment Tables "),h(),u(46,"button",9),m(47," Lookup Tables (Select Options) "),h(),u(48,"button",9),m(49," Table A. All Potentially Relevant AI Policies Reviewed "),h(),u(50,"button",9),m(51," Table B. Policy Analysis Table "),h()()()(),u(52,"mat-sidenav-content")(53,"mat-toolbar",13)(54,"span"),m(55,"Education and AI Policy Commons"),h()(),ie(56,"router-outlet"),h()()),e&2){let o=Rt(11),a=Rt(22),s=Rt(43);f(5),M("matMenuTriggerFor",o),f(7),M("routerLink","/")("routerLinkActive","active")("routerLinkActiveOptions",Ni(18,Gg)),f(2),M("routerLink","/tips"),f(2),M("matMenuTriggerFor",a),f(7),M("routerLink","/dashboards/all-policies"),f(2),M("routerLink","/dashboards/relevant-policies"),f(2),M("routerLink","/dashboards/creation-year"),f(2),M("routerLink","/dashboards/governance-practices"),f(2),M("routerLink","/dashboards/opportunity-risk"),f(2),M("routerLink","/dashboards/principles"),f(2),M("routerLink","/dashboards/essential-reading"),f(2),M("matMenuTriggerFor",s),f(7),M("routerLink","/data/relevance-assessment"),f(2),M("routerLink","/data/lookup-tables"),f(2),M("routerLink","/data/all-potentially-relevant-ai-policies-reviewed"),f(2),M("routerLink","/data/policy-analysis")}},dependencies:[je,mi,$i,Fr,wh,Sl,_h,vs,kh,Ch,is,uh,ch,Dl,dh,kl,wt,rn,qa,mn,fo,Mu],styles:["mat-sidenav[_ngcontent-%COMP%]{width:250px}mat-sidenav-container[_ngcontent-%COMP%]{height:100vh}mat-sidenav-content[_ngcontent-%COMP%]{padding:20px}.active[_ngcontent-%COMP%]{background-color:#0000000a}"]})};Qs(Is,Ih).catch(i=>console.error(i));
