{
  "columns": [
    {
      "id": "c-5WWbiBHe9B",
      "type": "column",
      "name": "Policy Name",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-5WWbiBHe9B",
      "format": {
        "type": "text",
        "isArray": false
      }
    },
    {
      "id": "c-JILGl3j9sD",
      "type": "column",
      "name": "Policy creator",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-JILGl3j9sD",
      "format": {
        "table": {
          "id": "grid-2iQy6VFcq_",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-2iQy6VFcq_",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-2iQy6VFcq_",
          "name": "Jurisdictions"
        },
        "type": "lookup",
        "isArray": true
      }
    },
    {
      "id": "c-V85VzcYUCM",
      "type": "column",
      "name": "Relevant?",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-V85VzcYUCM",
      "format": {
        "type": "select",
        "isArray": false
      }
    },
    {
      "id": "c-iohuaEflSp",
      "type": "column",
      "name": "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-iohuaEflSp",
      "format": {
        "type": "text",
        "isArray": false
      }
    },
    {
      "id": "c-84Ex4h0pTV",
      "type": "column",
      "name": "File",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-84Ex4h0pTV",
      "format": {
        "type": "attachments",
        "isArray": true
      }
    },
    {
      "id": "c-FlyVKlvCIx",
      "type": "column",
      "name": "Year of Commencement or Creation",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-FlyVKlvCIx",
      "format": {
        "type": "text",
        "isArray": false
      }
    },
    {
      "id": "c-2pT34POxIT",
      "type": "column",
      "name": "Relevance Type",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-2pT34POxIT",
      "format": {
        "table": {
          "id": "grid-1ohiEKjQFc",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-1ohiEKjQFc",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-1ohiEKjQFc",
          "name": "Nature of relevance"
        },
        "type": "lookup",
        "isArray": true
      }
    },
    {
      "id": "c-fJvB8zmh-Y",
      "type": "column",
      "name": "What kinds of education, if any, are contemplated by the policy?",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-fJvB8zmh-Y",
      "format": {
        "table": {
          "id": "grid-0_3yg-Vkoy",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-0_3yg-Vkoy",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-0_3yg-Vkoy",
          "name": "Which kind of education does it expressly mention?"
        },
        "type": "lookup",
        "isArray": true
      }
    },
    {
      "id": "c-zdfmo_m_Tj",
      "type": "column",
      "name": "Principles on AI in education",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-zdfmo_m_Tj",
      "format": {
        "table": {
          "id": "grid-zXkG0jBLna",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-zXkG0jBLna",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-zXkG0jBLna",
          "name": "AI in education principles"
        },
        "type": "lookup",
        "isArray": true
      }
    },
    {
      "id": "c-5VlrDV5zWa",
      "type": "column",
      "name": "Governance practices employed",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-5VlrDV5zWa",
      "format": {
        "table": {
          "id": "grid-Xr9iAFDRZl",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-Xr9iAFDRZl",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-Xr9iAFDRZl",
          "name": "Type of policy initaitive"
        },
        "type": "lookup",
        "isArray": true
      }
    },
    {
      "id": "c-r-XaOjk8Lk",
      "type": "column",
      "name": "Analysis Complete",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-r-XaOjk8Lk",
      "format": {
        "displayType": "check",
        "type": "checkbox",
        "isArray": false
      }
    },
    {
      "id": "c-Nq_phIQjPG",
      "type": "column",
      "name": "Link (OECD or Other)",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-Nq_phIQjPG",
      "format": {
        "display": "iconOnly",
        "type": "link",
        "isArray": false
      }
    },
    {
      "id": "c-gdxdwF0OOx",
      "type": "column",
      "name": "Series #",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-gdxdwF0OOx",
      "format": {
        "precision": 22,
        "useThousandsSeparator": true,
        "type": "number",
        "isArray": false
      }
    },
    {
      "id": "c-Sm3wWbxOJ2",
      "type": "column",
      "name": "Title",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-Sm3wWbxOJ2",
      "display": true,
      "calculated": true,
      "format": {
        "type": "text",
        "isArray": false
      },
      "formula": "Concatenate([Policy creator],\": \",[Policy Name])"
    },
    {
      "id": "c-zAp89itebl",
      "type": "column",
      "name": "Opportunity and risk orientation",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-zAp89itebl",
      "format": {
        "table": {
          "id": "grid-P_wv2uo4M6",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-P_wv2uo4M6",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-P_wv2uo4M6",
          "name": "Considering both opportunities and risks?"
        },
        "type": "lookup",
        "isArray": false
      }
    },
    {
      "id": "c-L3R0H6xpKL",
      "type": "column",
      "name": "Category of creator",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-L3R0H6xpKL",
      "calculated": true,
      "format": {
        "type": "select",
        "isArray": false
      },
      "formula": "[Policy creator].[OECD?].ListCombine()"
    },
    {
      "id": "c-9Qm-26QJsu",
      "type": "column",
      "name": "Translation Comments",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-9Qm-26QJsu",
      "format": {
        "type": "select",
        "isArray": false
      }
    },
    {
      "id": "c-wPHcwhpe1X",
      "type": "column",
      "name": "Key quotes on AI in education principles",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-wPHcwhpe1X",
      "format": {
        "type": "canvas",
        "isArray": false
      }
    },
    {
      "id": "c-5hHdZ0sfu8",
      "type": "column",
      "name": "Does the policy reflect the principle of human rights compatibility?",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-5hHdZ0sfu8",
      "format": {
        "table": {
          "id": "grid-qlBRzb18gd",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-qlBRzb18gd",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-qlBRzb18gd",
          "name": "Does it make reference to human, fundamental, or inalienable rights?"
        },
        "type": "lookup",
        "isArray": false
      }
    },
    {
      "id": "c-Y854zWDfFY",
      "type": "column",
      "name": "Key quote on human rights",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-Y854zWDfFY",
      "format": {
        "type": "text",
        "isArray": false
      }
    },
    {
      "id": "c-LxM7tcl6OJ",
      "type": "column",
      "name": "Does the policy reflect the principle of equity/equality?",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-LxM7tcl6OJ",
      "format": {
        "table": {
          "id": "grid-OWGRQYLMAA",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-OWGRQYLMAA",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-OWGRQYLMAA",
          "name": "Does it make reference to equity?"
        },
        "type": "lookup",
        "isArray": false
      }
    },
    {
      "id": "c-U0fCdFgXTA",
      "type": "column",
      "name": "Key quote on equity/equality",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-U0fCdFgXTA",
      "format": {
        "type": "text",
        "isArray": false
      }
    },
    {
      "id": "c-tQrodNzumD",
      "type": "column",
      "name": "General principles on AI",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-tQrodNzumD",
      "format": {
        "table": {
          "id": "grid-Jef7egIzgb",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-Jef7egIzgb",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-Jef7egIzgb",
          "name": "General AI principles"
        },
        "type": "lookup",
        "isArray": true
      }
    },
    {
      "id": "c-81BAzxH2C6",
      "type": "column",
      "name": "Draft Analysis Complete",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-81BAzxH2C6",
      "format": {
        "displayType": "check",
        "type": "checkbox",
        "isArray": false
      }
    },
    {
      "id": "c-erzTbcFItg",
      "type": "column",
      "name": "Reasons for non-inclusion (other than \"Irrelevant\")",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-erzTbcFItg",
      "format": {
        "type": "select",
        "isArray": false
      }
    },
    {
      "id": "c-cH92ZKzGzy",
      "type": "column",
      "name": "Weekend",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-cH92ZKzGzy",
      "format": {
        "displayType": "check",
        "type": "checkbox",
        "isArray": false
      }
    },
    {
      "id": "c-lgXRPxQGDm",
      "type": "column",
      "name": "Key quotes on general AI principles",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-lgXRPxQGDm",
      "format": {
        "type": "canvas",
        "isArray": false
      }
    },
    {
      "id": "c-nKkCVHlbQZ",
      "type": "column",
      "name": "WC Favourite",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-nKkCVHlbQZ",
      "format": {
        "displayType": "check",
        "type": "checkbox",
        "isArray": false
      }
    },
    {
      "id": "c-OgsmPhUiK0",
      "type": "column",
      "name": "Notable Case Studes - Examples of AI in Education",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-OgsmPhUiK0",
      "format": {
        "type": "canvas",
        "isArray": false
      }
    },
    {
      "id": "c-O2MdT9sMx2",
      "type": "column",
      "name": "Other Points of Interest",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-O2MdT9sMx2",
      "format": {
        "type": "canvas",
        "isArray": false
      }
    },
    {
      "id": "c-LT8GCmk4tr",
      "type": "column",
      "name": "Record Entered By",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-LT8GCmk4tr",
      "format": {
        "table": {
          "id": "grid-vq4WMZ5Lm7",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-vq4WMZ5Lm7",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-vq4WMZ5Lm7",
          "name": "Record Entered By"
        },
        "type": "lookup",
        "isArray": true
      }
    }
  ],
  "rows": [
    {
      "values": {
        "Policy Name": "Framework Act on Artificial Intelligence Development and Establishment of a Foundation for Trustworthiness ",
        "Policy creator": [
          "South Korea"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "A general framework regulates high-impact AI including education",
        "File": [
          "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122) ENGLISH.pdf",
          "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf"
        ],
        "Year of Commencement or Creation": "2025",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Binds. It creates binding obligations in relation to AI",
          "Proposes law. It proposes a law or provides a draft law on AI",
          "Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)",
          "Tracks. It sets out to boost understanding specifically of where and how AI is being used",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://www.law.go.kr/%25EB%25B2%2595%25EB%25A0%25B9/%25EC%259D%25B8%25EA%25B3%25B5%25EC%25A7%2580%25EB%258A%25A5%2520%25EB%25B0%259C%25EC%25A0%2584%25EA%25B3%25BC%2520%25EC%258B%25A0%25EB%25A2%25B0%2520%25EA%25B8%25B0%25EB%25B0%2598%2520%25EC%25A1%25B0%25EC%2584%25B1%2520%25EB%2593%25B1%25EC%2597%2590%2520%25EA%25B4%2580%25ED%2595%259C%2520%25EA%25B8%25B0%25EB%25B3%25B8%25EB%25B2%2595/(20676,20250121)",
        "Series #": "",
        "Title": "South Korea: Framework Act on Artificial Intelligence Development and Establishment of a Foundation for Trustworthiness ",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Completed (DeepL)",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress."
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-6vjnfILLDk",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-6vjnfILLDk",
      "name": "South Korea: Framework Act on Artificial Intelligence Development and Establishment of a Foundation for Trustworthiness ",
      "index": 494,
      "createdAt": "2025-04-30T01:49:31.178Z",
      "updatedAt": "2025-04-30T06:34:32.834Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-6vjnfILLDk"
    },
    {
      "values": {
        "Policy Name": "A pro-innovation approach  to AI regulation",
        "Policy creator": [
          "United Kingdom"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "A general regulation approach but can inform education",
        "File": [
          "a-pro-innovation-approach-to-ai-regulation-amended-web-ready.pdf"
        ],
        "Year of Commencement or Creation": "2023",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI",
          "Plans further action. It sets out a strategy on AI",
          "Tracks. It sets out to boost understanding specifically of where and how AI is being used",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper",
        "Series #": "",
        "Title": "United Kingdom: A pro-innovation approach  to AI regulation",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "We anticipate that regulators will need to:\n\n1. Interpret and articulate ‘fairness’ as relevant to their sector or domain,\n\n2. Decide in which contexts and specific instances fairness is important and relevant (which it may not always be).\n\n3. Design, implement and enforce appropriate governance requirements for ‘fairness’ as applicable to the entities that they regulate.\n\n4. Where a decision involving use of an AI system has a legal or similarly significant effect on an individual, regulators will need to consider the suitability of requiring AI system operators to provide an appropriate justification for that decision to affected parties.\n\n5. AI systems should comply with regulatory requirements relating to vulnerability of individuals within specific regulatory domains. Regulators will need to consider how use of AI systems may alter individuals’ vulnerability, pursuant to their existing powers and remits.\n\n6. Consider the role of available technical standards addressing AI fairness, bias mitigation and ethical considerations (for example, ISO/IEC TR 24027:2021, ISO/IEC 12791*, ISO/IEC TR 24368:2022) to clarify regulatory guidance and support the implementation of risk treatment measures.",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Inclusive development. AI systems should be developed inclusively. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-mVcrtMCV1l",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-mVcrtMCV1l",
      "name": "United Kingdom: A pro-innovation approach  to AI regulation",
      "index": 493,
      "createdAt": "2025-04-30T01:12:12.328Z",
      "updatedAt": "2025-04-30T01:33:26.550Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-mVcrtMCV1l"
    },
    {
      "values": {
        "Policy Name": "The National Artificial Intelligence Strategy of Mauritania for 2025–2029",
        "Policy creator": [
          "Mauritius"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The strategy includes AI in education sector",
        "File": [
          "The National Artificial Intelligence Strategy of Mauritania for 2025–2029.pdf"
        ],
        "Year of Commencement or Creation": "2024",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI",
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)",
          "Communicates a stance. It expresses a hope for the future of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://mtnima.gov.mr/wp-content/uploads/2024/07/strategie-EN-Final-26-07-2024-.pdf",
        "Series #": "",
        "Title": "Mauritius: The National Artificial Intelligence Strategy of Mauritania for 2025–2029",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "This strategy will integrate artificial intelligence technologies into the field of education through projects aimed at serving all stakeholders in the educational system. one the one hand , these projects will be used to enhance student learning by providing interactive tools and programs specifically designed to meet their needs, thereby boosting their academic success. On the other hand, teachers will benefit from these projects by creating innovative educational content, analyzing student performance, and tailoring instruction based on each student's individual progress.  At the institutional level, these projects will assist educational institutions in improving resource management, curriculum planning, and decision-making based on accurate data and in-depth analyses.  Additionally, this strategy includes a project for translating various national dialects, which aims to enhance social cohesion by facilitating linguistic communication and access to knowledge resources in the different dialects used in the country.",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,"
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "This strategic priority focuses on ensure that the development and utilization of artificial intelligence complies with stringent ethical and legal standards. These standards encompass safeguarding personal data, ensuring data protection and privacy, respecting intellectual property rights, and adhering to pertinent regulations. Our commitment to upholding the ethical standards of the Arab League, the African Union and the United Nations is integral to accomplishing this strategy.",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-0SqFdnPRIL",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-0SqFdnPRIL",
      "name": "Mauritius: The National Artificial Intelligence Strategy of Mauritania for 2025–2029",
      "index": 492,
      "createdAt": "2025-04-30T00:52:07.857Z",
      "updatedAt": "2025-04-30T01:08:56.524Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-0SqFdnPRIL"
    },
    {
      "values": {
        "Policy Name": "Driving U.S. Innovation in Artificial Intelligence: A Roadmap for Artificial Intelligence Policy in the United States Senate",
        "Policy creator": [
          "United States"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "A comprehensive framework aimed at addressing the multifaceted opportunities and risks presented by artificial intelligence (“AI”) technologies could inform the governance of AI in education",
        "File": [
          "Driving U.S. Innovation in Artificial Intelligence A Roadmap for Artificial Intelligence Policy in.pdf"
        ],
        "Year of Commencement or Creation": "2024",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Plans further action. It sets out a strategy on AI",
          "Proposes law. It proposes a law or provides a draft law on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "United States: Driving U.S. Innovation in Artificial Intelligence: A Roadmap for Artificial Intelligence Policy in the United States Senate",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-j33OQcVixo",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-j33OQcVixo",
      "name": "United States: Driving U.S. Innovation in Artificial Intelligence: A Roadmap for Artificial Intelligence Policy in the United States Senate",
      "index": 491,
      "createdAt": "2025-04-30T00:26:12.572Z",
      "updatedAt": "2025-04-30T00:50:46.186Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-j33OQcVixo"
    },
    {
      "values": {
        "Policy Name": "Sri Lanka's National Strategy on AI",
        "Policy creator": [
          "Sri Lanka"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Mentions education as a high-impact area and a key governance domain",
        "File": [
          "National AI strategy for Sri Lanka.pdf"
        ],
        "Year of Commencement or Creation": "2024",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "Sri Lanka: Sri Lanka's National Strategy on AI",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          ""
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Human-centricity: AI systems should respect human-centred values and pursue benefits for society, including health, well-being, relationships, personhood, and individual dignity. They should not be used for malicious purposes or to sway or deceive users into making harmful decisions.",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "Fairness and Equity: AI systems should be designed and implemented with fairness in mind, minimizing bias and discrimination to ensure equitable treatment for all individuals. They must not undermine legal rights, discriminate unfairly, or create unfair market outcomes.",
        "General principles on AI": [
          "Augmentation, not replacement. AI systems should augment, not displace, workers.",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power.",
          "Freedom of speech and assembly [NEW]. AI systems should not abrogate freedom of speech or assembly. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-wycemXJq9G",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-wycemXJq9G",
      "name": "Sri Lanka: Sri Lanka's National Strategy on AI",
      "index": 490,
      "createdAt": "2025-04-29T08:07:44.766Z",
      "updatedAt": "2025-04-29T08:30:26.654Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-wycemXJq9G"
    },
    {
      "values": {
        "Policy Name": "2024 Artificial Intelligence Strategy",
        "Policy creator": [
          "Spain"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Although not focused on education, the strategy identifies education as one of the social domains for AI supervision and calls for developing flexible yet robust frameworks tailored to contexts such as education.",
        "File": [
          "Spain’s 2024 Artificial Intelligence Strategy.pdf"
        ],
        "Year of Commencement or Creation": "2024",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)",
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "Spain: 2024 Artificial Intelligence Strategy",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "R&D. Sufficient resources should be invested in AI R&D."
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-b9L-R5YgBc",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-b9L-R5YgBc",
      "name": "Spain: 2024 Artificial Intelligence Strategy",
      "index": 489,
      "createdAt": "2025-04-29T07:44:44.345Z",
      "updatedAt": "2025-04-29T08:06:18.710Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-b9L-R5YgBc"
    },
    {
      "values": {
        "Policy Name": "AI Adoption Framework",
        "Policy creator": [
          "Saudi Arabia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "not engage with governance of AI in education.",
        "File": "",
        "Year of Commencement or Creation": "2024",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "Saudi Arabia: AI Adoption Framework",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-uSLrgrzipe",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-uSLrgrzipe",
      "name": "Saudi Arabia: AI Adoption Framework",
      "index": 488,
      "createdAt": "2025-04-29T07:43:14.954Z",
      "updatedAt": "2025-04-29T07:44:17.439Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-uSLrgrzipe"
    },
    {
      "values": {
        "Policy Name": "Generative Artificial Intelligence Guidelines For Government",
        "Policy creator": [
          "Saudi Arabia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "not engage with governance of AI in education.",
        "File": [
          "Saudi Arabia-Generative Artificial Intelligence Guidelines For Government.pdf"
        ],
        "Year of Commencement or Creation": "2024",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "Saudi Arabia: Generative Artificial Intelligence Guidelines For Government",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-Igg1ZQ9Nl4",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Igg1ZQ9Nl4",
      "name": "Saudi Arabia: Generative Artificial Intelligence Guidelines For Government",
      "index": 487,
      "createdAt": "2025-04-29T07:41:15.118Z",
      "updatedAt": "2025-04-29T07:42:25.286Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Igg1ZQ9Nl4"
    },
    {
      "values": {
        "Policy Name": "Generative Artificial Intelligence Guidelines Public",
        "Policy creator": [
          "Saudi Arabia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "just one sentence acknowledges risks GenAI poses to educational assessment integrity (e.g., certification fraud)",
        "File": "",
        "Year of Commencement or Creation": "2024",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "Saudi Arabia: Generative Artificial Intelligence Guidelines Public",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-HYFubXllDU",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-HYFubXllDU",
      "name": "Saudi Arabia: Generative Artificial Intelligence Guidelines Public",
      "index": 486,
      "createdAt": "2025-04-29T07:36:50.252Z",
      "updatedAt": "2025-04-29T07:40:50.700Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-HYFubXllDU"
    },
    {
      "values": {
        "Policy Name": "State of AI in Saudi Arabia",
        "Policy creator": [
          "Saudi Arabia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The policy discusses AI talent development and human capacity building, but it does not address the governance of AI in education systems or the responsible management of AI technologies in education.",
        "File": "",
        "Year of Commencement or Creation": "2024",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "Saudi Arabia: State of AI in Saudi Arabia",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-qlhowcHxuY",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-qlhowcHxuY",
      "name": "Saudi Arabia: State of AI in Saudi Arabia",
      "index": 485,
      "createdAt": "2025-04-29T07:34:35.472Z",
      "updatedAt": "2025-04-29T07:36:04.676Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-qlhowcHxuY"
    },
    {
      "values": {
        "Policy Name": "Nigirian National AI Strategy",
        "Policy creator": [
          "Nigeria"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The policy contains some fleeting references to education-related AI initiatives such as training, curriculum development, and capacity building. However, it does not engage with the governance of AI in education or propose frameworks for managing AI technologies within educational systems.",
        "File": "",
        "Year of Commencement or Creation": "2024",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "Nigeria: Nigirian National AI Strategy",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-KW-T-1Ebam",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-KW-T-1Ebam",
      "name": "Nigeria: Nigirian National AI Strategy",
      "index": 484,
      "createdAt": "2025-04-29T07:20:00.904Z",
      "updatedAt": "2025-04-29T07:32:20.262Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-KW-T-1Ebam"
    },
    {
      "values": {
        "Policy Name": "National Programme on Artificial Intelligence (NPAI) Skilling Framework",
        "Policy creator": [
          "India"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Addresses AI skilling across education and embeds responsible AI principles into educational governance.",
        "File": [
          "5732498_Report-on-NPAI-Skilling-Framework.pdf"
        ],
        "Year of Commencement or Creation": "2023",
        "Relevance Type": [
          "Policy is about AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Secondary",
          "Tertiary",
          "Vocational or Professional"
        ],
        "Principles on AI in education": [
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Managing bias. The risk of bias should be managed with care. ",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ",
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Plans further action. It sets out a strategy on AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "India: National Programme on Artificial Intelligence (NPAI) Skilling Framework",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "Ethical artificial intelligence (AI) refers to the development and use of AI systems in a responsible and morally acceptable manner. It involves ensuring that AI technologies align with ethical principles and values, protect human rights, and minimize potential harms.",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "Fairness and Bias: AI systems should be designed and trained to avoid bias and discrimination based on factors like race, gender, or ethnicity. Developers should carefully select training data, regularly evaluate, and address biases, and promote transparency in algorithmic decisionmaking.",
        "General principles on AI": [
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Augmentation, not replacement. AI systems should augment, not displace, workers.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "In summary, ethical AI requires a multidimensional approach that considers fairness, transparency, privacy, accountability, human oversight, social impact, testing, and continuous improvement.",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-KqWfv_mXvr",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-KqWfv_mXvr",
      "name": "India: National Programme on Artificial Intelligence (NPAI) Skilling Framework",
      "index": 483,
      "createdAt": "2025-04-29T06:33:28.411Z",
      "updatedAt": "2025-04-29T07:17:34.495Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-KqWfv_mXvr"
    },
    {
      "values": {
        "Policy Name": "Visioning the Future by Transforming Education-National Education Strategy",
        "Policy creator": [
          "Malta"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "It explicitly mentions professional training on AI for teachers​, AI literacy and digital citizenship skills for students​ and the use of AI for data analysis and education policy planning​.",
        "File": [
          "Maltese National Education Strategy 2024-2030.pdf"
        ],
        "Year of Commencement or Creation": "2024",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "
        ],
        "Governance practices employed": [
          "Communicates a stance. It expresses a hope for the future of AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://www.gov.mt/en/publicconsultation/Pages/2023/NL-0051-2023.aspx",
        "Series #": "",
        "Title": "Malta: Visioning the Future by Transforming Education-National Education Strategy",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "Eventually, it is the Ministry’s plan to employ AI technologies for data analysis and forecasting, the results of which will serve as evidence for future policies and strategies.",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "Internationally, equity and inclusion have been set high on the agenda since there is a general understanding that social gaps have been exacerbated following the pandemic, a higher rate of migration and due to the digital divide28. The Ministry is committed to addressing social fragmentation and inequalities since it is our belief that education is a fundamental tool through which everyone is given the opportunity to reach their potential. To this end, one of the first steps to be taken to understand how different policies and decisions are impacting different groups of students, is employing a system-wide data disaggregation exercise29, which is also one of the SDG indicators for quality education. Eventually, it is the Ministry’s plan to employ AI technologies for data analysis and forecasting, the results of which will serve as evidence for future policies and strategies.",
        "General principles on AI": [
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-SL_Hq9MiTY",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-SL_Hq9MiTY",
      "name": "Malta: Visioning the Future by Transforming Education-National Education Strategy",
      "index": 482,
      "createdAt": "2025-04-28T06:34:16.612Z",
      "updatedAt": "2025-04-28T07:13:32.996Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-SL_Hq9MiTY"
    },
    {
      "values": {
        "Policy Name": "Our AI: Our Ambition for France",
        "Policy creator": [
          "France"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The policy discusses AI’s integration into public services including education",
        "File": [
          "France-Our AI Our Ambition for France.pdf"
        ],
        "Year of Commencement or Creation": "2024",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Develops tools. It provides tools and place them in the hands of businesses or governments"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://www.info.gouv.fr/upload/media/content/0001/09/02cbcb40c3541390be391feb3d963a4126b12598.pdf",
        "Series #": "",
        "Title": "France: Our AI: Our Ambition for France",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "Finally, AI systems should be used to improve the quality of public services. Artificial intelligence can improve public services, by helping to personalize education, give patients more time, better support and anticipate professional transitions, and reduce bureaucracy.\nWe also need to invest in training for everyone, at every age: young people in school and afterschool, specialized and non-specialized students, employees, the self-employed and publicsector workers, retirees This means preparing for tomorrow's professions, in particular by structuring a range of hybrid higher education courses, such as \"AI + biology\" and \"law + AI\", or by creating AI chairs in design schools We must also enable the use of AI in today's professions, for example by planning an AI awareness course for all civil servants\n",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "Today, it's up to us to take advantage of AI by putting it in its rightful place: that of a technological means at the service of an ambition for humanity, equality, solidarity, justice, prosperity and freedom.\nAlgorithms contribute to inequalities in work and employment The massification of uses is accompanied by a growing environmental impact.",
        "General principles on AI": [
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power."
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-H-8vLe7oN4",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-H-8vLe7oN4",
      "name": "France: Our AI: Our Ambition for France",
      "index": 481,
      "createdAt": "2025-04-28T06:14:24.710Z",
      "updatedAt": "2025-04-28T06:33:47.438Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-H-8vLe7oN4"
    },
    {
      "values": {
        "Policy Name": "Policies for the digitalisation of education and training until 2027",
        "Policy creator": [
          "Finland"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The policy focuses on digitalisation across the education system, supporting the development of digital competence, digital infrastructures, and knowledge-based management, and no AI-related regulations, but references principles that could inform the governance of AI in education.",
        "File": [
          "Policies for the digitalisation of education and training until 2027.pdf"
        ],
        "Year of Commencement or Creation": "2023",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://julkaisut.valtioneuvosto.fi/bitstream/handle/10024/165248/OKM_2023_48.pdf?sequence=1&isAllowed=y",
        "Series #": "",
        "Title": "Finland: Policies for the digitalisation of education and training until 2027",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-hQimX1iSvX",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-hQimX1iSvX",
      "name": "Finland: Policies for the digitalisation of education and training until 2027",
      "index": 480,
      "createdAt": "2025-04-28T04:30:01.203Z",
      "updatedAt": "2025-04-28T06:13:13.374Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-hQimX1iSvX"
    },
    {
      "values": {
        "Policy Name": "The Digital Switzerland Strategy 2025",
        "Policy creator": [
          "Switzerland"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "not focus on AI specifically in education.",
        "File": "",
        "Year of Commencement or Creation": "2024",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "Switzerland: The Digital Switzerland Strategy 2025",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-a0B8yTB0oB",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-a0B8yTB0oB",
      "name": "Switzerland: The Digital Switzerland Strategy 2025",
      "index": 479,
      "createdAt": "2025-04-28T04:21:46.974Z",
      "updatedAt": "2025-04-28T04:28:59.417Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-a0B8yTB0oB"
    },
    {
      "values": {
        "Policy Name": "AI Opportunity Action Plan",
        "Policy creator": [
          "United Kingdom"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This policy is included because it explicitly proposes developing AI talent through education systems and anticipates AI being used as a tool for assessment within the education sector.",
        "File": [
          "UK-AI Opportunity Action Plan.pdf"
        ],
        "Year of Commencement or Creation": "2025",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Tertiary",
          "Vocational or Professional"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Communicates a stance. It expresses a hope for the future of AI",
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "United Kingdom: AI Opportunity Action Plan",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "AI directly benefits working people by improving health care and education and how citizens interact with their government.",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women. Achieving parity would mean thousands of additional workers.",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-BlChGUymUq",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-BlChGUymUq",
      "name": "United Kingdom: AI Opportunity Action Plan",
      "index": 478,
      "createdAt": "2025-04-24T05:16:56.617Z",
      "updatedAt": "2025-04-24T05:30:58.621Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-BlChGUymUq"
    },
    {
      "values": {
        "Policy Name": "Introduction to AI Assurance",
        "Policy creator": [
          "United Kingdom"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "It illustrates a practical approach to AI governance through internal organisational processes. The use of structured ‘risk assessments’—including staff workshops, detailed questionnaires, and internal audits—demonstrates how educational technology providers can identify and mitigate potential harms (e.g. to user safety, institutional reputation, or learning outcomes).",
        "File": [
          "UK-Introduction to AI Assurance.pdf"
        ],
        "Year of Commencement or Creation": "2024",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. "
        ],
        "Governance practices employed": [
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "United Kingdom: Introduction to AI Assurance",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "Risk assessments are used to consider and identify a range of potential risks that might arise  from the development and/or deployment of an  AI product/systems.",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "Impact assessments are used to anticipate the wider  effects of a system/product on the environment,  equality, human rights, data protection, or other  outcomes.",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "Impact assessments are used to anticipate the wider  effects of a system/product on the environment,  equality, human rights, data protection, or other  outcomes.",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-l6Q9QbdRI3",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-l6Q9QbdRI3",
      "name": "United Kingdom: Introduction to AI Assurance",
      "index": 477,
      "createdAt": "2025-04-24T05:02:50.459Z",
      "updatedAt": "2025-04-24T05:15:49.398Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-l6Q9QbdRI3"
    },
    {
      "values": {
        "Policy Name": "Council of Europe Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law",
        "Policy creator": [
          "European Union"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "only refer to the rights of children, but not education",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "European Union: Council of Europe Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "IO"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-aC9vh-8Ol5",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-aC9vh-8Ol5",
      "name": "European Union: Council of Europe Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law",
      "index": 476,
      "createdAt": "2025-04-24T04:54:47.382Z",
      "updatedAt": "2025-04-24T05:01:59.943Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-aC9vh-8Ol5"
    },
    {
      "values": {
        "Policy Name": "Policy for the responsible use of AI in government",
        "Policy creator": [
          "Australia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "a coordinated approach to government’s use of AI and has been designed to complement and strengthen the existing frameworks, may provide important insights for education department",
        "File": "",
        "Year of Commencement or Creation": "2024",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "Australia: Policy for the responsible use of AI in government",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-78VCmThDKv",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-78VCmThDKv",
      "name": "Australia: Policy for the responsible use of AI in government",
      "index": 475,
      "createdAt": "2025-04-24T04:48:21.284Z",
      "updatedAt": "2025-04-24T04:52:03.544Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-78VCmThDKv"
    },
    {
      "values": {
        "Policy Name": "Guide On The Use Of Generative AI",
        "Policy creator": [
          "Canada"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Involved generative AI may not be suited for use in administrative [such as in the education field] decision-making at this stage.",
        "File": [
          "BT48-37-2023-eng.pdf"
        ],
        "Year of Commencement or Creation": "2023",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "[N/A]"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "Canada: Guide On The Use Of Generative AI",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "However, generative AI may not be suited for use in administrative  decision-making at this stage. The design and functioning of generative  models can limit federal institutions’ ability to ensure transparency,  8 accountability and fairness in decisions made by generative AI systems or  informed by their outputs. As well, the terms of use for the generative AI  products of many leading technology companies prohibit using their  products to make high-impact decisions. For example, OpenAI instructs  users not to employ ChatGPT in decisions about credit, employment,  educational institutions, or public assistance services; law enforcement and  criminal justice; and migration and asylum.",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Issue: generative AI poses risks to human rights, privacy, intellectual property protection, and procedural fairness",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "Risks could also arise from the opacity of generative AI models and their  potential for producing inaccurate, biased or inconsistent outputs. This  opacity makes it difficult to trace and understand how the AI system  produces outputs, which can undermine procedural fairness in instances  where a federal institution is obliged to provide clients with reasons for  administrative decisions, such as decisions to deny benefits. The quality of AI outputs can also impact individuals’ legal rights. For example, biased  outputs could lead to discrimination in services, potentially violating human  rights.\nTo maintain public trust and ensure the responsible use of generative AI  tools, federal institutions should align with the “FASTER” principles-Fair: ensure that content from these tools does not include or amplify  biases and that it complies with human rights, accessibility, and  procedural and substantive fairness obligations",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Augmentation, not replacement. AI systems should augment, not displace, workers.",
          "Bias testing. AI systems should be tested for bias. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Environmental wellbeing. The use of AI should not harm the environment. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "This guide also seeks to raise awareness and foster coordination among  federal institutions. It highlights the importance of engaging key  stakeholders before deploying generative AI tools for public use and before  using them for purposes such as service delivery.",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-7EwyhnaVd0",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-7EwyhnaVd0",
      "name": "Canada: Guide On The Use Of Generative AI",
      "index": 474,
      "createdAt": "2025-04-24T04:13:43.970Z",
      "updatedAt": "2025-04-24T04:47:33.413Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-7EwyhnaVd0"
    },
    {
      "values": {
        "Policy Name": "Executive Order On Advancing Racial Equity And Support For Underserved Communities Through The Federal Government",
        "Policy creator": [
          "United States"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "mentioned pursuing educational equity so that our Nation’s schools put every student on a path to success, but not AI-related",
        "File": "",
        "Year of Commencement or Creation": "2023",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "United States: Executive Order On Advancing Racial Equity And Support For Underserved Communities Through The Federal Government",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i--IrNbfj3Fx",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i--IrNbfj3Fx",
      "name": "United States: Executive Order On Advancing Racial Equity And Support For Underserved Communities Through The Federal Government",
      "index": 473,
      "createdAt": "2025-04-24T04:05:32.364Z",
      "updatedAt": "2025-04-24T04:12:42.874Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui--IrNbfj3Fx"
    },
    {
      "values": {
        "Policy Name": "National framework for the assurance of artificial intelligence in government",
        "Policy creator": "Australia",
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Instead of focusing on technical detail, the framework sets foundations across all aspects of government, so including education.",
        "File": [
          "National framework for the assurance of artificial intelligence in government.pdf"
        ],
        "Year of Commencement or Creation": "2024",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Human rights-centred. The technology must be consistent with human rights. ",
          "Information. Information about the technology in use should be readily available. ",
          "Managing bias. The risk of bias should be managed with care. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Trust. Organisations seeking to incorporate AI into educational settings must build trust.",
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. ",
          "Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology."
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "Australia: National framework for the assurance of artificial intelligence in government",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "AI systems should respect human rights, diversity and the autonomy of individuals.\nGovernments should involve people with different lived experiences, including marginalisation, throughout the lifecycles of a use case to gather informed perspectives,  remove preconceptions and avoid overlooking important considerations.",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "Governments should ensure high-quality data and algorithmic design. Audits of AI inputs and outputs for unfair biases, data quality statements and other data  governance and management practices may assist to understand and mitigate bias in AI systems.",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "Australia's 8 AI Ethics Principles, demonstrating how governments can practically apply them to their assurance of AI. \nHuman, societal and environmental wellbeing: Throughout their lifecycle, AI systems should benefit  individuals, society and the environment\nHuman-centred values: AI systems should respect human rights, diversity and the autonomy of individuals.\nFairness: AI systems should be inclusive and accessible, and should not involve or result in unfair discrimination against individuals, communities or groups.\nPrivacy protection and security: AI systems should respect and uphold privacy rights of individuals and ensure the protection of data.\nReliability and safety: Throughout their lifecycle, AI systems should reliably operate in accordance with their intended purpose.\nTransparency and explainability: There should be transparency and responsible disclosure so people can understand when they are being significantly impacted by AI, and can find out when an AI system is engaging with them.\nContestability: When an AI system significantly impacts a person, community,  group or environment, there should be a timely process to allow  people to challenge the use or outcomes of the AI system.\nAccountability: Those responsible for the different phases of the AI  system lifecycle should be identifiable and accountable for the outcomes of the AI systems, and human oversight of AI systems should be enabled.",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-OCnVnwg791",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-OCnVnwg791",
      "name": "Australia: National framework for the assurance of artificial intelligence in government",
      "index": 472,
      "createdAt": "2025-03-03T02:22:23.278Z",
      "updatedAt": "2025-03-04T23:49:34.774Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-OCnVnwg791"
    },
    {
      "values": {
        "Policy Name": "Italian Strategy for Artificial Intelligence 2024-2026",
        "Policy creator": "Italy",
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Education as one of the four marco-area in the strategic actions",
        "File": [
          "Italian Strategy for Artificial Intelligence 2024-2026.pdf"
        ],
        "Year of Commencement or Creation": "2024",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Tertiary",
          "Primary",
          "Secondary"
        ],
        "Principles on AI in education": [
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ",
          "Critical thinking. Use of the tools should not come at the cost of critical thinking.  ",
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "Italy: Italian Strategy for Artificial Intelligence 2024-2026",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "To harness the benefits of AI, however, high professional skills capable of developing and managing algorithms and AI systems are required...As a preliminary to any strategic action, it is therefore essential to address this structural problem by deploying a major plan to strengthen, integrate, and disseminate AI knowledge and related digital skills throughout the education system: from Higher Technical Institutes (ITS) to universities, with particular attention to research doctorates.\nThe development of a national strategy for Artificial Intelligence must be based on the premise that, in this exceptionally dynamic context, no worker can be left behind. In order for AI-derived applications to have positive effects on the whole society, reducing risks, it will be necessary to further expand the concept of “education” by aiming in Italy to implement an AI literacy process that involves schools, workers, and all citizens, with attention to the most vulnerable categories.\nObjectives: Promote widespread university education on AI; Implement educational pathways on AI in schools\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "(Design of Intalian large molecule models)Development should focus on specific applications contextualized in significant application domains for our country, for example in Public Administration or in the health sector, that fully comply with European values and regulations in terms of: (i) transparency of training data, to ensure compliance with non-discrimination laws, privacy (GDPR), human rights protection, providing reliable information on the sources from which content is generated;",
        "Does the policy reflect the principle of equity/equality?": "[N/A]",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-4zUYKmQq-a",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-4zUYKmQq-a",
      "name": "Italy: Italian Strategy for Artificial Intelligence 2024-2026",
      "index": 471,
      "createdAt": "2025-03-03T01:04:13.795Z",
      "updatedAt": "2025-03-03T02:18:41.052Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-4zUYKmQq-a"
    },
    {
      "values": {
        "Policy Name": "Continental Artificial Intelligence Strategy",
        "Policy creator": "African Union",
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This includes a section on expanding AI adoption in the education sector in Africa with recommendation and associated actions",
        "File": [
          "African Union-Continental Artificial Intelligence Strategy.pdf"
        ],
        "Year of Commencement or Creation": "2024",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": "",
        "Title": "African Union: Continental Artificial Intelligence Strategy",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "IO"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "Despite the risks, AI has the potential to facilitate higher-order thinking if guided by proper instructional design and support formative assessment of basic skills.",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Human Rights and Human Dignity—The production, development, use and assessment of AI systems in Africa will always uphold human dignity, gender equality and respect and promote all the human rights set out under the African Charter on Human and Peoples’ Rights and its subsidiary instruments, as well as the Universal Declaration on Human Rights and related instruments of international human rights law.",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "Special efforts are needed from continental, regional and national agencies and governments to ensure that the development and adoption of AI are inclusive and benefit all Africans, empower women and girls, and underrepresented groups and respect Africa’s cultural and linguistic diversity.",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-ViAANnebu8",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ViAANnebu8",
      "name": "African Union: Continental Artificial Intelligence Strategy",
      "index": 470,
      "createdAt": "2025-03-03T00:55:02.832Z",
      "updatedAt": "2025-03-03T01:01:16.746Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ViAANnebu8"
    },
    {
      "values": {
        "Policy Name": "Inquiry into the Use of Generative Artificial Intelligence in the Australian Education System",
        "Policy creator": [
          "Australia"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is directly on the topic. Lots of interesting submissions.\nSubmissions – Parliament of Australia (aph.gov.au)",
        "File": "",
        "Year of Commencement or Creation": "2023",
        "Relevance Type": [
          "Policy is about AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "[N/A: This is an inquiry, and does not presuppose the answer to questions]"
        ],
        "Governance practices employed": [
          "Seeks information. It gathers inputs on public sentiment about AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://www.aph.gov.au/Parliamentary_Business/Committees/House/Employment_Education_and_Training/AIineducation/Terms_of_Reference",
        "Series #": 21,
        "Title": "Australia: Inquiry into the Use of Generative Artificial Intelligence in the Australian Education System",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "“The House of Representatives Standing Committee on Employment, Education and Training will inquire into the issues and opportunities presented by generative Artificial Intelligence (AI), and comprehensively explore current and future impacts on Australia’s early childhood education, schools, and higher education sectors.\n The inquiry will include consideration of:\nThe strengths and benefits of generative AI tools for children, students, educators and systems and the ways in which they can be used to improve education outcomes;\nThe future impact generative AI tools will have on teaching and assessment practices in all education sectors, the role of educators, and the education workforce generally;\nThe risks and challenges presented by generative AI tools, including in ensuring their safe and ethical use and in promoting ongoing academic and research integrity;\nHow cohorts of children, students and families experiencing disadvantage can access the benefits of AI;\nInternational and domestic practices and policies in response to the increased use of generative AI tools in education, including examples of best practice implementation, independent evaluation of outcomes, and lessons applicable to the Australian context; and\nRecommendations to manage the risks, seize the opportunities, and guide the potential development of generative AI tools including in the area of standards.”\n\nNote that the submissions might be interesting as secondary materials. ",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "The terms of reference do not use the language of “human rights”. ",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "The terms of reference do not use the language of “equity”. ",
        "General principles on AI": [
          "[N/A]"
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-dsHz67wttW",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-dsHz67wttW",
      "name": "Australia: Inquiry into the Use of Generative Artificial Intelligence in the Australian Education System",
      "index": 18,
      "createdAt": "2024-06-01T06:56:56.730Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-dsHz67wttW"
    },
    {
      "values": {
        "Policy Name": "Estonia 2035 + 2023 Action Plan",
        "Policy creator": [
          "Estonia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "General remarks on Estonia’s national strategy. ",
        "File": [
          "Eesti 2035_PUHTAND ÜLDOSA_210512_ENG_0.pdf",
          "Eesti 2035__tegevuskava_ENG_30.06 2.pdf"
        ],
        "Year of Commencement or Creation": "2021 (Estonia 2035), 2023 (Action Plan)",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "",
        "Series #": 13,
        "Title": "Estonia: Estonia 2035 + 2023 Action Plan",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-_yxkr4vXdf",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_yxkr4vXdf",
      "name": "Estonia: Estonia 2035 + 2023 Action Plan",
      "index": 17,
      "createdAt": "2024-06-01T06:34:59.151Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_yxkr4vXdf"
    },
    {
      "values": {
        "Policy Name": "Estonia Education Strategy 2035",
        "Policy creator": [
          "Estonia"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is directly on point — part of their education strategy involves using technology to make progress. Note I have included some supplementary documents in addition to the actual strategy. The big focus is “digital pedagogy”. ",
        "File": [
          "Estonia's Education Minister Kristina Kallas on the challenges and opportunities of AI in learning and empowerment [Q&A] - TNGlobal.pdf",
          "Estonia - Education Strategy 2021-2035 _ Digital Skills and Jobs Platform.pdf",
          "Estonia to unleash AI for personalisation of education.pdf",
          "The AI debate in Estonian education_ A balanced approach - Education Estonia.pdf",
          "estonia_education_strategy_2021-2023.pdf"
        ],
        "Year of Commencement or Creation": "2021",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://technode.global/2024/05/17/estonias-education-minister-kristina-kallas-on-the-challenges-and-opportunities-of-ai-in-learning-and-empowerment-qa/",
        "Series #": 12,
        "Title": "Estonia: Estonia Education Strategy 2035",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "Digital pedagogy:\n“Educators are familiar with trends, opportunities, risks and methodologies related to new technologies, and apply the technologies in a purposeful way. Smart learning resources and methodology support captivating and effective learning and teaching, and help to give and receive immediate and substantial feedback.” (2035 Education Strategy (English), p 19)\nSmart learning resources:\n“Smart learning resources allow personalised and adaptive learning by means of technology. Smart learning resources enable the empowerment of learners and the addition of value to the learning process through the use of technology (learning analytics, AI, etc.).” (2035 Education Strategy (English), p 36)\nSummary \n“Educators are familiar with trends, opportunities, risks and methodologies related to new technologies, and apply the technologies in a purposeful way. Smart learning resources and methodology support captivating and effective learning and teaching, and help to give and receive immediate and substantial feedback. Essential action is personalisation and diversification of learning and supporting learning through digital solutions. It is necessary to: promote the development and implementation of diverse methods of learning and teaching (including digital pedagogy); develop and use digital solutions as tools for educational innovation that enable the diversification and personalisation of education, including assessment for learning; raise awareness among participants in the learning process of the opportunities and risks of the information society; adopt a systematic approach to the introduction of new solutions; improve access to Estonian – language education and learning of Estonian by introducing digital solutions.” (Education Strategy Summary Document, no pinpoint)\nInterview with the Minister leading this:\n“Minister Kallas acknowledges the challenges of teacher shortages and the need for curriculum adaptation in light of the rapid emergence of AI. However, she remains optimistic, emphasizing the importance of investing in teacher training, developing AI-enhanced learning tools, and fostering collaboration between the public and private sectors. Estonia’s groundbreaking initiatives, such as the AI-enabled infrastructure for personalized learning and the ProgeTiiger Program for teaching programming skills, have garnered international attention. Kallas envisions further collaboration with countries like Singapore, sharing insights and expertise to advance the field of EdTech innovation.” (Interview doc, no pinpoint)",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "N/A",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "N/A",
        "General principles on AI": [
          "[N/A]"
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": true,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-viyYHzDKAf",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-viyYHzDKAf",
      "name": "Estonia: Estonia Education Strategy 2035",
      "index": 16,
      "createdAt": "2024-06-01T06:29:39.281Z",
      "updatedAt": "2024-06-03T23:12:54.856Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-viyYHzDKAf"
    },
    {
      "values": {
        "Policy Name": "Guidance for generative AI in education and research",
        "Policy creator": [
          "UNESCO"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Highly relevant. ",
        "File": [
          "386693eng.pdf"
        ],
        "Year of Commencement or Creation": "2023",
        "Relevance Type": [
          "Policy is about AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Academic integrity. Students should be supported to use AI tools ethically in their work, which extends to appropriate attribution.",
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Critical thinking. Use of the tools should not come at the cost of critical thinking.  ",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Human rights-centred. The technology must be consistent with human rights. ",
          "Information. Information about the technology in use should be readily available. ",
          "Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.",
          "Managing bias. The risk of bias should be managed with care. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.",
          "Promoting diversity. Technology should be used to expose users to diverse perspectives. ",
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": 5,
        "Title": "UNESCO: Guidance for generative AI in education and research",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "IO"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "To properly understand where they are coming from, note the introduction:\n“However, a thematic set of guidance on GenAI for education should not be understood as a claim that GenAI is the solution to education’s fundamental challenges. Despite the media hyperbole, it is unlikely that GenAI alone will solve any of the problems facing education systems around the world. In responding to long-standing educational issues, it is key to uphold the idea that human capacity and collective action, and not technology, is the determining factor in effective solutions to fundamental challenges faced by societies.” (p 7)\nThere is so much in here that I suggest it is better to read pp 24 to 27\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“UNESCO’s 2021 Recommendation on the Ethics of Artificial Intelligence provides the requisite normative framework to start addressing the multiple controversies around generative AI, including those that pertain to education and research. It is based on a human-centred approach to AI which advocates that the use of AI should be at the service of the development of human capabilities for inclusive, just and sustainable futures. Such an approach must be guided by human rights principles, and the need to protect human dignity and the cultural diversity that defines the knowledge commons. In terms of governance, a human-centred approach requires proper regulation that can ensure human agency, transparency and public accountability.” (p 18)\n“EdGPT. Finally, there is also a need for robust research to ensure that EdGPT does not undermine students’ human rights nor disempower teachers.” (p 13)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "Data poverty: Kalervo Gulson \nAs noted earlier, GenAI relies upon huge amounts of data and massive computing power in addition to its iterative innovations in AI architectures and training methods, which are mostly only available to the largest international technology companies and a few economies (mostly the United States, People’s Republic of China, and to a lesser extent Europe). This means that the possibility to create and control GenAI is out of reach of most companies and most countries, especially those in the Global South. \nAs access to data becomes increasingly essential for the economic development of countries and for the digital opportunities of individuals, those countries and people who do not have access to or cannot afford enough data are left in a situation of ‘data poverty’ (Marwala, 2023). The situation is similar for access to computing power. The rapid pervasion of GenAI in technologically advanced countries and regions has accelerated exponentially the generation and processing of data, and has simultaneously intensified the concentration of AI wealth in the Global North. As an immediate consequence, the data-poor regions have been further excluded and put at long-term risk of being colonized by the standards embedded in the GPT models. The current ChatGPT models are trained on data from online users which reflect the values and norms of the Global North, making them inappropriate for locally relevant AI algorithms in data-poor communities in many parts of the Global South or in more disadvantaged communities in the Global North. (p 14)\nA few other references:\nA starting point for this is the 2022 AI and education: guidance for policy-makers (UNESCO, 2022b). It proposes a comprehensive set of recommendations to guide governments in the development and implementation of sector-wide policies on AI and education with a focus on promoting quality education, social equity and inclusion. Most of the recommendations remain applicable and can be further adapted to guide the formulation of specific policies on GenAI in education. The following eight specific measures for the planning of policies on GenAI in education and research are proposed here to complement this existing guidance. (p 24)\nAccess and equity: GenAI systems in education may exacerbate existing disparities in access to technology and educational resources, further deepening inequities. (p 36)",
        "General principles on AI": [
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Augmentation, not replacement. AI systems should augment, not displace, workers."
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "Note: It is hard to uncouple general and education-specific principles. It is clear that the general principles are intended to apply to education (indeed, they are expressly restated), but one can infer that the narrower principles are intended to apply more broadly. ",
        "WC Favourite": true,
        "Notable Case Studes - Examples of AI in Education": "See, for example, p 33 — “Socratic challenger” and “Advisor for project-based learning”",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-3KYj_XmjkW",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-3KYj_XmjkW",
      "name": "UNESCO: Guidance for generative AI in education and research",
      "index": 59,
      "createdAt": "2024-05-30T22:56:41.285Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-3KYj_XmjkW"
    },
    {
      "values": {
        "Policy Name": "Shaping Digital Education Policy",
        "Policy creator": [
          "European Union"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Would have been relevant—but seems to have been a precursor to policies that have now been created. ",
        "File": [
          "TA-9-2021-0095_EN.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "",
        "Series #": 4,
        "Title": "European Union: Shaping Digital Education Policy",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "IO"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-zVxsoTDPNe",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-zVxsoTDPNe",
      "name": "European Union: Shaping Digital Education Policy",
      "index": 172,
      "createdAt": "2024-05-30T22:52:27.615Z",
      "updatedAt": "2024-06-04T00:44:52.789Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-zVxsoTDPNe"
    },
    {
      "values": {
        "Policy Name": "AI Act (Resolution on the text of the AI Act)",
        "Policy creator": [
          "European Union"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Note that this regulation lists education as high-risk. ",
        "File": [
          "TA-9-2024-0138_EN.pdf"
        ],
        "Year of Commencement or Creation": "2024",
        "Relevance Type": [
          "Policy has an AI in education component",
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ",
          "Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.",
          "Human rights-centred. The technology must be consistent with human rights. ",
          "Managing bias. The risk of bias should be managed with care. ",
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Transparency (transparency to government). The extent to which AI is used in educational settings should be clear to the government. ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.",
          "Interoperability. AI systems deployed in educational settings should be able to work with other systems. "
        ],
        "Governance practices employed": [
          "Proposes law. It proposes a law or provides a draft law on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence",
        "Series #": 3,
        "Title": "European Union: AI Act (Resolution on the text of the AI Act)",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "IO"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "Note: Given that the entire scheme for “high-risk” systems applies to AI in education, there is some duplication here. The norms that directly apply to AI in education are expressed generally, so both sets of boxes have been ticked. I have not spent a disproportionate amount of time thinking about whether the draft AI Act impliedly expresses particular norms. It would be worth getting Jose-Miguel to look over this record and tweak it using his working knowledge of the scheme. \nNote 2: No page numbers provided in text. \n\nSpecification of education as high-risk:\n“Education and vocational training: (a) AI systems intended to be used to determine access or admission or to assign natural persons to educational and vocational training institutions at all levels; (b) AI systems intended to be used to evaluate learning outcomes, including when those outcomes are used to steer the learning process of natural persons in educational and vocational training institutions at all levels; (c) AI systems intended to be used for the purpose of assessing the appropriate level of education that an individual will receive or will be able to access, in the context of or within educational and vocational training institutions; (d) AI systems intended to be used for monitoring and detecting prohibited behaviour of students during tests in the context of or within educational and vocational training institutions.” \nOpportunity:\n“By improving prediction, optimising operations and resource allocation, and personalising digital solutions available for individuals and organisations, the use of AI can provide key competitive advantages to undertakings and support socially and environmentally beneficial outcomes, for example in... education” \n“The deployment of AI systems in education is important to promote high-quality digital education and training and to allow all learners and teachers to acquire and share the necessary digital skills and competences, including media literacy, and critical thinking, to take an active part in the economy, society, and in democratic processes.” \nHarm:\n“Considering the imbalance of power in the context of work or education, combined with the intrusive nature of these systems, such systems could lead to detrimental or unfavourable treatment of certain natural persons or whole groups thereof. Therefore, the placing on the market, the putting into service, or the use of AI systems intended to be used to detect the emotional state of individuals in situations related to the workplace and education should be prohibited. That prohibition should not cover AI systems placed on the market strictly for medical or safety reasons, such as systems intended for therapeutical use.” \n“However, AI systems used in education or vocational training, in particular for determining access or admission, for assigning persons to educational and vocational training institutions or programmes at all levels, for evaluating learning outcomes of persons, for assessing the appropriate level of education for an individual and materially influencing the level of education and training that individuals will receive or will be able to access or for monitoring and detecting prohibited behaviour of students during tests should be classified as high-risk AI systems, since they may determine the educational and professional course of a person’s life and therefore affect that person’s ability to secure a livelihood. When improperly designed and used, such systems may be particularly intrusive and may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation.” \nImpact assessments:\n“In order to efficiently ensure that fundamental rights are protected, deployers of high-risk AI systems that are bodies governed by public law, or private operators providing public services and operators deploying certain high-risk AI systems listed in an annex to this Regulation, such as banking or insurance entities, should carry out a fundamental rights impact assessment prior to putting it into use. Services important for individuals that are of public nature may also be provided by private entities. Private operators providing such services of public nature are linked to tasks in the public interest such as in the area of education, healthcare, social services, housing, administration of justice. The aim of the fundamental rights impact assessment is for the deployer to identify the specific risks to the rights of individuals or groups of individuals likely to be affected, identify measures to be taken in the case of a materialisation of those risk. The impact assessment should apply to the first use of the high-risk AI system, and should be updated when the deployer considers that any of the relevant factors have changed. The impact assessment should identify the deployer’s relevant processes in which the high-risk AI system will be used in line with its intended purpose, and should include a description of the period of time and frequency in which the system is intended to be used as well as of specific categories of natural persons and groups who are likely to be affected in the specific context of use.” ",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "The whole regime is built around rights protections. Examples can be found everywhere. Just one example:\n“In order to efficiently ensure that fundamental rights are protected, deployers of high-risk AI systems that are bodies governed by public law, or private operators providing public services and operators deploying certain high-risk AI systems listed in an annex to this Regulation, such as banking or insurance entities, should carry out a fundamental rights impact assessment prior to putting it into use. Services important for individuals that are of public nature may also be provided by private entities. Private operators providing such services of public nature are linked to tasks in the public interest such as in the area of education, healthcare, social services, housing, administration of justice. The aim of the fundamental rights impact assessment is for the deployer to identify the specific risks to the rights of individuals or groups of individuals likely to be affected, identify measures to be taken in the case of a materialisation of those risk. The impact assessment should apply to the first use of the high-risk AI system, and should be updated when the deployer considers that any of the relevant factors have changed. The impact assessment should identify the deployer’s relevant processes in which the high-risk AI system will be used in line with its intended purpose, and should include a description of the period of time and frequency in which the system is intended to be used as well as of specific categories of natural persons and groups who are likely to be affected in the specific context of use.” ",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "One of the key concerns specific to education is the perpetuation of discrimination:  \n“However, AI systems used in education or vocational training, in particular for determining access or admission, for assigning persons to educational and vocational training institutions or programmes at all levels, for evaluating learning outcomes of persons, for assessing the appropriate level of education for an individual and materially influencing the level of education and training that individuals will receive or will be able to access or for monitoring and detecting prohibited behaviour of students during tests should be classified as high-risk AI systems, since they may determine the educational and professional course of a person’s life and therefore affect that person’s ability to secure a livelihood. When improperly designed and used, such systems may be particularly intrusive and may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation.” \n",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "Lots to say on this — JM already an expert in this Act, so will defer spending a lot of time extracting quotations. ",
        "WC Favourite": true,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-eCAcTesvI4",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-eCAcTesvI4",
      "name": "European Union: AI Act (Resolution on the text of the AI Act)",
      "index": 171,
      "createdAt": "2024-05-30T22:45:59.556Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-eCAcTesvI4"
    },
    {
      "values": {
        "Policy Name": "European Parliament resolution of 19 May 2021 on artificial intelligence in education, culture and the audiovisual sector (2020/2017(INI))",
        "Policy creator": [
          "European Union"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is directly relevant—and very broad. It covers (almost) as many principles as one could think of. ",
        "File": [
          "TA-9-2021-0238_EN (2).pdf"
        ],
        "Year of Commencement or Creation": "2021",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ",
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. ",
          "Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Human rights-centred. The technology must be consistent with human rights. ",
          "Managing bias. The risk of bias should be managed with care. ",
          "Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.",
          "Competition. There should be sufficient competition in the market to ensure that one AI edtech provider does not have excessive market power. ",
          "Interoperability. AI systems deployed in educational settings should be able to work with other systems. ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Transparency (transparency to government). The extent to which AI is used in educational settings should be clear to the government. "
        ],
        "Governance practices employed": [
          "Communicates a stance. It expresses a hope for the future of AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://www.europarl.europa.eu/doceo/document/TA-9-2021-0238_EN.html",
        "Series #": 1,
        "Title": "European Union: European Parliament resolution of 19 May 2021 on artificial intelligence in education, culture and the audiovisual sector (2020/2017(INI))",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "IO"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "Opportunities:\n“whereas AI has particular potential to offer solutions for the day-to-day challenges of the education sector, such as the personalisation of learning, monitoring learning difficulties, the automation of subject-specific content/knowledge, providing better professional training and supporting the transition to a digital society” (paragraph X)\n“whereas AI could have practical applications in terms of reducing the administrative work of educators and educational institutions, freeing up time for their core teaching and learning activities” (paragraph Y)\n“whereas AI-enabled personalised learning experiences can not only help to increase students’ motivation and enable them to reach their full potential, but also reduce drop-out rates” (paragraph AA)\n“Highlights that the use of AI in education systems brings a wide range of possibilities, opportunities and tools for making it more innovative, inclusive, efficient and increasingly effective by introducing new high-quality learning methods that are quick, personalised and student-centric; stresses, however, that as it will impact education and social inclusion, the availability of such tools must be ensured for all social groups by establishing equal access to education and learning and leaving no one behind, especially people with disabilities;” (paragraph 31)\n“Stresses that the real objective of AI in education systems should be to make education as individualised as possible, offering students personalised academic paths in line with their strengths and weaknesses and didactic material tailored to their characteristics, while maintaining educational quality and the integrating principle of our education systems” (paragraph 33)\nOpportunities to understand:\n“whereas it is essential to ensure that all people in the Union acquire the necessary skills from an early age in order to better understand the capabilities and limitations of AI” (paragraph U)\nHarm:\n“whereas the application of AI in education raises concerns around the ethical use of data, learners’ rights, data access and protection of personal data, and therefore entails risks to fundamental rights such as the creation of stereotyped models of learners’ profiles and behaviour that could lead to discrimination or risks of doing harm by the scaling-up of bad pedagogical practices;” (paragraph AD)\nAugmentation not replacement:\n“AI technologies cannot be used to the detriment or at the expense of in-person education, as teachers must not be replaced by any AI or AI-related technologies” (paragraph 34)\nProcurement:\n“encourages public authorities, in this regard, to incentivise the development and deployment of AI technologies through public funding and public procurement” (paragraph 46)\nCooperation and inclusion:\n“Stresses that the learning benefits of using AI in education will depend not only on AI itself, but on how teachers use AI in the digital learning environment to meet the needs of pupils, students and teachers; points out, therefore, the need for AI programmers to involve teaching communities in the development, deployment and use of AI technologies where possible, creating a nexus environment to form connections and cooperation between AI programmers, developers, companies, schools, teachers and other public and private stakeholders in order to create AI technologies that are suitable for real-life educational environments, reflect the age and developmental readiness of each learner and meet the highest ethical standards; highlights that educational institutions should only deploy trustworthy, ethical, human-centred technologies which are auditable at every stage of their lifecycle by public authorities and civil society; emphasises the advantages of free and open-source solutions in this regard; calls for schools and other educational establishments to be provided with the financial and logistical support as well as the expertise required to introduce solutions for the learning of the future;” (paragraph 35)\nTeacher training:\n“Highlights, moreover, the need to continuously train teachers so they can adapt to the realities of AI-powered education and acquire the necessary knowledge and skills to use AI technologies in a pedagogical and meaningful way, enabling them to fully embrace the possibilities offered by AI and to understand its limitations” (paragraph 36)\nInteroperability:\n“calls for the data used and produced by AI applications in education to be accessible, interoperable and of high quality, and to be shared with the relevant public authorities in an accessible way and with respect for copyright and trade secrets legislation; recalls that children constitute a vulnerable group who deserve particular attention and protection” (paragraph 43)\nSo much more could be included, but suffice it to say that all of the boxes ticked reflect clear statements by the European Parliament. ",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Human rights are built into this document—although they are not the only end pursued. Given acknowledged underinvestment in AI, there are also economic considerations at play. \n\nPerhaps the strongest statement:\n“Underlines the strategic importance of AI and related technologies for the Union; stresses that the approach to AI and its related technologies must be human-centred and anchored in human rights and ethics, so that AI genuinely becomes an instrument that serves people, the common good and the general interest of citizens;” (paragraph 1)\nMore education-specific: \n“Asserts that education, culture and the audiovisual sector are sensitive areas as far as the use of AI and related technologies is concerned, as they have the potential to impact on the cornerstones of the fundamental rights and values of our society” (paragraph 3)\n",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "There are many, many examples. Education-specific ones include: \n“whereas education and educational opportunities are a fundamental right; whereas the development, deployment and use of AI technologies in the education sector should be classified as high risk and subject to stricter requirements on safety, transparency, fairness and accountability;” (paragraph R)\n“whereas AI and related technologies can be used to improve learning and teaching methods, notably by helping education systems to use fair data to improve educational equity and quality, while promoting tailor-made curricula and better access to education and improving and automating certain administrative tasks; whereas equal and fair access to digital technologies and high-speed connectivity are required in order to make the use of AI beneficial to the whole of society; whereas it is of the utmost importance to ensure that digital education is accessible to all, including those from disadvantaged backgrounds and people with disabilities; whereas learning outcomes do not depend on technology per se, but on how teachers can use technology in pedagogically meaningful ways;” (paragraph W)",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress."
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "These general principles are referred to as background (”Whereas...”). \n\nSome of the principles absent here are stated more specifically (e.g., the ‘augmentation not replacement’ is not expressed generally, but is expressed specifically with regard to teachers. ",
        "WC Favourite": true,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "“Calls on the Commission to include education in the regulatory framework for high-risk AI applications, given the importance of ensuring that education continues to contribute to the public good, as well as the high sensitivity of data on pupils, students and other learners;” — this happened",
        "Record Entered By": ""
      },
      "id": "i-wfPuoK3OXV",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-wfPuoK3OXV",
      "name": "European Union: European Parliament resolution of 19 May 2021 on artificial intelligence in education, culture and the audiovisual sector (2020/2017(INI))",
      "index": 19,
      "createdAt": "2024-05-30T22:41:18.325Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-wfPuoK3OXV"
    },
    {
      "values": {
        "Policy Name": "AI Principles",
        "Policy creator": [
          "OECD"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "These are important principles that apply to EdTech. ",
        "File": [
          "AI Principles Overview - OECD.AI.pdf"
        ],
        "Year of Commencement or Creation": "2019",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": 1,
        "Title": "OECD: AI Principles",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "IO"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“AI actors should respect the rule of law, human rights, democratic and human-centred values throughout the AI system lifecycle. These include non-discrimination and equality, freedom, dignity, autonomy of individuals, privacy and data protection, diversity, fairness, social justice, and internationally recognised labour rights. This also includes addressing misinformation and disinformation amplified by AI, while respecting freedom of expression and other rights and freedoms protected by applicable international law.\nTo this end, AI actors should implement mechanisms and safeguards, such as capacity for human agency and oversight, including to address risks arising from uses outside of intended purpose, intentional misuse, or unintentional misuse in a manner appropriate to the context and consistent with the state of the art.” (https://oecd.ai/en/dashboards/ai-principles/P6)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“Stakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for people and the planet, such as augmenting human capabilities and enhancing creativity, advancing inclusion of underrepresented populations, reducing economic, social, gender and other inequalities, and protecting natural environments, thus invigorating inclusive growth, well-being, sustainable development and environmental sustainability.”  (https://oecd.ai/en/dashboards/ai-principles/P5)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "
        ],
        "Draft Analysis Complete": true,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": true,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-7fKHs4fMnK",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-7fKHs4fMnK",
      "name": "OECD: AI Principles",
      "index": 60,
      "createdAt": "2024-05-30T09:47:57.293Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-7fKHs4fMnK"
    },
    {
      "values": {
        "Policy Name": "AI and education: Guidance for policy-makers",
        "Policy creator": [
          "UNESCO"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is an excellent contribution. Given the subsequent (2023) GenAI document, I have decided to exclude this from the policy table (on the basis of significant overlap) but I will include it in the secondary materials so that it is still captured. \nI cannot help but wonder whether UNESCO’s disposition changed (the old document is more opportunity-oriented) in the direction of being more risk-focused?",
        "File": [
          "6577a65af258ab9af098691b074dc35a3467c5ad0dd5a7fb4e01d51b7beac85682a0c6938af08caf8cdae3808c9199a919d262fcf16fb6d801eba59e2aa2089e5d8443a45f71da7d922ed36886a3b224fbb98fcf4cd42ab87256f1dd7a717a7b9ad8d3bf.pdf"
        ],
        "Year of Commencement or Creation": "2021",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "",
        "Series #": 4,
        "Title": "UNESCO: AI and education: Guidance for policy-makers",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "IO"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Would have been relevant but superseded",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-cwFk9KQ50w",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-cwFk9KQ50w",
      "name": "UNESCO: AI and education: Guidance for policy-makers",
      "index": 58,
      "createdAt": "2024-05-30T09:46:33.813Z",
      "updatedAt": "2024-06-04T04:51:24.936Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-cwFk9KQ50w"
    },
    {
      "values": {
        "Policy Name": "Recommendation on Ethics in Artificial Intelligence",
        "Policy creator": [
          "UNESCO"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This document provides a general summary of artificial intelligence principles, but has a dedicated section on education and research (see Area 8). This document is also very human rights oriented. ",
        "File": [
          "381137eng (1) (1).pdf"
        ],
        "Year of Commencement or Creation": "2021",
        "Relevance Type": [
          "Policy has an AI in education component",
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": [
          "Human rights-centred. The technology must be consistent with human rights. ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology.",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. ",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": 3,
        "Title": "UNESCO: Recommendation on Ethics in Artificial Intelligence",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "IO"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "“Member States should promote general awareness programmes about AI developments, including on data and the opportunities and challenges brought about by AI technologies, the impact of AI systems on human rights and their implications, including children’s rights. These programmes should be accessible to nontechnical as well as technical groups.” (p 34)\n“AI systems used in learning should be subject to strict requirements when it comes to the monitoring, assessment of abilities, or prediction of the learners’ behaviours. AI should support the learning process without reducing cognitive abilities and without extracting sensitive information, in compliance with relevant personal data protection standards.” (p 34)\n“Member States should promote the participation and leadership of girls and women, diverse ethnicities and cultures, persons with disabilities, marginalized and vulnerable people or people in vulnerable situations, minorities and all persons not enjoying the full benefits of digital inclusion, in AI education programmes at all levels, as well as the monitoring and sharing of best practices in this regard with other Member States.” (p 34)\n“Member States should ensure that AI researchers are trained in research ethics and require them to include ethical considerations in their designs, products and publications, especially in the analyses of the datasets they use, how they are annotated, and the quality and scope of the results with possible applications.” (p 35)\n\n“Member States should develop guidelines for humanrobot interactions and their impact on human-human relationships, based on research and directed at the future development of robots, and with special attention to the mental and physical health of human beings. Particular attention should be given to the use of robots in health care and the care for older persons and persons with disabilities, in education, and robots for use by children, toy robots, chatbots and companion robots for children and adults. Furthermore, assistance of AI technologies should be applied to increase the safety and ergonomic use of robots, including in a human-robot working environment. Special attention should be paid to the possibility of using AI to manipulate and abuse human cognitive biases.” (p 37)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“AI systems raise new types of ethical issues that include, but are not limited to, their impact on decision-making, employment and labour, social interaction, health care, education, media, access to information, digital divide, personal data and consumer protection, environment, democracy, rule of law, security and policing, dual use, and human rights and fundamental freedoms, including freedom of expression, privacy and nondiscrimination.” (p 10)\n\n“From a socio-technical lens, greater transparency contributes to more peaceful, just, democratic and inclusive societies. It allows for public scrutiny that can decrease corruption and discrimination, and can also help detect and prevent negative impacts on human rights.” (p 22)\n\n“Recalling that, by the terms of its Constitution, UNESCO seeks to contribute to peace and security by promoting collaboration among nations through education, the sciences, culture, and communication and information, in order to further universal respect for justice, for the rule of law and for the human rights and fundamental freedoms which are affirmed for the peoples of the world” (p 5)\n\n“Convinced that the Recommendation presented here, as a standard-setting instrument developed through a global approach, based on international law, focusing on human dignity and human rights, as well as gender equality, social and economic justice and development, physical and mental well-being, diversity, interconnectedness, inclusiveness, and environmental and ecosystem protection can guide AI technologies in a responsible direction” (p 5)\n\n“Considering that AI technologies can be of great service to humanity and all countries can benefit from them, but also raise fundamental ethical concerns, for instance regarding the biases they can embed and exacerbate, potentially resulting in discrimination, inequality, digital divides, exclusion and a threat to cultural, social and biological diversity and social or economic divides; the need for transparency and understandability of the workings of algorithms and the data with which they have been trained; and their potential impact on, including but not limited to, human dignity, human rights and fundamental freedoms, gender equality, democracy, social, economic, political and cultural processes, scientific and engineering practices, animal welfare, and the environment and ecosystems” (p 5)\n\n“The objectives of this Recommendations are (c) to protect, promote and respect human rights and fundamental freedoms, human dignity and equality, including gender equality; to safeguard the interests of present and future generations; to preserve the environment, biodiversity and ecosystems; and to respect cultural diversity in all stages of the AI system life cycle.” (p 15) \n\n“In all cases, any possible limitations on human rights and fundamental freedoms must have a lawful basis, and be reasonable, necessary and proportionate, and consistent with States’ obligations under international law.” (p 18)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“AI actors should promote social justice and safeguard fairness and non-discrimination of any kind in compliance with international law. This implies an inclusive approach to ensuring that the benefits of AI technologies are available and accessible to all, taking into consideration the specific needs of different age groups, cultural systems, different language groups, persons with disabilities, girls and women, and disadvantaged, marginalized and vulnerable people or people in vulnerable situations.” (p 20)\n“Member States should work to promote inclusive access for all, including local communities, to AI systems with locally relevant content and services, and with respect for multilingualism and cultural diversity.” (p 20)\n“Member States should work to tackle digital divides and ensure inclusive access to and participation in the development of AI” (p 20)\n“At the national level, Member States should promote equity between rural and urban areas, and among all persons regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds, in terms of access to and participation in the AI system life cycle.” (p 20)\n\n“At the international level, the most technologically advanced countries have a responsibility of solidarity with the least advanced to ensure that the benefits of AI technologies are shared such that access to and participation in the AI system life cycle for the latter contributes to a fairer world order with regard to information, communication, culture, education, research and socio-economic and political stability.” (p 20)\n\n“Furthermore, new ethical challenges are created by the potential of AI algorithms to reproduce and reinforce existing biases, and thus to exacerbate already existing forms of discrimination, prejudice and stereotyping.” (p 10)\n\n“AI actors should make all reasonable efforts to minimize and avoid reinforcing or perpetuating discriminatory or biased applications and outcomes throughout the life cycle of the AI system to ensure fairness of such systems. Effective remedy should be available against discrimination and biased algorithmic determination.” (p 20)\n\n“Respect, protection and promotion of diversity and inclusiveness should be ensured throughout the life cycle of AI systems, consistent with international law, including human rights law. This may be done by promoting active participation of all individuals or groups regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds.” (p 19)\n\n“Learning about the impact of AI systems should include learning about, through and for human rights and fundamental freedoms, meaning that the approach and understanding of AI systems should be grounded by their impact on human rights and access to rights, as well as on the environment and ecosystems.” (p 23) ",
        "General principles on AI": [
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Draft Analysis Complete": true,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": true,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-eIePcoMdFY",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-eIePcoMdFY",
      "name": "UNESCO: Recommendation on Ethics in Artificial Intelligence",
      "index": 57,
      "createdAt": "2024-05-30T09:45:24.008Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-eIePcoMdFY"
    },
    {
      "values": {
        "Policy Name": "AI Standardisation Committee",
        "Policy creator": [
          "India"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a cool initiative — building a committee around questions of assessing trustworthiness/standards — but is not directly relevant to EdTech. The committee itself is not super relevant to EdTech. It seems to have produced some handy general resources, but they are not EdTech-focussed, and I have already included general principles included created by the Indian government. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26854",
        "Series #": 7,
        "Title": "India: AI Standardisation Committee",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-w9ONOvfaTB",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-w9ONOvfaTB",
      "name": "India: AI Standardisation Committee",
      "index": 23,
      "createdAt": "2024-05-30T04:39:58.399Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-w9ONOvfaTB"
    },
    {
      "values": {
        "Policy Name": "IndiaAI 2023: Expert Group Report",
        "Policy creator": [
          "India"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is an interesting document, but it does not have a whole heap of information over and above India’s national strategy, so I will focus on that. ",
        "File": [
          "IndiaAI-Expert-Group-Report-First-Edition.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27604",
        "Series #": 6,
        "Title": "India: IndiaAI 2023: Expert Group Report",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-zH86oFtb00",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-zH86oFtb00",
      "name": "India: IndiaAI 2023: Expert Group Report",
      "index": 22,
      "createdAt": "2024-05-30T04:38:43.016Z",
      "updatedAt": "2024-06-04T06:32:32.370Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-zH86oFtb00"
    },
    {
      "values": {
        "Policy Name": "India AI: National Program on Artificial Intelligence ",
        "Policy creator": [
          "India"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This seems to be some kind of coordination/monitoring body. Not directly relevant to EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27510",
        "Series #": 5,
        "Title": "India: India AI: National Program on Artificial Intelligence ",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-83g0BjFeEs",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-83g0BjFeEs",
      "name": "India: India AI: National Program on Artificial Intelligence ",
      "index": 21,
      "createdAt": "2024-05-30T04:37:10.968Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-83g0BjFeEs"
    },
    {
      "values": {
        "Policy Name": "AI Task Force for India’s Economic Transformation ",
        "Policy creator": [
          "India"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The creation of this body is not specifically relevant to EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24667",
        "Series #": 4,
        "Title": "India: AI Task Force for India’s Economic Transformation ",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-KnhwFmfPzJ",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-KnhwFmfPzJ",
      "name": "India: AI Task Force for India’s Economic Transformation ",
      "index": 20,
      "createdAt": "2024-05-30T04:36:35.014Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-KnhwFmfPzJ"
    },
    {
      "values": {
        "Policy Name": "Approach Document for India — Operationalizing Principles for Responsible AI",
        "Policy creator": [
          "India"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is about mechanisms for operationalising principles set out in the first of this two-part series. This is all broadly relevant. ",
        "File": [
          "Part2-Responsible-AI-12082021.pdf"
        ],
        "Year of Commencement or Creation": "2021",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Develops tools. It provides tools and place them in the hands of businesses or governments"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27226",
        "Series #": 3,
        "Title": "India: Approach Document for India — Operationalizing Principles for Responsible AI",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Implication of “security risks” - “Real-world deployments may lead to malfunctioning and potentially impact the fundamental rights if underlying AI models are manipulated” (p 3)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“The diversity, scale, digital divide, lack of awareness and inequality serves a fertile ground for the negative effects of AI to amplify. Creating a trusted AI ecosystem is important to realise both the economic and social potential of AI.” (p 7)\n\n“Social research must be aimed at understanding the interaction of AI systems with the local and marginalised communities. This includes understanding how different communities are impacted by the deployment of AI technologies for the delivery of benefits and services, and if benefits are reaching the population as intended, ramifications of risks and considerations such as discrimination, inclusivity, privacy, etc on local and marginalised communities, and identify any other concerns, both in the short term and long term, shaped by the introduction of Artificial Intelligence.” (p 15)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Draft Analysis Complete": true,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": true,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-Zc3haNaboY",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Zc3haNaboY",
      "name": "India: Approach Document for India — Operationalizing Principles for Responsible AI",
      "index": 24,
      "createdAt": "2024-05-30T04:34:33.796Z",
      "updatedAt": "2024-06-03T07:19:30.253Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Zc3haNaboY"
    },
    {
      "values": {
        "Policy Name": "Approach Document for India — Principles for Responsible AI",
        "Policy creator": [
          "India"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is an interesting little paragraph here on positive discrimination — helping certain persons access education (which, in context, is to be achieved through AI). These principles are not framed in terms of EdTech, but could be applied.",
        "File": [
          "Responsible-AI-22022021.pdf"
        ],
        "Year of Commencement or Creation": "2021",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Proposes law. It proposes a law or provides a draft law on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27225",
        "Series #": 2,
        "Title": "India: Approach Document for India — Principles for Responsible AI",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Under “Systems Consideration 4: Incorrect decisions leading to exclusion from access to services or benefits”, it notes that: \n“In a beneficiary identification system, an incorrect decision could lead to exclusion of services and benefits guaranteed by the State and in criminal identification systems, it could lead to loss of fundamental rights. When the AI systems are used, particularly for critical services by the Government, it is important to have processes and systems in place for raising an objection.” (p 25)\n\nSee also Appendix 2 (p 59) for the review of global regulatory landscape (some mentions of human rights in the context of EU). ",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "Note that both formal equality and substantive equality are captured. \n\n“Principle of Inclusivity and Non-discrimination: AI systems should not deny opportunity to a qualified person on the basis of their identity. It should not deepen the harmful historic and social divisions based on religion, race, caste, sex, descent, place of birth or residence in matters of education, employment, access to public spaces, etc. It should also strive to ensure that unfair exclusion of services or benefits does not happen. In case of an adverse decision, appropriate grievance redressal mechanism should be designed in a manner affordable and accessible to everyone irrespective of their background.” (p 50)\n\n“Safety and robustness of AI systems can pose serious challenges especially in high risk prone applications; unequal access to AI powered applications for marginalized populations can further accentuate digital divide.” (p 17)\n\n“The ‘systematic’ exclusion from access to services and benefits could undermine trust in the system.” (p 16)",
        "General principles on AI": [
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Opportunity. The opportunities of AI should be harnessed."
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": true,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-gW1QzUap3c",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-gW1QzUap3c",
      "name": "India: Approach Document for India — Principles for Responsible AI",
      "index": 26,
      "createdAt": "2024-05-30T04:30:01.440Z",
      "updatedAt": "2024-06-03T07:19:52.294Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-gW1QzUap3c"
    },
    {
      "values": {
        "Policy Name": "National Strategy on AI",
        "Policy creator": [
          "India"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is super important: India is a very linguistically diverse place. So it’s national strategy envisaged leveraging AI technologies to help with education. Education is one of the five areas that AI will be applied to. ",
        "File": [
          "National-Strategy-for-Artificial-Intelligence.pdf"
        ],
        "Year of Commencement or Creation": "2018",
        "Relevance Type": [
          "Policy has an AI in education component",
          "Policy contains case studies on AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary",
          "Vocational or Professional"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24951",
        "Series #": 1,
        "Title": "India: National Strategy on AI",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "The key story here is: India is experiencing low retention rates and poor learning outcomes, and one of the problems is a lack of technology. \n“AI can potentially solve for quality and access issues observed in the Indian education sector. Potential use cases include augmenting and enhancing the learning experience through personalised learning, automating and expediting administrative tasks, and predicting the need for student intervention to reduce dropouts or recommend vocational training.” (p 20)\n“AI has the potential to bring about changes in the sector by supplementing pedagogy and establishing systems to inform and support decision making across stakeholders and administrative levels. However, implementation of AI must be preceded by efforts to digitise records of teacher performance, student performance, and curriculum. Several AI tools are being successfully used in other parts of the world, and they can be adapted to the Indian context to target specific challenges.”\nWhat they are interested in: see use cases below. \nTeacher training:\nA recent survey found that level of adoption of technology in schools is lacking, and can be largely attributed to lack of teacher training, despite provision of the ICT infrastructure. (p 36)\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "“Address and implement data protection framework, which protects human rights and privacy without stifling innovation in India.” (p 93) — only reference",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "There are a few references to discrimination, but this plan is not really framed in the language of equality/equity. Even the opportunity here is framed as an opportunity to improve education (rather than, for example, decrease educational inequality — cf Indonesia). ",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society."
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "Note — education is considered in an “opportunity-only” way. The content on ethics is addressed in broad terms. ",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "a) Adaptive learning tools for customised learning: While AI may not completely replace a teacher, it has the potential to greatly assist teachers in efficiently and effectively managing multi-level / multi?grade classrooms, by judging learning levels of individual students, and allowing automated development of customised educational content adapted to each child’s class and learning level. Assessing time spent by a student on each part / page of the learning material, for example, would allow real-time feedback on student performance to help the teacher appropriately tailor her guidance to the child. This concept can be extended to automatic grading of tests, as well. \nb) Intelligent and interactive tutoring systems: Intelligent Tutoring Systems can provide great benefit to students through delivery of learning materials adapted to the child’s proficiency level, learning style, and pace of learning. In-built pop-up questions tailored to students, for example, can help increase interactivity, and catch student’s attention and interest. It can also help in assessment of student’s level of attention or comprehension to appropriately design remedial instruction. GradeGuardian, for example, uses predictive models and visualisations for student performance with an interactive dashboard showing anticipated effect of policy changes. Submission includes 3 components packaged as a single web app – a Chatbot that inputs student information, an Advisor Console that shows students at risk, and a prediction module for policymakers.\nc) Predictive tools to inform pre-emptive action for students predicted to drop out of school: Analysis of test results and attendance records using AI can be used to predict probable student activities and inform pre-emptive action. For instance, in a recent preliminary experiment conducted in Andhra Pradesh, AI applications processed data on all students based on parameters such as gender, socio?economic factors, academic performance, school infrastructure, teacher skills, etc., with the objective of helping the government identify students likely to drop out. Test results could inform suggestions to enroll students in vocational studies. Additionally, redressal mechanisms could be put in place to identify students whose performance can be improved by focus of existing schemes to their family.\n(d)) Automated rationalisation of teachers: AI tools can be used to develop automated teacher posting and transfer systems, using analytics based on demand – supply gaps across schools in the State, candidate’s prior postings, candidate preferences, etc. This would help in plugging of gaps in teacher distribution more effectively. \ne) Customised professional development courses: To tackle issues of poorly designed professional development courses with poor coverage, adaptive AI tools can be used to design automated, customised professional development training content for the teacher based on their performance, identification of their knowledge and skill gaps. This could then be continuously adapted as teacher’s skills and concepts improve.\n (p 37-38 — read this section, noting the pop-out boxes with concrete case studies)\n",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-F0cUMbalq-",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-F0cUMbalq-",
      "name": "India: National Strategy on AI",
      "index": 25,
      "createdAt": "2024-05-30T04:29:45.240Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-F0cUMbalq-"
    },
    {
      "values": {
        "Policy Name": "Malta’s educational initiatives: Masters in AI, Skills Development, Start-up Residence Programme, Tax Credit on Higher Educational Qualifications, Future Innovators Summer School, AI Certification Programme, etc",
        "Policy creator": [
          "Malta"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Malta have done a whole heap to encourage — even financially incentivise — AI study. It has reduced friction to learning about AI. However, this is not so much an “EdTech” initiative as an education in AI initiative. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives?conceptUris=http:%2F%2Fkim.oecd.org%2FTaxonomy%2FGeographicalAreas%23Malta",
        "Series #": 4,
        "Title": "Malta: Malta’s educational initiatives: Masters in AI, Skills Development, Start-up Residence Programme, Tax Credit on Higher Educational Qualifications, Future Innovators Summer School, AI Certification Programme, etc",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-i3W1QFey6_",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-i3W1QFey6_",
      "name": "Malta: Malta’s educational initiatives: Masters in AI, Skills Development, Start-up Residence Programme, Tax Credit on Higher Educational Qualifications, Future Innovators Summer School, AI Certification Programme, etc",
      "index": 30,
      "createdAt": "2024-05-30T04:23:44.586Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-i3W1QFey6_"
    },
    {
      "values": {
        "Policy Name": "Malta Digital Innovation Authority",
        "Policy creator": [
          "Malta"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The creation of this body is not EdTech-focused, so its specific initiatives are more relevant. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27518",
        "Series #": 3,
        "Title": "Malta: Malta Digital Innovation Authority",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-aw2IreqB1O",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-aw2IreqB1O",
      "name": "Malta: Malta Digital Innovation Authority",
      "index": 29,
      "createdAt": "2024-05-30T04:23:07.446Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-aw2IreqB1O"
    },
    {
      "values": {
        "Policy Name": "Technology Assessment Recognition Framework",
        "Policy creator": [
          "Malta"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is an interesting model that could definitely be applied to EdTech. TARF - Technology Assessment Recognition Framework - Malta Digital Innovation Authority (gov.mt)",
        "File": "",
        "Year of Commencement or Creation": "2023",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI",
          "Develops tools. It provides tools and place them in the hands of businesses or governments"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27583",
        "Series #": 2,
        "Title": "Malta: Technology Assessment Recognition Framework",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities."
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": true,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-noNor4BMYA",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-noNor4BMYA",
      "name": "Malta: Technology Assessment Recognition Framework",
      "index": 28,
      "createdAt": "2024-05-30T04:22:26.071Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-noNor4BMYA"
    },
    {
      "values": {
        "Policy Name": "Towards Trustworthy AI: Malta’s Ethical AI Framework",
        "Policy creator": [
          "Malta"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a nuanced framework for AI. It talks authorities through precisely what should be done (rather than merely expressing broad norms). Focus on its “governance practices” table. ",
        "File": [
          "Malta_Towards_Ethical_and_Trustworthy_AI_vFINAL.pdf"
        ],
        "Year of Commencement or Creation": "2019",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24993",
        "Series #": 1,
        "Title": "Malta: Towards Trustworthy AI: Malta’s Ethical AI Framework",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "N/A",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "It stresses: “Respect for all applicable laws and regulations, human rights and democratic values;” — this theme keeps coming back. \n“Conduct human rights impact assessment, identifying and documenting potential trade-offs between different principles and rights.”",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“Equality, non-discrimination and solidarity — AI operations can not generate unfairly biased outcomes, and the benefits and opportunities of AI should be equitably available to all.” (p 9)",
        "General principles on AI": [
          "Respect for laws [NEW]. AI should respect existing law.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "Note: These principles are inferred from governance control. ",
        "WC Favourite": true,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "This is interesting for its “governance practices” table. Worth paying attention to. \n\nNote that this has been characterised as being equally interested in risks and opportunities. Why? The primary justification is that it sees ETHICS as being one of the central tools for being the “ultimate launchpad” for AI. This is an important point—it is not merely seeing ethics as belonging to the domain of risk mitigation. ",
        "Record Entered By": ""
      },
      "id": "i-KzUPzwvpZR",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-KzUPzwvpZR",
      "name": "Malta: Towards Trustworthy AI: Malta’s Ethical AI Framework",
      "index": 27,
      "createdAt": "2024-05-30T04:11:49.801Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-KzUPzwvpZR"
    },
    {
      "values": {
        "Policy Name": "National Center for Innovation and Artificial Intelligence ",
        "Policy creator": [
          "Peru"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The creation of this body is not itself relevant to EdTech (though might affect it indirectly). It is the stuff it is doing (captured in other policy entries) that is relevant. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27148",
        "Series #": 5,
        "Title": "Peru: National Center for Innovation and Artificial Intelligence ",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-j871MoGjLo",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-j871MoGjLo",
      "name": "Peru: National Center for Innovation and Artificial Intelligence ",
      "index": 469,
      "createdAt": "2024-05-30T04:08:06.339Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-j871MoGjLo"
    },
    {
      "values": {
        "Policy Name": "National Artificial Intelligence Authority",
        "Policy creator": [
          "Peru"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The creation of this body is not itself relevant to EdTech (though might affect it indirectly). ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27625",
        "Series #": 4,
        "Title": "Peru: National Artificial Intelligence Authority",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-9M8cvKwdSr",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-9M8cvKwdSr",
      "name": "Peru: National Artificial Intelligence Authority",
      "index": 34,
      "createdAt": "2024-05-30T04:07:58.370Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-9M8cvKwdSr"
    },
    {
      "values": {
        "Policy Name": "Law 31814, Law that promotes the use of AI in favour of the economic and social development of the country",
        "Policy creator": [
          "Peru"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Does not mention education in the summary, but might well be relevant. ",
        "File": [
          "ley-que-promueve-el-uso-de-la-inteligencia-artificial-en-fav-ley-n-31814.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27613",
        "Series #": 3,
        "Title": "Peru: Law 31814, Law that promotes the use of AI in favour of the economic and social development of the country",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Cannot Access",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-ffcn-cX3Rq",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ffcn-cX3Rq",
      "name": "Peru: Law 31814, Law that promotes the use of AI in favour of the economic and social development of the country",
      "index": 33,
      "createdAt": "2024-05-30T04:05:36.779Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ffcn-cX3Rq"
    },
    {
      "values": {
        "Policy Name": "Transformacion Digital",
        "Policy creator": [
          "Peru"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This seems to have a fair bit on “educativos”. Worth translating to check more thoroughly. ",
        "File": [
          "Política Nacional de Transformación Digital al 2030.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27620",
        "Series #": 2,
        "Title": "Peru: Transformacion Digital",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-Ah0jZ30aTx",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Ah0jZ30aTx",
      "name": "Peru: Transformacion Digital",
      "index": 32,
      "createdAt": "2024-05-30T04:03:04.376Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Ah0jZ30aTx"
    },
    {
      "values": {
        "Policy Name": "National AI Strategy (2021-2026)",
        "Policy creator": [
          "Peru"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is directly relevant to AI in education (particularly individualisation of education for each student)",
        "File": [
          "Peru_National_Artificial_Intelligence_Strategy_2021-2026.pdf"
        ],
        "Year of Commencement or Creation": "2021",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Secondary",
          "Primary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": "",
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": 1,
        "Title": "Peru: National AI Strategy (2021-2026)",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "“Use case in education:\nAI adapted to the needs of each student\nFrom school to college, AI could individualize the learning needs of each student. \nThe system could respond to the needs of the student, placing greater emphasis on certain topics, repeating things until the student masters it. \nIn general, helping the student to learn at her own pace, whatever this could be. \nAI could give feedback to students and teachers \nAI could give feedback to teachers and students about the results of the course itself. \nSome AI systems are used to monitor student progress and alert teachers when there might be a problem with student performance. \nThese systems could give the support to the students who need it, and to the teacher, to find the areas where he can improve the instructions to the student so that he does not fail with the subject of the course.” (p 19)\n \n“Through the National Center for Innovation and Artificial Intelligence, prioritize the development of use cases where Artificial Intelligence can generate concrete solutions such as those proposed in various investigations aligned to the United Nations 2030 sustainable development goals, such as the elimination of poverty, zero hunger, quality education, clean and accessible energy, clean water and sustainable cities, good health, better qualified jobs, the reduction of social gaps and others.” (p 67)",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“A.5.1.7. In the public sector, in all cases of use of AI to classify people (to provide benefits, opportunities or sanctions to citizens), they must have a socioeconomic impact study to guarantee equity.” (p 79)",
        "General principles on AI": [
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities."
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "image.png",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-4zem25qHQm",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-4zem25qHQm",
      "name": "Peru: National AI Strategy (2021-2026)",
      "index": 31,
      "createdAt": "2024-05-30T04:01:52.887Z",
      "updatedAt": "2024-06-06T03:04:13.416Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-4zem25qHQm"
    },
    {
      "values": {
        "Policy Name": "Vision 2030 Program",
        "Policy creator": [
          "Saudi Arabia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is focused on “matching  educational outcomes to the needs of the labor market”",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26017",
        "Series #": 3,
        "Title": "Saudi Arabia: Vision 2030 Program",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-EaM1Ulberi",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-EaM1Ulberi",
      "name": "Saudi Arabia: Vision 2030 Program",
      "index": 41,
      "createdAt": "2024-05-30T03:58:53.619Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-EaM1Ulberi"
    },
    {
      "values": {
        "Policy Name": "National Centre for AI",
        "Policy creator": [
          "Saudi Arabia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is not EdTech-focused. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26015",
        "Series #": 2,
        "Title": "Saudi Arabia: National Centre for AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-MO23ahP2j0",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-MO23ahP2j0",
      "name": "Saudi Arabia: National Centre for AI",
      "index": 40,
      "createdAt": "2024-05-30T03:58:22.655Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-MO23ahP2j0"
    },
    {
      "values": {
        "Policy Name": "National Data and AI Strategy",
        "Policy creator": [
          "Saudi Arabia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is about AI education, not AI in education. ",
        "File": [
          "Brochure_NSDAI_Summit version_EN.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26934",
        "Series #": 1,
        "Title": "Saudi Arabia: National Data and AI Strategy",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-Xn1rJfBsRO",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Xn1rJfBsRO",
      "name": "Saudi Arabia: National Data and AI Strategy",
      "index": 39,
      "createdAt": "2024-05-30T03:56:53.432Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Xn1rJfBsRO"
    },
    {
      "values": {
        "Policy Name": "Ethics Guidelines for AI",
        "Policy creator": [
          "Thailand"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "These guidelines might be broadly applicable to EdTech. Need to translate to get deeper (most of the doc is in Thai). ",
        "File": [
          "Digital-Thailand-AI-Ethics-Principle-and-Guideline.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26337",
        "Series #": 4,
        "Title": "Thailand: Ethics Guidelines for AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-3tvtidLFCb",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-3tvtidLFCb",
      "name": "Thailand: Ethics Guidelines for AI",
      "index": 38,
      "createdAt": "2024-05-30T03:54:23.037Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-3tvtidLFCb"
    },
    {
      "values": {
        "Policy Name": "AI Governance Guidelines for Executives ",
        "Policy creator": [
          "Thailand"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This looks interesting, but needs to be translated fully. ",
        "File": [
          "Thailand AI Ethics Guideline (White paper) Edit Version.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27608",
        "Series #": 3,
        "Title": "Thailand: AI Governance Guidelines for Executives ",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-7C093DCOGE",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-7C093DCOGE",
      "name": "Thailand: AI Governance Guidelines for Executives ",
      "index": 37,
      "createdAt": "2024-05-30T03:51:53.239Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-7C093DCOGE"
    },
    {
      "values": {
        "Policy Name": "12th National Economic and Social Development Plan",
        "Policy creator": [
          "Thailand"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Not EdTech-focused (and not that EdTech-focused). ",
        "File": [
          "thailand_national_economic_and_social_development_plan_nesdp.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26088",
        "Series #": 2,
        "Title": "Thailand: 12th National Economic and Social Development Plan",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-a_AMPDj4WM",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-a_AMPDj4WM",
      "name": "Thailand: 12th National Economic and Social Development Plan",
      "index": 36,
      "createdAt": "2024-05-30T03:48:22.308Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-a_AMPDj4WM"
    },
    {
      "values": {
        "Policy Name": "Thailand National AI Plan",
        "Policy creator": [
          "Thailand"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Based on the very limited information available on the OECD Policy Observatory and online, it seems that this is not EdTech-focused. \nNational Artificial Intelligence Action Plan for Thailand Development (2022 – 2027) - AI Thailand",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27299",
        "Series #": 1,
        "Title": "Thailand: Thailand National AI Plan",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-YpUUxnDmQT",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-YpUUxnDmQT",
      "name": "Thailand: Thailand National AI Plan",
      "index": 35,
      "createdAt": "2024-05-30T03:46:41.475Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-YpUUxnDmQT"
    },
    {
      "values": {
        "Policy Name": "National Strategy for the Development of AI in Ukraine",
        "Policy creator": [
          "Ukraine"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Ukraine is apparently focused on AI in education and defence. I am not sure whether there is project is at—given obvious disruptions. \n\nFurther, questionable source — need more information. ",
        "File": [
          "Ukraine’s roadmap to an artificial intelligence future - Atlantic Council.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27224",
        "Series #": 1,
        "Title": "Ukraine: National Strategy for the Development of AI in Ukraine",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Cannot Access",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-_kRhBVMYRz",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_kRhBVMYRz",
      "name": "Ukraine: National Strategy for the Development of AI in Ukraine",
      "index": 42,
      "createdAt": "2024-05-30T03:28:06.898Z",
      "updatedAt": "2024-06-03T02:28:38.370Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_kRhBVMYRz"
    },
    {
      "values": {
        "Policy Name": "Data Science and ML Roadmap",
        "Policy creator": [
          "Uruguay"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Translation needed.",
        "File": [
          "6112019+Hoja+de+Ruta+CD+AA.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "",
        "Series #": 4,
        "Title": "Uruguay: Data Science and ML Roadmap",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-m0uQnPjhJ9",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-m0uQnPjhJ9",
      "name": "Uruguay: Data Science and ML Roadmap",
      "index": 50,
      "createdAt": "2024-05-30T03:24:55.364Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-m0uQnPjhJ9"
    },
    {
      "values": {
        "Policy Name": "Data Policy and Strategy for Digital Transformation",
        "Policy creator": [
          "Uruguay"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is more foundational than EdTech.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26697",
        "Series #": 3,
        "Title": "Uruguay: Data Policy and Strategy for Digital Transformation",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-140mzLUitn",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-140mzLUitn",
      "name": "Uruguay: Data Policy and Strategy for Digital Transformation",
      "index": 49,
      "createdAt": "2024-05-30T03:24:32.591Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-140mzLUitn"
    },
    {
      "values": {
        "Policy Name": "AI Use Cases in the Public Sector",
        "Policy creator": [
          "Uruguay"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is about fostering R&D/innovation for the implementation of AI. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27151",
        "Series #": 2,
        "Title": "Uruguay: AI Use Cases in the Public Sector",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-b2NNWbWnEW",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-b2NNWbWnEW",
      "name": "Uruguay: AI Use Cases in the Public Sector",
      "index": 48,
      "createdAt": "2024-05-30T03:23:38.399Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-b2NNWbWnEW"
    },
    {
      "values": {
        "Policy Name": "AI Strategy for the Digital Government",
        "Policy creator": [
          "Uruguay"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "All this really does is acknowledge that AI is being used in ‘sensitive’ areas such as education (not wrong!). But Uruguay’s aspirations are more foundational.",
        "File": [
          "Uruguay_Artificial_Intelligence_Strategy_for_Digital_Government_2019.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26477",
        "Series #": 1,
        "Title": "Uruguay: AI Strategy for the Digital Government",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-vfqS9r-iRb",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-vfqS9r-iRb",
      "name": "Uruguay: AI Strategy for the Digital Government",
      "index": 47,
      "createdAt": "2024-05-30T03:10:21.866Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-vfqS9r-iRb"
    },
    {
      "values": {
        "Policy Name": "Kenya’s Digital Economy Strategy",
        "Policy creator": [
          "Kenya"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is a hugely important case study on digital inequality here:\nThe same assumption was extended to the basic education too where it turned out that only less than 25% of learners could participate in remote/online learning. Similarly, the Kenyan labour force are largely in the informal sector where working remotely was not a solution. Unfortunately, the measures that were put in place to address the digital inequalities during the pandemic were seen more as a necessity and not as priorities.\nI am including this for the purpose or asking: How do we roll out AI if the basic infrastructure is not there?",
        "File": [
          "10TH-JULY-FINAL-COPY-DIGITAL-ECONOMY-STRATEGY-DRAFT-ONE.pdf"
        ],
        "Year of Commencement or Creation": "2020",
        "Relevance Type": [
          "Policy contains case studies on AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A Other]"
        ],
        "Governance practices employed": [
          "[N/A]"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27138",
        "Series #": 4,
        "Title": "Kenya: Kenya’s Digital Economy Strategy",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "[N/A]",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "[N/A]"
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "This is a case study in the failure to get AI in education projects off the ground. \nThe key point is as follows:\n\nThe same assumption was extended to the basic education too where it turned out that only less than 25% of learners could participate in remote/online learning. Similarly, the Kenyan labour force are largely in the informal sector where working remotely was not a solution. Unfortunately, the measures that were put in place to address the digital inequalities during the pandemic were seen more as a necessity and not as priorities.\n\nThis should be read together with Kenya’s other policies, which deal expressly with AI and blockchain. ",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-TkXOJxaGiN",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-TkXOJxaGiN",
      "name": "Kenya: Kenya’s Digital Economy Strategy",
      "index": 46,
      "createdAt": "2024-05-30T03:06:58.553Z",
      "updatedAt": "2024-06-04T23:03:49.690Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-TkXOJxaGiN"
    },
    {
      "values": {
        "Policy Name": "Blockchain and AI Task Force",
        "Policy creator": [
          "Kenya"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "I have included materials produced by this body—but it — as a policy initiative — is less relevant. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26983",
        "Series #": 3,
        "Title": "Kenya: Blockchain and AI Task Force",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-fbSmfNegBW",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-fbSmfNegBW",
      "name": "Kenya: Blockchain and AI Task Force",
      "index": 45,
      "createdAt": "2024-05-30T03:05:15.422Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-fbSmfNegBW"
    },
    {
      "values": {
        "Policy Name": "Emerging Digital Technologies for Kenya — Exploration and Analysis",
        "Policy creator": [
          "Kenya"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This work was undertaken by the government’s Blockchain and AI Taskforce, and is “AI for development” focused. There is broad awareness that this technology could be used to deliver personalised virtual lessons. They also point to systems already in place — including an SMS-based learning platform. This is a really interesting research paper. ",
        "File": [
          "KenEcon_30.pdf"
        ],
        "Year of Commencement or Creation": "2019",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27135",
        "Series #": 1,
        "Title": "Kenya: Emerging Digital Technologies for Kenya — Exploration and Analysis",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "Opportunity\n“In the education sector, AI exhibits the potential to improve learning outcomes by supporting the delivery of personalised virtual lessons. A good example here is M-Shule, an SMS-based learning platform in Kenya, which uses AI to track and analyse student performance and to deliver lessons that satisfy their needs and increase their competency. The platform reduces the fear of failure that is inherent in several learning environments, allowing students to advance at their own pace and to ultimately improve their learning outcomes.” (p 10)\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "“The technology will enable the constitutional rights of the citizens and is expected to continually ensure transparent elections in the country. Elected officials will also be held accountable relative to the use of public resources and effective delivery of government services.” (p 87)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“Essentially, the sharing economy is expected to transition to the next level, where the middleman is not extracting maximum value at the expense of the other participants. Instead, depending on the specific use case or design, the created value will be distributed more equitably” (p 107)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Bias testing. AI systems should be tested for bias. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "“In the education sector, AI has the potential to improve learning outcomes through more personalised, virtual lessons. For example, M-Shule, an SMS-based learning platform in Kenya, uses AI to track and analyse student performance and to deliver lessons that meet their individual needs and thereby grow their competency. The M-Shule platform reduces the fear of failure inherent in many learning environments. Students can advance at their own pace and ultimately improve their learning outcomes.” (p 39)\n\n(p 40)",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-6wgFj6IDsa",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-6wgFj6IDsa",
      "name": "Kenya: Emerging Digital Technologies for Kenya — Exploration and Analysis",
      "index": 44,
      "createdAt": "2024-05-30T03:02:11.353Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-6wgFj6IDsa"
    },
    {
      "values": {
        "Policy Name": "AI Use Cases in the Public Sector",
        "Policy creator": [
          "Kenya"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is no reference to education here. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27140",
        "Series #": 2,
        "Title": "Kenya: AI Use Cases in the Public Sector",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-kEFf6ACRZc",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-kEFf6ACRZc",
      "name": "Kenya: AI Use Cases in the Public Sector",
      "index": 43,
      "createdAt": "2024-05-30T03:01:50.674Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-kEFf6ACRZc"
    },
    {
      "values": {
        "Policy Name": "National Strategic Framework in the Field of Artificial Intelligence (2023-2027)",
        "Policy creator": [
          "Romania"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Need a translation to assess. ",
        "File": [
          "Strategie-Inteligenta-Artificiala-22012024_clean_final.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27581",
        "Series #": 3,
        "Title": "Romania: National Strategic Framework in the Field of Artificial Intelligence (2023-2027)",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-EKk4n9-usB",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-EKk4n9-usB",
      "name": "Romania: National Strategic Framework in the Field of Artificial Intelligence (2023-2027)",
      "index": 52,
      "createdAt": "2024-05-30T02:57:32.142Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-EKk4n9-usB"
    },
    {
      "values": {
        "Policy Name": "National Strategy for Research, Innovation and Smart Specialisation 2021-2027",
        "Policy creator": [
          "Romania"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is very “AI Education” focused rather than “AI in education”. ",
        "File": [
          "SNCISIenglish version.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26914",
        "Series #": 2,
        "Title": "Romania: National Strategy for Research, Innovation and Smart Specialisation 2021-2027",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-J6wl-zVCYi",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-J6wl-zVCYi",
      "name": "Romania: National Strategy for Research, Innovation and Smart Specialisation 2021-2027",
      "index": 51,
      "createdAt": "2024-05-30T02:53:41.765Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-J6wl-zVCYi"
    },
    {
      "values": {
        "Policy Name": "Romania’s National Strategy",
        "Policy creator": [
          "Romania"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Romania has a clear intention to use AI in education—specifically: \nPersonalised content presentation, evaluation and feedback \nClasses augmented with AR & VR technologies\nRecommendations for further studying and curation of content\nEnhanced blended learning through AI \nGamification concepts implemented through AI technology\n",
        "File": [
          "Romania-2019.pdf"
        ],
        "Year of Commencement or Creation": "2019",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24849",
        "Series #": 1,
        "Title": "Romania: Romania’s National Strategy",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "“Romania’s future depends on the education system available to young generations. The obsolete methods used in teaching combined with the poor training of teachers lead to concerning percentages of functional analphabetism in Romania, especially in rural areas. \nAI technologies have the potential to revolutionise the education system through projects such as:\nPersonalised content presentation, evaluation and feedback\nClasses augmented with AR & VR technologies\nRecommendations for further studying and curation of content \nEnhanced blended learning through AI \nGamification concepts implemented through AI technology” (p 9)\n\nAnother initiative concerning training (p 15):\n",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Opportunity. The opportunities of AI should be harnessed."
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "Very little of interest in this strategy — very “carpe diem”, but not a lot of detail or discussion of risk. ",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-AkCFVNxew3",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-AkCFVNxew3",
      "name": "Romania: Romania’s National Strategy",
      "index": 468,
      "createdAt": "2024-05-30T02:23:12.056Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-AkCFVNxew3"
    },
    {
      "values": {
        "Policy Name": "National Council for AI",
        "Policy creator": [
          "China"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This was not set up for EdTech purposes, so is only very generally/loosely relevant. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26475",
        "Series #": 5,
        "Title": "China: National Council for AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-9F3OUw9L91",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-9F3OUw9L91",
      "name": "China: National Council for AI",
      "index": 467,
      "createdAt": "2024-05-30T02:16:10.238Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-9F3OUw9L91"
    },
    {
      "values": {
        "Policy Name": "Arab AI Working Group",
        "Policy creator": [
          "Egypt"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "It is not clear that they are working on EdTech-related projects. The strategies listed concern eCommerce, social responsibility, cloud computing, etc. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26473",
        "Series #": 4,
        "Title": "Egypt: Arab AI Working Group",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-mBhy8jh-sU",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-mBhy8jh-sU",
      "name": "Egypt: Arab AI Working Group",
      "index": 466,
      "createdAt": "2024-05-30T02:16:01.522Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-mBhy8jh-sU"
    },
    {
      "values": {
        "Policy Name": "Applied Innovation Center",
        "Policy creator": [
          "Egypt"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "One of the areas it is poised to work with is education. Fleeting reference only — no significant action in this space. ",
        "File": [
          "STC Establishes First AI Application Center in Smart Village.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26472",
        "Series #": 3,
        "Title": "Egypt: Applied Innovation Center",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "Translation Completed (Google Translate)",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-ESexmMrcBn",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ESexmMrcBn",
      "name": "Egypt: Applied Innovation Center",
      "index": 465,
      "createdAt": "2024-05-30T02:15:56.407Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ESexmMrcBn"
    },
    {
      "values": {
        "Policy Name": "African Working Group on AI",
        "Policy creator": [
          "Egypt"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This does not make reference to education, let alone EdTech. It focuses on more foundational aspects of AI development. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26474",
        "Series #": 2,
        "Title": "Egypt: African Working Group on AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-zCUU5ANi-7",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-zCUU5ANi-7",
      "name": "Egypt: African Working Group on AI",
      "index": 53,
      "createdAt": "2024-05-30T02:15:50.968Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-zCUU5ANi-7"
    },
    {
      "values": {
        "Policy Name": "Egypt National AI Strategy",
        "Policy creator": [
          "Egypt"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The focus here is on AI education, but it is recognised that EdTech could help Egypt achieve its development goals.",
        "File": [
          "Publications_672021000_Egypt-National-AI-Strategy-English.pdf"
        ],
        "Year of Commencement or Creation": "2020",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26476",
        "Series #": 1,
        "Title": "Egypt: Egypt National AI Strategy",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "Official Translation Obtained",
        "Key quotes on AI in education principles": "The key reference to EdTech is as follows:\n\n“Applying AI to areas such as education or healthcare can facilitate access, overcome staff shortages, and reduce risks and costs. On the other hand, concerns are growing about increasingly automated and autonomous AI systems widening the technological, economic, and social gaps due to the lack of basic infrastructure and human capacity capable of exploiting this technology, especially in countries with a large proportion of low-skilled or unskilled labor.” [8]\nIt shows that Egypt is curious but recognises the practical difficulties of harnessing the technology. ",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "N/A",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“The National AI Strategy is a key priority for helping Egypt achieve relevant UN Sustainable Development Goals as they pertain to Egypt (in numerical order 4, 5, 8, 9, 10, 11). The relevant SDGs address inclusive and equitable education” (p 24)\n",
        "General principles on AI": [
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Bias testing. AI systems should be tested for bias. ",
          "Augmentation, not replacement. AI systems should augment, not displace, workers.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,"
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-dELwsp5J0Y",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-dELwsp5J0Y",
      "name": "Egypt: Egypt National AI Strategy",
      "index": 54,
      "createdAt": "2024-05-30T02:11:00.927Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-dELwsp5J0Y"
    },
    {
      "values": {
        "Policy Name": "National Plan for the Development of AI",
        "Policy creator": [
          "Croatia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The government said that it had started working on this and would provide an update. That was in 2020.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26501",
        "Series #": 1,
        "Title": "Croatia: National Plan for the Development of AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-cvscTZom8Q",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-cvscTZom8Q",
      "name": "Croatia: National Plan for the Development of AI",
      "index": 55,
      "createdAt": "2024-05-30T02:09:55.584Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-cvscTZom8Q"
    },
    {
      "values": {
        "Policy Name": "White Paper on Trustworthy AI",
        "Policy creator": [
          "China"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is generally relevant material here. Also, interesting commentary surrounding China’s AI governance:\nChina’s New AI Governance Initiatives Shouldn’t Be Ignored - Carnegie Endowment for International Peace",
        "File": [
          "t0390_trustworthy_AI_EN.pdf"
        ],
        "Year of Commencement or Creation": "2021",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27294",
        "Series #": 1,
        "Title": "China: White Paper on Trustworthy AI",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "“(4) AI fairness technology With the widespread application of AI systems, such systems have exhibited unfair decision-making behaviors and discrimination against certain groups. Academia holds that the main reasons for such decision-making biases are as follows: limited by data collection conditions, the weights of different groups in the data are unbalanced; the AI model trained on the unbalanced dataset may then be applied to the overall data, and while performance is sacrificed on a small amount of data, the model's decision-making becomes unfair. In order to ensure the fairness of decision-making in AI systems, relevant researchers have mainly constructed completely heterogeneous datasets to minimize inherent discrimination and bias in the data; datasets are then checked periodically to ensure the high quality of the data. In addition, there are also algorithms that use fair decision-making quantitative indicators to reduce or eliminate decision-making bias and potential discrimination. Such existing fairness indicators can be divided into two categories: individual fairness and group fairness. Specifically, individual fairness measures the degree of prejudice of intelligent decision-making toward different individuals, and group fairness measures the degree of prejudice of intelligent decision-making toward different groups.” (p 11)\n\n“The number of AI applications in sensitive fields continues to grow, such as in hiring, criminal justice, and healthcare, and its fairness has also been the subject of widespread concern. Fairness technology can balance data from a technical perspective, thereby further guiding the model to give fair results, which is of great significance for improving the fairness of decision-making in AI systems.” (p 11)\n\n“In terms of diversity and tolerance, attention should be paid to the fairness and diversity of training datasets to avoid lack of trust caused by data bias. The performance of an AI system depends on the quality of the training data. The dataset may contain implicit race, gender, or ideological bias (Table 1), which may cause the AI system’s decision-making to be inaccurate or biased and discriminatory. Enterprises should focus on improving the diversity and fairness of training data to meet the requirements of diversity and inclusion. On the one hand, attention must be paid to the inherent discrimination and prejudice that may appear in the data and proactive measures should be taken to weaken the impact of such prejudice; on the other hand, the dataset should be reviewed periodically to ensure the high quality of the data. Also, the testing process should use quantitative indicators based on fair decision-making capabilities to test the AI system.” (p 15)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Draft Analysis Complete": true,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": true,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-88Rbwn15L0",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-88Rbwn15L0",
      "name": "China: White Paper on Trustworthy AI",
      "index": 464,
      "createdAt": "2024-05-30T01:18:25.206Z",
      "updatedAt": "2024-06-05T21:37:17.815Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-88Rbwn15L0"
    },
    {
      "values": {
        "Policy Name": "Trustworthy Facial Recognition Applications and Protections Plan",
        "Policy creator": [
          "China"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Tangential to EdTech. There is far more relevant in China’s policy portfolio. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27295",
        "Series #": 10,
        "Title": "China: Trustworthy Facial Recognition Applications and Protections Plan",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-jTtgsZIXeF",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-jTtgsZIXeF",
      "name": "China: Trustworthy Facial Recognition Applications and Protections Plan",
      "index": 463,
      "createdAt": "2024-05-30T01:18:16.229Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-jTtgsZIXeF"
    },
    {
      "values": {
        "Policy Name": "Three-Year Guidance for Internet Plus AI Plan",
        "Policy creator": [
          "China"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This was from 2016-2018—has been superseded. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24471",
        "Series #": 9,
        "Title": "China: Three-Year Guidance for Internet Plus AI Plan",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-or0Bnw6OLs",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-or0Bnw6OLs",
      "name": "China: Three-Year Guidance for Internet Plus AI Plan",
      "index": 462,
      "createdAt": "2024-05-30T01:18:08.954Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-or0Bnw6OLs"
    },
    {
      "values": {
        "Policy Name": "National New Generation AI Promotion Office",
        "Policy creator": [
          "China"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This dates back to 2017, and has been superseded. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27192",
        "Series #": 8,
        "Title": "China: National New Generation AI Promotion Office",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-I_xhQt8dBI",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-I_xhQt8dBI",
      "name": "China: National New Generation AI Promotion Office",
      "index": 461,
      "createdAt": "2024-05-30T01:17:54.534Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-I_xhQt8dBI"
    },
    {
      "values": {
        "Policy Name": "National New Generation AI Governance Specialist Committee",
        "Policy creator": [
          "China"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The creation of this committee is less relevant than the material it has produced, which I have included. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24426",
        "Series #": 7,
        "Title": "China: National New Generation AI Governance Specialist Committee",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-6ncAQ_DcZN",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-6ncAQ_DcZN",
      "name": "China: National New Generation AI Governance Specialist Committee",
      "index": 460,
      "createdAt": "2024-05-30T01:17:34.411Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-6ncAQ_DcZN"
    },
    {
      "values": {
        "Policy Name": "Guiding Opinions on Strengthening Overall Governance of Internet Information Service Algorithms",
        "Policy creator": [
          "China"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is only loosely relevant. There is more directly relevant material.\nTranslation: Guiding Opinions on Strengthening Overall Governance of Internet Information Service Algorithms (stanford.edu)",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27297",
        "Series #": 6,
        "Title": "China: Guiding Opinions on Strengthening Overall Governance of Internet Information Service Algorithms",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-B-nnpKgtJx",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-B-nnpKgtJx",
      "name": "China: Guiding Opinions on Strengthening Overall Governance of Internet Information Service Algorithms",
      "index": 459,
      "createdAt": "2024-05-30T01:17:13.688Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-B-nnpKgtJx"
    },
    {
      "values": {
        "Policy Name": "Governance Principles for New Generation AI",
        "Policy creator": [
          "China"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "These are broadly relevant.",
        "File": [
          "Governance Principles for the New Generation Artificial Intelligence--Developing Responsible Artificial Intelligence - Chinadaily.com.cn.pdf"
        ],
        "Year of Commencement or Creation": "2019",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24427",
        "Series #": 5,
        "Title": "China: Governance Principles for New Generation AI",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“The development of AI should be based on the premise of ensuring social security and respecting human rights, and should prevent misuse, abuse and evil use of AI technology by all means.” (p 1)\n“AI development should respect and protect the privacy of individuals and fully protect an individual’s rights to know and to choose.” (p 2)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“The development of AI should promote fairness and justice, protect the rights and interests of all stakeholders, and promote equal opportunities.” (p 2)\n\nCould also be interpreted as formal (rather than substantive) equality: \n“Through technology advancement and management improvement, prejudices and discriminations should be eliminated as much as possible in the process of data acquisition, algorithm design, technology development, and product development and application.” (p 2)",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society."
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": true,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-VbWA0f4jSi",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-VbWA0f4jSi",
      "name": "China: Governance Principles for New Generation AI",
      "index": 458,
      "createdAt": "2024-05-30T01:17:03.342Z",
      "updatedAt": "2024-06-04T22:34:36.295Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-VbWA0f4jSi"
    },
    {
      "values": {
        "Policy Name": "14th Five-Year Plan for National Economic and Social Development of the People’s Republic of China",
        "Policy creator": [
          "China"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Did a translation, but not relevant—focused on development broadly, and does not talk about “intelligent education” in any depth. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27179",
        "Series #": 4,
        "Title": "China: 14th Five-Year Plan for National Economic and Social Development of the People’s Republic of China",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "Translation Completed (Google Translate)",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-di6dDFy-xR",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-di6dDFy-xR",
      "name": "China: 14th Five-Year Plan for National Economic and Social Development of the People’s Republic of China",
      "index": 457,
      "createdAt": "2024-05-30T01:16:47.649Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-di6dDFy-xR"
    },
    {
      "values": {
        "Policy Name": "National New Generation AI Plan",
        "Policy creator": [
          "China"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "“Intelligent education” is built into China’s plan. \nNote that far more detailed information about its educational intentions are built into its subsequent education policy (included in our policy tool). ",
        "File": [
          "P020210628714286134479.pdf"
        ],
        "Year of Commencement or Creation": "2017",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24274",
        "Series #": 3,
        "Title": "China: National New Generation AI Plan",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "Official Translation Obtained",
        "Key quotes on AI in education principles": "(p 7)\n\nVery minimal commentary on risks. This is it: “While robustly developing AI, we must highlight the potential safety risks, enhance early prevention and guidance, reduce risks to a maximum degree and ensure the safe, reliable and manageable development of AI.”\n\nThe main usage of “governance” relates to “intelligent social governance” (by which it means “public administration”). \n",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "N/A",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "[N/A]"
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-5nkZlHdSBx",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-5nkZlHdSBx",
      "name": "China: National New Generation AI Plan",
      "index": 456,
      "createdAt": "2024-05-30T01:16:33.257Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-5nkZlHdSBx"
    },
    {
      "values": {
        "Policy Name": "AI Innovation Action Plan for Institutions of Higher Education",
        "Policy creator": [
          "China"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This has a section on “intelligent education” that is directly relevant—and really interesting. As far back as 2018, it was looking into the following: “Accelerate and promote the deep integration and innovative development of AI in education.” See details below. \nNote, however, that this strategy is broader in scope than “EdTech governance” — it considers the role of educational institutions in developing a robust AI sector. ",
        "File": [
          "Notice-of-the-Ministry-of-Education-on-Issuing-the-Artificial-Intelligence-Innovation-Action-Plan-for-Institutes-of-Higher-Education.pdf"
        ],
        "Year of Commencement or Creation": "2018",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Communicates a stance. It expresses a hope for the future of AI",
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26851",
        "Series #": 2,
        "Title": "China: AI Innovation Action Plan for Institutions of Higher Education",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "Official Translation Obtained",
        "Key quotes on AI in education principles": "There is significant appetite here:\n“Using smart technology to innovate new ways to provide training, revolutionize teaching methods, improve academic administration, and build an intelligentized, networked, personalized, lifelong education system are important measures for promoting the development of balanced education, educational equity, and increased education quality. It is an indispensable driver of and support for educational modernization.” (p 2)\n\nWhat does it want to do with AI in education?\n“Promote the development of intelligent education. Promote educational and teaching reform. Move towards a smart campus model based on digital campuses. Create a technology-enabled teaching environment. Explore new AI-based teaching models. Reconstruct how teachers teach, using AI to monitor the teaching process, analyze students, and assess attainment levels. Set up comprehensive, multi-dimensional, big data-based smart assessments. Accurately evaluate both teacher and student performance. Institute individualized aptitude-based curricula. Promote academic administration reform. Support schools’ use of AI technology to modify their organizational structures and management systems and optimize how they operate and serve their students. Implement delicacy management and personalized service on campuses to completely upgrade schools’ administrative levels. Promote lifelong online learning, encourage the development of student-centric intelligentized learning platforms, provide a rich variety of personalized learning resources, innovate how services are provided, and tailor lifelong learning.” (p 10)\n“Demonstrating the application of AI in intelligent education. Accelerate and promote the deep integration and innovative development of AI in education. Research strategies, standards, and specifications for developing intelligent education. Explore channels and methods for integrating AI technology into the educational environment, teaching models, curricula, teaching methods, academic administration, educational assessment, and educational research. Develop an intelligentized, cloud-based education platform and encourage new ways of teaching that are supported by AI to modernize education from the ground up.” (p 11)",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "N/A",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“Using smart technology to innovate new ways to provide training, revolutionize teaching methods, improve academic administration, and build an intelligentized, networked, personalized, lifelong education system are important measures for promoting the development of balanced education, educational equity, and increased education quality. It is an indispensable driver of and support for educational modernization” (p 2)",
        "General principles on AI": [
          "[N/A]"
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-SE9pMo8wjZ",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-SE9pMo8wjZ",
      "name": "China: AI Innovation Action Plan for Institutions of Higher Education",
      "index": 61,
      "createdAt": "2024-05-30T01:15:57.142Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-SE9pMo8wjZ"
    },
    {
      "values": {
        "Policy Name": "Beijing Consensus on AI and Education",
        "Policy creator": [
          "UNESCO"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "It is difficult to think of a more relevant document than this. It is all about AI empowering teachers, helping manage schools, and so on. ",
        "File": [
          "W020190828311234688933.pdf"
        ],
        "Year of Commencement or Creation": "2019",
        "Relevance Type": [
          "Policy is about AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Managing bias. The risk of bias should be managed with care. "
        ],
        "Governance practices employed": "",
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27218",
        "Series #": 1,
        "Title": "UNESCO: Beijing Consensus on AI and Education",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "IO"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "Opportunities:\n“We are committed to leading appropriate policy responses aimed at the systematic integration of AI and education to innovate education, teaching and learning, and at leveraging AI to accelerate the delivery of open and flexible education systems that enable equitable, relevant and quality lifelong learning opportunities for all that will contribute to achieving the SDGs and the shared future for mankind.” (p 3)\nTalks about AI for education management and delivery\n“10. Be cognizant of the breakthrough in the use of data in transforming evidence-based policy planning processes. Consider integrating or developing AI technologies and tools that are relevant for upgrading education management information systems (EMIS) in order to enhance data collection and processing, making education management and provision more equitable, inclusive, open and personalized. “\n“11. Consider also introducing new models for delivering education and training in different learning institutions and settings that can be enabled by the use of AI, in order to serve different actors such as students, teaching staff, parents and communities” (p 5)\nTalks about AI to empower teaching and teachers\n“Be mindful that while AI provides opportunities to support teachers in their educational and pedagogical responsibilities, human interaction and collaboration between teachers and learners must remain at the core of education...” (p 5)\n“Dynamically review and define teachers’ roles and required competencies in the context of teacher policies, strengthen teacher training institutions, and develop appropriate capacity-building programmes to prepare teachers to work effectively in AI-rich education settings.” (p 5)\nTalks about AI for learning and assessment\n“Be cognizant of trends regarding the potential of AI to support learning and learning assessments”... (p 5)\nAugmentation not replacement\n“Be aware that teachers cannot be displaced by machines, and ensure that their rights and working conditions are protected” (p 5)\nEthical, transparent, and auditable\nSee p 8\n\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Starts with a background statement:\n“We also recognize the distinctive features of human intelligence. Recalling the principles set forth in the Universal Declaration of Human Rights, we reaffirm UNESCO’s humanistic approach to the use of AI with a view towards protecting human rights and preparing all people with the appropriate values and skills needed for effective human–machine collaboration in life, learning and work, and for sustainable development.” (p 4)\nMoves on to more significant propositions:\n“Coordinate collective actions to promote the equitable use of AI in education in the context of the global and regional Education 2030 architecture, including through sharing AI technology, programmes and resources for capacity-building, with due respect for human rights and gender equality” (p 9)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "“Recalling the Qingdao Declaration adopted in 2015 on leveraging information and communication technology (ICT) to achieve SDG 4, which stated that emerging technologies must be harnessed to strengthen education systems, access to education for all, quality and effective learning, and equitable and more efficient service provision, we are cognizant of the urgency of reaffirming and renewing this commitment as we move towards an era characterized by the widespread application of AI.” (p 3)\nThe main section on equity comes later:\n“22. Reaffirm that ensuring inclusion and equity in and through education, and offering lifelong learning opportunities to all, are the cornerstones of achieving SDG 4 – Education 2030. Reaffirm that technological breakthroughs in the field of AI in education are an opportunity to improve access to education for the most vulnerable groups.” (p 7)\n“23. Ensure that AI promotes high-quality education and learning opportunities for all, irrespective of gender, disability, social or economic status, ethnic or cultural background, or geographic location. The development and use of AI in education should not deepen the digital divide and must not display bias against any minority or vulnerable groups.” (p 7)\n“24. Ensure that AI tools in teaching and learning enable the effective inclusion of students with learning impairments or disabilities and those studying in a language other than their mother tongue.” (p 7)\nEtc",
        "General principles on AI": [
          "[N/A]"
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-0pzKRyXc_Y",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-0pzKRyXc_Y",
      "name": "UNESCO: Beijing Consensus on AI and Education",
      "index": 56,
      "createdAt": "2024-05-30T01:15:43.255Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-0pzKRyXc_Y"
    },
    {
      "values": {
        "Policy Name": "Development of common standards in the use of artificial intelligence in the digitization process in order to ensure guarantees of equal access and respect for human rights. ",
        "Policy creator": [
          "Bulgaria"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This sounds interesting, sure; but the policy does not seem to exist. There is no link or native-language reference to search. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27670",
        "Series #": 3,
        "Title": "Bulgaria: Development of common standards in the use of artificial intelligence in the digitization process in order to ensure guarantees of equal access and respect for human rights. ",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Cannot Access",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-_N74miOuk9",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_N74miOuk9",
      "name": "Bulgaria: Development of common standards in the use of artificial intelligence in the digitization process in order to ensure guarantees of equal access and respect for human rights. ",
      "index": 64,
      "createdAt": "2024-05-30T01:10:19.669Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_N74miOuk9"
    },
    {
      "values": {
        "Policy Name": "Innovation Strategy for Smart Specialisation 2021-2027",
        "Policy creator": [
          "Bulgaria"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This does not seem as relevant as the previous document—it is focused in par on informatics, but a lot of other stuff: mechatronics, biotechnology, clean technologies, etc. Education is not mentioned. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27671",
        "Series #": 2,
        "Title": "Bulgaria: Innovation Strategy for Smart Specialisation 2021-2027",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-y3WNKE3QaF",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-y3WNKE3QaF",
      "name": "Bulgaria: Innovation Strategy for Smart Specialisation 2021-2027",
      "index": 63,
      "createdAt": "2024-05-30T01:07:58.329Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-y3WNKE3QaF"
    },
    {
      "values": {
        "Policy Name": "Concept for the Development of AI in Bulgaria until 2030",
        "Policy creator": [
          "Bulgaria"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is broad acknowledgment that AI will contribute to modernisation of schools, but also generally relevant governance norms. ",
        "File": [
          "conceptforthedevelopmentofaiinbulgariauntil2030.pdf"
        ],
        "Year of Commencement or Creation": "2020",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education",
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. ",
          "Human rights-centred. The technology must be consistent with human rights. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Communicates a stance. It expresses a hope for the future of AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26500",
        "Series #": 1,
        "Title": "Bulgaria: Concept for the Development of AI in Bulgaria until 2030",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "The document makes some general remarks regarding the importance of AI education (curriculum) in primary and secondary schools in meeting skills requirements, as well as development of AI-focused university programs (including for noting, but not relevant to current project):\n“A key role for the development and implementation of AI is the availability of human potential: specialists who are familiar with the latest discoveries and trends in the field, to master methods and tools for scientific research, implementation in practice and teaching, or to be able explain the benefits of adopting intelligent systems for widespread use.\nMore relevant content — \nGeneral governance norm: \n“Special attention to the study of the impact of AI on society, as well as to the standards for building reliable AI. This suggests, on the one hand, the inclusion in the university educational programmes in informatics and technical specialties of academic disciplines focused on the legal, ethical and social aspects of AI, and on the other hand, the inclusion of disciplines for researching the impact of AI in the schools of social sciences, legal sciences and humanities.” (p 37)\nOther norms include preparing students to understand the risks of the technology, which is relevant:\n“Increasing students' competencies in the field of ethical issues related to the use of information technology and their rights in the digital world in which they live.” (p 36)\nRelevant to opportunity: \n“Applying AI tools in education to increase the quality, attractiveness and efficiency of the educational process, while strictly observing the protection of fundamental rights and proper consideration of the vulnerable situation of children.” (p 36)\n“Implementing AI in university management. Given the breakthrough in the use of data to transform planning processes, to develop and integrate AI technologies and tools that are important for improving education management information systems (EMIS) to optimize data collection and processing to achieve a fairer, more inclusive, open and personalized education.” (p 37)\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "“It must create a unique \"trust ecosystem\" by ensuring compliance with EU rules, including those for the protection of fundamental human rights and consumer rights, especially in relation to high-risk AI systems.” (p 31)\n“Reliable AI presupposes the development of a legal framework to ensure that the fundamental rights of citizens are preserved, including ensuring product safety and determining legal liability.” (p 16)\n“The principles of respect for fundamental rights, non-discrimination and the protection of personal data should be seen as an integral part of the requirements that ensure the safety of AI technologies.” (p 40)\n“To provide the necessary conditions for ensuring the development of reliable AI technologies in Bulgaria, an assessment of the applicability and effectiveness of the existing regulations on guaranteeing the fundamental rights of citizens and the safety of new products, including AI technologies, as well as the methodology for licensing these products and putting them into operation.” (p 41)",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": true,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-ks1e65Ehoi",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ks1e65Ehoi",
      "name": "Bulgaria: Concept for the Development of AI in Bulgaria until 2030",
      "index": 62,
      "createdAt": "2024-05-30T01:05:01.550Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ks1e65Ehoi"
    },
    {
      "values": {
        "Policy Name": "Jaque and Services Guide",
        "Policy creator": [
          "Brazil"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is really cool: “Jaque is a virtual clerk based on AI made to guide citizens through “Services Guide”, a digital catalogue that centralises all information regarding public services offered by the State Government of Alagoas. Services Guide provides a step-by-step explanation for each service provided by each public agency. It contains information such as the length of processes, documents needed, location and operation time of agencies, availability of services and so on.”\nHowever, it is not super relevant to EdTech. There is no regulatory documentation provided as part of this, so effectively the initiative is the creation of a chatbot. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27235",
        "Series #": 5,
        "Title": "Brazil: Jaque and Services Guide",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-g4h_KRp_Ah",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-g4h_KRp_Ah",
      "name": "Brazil: Jaque and Services Guide",
      "index": 455,
      "createdAt": "2024-05-29T08:50:45.460Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-g4h_KRp_Ah"
    },
    {
      "values": {
        "Policy Name": "Government Committee of the Brazilian AI Strategy",
        "Policy creator": [
          "Brazil"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The existence of this committee is not the relevant aspect of the broader policy initiative. It is some of the things created, which are included in this list. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27343",
        "Series #": 4,
        "Title": "Brazil: Government Committee of the Brazilian AI Strategy",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-BSHcOwqz1n",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-BSHcOwqz1n",
      "name": "Brazil: Government Committee of the Brazilian AI Strategy",
      "index": 454,
      "createdAt": "2024-05-29T08:50:31.869Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-BSHcOwqz1n"
    },
    {
      "values": {
        "Policy Name": "Brazilian Strategy for Digital Innovation",
        "Policy creator": [
          "Brazil"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This focuses on basic infrastructure and digitisation — very limited AI focus, and little (if anything) on EdTech. ",
        "File": [
          "digitalstrategy_2022-2026.pdf"
        ],
        "Year of Commencement or Creation": "2022",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24273",
        "Series #": 3,
        "Title": "Brazil: Brazilian Strategy for Digital Innovation",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-pDgALXxLja",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-pDgALXxLja",
      "name": "Brazil: Brazilian Strategy for Digital Innovation",
      "index": 453,
      "createdAt": "2024-05-29T08:50:19.460Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-pDgALXxLja"
    },
    {
      "values": {
        "Policy Name": "AI Use Cases in the Public Sector",
        "Policy creator": [
          "Brazil"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This looks really, really cool. Discussed here:\nArtificial ladies against corruption: searching for legitimacy at the Brazilian Supreme Audit Institution (redalyc.org)\nHowever, less relevant to EdTech. Something to be aware of for future projects. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27107",
        "Series #": 2,
        "Title": "Brazil: AI Use Cases in the Public Sector",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-QyQqT289r6",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-QyQqT289r6",
      "name": "Brazil: AI Use Cases in the Public Sector",
      "index": 452,
      "createdAt": "2024-05-29T08:50:13.960Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-QyQqT289r6"
    },
    {
      "values": {
        "Policy Name": "Brazilian AI Strategy",
        "Policy creator": [
          "Brazil"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "It is worth assessing this, but I can say just looking at the summary that it is at least generally relevant as a broad governance initiative (it expresses key AI governance norms that are familiar—transparency, explainability, etc). ",
        "File": [
          "Brazil_Brazilian_AI_Strategy_2021.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27104",
        "Series #": 1,
        "Title": "Brazil: Brazilian AI Strategy",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-_lBFf1wOCQ",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_lBFf1wOCQ",
      "name": "Brazil: Brazilian AI Strategy",
      "index": 65,
      "createdAt": "2024-05-29T08:49:45.629Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_lBFf1wOCQ"
    },
    {
      "values": {
        "Policy Name": "AI4T",
        "Policy creator": [
          "France",
          "Italy",
          "Ireland",
          "Luxembourg",
          "Slovenia"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is highly relevant — about preparing teachers to embrace AI in education / ensuring that have the skills to manage it. Note that it is France and others. \nAI4T - Artificial Intelligence for and by teachers | France Education international (france-education-international.fr)\n\nHere is a link to the textbook, which I have included as a secondary source:\nAI for Teachers — Textbook",
        "File": [
          "AI4T - Artificial Intelligence for and by teachers _ France Education international.pdf"
        ],
        "Year of Commencement or Creation": "2021",
        "Relevance Type": [
          "Policy is about AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary"
        ],
        "Principles on AI in education": [
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Develops tools. It provides tools and place them in the hands of businesses or governments"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "",
        "Series #": 13,
        "Title": "FranceItalyIrelandLuxembourgSlovenia: AI4T",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "OECD",
          "OECD",
          "OECD",
          "OECD",
          "OECD"
        ],
        "Translation Comments": "Translation Completed (Google Translate)",
        "Key quotes on AI in education principles": "“At the end of the project, the aim is that teachers will become more confident and aware users of AI-based resources, which will help them to improve their practice. In addition, AI4T is contributing to the implementation of new teaching methods in the classroom and to the informed use of AI as a decision-making aid. A European network is being set up to share experience and best practice.” (no pinpoint)\n\nNote that they actually built a textbook:\nTextbook – AI4T project",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "[N/A]"
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": true,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-NzS1c7nWDB",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-NzS1c7nWDB",
      "name": "FranceItalyIrelandLuxembourgSlovenia: AI4T",
      "index": 441,
      "createdAt": "2024-05-29T08:20:33.114Z",
      "updatedAt": "2024-06-04T22:38:02.206Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-NzS1c7nWDB"
    },
    {
      "values": {
        "Policy Name": "Teleworking: The Rules and Best Practices to Follow",
        "Policy creator": [
          "France"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Initially, I wondered whether this could be applied to surveillance issues pertaining to EdTech. However, it is very particular to “work” (and France’s legal framework/culture). Difficult to apply more broadly. ",
        "File": [],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27434",
        "Series #": 12,
        "Title": "France: Teleworking: The Rules and Best Practices to Follow",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-lWNXwOfiPL",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-lWNXwOfiPL",
      "name": "France: Teleworking: The Rules and Best Practices to Follow",
      "index": 451,
      "createdAt": "2024-05-29T07:50:40.866Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-lWNXwOfiPL"
    },
    {
      "values": {
        "Policy Name": "Our AI: Our Ambition for France",
        "Policy creator": [
          "France"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This seems to be the latest strategy for France. It looks promising, but I need to translate it to assess relevance. ",
        "File": [
          "4d3cc456dd2f5b9d79ee75feea63b47f10d75158.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27690",
        "Series #": 11,
        "Title": "France: Our AI: Our Ambition for France",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-0uDK4VOD0p",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-0uDK4VOD0p",
      "name": "France: Our AI: Our Ambition for France",
      "index": 450,
      "createdAt": "2024-05-29T07:50:31.398Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-0uDK4VOD0p"
    },
    {
      "values": {
        "Policy Name": "Labour AI",
        "Policy creator": [
          "France"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a research centre. It does not appear to carry out work on EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26504",
        "Series #": 10,
        "Title": "France: Labour AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-m3Ejw5rxRR",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-m3Ejw5rxRR",
      "name": "France: Labour AI",
      "index": 449,
      "createdAt": "2024-05-29T07:50:23.193Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-m3Ejw5rxRR"
    },
    {
      "values": {
        "Policy Name": "International Panel on AI",
        "Policy creator": [
          "France"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is an “international study group”. It is not EdTech related, so only their specific work on EdTech would make the cut. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27217",
        "Series #": 9,
        "Title": "France: International Panel on AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-G63j8tX4ZP",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-G63j8tX4ZP",
      "name": "France: International Panel on AI",
      "index": 448,
      "createdAt": "2024-05-29T07:50:13.385Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-G63j8tX4ZP"
    },
    {
      "values": {
        "Policy Name": "Health Data Hub",
        "Policy creator": [
          "France"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "One plausible point of relevance would be if schools were collecting health data on students—but even still, this is not regulatory, but a project designed to collect the data. That collection exercise is not relevant to EdTech governance. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27214",
        "Series #": 8,
        "Title": "France: Health Data Hub",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-i6muk9OQS0",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-i6muk9OQS0",
      "name": "France: Health Data Hub",
      "index": 447,
      "createdAt": "2024-05-29T07:50:07.804Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-i6muk9OQS0"
    },
    {
      "values": {
        "Policy Name": "Gaia-X",
        "Policy creator": [
          "France"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is an interoperable data exchange for businesses to exchange information. Not especially relevant. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26761",
        "Series #": 7,
        "Title": "France: Gaia-X",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-ybly4XtJaP",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ybly4XtJaP",
      "name": "France: Gaia-X",
      "index": 446,
      "createdAt": "2024-05-29T07:50:02.602Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ybly4XtJaP"
    },
    {
      "values": {
        "Policy Name": "France AI",
        "Policy creator": [
          "France"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is an old report. It has been superseded by Villani’s report. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-16323",
        "Series #": 6,
        "Title": "France: France AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-Nhrznf1Pjy",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Nhrznf1Pjy",
      "name": "France: France AI",
      "index": 445,
      "createdAt": "2024-05-29T07:49:47.719Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Nhrznf1Pjy"
    },
    {
      "values": {
        "Policy Name": "Etalab",
        "Policy creator": [
          "France"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a body created to coordinate strategy in the data domain. Its creation is only very loosely related to EdTech governance. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27267",
        "Series #": 5,
        "Title": "France: Etalab",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-XvjNjbosTy",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-XvjNjbosTy",
      "name": "France: Etalab",
      "index": 444,
      "createdAt": "2024-05-29T07:49:39.283Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-XvjNjbosTy"
    },
    {
      "values": {
        "Policy Name": "Confiance.AI Program",
        "Policy creator": [
          "France"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The body — as a policy initiative — is interesting but removed from EdTech. Perhaps some of the work they do — secondary materials — would be useful when doing our literature review, but given our focus here on policy, this can be set aside. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27280",
        "Series #": 4,
        "Title": "France: Confiance.AI Program",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-knoo63cMO3",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-knoo63cMO3",
      "name": "France: Confiance.AI Program",
      "index": 443,
      "createdAt": "2024-05-29T07:49:33.678Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-knoo63cMO3"
    },
    {
      "values": {
        "Policy Name": "Cloud Strategy",
        "Policy creator": [
          "France"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is quite a broad infrastructural project. It is only loosely relevant to EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27279",
        "Series #": 3,
        "Title": "France: Cloud Strategy",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-Q4het9T_ad",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Q4het9T_ad",
      "name": "France: Cloud Strategy",
      "index": 442,
      "createdAt": "2024-05-29T07:49:29.921Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Q4het9T_ad"
    },
    {
      "values": {
        "Policy Name": "AI Education & Training Development Plan",
        "Policy creator": [
          "France"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "It seems as though the resource linked is incorrect. It seems very focused on building skills/research rather than EdTech, but we cannot be sure. I searched the French title, but could not find the relevant document. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27288",
        "Series #": 2,
        "Title": "France: AI Education & Training Development Plan",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Cannot Access",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-BVeDyvWUNx",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-BVeDyvWUNx",
      "name": "France: AI Education & Training Development Plan",
      "index": 440,
      "createdAt": "2024-05-29T07:49:22.574Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-BVeDyvWUNx"
    },
    {
      "values": {
        "Policy Name": "National Strategy on AI",
        "Policy creator": [
          "France"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Potentially relevant — but the report cannot be downloaded (”Cannot reach this page”). Try again at a later date. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25374",
        "Series #": 1,
        "Title": "France: National Strategy on AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Cannot Access",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-9ZTn46N9cK",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-9ZTn46N9cK",
      "name": "France: National Strategy on AI",
      "index": 66,
      "createdAt": "2024-05-29T07:49:15.022Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-9ZTn46N9cK"
    },
    {
      "values": {
        "Policy Name": "Technology Committee within the Framework of the National System of Competitiveness and Innovation",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is only very loosely related — the initiative is the creation of a body to steer numerous AI initiatives. Only remotely related to EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27696",
        "Series #": 17,
        "Title": "Colombia: Technology Committee within the Framework of the National System of Competitiveness and Innovation",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-icfqZ7fYsA",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-icfqZ7fYsA",
      "name": "Colombia: Technology Committee within the Framework of the National System of Competitiveness and Innovation",
      "index": 439,
      "createdAt": "2024-05-29T07:10:04.092Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-icfqZ7fYsA"
    },
    {
      "values": {
        "Policy Name": "Strategic Plan for Knowledge Transfer in AI",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is focused on the scientific sector—communicating knowledge to industry. Not especially relevant. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27093",
        "Series #": 16,
        "Title": "Colombia: Strategic Plan for Knowledge Transfer in AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-_TEusYyffp",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_TEusYyffp",
      "name": "Colombia: Strategic Plan for Knowledge Transfer in AI",
      "index": 438,
      "createdAt": "2024-05-29T07:09:49.403Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_TEusYyffp"
    },
    {
      "values": {
        "Policy Name": "Policy of Research Ethics, Bioethics and Scientific Integrity",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Not relevant to EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26741",
        "Series #": 15,
        "Title": "Colombia: Policy of Research Ethics, Bioethics and Scientific Integrity",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-oDKlUj88YN",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-oDKlUj88YN",
      "name": "Colombia: Policy of Research Ethics, Bioethics and Scientific Integrity",
      "index": 437,
      "createdAt": "2024-05-29T07:09:37.057Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-oDKlUj88YN"
    },
    {
      "values": {
        "Policy Name": "Mechanism for the Implementation of Principles and International Standards in AI",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This looks like an interesting policy. This initiative could be replicated in the EdTech space. However, a translation is needed before we can make a final assessment of relevance. ",
        "File": [
          "libro final No 2 Parte 1 Libro No 2 Plan_Seguimiento_OCDE_Astrid_Angarita.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27038",
        "Series #": 14,
        "Title": "Colombia: Mechanism for the Implementation of Principles and International Standards in AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-tvgopeO6Rq",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-tvgopeO6Rq",
      "name": "Colombia: Mechanism for the Implementation of Principles and International Standards in AI",
      "index": 436,
      "createdAt": "2024-05-29T07:08:51.993Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-tvgopeO6Rq"
    },
    {
      "values": {
        "Policy Name": "Law for the Promotion of AI Technology and Entrepreneurship",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "I was interested to see whether education was singled out. It does not appear so. It is a broader regulatory framework. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27183",
        "Series #": 13,
        "Title": "Colombia: Law for the Promotion of AI Technology and Entrepreneurship",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-dAbc1DZA4V",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-dAbc1DZA4V",
      "name": "Colombia: Law for the Promotion of AI Technology and Entrepreneurship",
      "index": 435,
      "createdAt": "2024-05-29T07:08:44.211Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-dAbc1DZA4V"
    },
    {
      "values": {
        "Policy Name": "GovTech Ecosystem for AI Implementation ",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is procurement-oriented. One imagines that this could be applied to EdTech. There is not a whole heap of information available here about this. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26994",
        "Series #": 12,
        "Title": "Colombia: GovTech Ecosystem for AI Implementation ",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Cannot Access",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-rvsG1Riaj1",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-rvsG1Riaj1",
      "name": "Colombia: GovTech Ecosystem for AI Implementation ",
      "index": 434,
      "createdAt": "2024-05-29T07:08:33.425Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-rvsG1Riaj1"
    },
    {
      "values": {
        "Policy Name": "Ethical Framework for AI in Columbia",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Cannot presently access this material — links to one of the Colombian government sites are not opening. Check back as this looks promising. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26737",
        "Series #": 11,
        "Title": "Colombia: Ethical Framework for AI in Columbia",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Cannot Access",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-1ykChTTv8T",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-1ykChTTv8T",
      "name": "Colombia: Ethical Framework for AI in Columbia",
      "index": 433,
      "createdAt": "2024-05-29T07:08:22.113Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-1ykChTTv8T"
    },
    {
      "values": {
        "Policy Name": "Emerging Technologies Handbook ",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Cannot presently access this material — links to one of the Colombian government sites are not opening. Check back as this looks promising. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27143",
        "Series #": 10,
        "Title": "Colombia: Emerging Technologies Handbook ",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Cannot Access",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-CQu8KC-90B",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-CQu8KC-90B",
      "name": "Colombia: Emerging Technologies Handbook ",
      "index": 432,
      "createdAt": "2024-05-29T07:08:10.610Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-CQu8KC-90B"
    },
    {
      "values": {
        "Policy Name": "Data Marketplace and Data Infrastructure",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Only loosely related to EdTech—cool infrastructure, but a little tangential to our work at this stage.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26995",
        "Series #": 9,
        "Title": "Colombia: Data Marketplace and Data Infrastructure",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-5xIBSFk8Qs",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-5xIBSFk8Qs",
      "name": "Colombia: Data Marketplace and Data Infrastructure",
      "index": 431,
      "createdAt": "2024-05-29T07:08:02.739Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-5xIBSFk8Qs"
    },
    {
      "values": {
        "Policy Name": "Cybersecurity Policy for AI Deployment",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Cybersecurity is a hugely important aspect of AI in education. This seems like a potentially relevant initiative. However, I am facing problems accessing the materials (they cannot be reached). We are probably going to be prioritising more directly relevant materials anyway, but this one would be good to come back to—time permitting. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27185",
        "Series #": 8,
        "Title": "Colombia: Cybersecurity Policy for AI Deployment",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-7NQ9ULxsi9",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-7NQ9ULxsi9",
      "name": "Colombia: Cybersecurity Policy for AI Deployment",
      "index": 430,
      "createdAt": "2024-05-29T07:07:49.724Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-7NQ9ULxsi9"
    },
    {
      "values": {
        "Policy Name": "Columbian Supercomputing Network",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Not focused here on supercomputers. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27182",
        "Series #": 7,
        "Title": "Colombia: Columbian Supercomputing Network",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-UOALbL_G4g",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-UOALbL_G4g",
      "name": "Colombia: Columbian Supercomputing Network",
      "index": 429,
      "createdAt": "2024-05-29T07:07:36.966Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-UOALbL_G4g"
    },
    {
      "values": {
        "Policy Name": "Co-Ordination Bodies for AI Policy Implementation",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is about coordinating a whole range of AI work across government. Not especially relevant to EdTech / AI in education. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27187",
        "Series #": 6,
        "Title": "Colombia: Co-Ordination Bodies for AI Policy Implementation",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-slPOkrUTED",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-slPOkrUTED",
      "name": "Colombia: Co-Ordination Bodies for AI Policy Implementation",
      "index": 428,
      "createdAt": "2024-05-29T07:07:21.127Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-slPOkrUTED"
    },
    {
      "values": {
        "Policy Name": "C4IR Network",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This seems to be some kind of thinktank for research and development. EdTech is not mentioned, and does not appear to be central (or even peripheral) to its agenda. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26448",
        "Series #": 5,
        "Title": "Colombia: C4IR Network",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-ZyUBSOjFMP",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ZyUBSOjFMP",
      "name": "Colombia: C4IR Network",
      "index": 427,
      "createdAt": "2024-05-29T07:07:18.908Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ZyUBSOjFMP"
    },
    {
      "values": {
        "Policy Name": "Building a Regulatory Ecosystem for AI",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This initiative is designed to enable regulatory experimentation. It does not talk about education per se. Only indirectly relevant. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26723",
        "Series #": 4,
        "Title": "Colombia: Building a Regulatory Ecosystem for AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-mlJlLqQ6Ny",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-mlJlLqQ6Ny",
      "name": "Colombia: Building a Regulatory Ecosystem for AI",
      "index": 426,
      "createdAt": "2024-05-29T07:07:11.359Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-mlJlLqQ6Ny"
    },
    {
      "values": {
        "Policy Name": "AI in the Public Sector",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Based on a general look at this — and the time “Educativo” is mentioned, this does not look super relevant. Given that Colombia has so many policy initiatives, more relevant materials may come up elsewhere. ",
        "File": [
          "07-10-2020 Proyectos de TD, Tramites y servicios para el ciudadano_Baja.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26727",
        "Series #": 3,
        "Title": "Colombia: AI in the Public Sector",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-IlxQemmFZc",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-IlxQemmFZc",
      "name": "Colombia: AI in the Public Sector",
      "index": 425,
      "createdAt": "2024-05-29T07:07:05.705Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-IlxQemmFZc"
    },
    {
      "values": {
        "Policy Name": "AI Expert Mission",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "As an initiative, this is not especially relevant to EdTech. It is a general group set up to guide AI policy. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26993",
        "Series #": 2,
        "Title": "Colombia: AI Expert Mission",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-InSdQ-kZ40",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-InSdQ-kZ40",
      "name": "Colombia: AI Expert Mission",
      "index": 424,
      "createdAt": "2024-05-29T07:06:59.845Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-InSdQ-kZ40"
    },
    {
      "values": {
        "Policy Name": "AI National Strategy",
        "Policy creator": [
          "Colombia"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This policy is labelled as “in progress”. It would be interesting to see what is in this, but we cannot consider it yet as it is not publicly available. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27698",
        "Series #": 1,
        "Title": "Colombia: AI National Strategy",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-w0UjQQbqI4",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-w0UjQQbqI4",
      "name": "Colombia: AI National Strategy",
      "index": 67,
      "createdAt": "2024-05-29T07:06:50.984Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-w0UjQQbqI4"
    },
    {
      "values": {
        "Policy Name": "PhD Scholarships for Technological Revolution and Digital Transformation",
        "Policy creator": [
          "Chile"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is just about incentivising the procurement of valuable skills. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26734",
        "Series #": 11,
        "Title": "Chile: PhD Scholarships for Technological Revolution and Digital Transformation",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-Vd4a3YEXQv",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Vd4a3YEXQv",
      "name": "Chile: PhD Scholarships for Technological Revolution and Digital Transformation",
      "index": 78,
      "createdAt": "2024-05-29T04:40:58.591Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Vd4a3YEXQv"
    },
    {
      "values": {
        "Policy Name": "Smart Job Retraining",
        "Policy creator": [
          "Chile"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is more promising — it is about providing “tools that help [citizens] in the process of job retraining’. IDB | Smart Job Retraining (iadb.org)\nIt is not entirely clear what the ‘machine learnin’ component is. ",
        "File": "",
        "Year of Commencement or Creation": "2020",
        "Relevance Type": [
          "Policy contains case studies on AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Vocational or Professional"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Develops tools. It provides tools and place them in the hands of businesses or governments"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27049",
        "Series #": 10,
        "Title": "Chile: Smart Job Retraining",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "[N/A]"
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "TC “aims at designing a technological platform called \"Intelligent Labor Retraining\" or RELINT (in Spanish), based on a data intelligence model that allows companies and individuals to be guided in the process of retraining. On the one hand, supporting companies in a digital transformation process by introducing reskilling, upskilling and outplacement mechanisms and, on the other hand, allowing workers to improve their skills for a new type of company or to start a new labor route. This is done by linking interests, experience and employability potential with the demand that the market is requesting for new skills derived from the ongoing digital transformation.”\n",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-H3DXVgh09v",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-H3DXVgh09v",
      "name": "Chile: Smart Job Retraining",
      "index": 77,
      "createdAt": "2024-05-29T04:38:15.161Z",
      "updatedAt": "2024-06-06T03:05:20.882Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-H3DXVgh09v"
    },
    {
      "values": {
        "Policy Name": "National Digital Languages Plan",
        "Policy creator": [
          "Chile"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This sounded possible, but it is not about using AI — or other EdTech — in education, but about training teachers in computational thinking. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27048",
        "Series #": 9,
        "Title": "Chile: National Digital Languages Plan",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-i7GitAY6pz",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-i7GitAY6pz",
      "name": "Chile: National Digital Languages Plan",
      "index": 76,
      "createdAt": "2024-05-29T04:36:55.480Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-i7GitAY6pz"
    },
    {
      "values": {
        "Policy Name": "National Challenges",
        "Policy creator": [
          "Chile"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is about building capacity etc—nothing on EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25989",
        "Series #": 8,
        "Title": "Chile: National Challenges",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-kqn6BeLHLf",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-kqn6BeLHLf",
      "name": "Chile: National Challenges",
      "index": 75,
      "createdAt": "2024-05-29T04:35:24.393Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-kqn6BeLHLf"
    },
    {
      "values": {
        "Policy Name": "National AI Research Centre",
        "Policy creator": [
          "Chile"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is about cutting-edge research. No mention of EdTech.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27335",
        "Series #": 7,
        "Title": "Chile: National AI Research Centre",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-C5Xsk1o9dw",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-C5Xsk1o9dw",
      "name": "Chile: National AI Research Centre",
      "index": 74,
      "createdAt": "2024-05-29T04:34:45.562Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-C5Xsk1o9dw"
    },
    {
      "values": {
        "Policy Name": "Digital Talent",
        "Policy creator": [
          "Chile"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is about filling gaps in IT professionals. They wanted to train 16,000 professionals between 2019-2022. There is no reference to doing that with education. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27047",
        "Series #": 6,
        "Title": "Chile: Digital Talent",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-DJtWUckQ3i",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-DJtWUckQ3i",
      "name": "Chile: Digital Talent",
      "index": 73,
      "createdAt": "2024-05-29T04:32:56.676Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-DJtWUckQ3i"
    },
    {
      "values": {
        "Policy Name": "Digital Economy Partnership Agreement",
        "Policy creator": [
          "Chile"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is all very high-level/infrastructural/economic. Nothing specifically on EdTech.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26800",
        "Series #": 5,
        "Title": "Chile: Digital Economy Partnership Agreement",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-DAo7xW1P69",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-DAo7xW1P69",
      "name": "Chile: Digital Economy Partnership Agreement",
      "index": 72,
      "createdAt": "2024-05-29T04:32:09.725Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-DAo7xW1P69"
    },
    {
      "values": {
        "Policy Name": "Data Observatory",
        "Policy creator": [
          "Chile"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is about the availability of data—quite removed from EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26733",
        "Series #": 4,
        "Title": "Chile: Data Observatory",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-_NrvlE_Txc",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_NrvlE_Txc",
      "name": "Chile: Data Observatory",
      "index": 71,
      "createdAt": "2024-05-29T04:29:30.911Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_NrvlE_Txc"
    },
    {
      "values": {
        "Policy Name": "Chilean Participation Process on AI",
        "Policy creator": [
          "Chile"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The objectives here are to promote conversation about AI opportunities and challenges. Nothing here specific to EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26732",
        "Series #": 3,
        "Title": "Chile: Chilean Participation Process on AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-PrYYQR0Usw",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-PrYYQR0Usw",
      "name": "Chile: Chilean Participation Process on AI",
      "index": 70,
      "createdAt": "2024-05-29T04:28:53.496Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-PrYYQR0Usw"
    },
    {
      "values": {
        "Policy Name": "AI Use Cases in the Public Sector",
        "Policy creator": [
          "Chile"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There only appears to be one listing, which is a predictive model on industrial pollution. Not related to EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27144",
        "Series #": 2,
        "Title": "Chile: AI Use Cases in the Public Sector",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i--D8jdghw5T",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i--D8jdghw5T",
      "name": "Chile: AI Use Cases in the Public Sector",
      "index": 69,
      "createdAt": "2024-05-29T04:27:24.443Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui--D8jdghw5T"
    },
    {
      "values": {
        "Policy Name": "AI National Policy",
        "Policy creator": [
          "Chile"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Need to translate this policy — could be broadly relevant, but it is difficult to tell. Provisionally assuming ‘yes’. ",
        "File": [
          "documento_politica_ia_digital_.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24840",
        "Series #": 1,
        "Title": "Chile: AI National Policy",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-Oxs8aeoG3r",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Oxs8aeoG3r",
      "name": "Chile: AI National Policy",
      "index": 68,
      "createdAt": "2024-05-29T04:24:57.897Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Oxs8aeoG3r"
    },
    {
      "values": {
        "Policy Name": "National AI Strategy",
        "Policy creator": [
          "Cyprus"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There was not a whole heap of content on the OECD entry, but I have located an EC summary: Cyprus AI Strategy Report - European Commission (europa.eu)The key point is that there is a focus on education in AI, but not AI in education. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24848",
        "Series #": 1,
        "Title": "Cyprus: National AI Strategy",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-LIfKhG8VFT",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-LIfKhG8VFT",
      "name": "Cyprus: National AI Strategy",
      "index": 79,
      "createdAt": "2024-05-29T04:09:58.707Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-LIfKhG8VFT"
    },
    {
      "values": {
        "Policy Name": "The Development of the Digital Government of the Bicentenary",
        "Policy creator": [
          "Costa Rica"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a directive focused on building a digital government. It doesn’t reach into the realm of EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25908",
        "Series #": 6,
        "Title": "Costa Rica: The Development of the Digital Government of the Bicentenary",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-spk0OG1Xdc",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-spk0OG1Xdc",
      "name": "Costa Rica: The Development of the Digital Government of the Bicentenary",
      "index": 423,
      "createdAt": "2024-05-29T03:58:13.748Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-spk0OG1Xdc"
    },
    {
      "values": {
        "Policy Name": "Regulation and Standardisation of Technology Acquisitions And/Or Development of Management Support Computer Systems",
        "Policy creator": [
          "Costa Rica"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Another foundational policy concerned with the acquisition of electronic equipment and using software in the public service. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25917",
        "Series #": 5,
        "Title": "Costa Rica: Regulation and Standardisation of Technology Acquisitions And/Or Development of Management Support Computer Systems",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-AeVwSrF1Al",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-AeVwSrF1Al",
      "name": "Costa Rica: Regulation and Standardisation of Technology Acquisitions And/Or Development of Management Support Computer Systems",
      "index": 422,
      "createdAt": "2024-05-29T03:57:55.267Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-AeVwSrF1Al"
    },
    {
      "values": {
        "Policy Name": "Improvements in the Efficiency of Public Spending Through the Appropriate Use of Digital Technologies in the Costa Rican Public Sector ",
        "Policy creator": [
          "Costa Rica"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is more of a FinTech initiative. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25917",
        "Series #": 4,
        "Title": "Costa Rica: Improvements in the Efficiency of Public Spending Through the Appropriate Use of Digital Technologies in the Costa Rican Public Sector ",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-fHLKx461fD",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-fHLKx461fD",
      "name": "Costa Rica: Improvements in the Efficiency of Public Spending Through the Appropriate Use of Digital Technologies in the Costa Rican Public Sector ",
      "index": 421,
      "createdAt": "2024-05-29T03:57:32.016Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-fHLKx461fD"
    },
    {
      "values": {
        "Policy Name": "Implementation of Accessible Websites in the Costa Rican Public Sector",
        "Policy creator": [
          "Costa Rica"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "A third policy initiative that is public sector oriented. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25914",
        "Series #": 3,
        "Title": "Costa Rica: Implementation of Accessible Websites in the Costa Rican Public Sector",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-inBajDAtSL",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-inBajDAtSL",
      "name": "Costa Rica: Implementation of Accessible Websites in the Costa Rican Public Sector",
      "index": 420,
      "createdAt": "2024-05-29T03:57:17.427Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-inBajDAtSL"
    },
    {
      "values": {
        "Policy Name": "Digital transformation strategy: The bicentennial of Costa Rica",
        "Policy creator": [
          "Costa Rica"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This work is more fundamental — foundational — than ‘EdTech in education’. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25382",
        "Series #": 2,
        "Title": "Costa Rica: Digital transformation strategy: The bicentennial of Costa Rica",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-Wr3CxbOtsJ",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Wr3CxbOtsJ",
      "name": "Costa Rica: Digital transformation strategy: The bicentennial of Costa Rica",
      "index": 419,
      "createdAt": "2024-05-29T03:57:09.144Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Wr3CxbOtsJ"
    },
    {
      "values": {
        "Policy Name": "Creation of a high-level commission for digital government of the bicentennial",
        "Policy creator": [
          "Costa Rica"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The goal here was to improve the functioning of the public service at large. Perhaps EdTech is the icing on a cake that they have not built yet?",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25910",
        "Series #": 1,
        "Title": "Costa Rica: Creation of a high-level commission for digital government of the bicentennial",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-WMkPlNJqUJ",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-WMkPlNJqUJ",
      "name": "Costa Rica: Creation of a high-level commission for digital government of the bicentennial",
      "index": 80,
      "createdAt": "2024-05-29T03:56:50.366Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-WMkPlNJqUJ"
    },
    {
      "values": {
        "Policy Name": "Regional Innovation Plan",
        "Policy creator": [
          "Belgium"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This regional innovation plan dates back to 2016, and seems to have been superseded by Belgium’s other policy initiatives. In any case, it focused on areas other than education technology. Even the new iteration of this plan is not focused on education. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-2316",
        "Series #": 9,
        "Title": "Belgium: Regional Innovation Plan",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-SHsoJYU0uK",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-SHsoJYU0uK",
      "name": "Belgium: Regional Innovation Plan",
      "index": 86,
      "createdAt": "2024-05-29T03:52:35.491Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-SHsoJYU0uK"
    },
    {
      "values": {
        "Policy Name": "Plan Next Tech Brussels",
        "Policy creator": [
          "Belgium"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is about boosting ICT entrepreneurship, and is quite old now. The link to the documentation is broken, and there was no suggestion that this was EdTech-focused. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-14797",
        "Series #": 8,
        "Title": "Belgium: Plan Next Tech Brussels",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-hzvMDDzi03",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-hzvMDDzi03",
      "name": "Belgium: Plan Next Tech Brussels",
      "index": 85,
      "createdAt": "2024-05-29T03:51:31.810Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-hzvMDDzi03"
    },
    {
      "values": {
        "Policy Name": "Flemish Policy Plan AI",
        "Policy creator": [
          "Belgium"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There was significant expenditure here ($32m), but not — it seems — on EdTech. Sounds like a useful but now dated research initiative that was not focused on EdTech.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24902",
        "Series #": 7,
        "Title": "Belgium: Flemish Policy Plan AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-ABmWuLOKGm",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ABmWuLOKGm",
      "name": "Belgium: Flemish Policy Plan AI",
      "index": 84,
      "createdAt": "2024-05-29T03:49:51.618Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ABmWuLOKGm"
    },
    {
      "values": {
        "Policy Name": "DigitalWallinia4AI",
        "Policy creator": [
          "Belgium"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The purpose of this 2019 was to integrate European strategies in AI with Belgian initiatives. The goal was to boost regional companies’ competitiveness. This is all quite removed from EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24904",
        "Series #": 6,
        "Title": "Belgium: DigitalWallinia4AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-oJ-isBGok3",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-oJ-isBGok3",
      "name": "Belgium: DigitalWallinia4AI",
      "index": 83,
      "createdAt": "2024-05-29T03:47:40.331Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-oJ-isBGok3"
    },
    {
      "values": {
        "Policy Name": "Clusters Hub.Brussels",
        "Policy creator": [
          "Belgium"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This policy was designed to stimulate regional cooperation in R&I. There is no reference to education here.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-2981",
        "Series #": 5,
        "Title": "Belgium: Clusters Hub.Brussels",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-H2JFEh-sQI",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-H2JFEh-sQI",
      "name": "Belgium: Clusters Hub.Brussels",
      "index": 82,
      "createdAt": "2024-05-29T03:45:01.532Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-H2JFEh-sQI"
    },
    {
      "values": {
        "Policy Name": "Brussels Region AI Policy",
        "Policy creator": [
          "Belgium"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is R&D-focused, and dates back to 2018. Too remote to be included. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24907",
        "Series #": 4,
        "Title": "Belgium: Brussels Region AI Policy",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-9pGqh4qi-y",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-9pGqh4qi-y",
      "name": "Belgium: Brussels Region AI Policy",
      "index": 81,
      "createdAt": "2024-05-29T03:44:29.667Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-9pGqh4qi-y"
    },
    {
      "values": {
        "Policy Name": "AI 4 Belgium",
        "Policy creator": [
          "Belgium"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "These guidelines have a section of “AI as an education tool”. Definitely translate the broader policy document to check for relevant content—but if not, you can firmly say that, in principle, the Belgium government supports two use cases:\nDeploy AI as a tool for individualised training adapted to each individual student \nApply AI as a tool for teachers to enhance their teaching",
        "File": [
          "report_en.pdf"
        ],
        "Year of Commencement or Creation": "2019",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24234",
        "Series #": 3,
        "Title": "Belgium: AI 4 Belgium",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "Note — the existence of risk is recognised, but this is a predominantly “seize the day” policy. ",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "N/A",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“Finally, AI can also be a tool in education. It can drastically improve quality and equity in many cases.”",
        "General principles on AI": [
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D."
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-zLeK3YsXOk",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-zLeK3YsXOk",
      "name": "Belgium: AI 4 Belgium",
      "index": 88,
      "createdAt": "2024-05-29T03:41:10.073Z",
      "updatedAt": "2024-06-03T02:37:13.450Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-zLeK3YsXOk"
    },
    {
      "values": {
        "Policy Name": "Action Plan AI",
        "Policy creator": [
          "Belgium"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This plan has been superseded, and focused on strategic research rather than the generation of EdTech.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26101",
        "Series #": 2,
        "Title": "Belgium: Action Plan AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-AdIiWoBxhk",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-AdIiWoBxhk",
      "name": "Belgium: Action Plan AI",
      "index": 87,
      "createdAt": "2024-05-29T03:40:03.684Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-AdIiWoBxhk"
    },
    {
      "values": {
        "Policy Name": "National Convergence Plan for the Development of AI",
        "Policy creator": [
          "Belgium"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The information about this plan does not seem to focus on EdTech. I have attached the original document, but it is difficult to see how EdTech fits into the (English) summary available online. Possibly not a high-priority policy. One to translate if time permits. \nBelgium adopts a national plan for the development of artificial intelligence - ActuIA",
        "File": [
          "Nationaal_convergentieplan_voor_de_ontwikkeling_van_artificiele_intelligentie (1).pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "",
        "Series #": 1,
        "Title": "Belgium: National Convergence Plan for the Development of AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-3lvQMPp8Sh",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-3lvQMPp8Sh",
      "name": "Belgium: National Convergence Plan for the Development of AI",
      "index": 89,
      "createdAt": "2024-05-29T03:36:48.393Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-3lvQMPp8Sh"
    },
    {
      "values": {
        "Policy Name": "Technology Pact ",
        "Policy creator": [
          "Denmark"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a commitment to developing AI capabilities more than anything. There was, apparently, a shortage of tech-capable people, and they wanted to solve it. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24780",
        "Series #": 4,
        "Title": "Denmark: Technology Pact ",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-52TMeuHguM",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-52TMeuHguM",
      "name": "Denmark: Technology Pact ",
      "index": 418,
      "createdAt": "2024-05-29T03:31:37.477Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-52TMeuHguM"
    },
    {
      "values": {
        "Policy Name": "National Centre for Public Sector Innovation",
        "Policy creator": [
          "Denmark"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This Centre is a cool idea, but there is no reference to EdTech. It would be better characterised as a GovTech initiative, and I cannot see any generally applicable norms that could be applied to education.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26491",
        "Series #": 3,
        "Title": "Denmark: National Centre for Public Sector Innovation",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-VrYNH0y7Vv",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-VrYNH0y7Vv",
      "name": "Denmark: National Centre for Public Sector Innovation",
      "index": 92,
      "createdAt": "2024-05-29T03:31:29.510Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-VrYNH0y7Vv"
    },
    {
      "values": {
        "Policy Name": "Disruption Council ",
        "Policy creator": [
          "Denmark"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a partnership between businesses and government institutions dating back to 2017, and focused on employment. No reference to EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26486",
        "Series #": 2,
        "Title": "Denmark: Disruption Council ",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-aIqsOBL8vG",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-aIqsOBL8vG",
      "name": "Denmark: Disruption Council ",
      "index": 91,
      "createdAt": "2024-05-29T03:31:02.432Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-aIqsOBL8vG"
    },
    {
      "values": {
        "Policy Name": "The Danish National Strategy for AI",
        "Policy creator": [
          "Denmark"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Education here is understood mostly as education for AI. However, there is one small case study on the Department of Education using a chatbot to handle enquiries from citizens. However, this is a little remote from EdTech. I am not convinced that this makes it over the line. ",
        "File": [
          "305755_gb_version_final-a.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24241",
        "Series #": 1,
        "Title": "Denmark: The Danish National Strategy for AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-Gj-55ez5zA",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Gj-55ez5zA",
      "name": "Denmark: The Danish National Strategy for AI",
      "index": 90,
      "createdAt": "2024-05-29T03:26:36.762Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Gj-55ez5zA"
    },
    {
      "values": {
        "Policy Name": "Website for Personal Data Protection Impact Assessments",
        "Policy creator": [
          "Mexico"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a really cool, interactive impact assessment tool worth noting (though not for AI per se — focuses on data protection). A version of this could be developed for EdTech, whether the data protection aspect or otherwise. Am I required to file a DPIA? – EIPDP (inai.org.mx) ",
        "File": "",
        "Year of Commencement or Creation": "2020",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27479",
        "Series #": 10,
        "Title": "Mexico: Website for Personal Data Protection Impact Assessments",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "This kind of system could be useful — an impact assessment tool of sorts. \nimage.png",
        "Record Entered By": ""
      },
      "id": "i-1xjaXeD9Ml",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-1xjaXeD9Ml",
      "name": "Mexico: Website for Personal Data Protection Impact Assessments",
      "index": 417,
      "createdAt": "2024-05-29T03:06:42.064Z",
      "updatedAt": "2024-06-03T04:55:12.590Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-1xjaXeD9Ml"
    },
    {
      "values": {
        "Policy Name": "Towards an AI Strategy in Mexico: Harnessing the AI Revolution",
        "Policy creator": [
          "Mexico"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is the whitepaper that came before the strategy. It has been superseded by the strategy. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24265",
        "Series #": 9,
        "Title": "Mexico: Towards an AI Strategy in Mexico: Harnessing the AI Revolution",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-xMU58B4DzQ",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-xMU58B4DzQ",
      "name": "Mexico: Towards an AI Strategy in Mexico: Harnessing the AI Revolution",
      "index": 416,
      "createdAt": "2024-05-29T03:06:26.597Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-xMU58B4DzQ"
    },
    {
      "values": {
        "Policy Name": "Specific Guidelines for Compliance with the Principles and Rights that Govern the Protection of Personal Data in AI Projects",
        "Policy creator": [
          "Mexico"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is the more detailed version of the “RIPD document”. It was approved as far back as 2017, but might still be relevant and useful on data protection issues within schools. Need to translate. ",
        "File": [
          "guia-orientaciones-específicas-proteccion-datos-ia.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27475",
        "Series #": 8,
        "Title": "Mexico: Specific Guidelines for Compliance with the Principles and Rights that Govern the Protection of Personal Data in AI Projects",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-yRO_xPJLwx",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-yRO_xPJLwx",
      "name": "Mexico: Specific Guidelines for Compliance with the Principles and Rights that Govern the Protection of Personal Data in AI Projects",
      "index": 415,
      "createdAt": "2024-05-29T03:01:52.447Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-yRO_xPJLwx"
    },
    {
      "values": {
        "Policy Name": "Principles and Impact Analysis Guide for the Development and Use of Systems Based on AI in the Federal Public Administration",
        "Policy creator": [
          "Mexico"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This would be worth translating and having a look at. ",
        "File": [
          "Consolidado_Comentarios_Consulta_IA__1_.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24666",
        "Series #": 7,
        "Title": "Mexico: Principles and Impact Analysis Guide for the Development and Use of Systems Based on AI in the Federal Public Administration",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-SEw5vlcrsh",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-SEw5vlcrsh",
      "name": "Mexico: Principles and Impact Analysis Guide for the Development and Use of Systems Based on AI in the Federal Public Administration",
      "index": 414,
      "createdAt": "2024-05-29T03:01:22.341Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-SEw5vlcrsh"
    },
    {
      "values": {
        "Policy Name": "National Ecosystem of Open Innovation",
        "Policy creator": [
          "Mexico"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This initiative is designed to drive innovation—no reference to EdTech.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26852",
        "Series #": 6,
        "Title": "Mexico: National Ecosystem of Open Innovation",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-czwSmtrTC1",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-czwSmtrTC1",
      "name": "Mexico: National Ecosystem of Open Innovation",
      "index": 413,
      "createdAt": "2024-05-29T03:01:15.158Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-czwSmtrTC1"
    },
    {
      "values": {
        "Policy Name": "National Alliance of AI",
        "Policy creator": [
          "Mexico"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is focused on sustainable development. Does not make reference to EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27473",
        "Series #": 5,
        "Title": "Mexico: National Alliance of AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-xbb8KTKzei",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-xbb8KTKzei",
      "name": "Mexico: National Alliance of AI",
      "index": 412,
      "createdAt": "2024-05-29T03:01:11.725Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-xbb8KTKzei"
    },
    {
      "values": {
        "Policy Name": "Guideline for the Elaboration of Privacy Impact Assessments",
        "Policy creator": [
          "Mexico"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "As described: “The Guideline offers a series of recommendations based on international standards and best practices in information security that may be applicable depending on the nature of the data, the purposes of processing, and the technical and economic capabilities of the data processors.” Given that information security is one of the salient concerns for schools, this is worth treating as provisionally relevant and translating. ",
        "File": [
          "guiaeip.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27477",
        "Series #": 4,
        "Title": "Mexico: Guideline for the Elaboration of Privacy Impact Assessments",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-JN-gPXDgVk",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-JN-gPXDgVk",
      "name": "Mexico: Guideline for the Elaboration of Privacy Impact Assessments",
      "index": 411,
      "createdAt": "2024-05-29T03:00:55.543Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-JN-gPXDgVk"
    },
    {
      "values": {
        "Policy Name": "General Recommendations for Data Processing in AI",
        "Policy creator": [
          "Mexico"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This looks interesting, but very narrow. Not EdTech-focused, and only loosely related to it. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27474",
        "Series #": 3,
        "Title": "Mexico: General Recommendations for Data Processing in AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-I73lSn6XXQ",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-I73lSn6XXQ",
      "name": "Mexico: General Recommendations for Data Processing in AI",
      "index": 410,
      "createdAt": "2024-05-29T03:00:34.283Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-I73lSn6XXQ"
    },
    {
      "values": {
        "Policy Name": "AI Use Cases in the Public Sector",
        "Policy creator": [
          "Mexico"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This seems to be another initiative designed to catalogue uses of AI. None of the examples were especially education-focused. Only loosely related (in the sense that AI tools used in schools could be stored in a database managed by the state).",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27149",
        "Series #": 2,
        "Title": "Mexico: AI Use Cases in the Public Sector",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-gqaD8100ST",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-gqaD8100ST",
      "name": "Mexico: AI Use Cases in the Public Sector",
      "index": 409,
      "createdAt": "2024-05-29T03:00:28.508Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-gqaD8100ST"
    },
    {
      "values": {
        "Policy Name": "Mexican National AI Agenda",
        "Policy creator": [
          "Mexico"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This strategy looks extensive, but I cannot read it (it’s in Spanish). Provisionally assuming that it is relevant, and I will translate it in due course. ",
        "File": [
          "7be025_6f45f669e2fa4910b32671a001074987.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26703",
        "Series #": 1,
        "Title": "Mexico: Mexican National AI Agenda",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-67LU4XWALv",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-67LU4XWALv",
      "name": "Mexico: Mexican National AI Agenda",
      "index": 93,
      "createdAt": "2024-05-29T03:00:23.195Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-67LU4XWALv"
    },
    {
      "values": {
        "Policy Name": "AI Ethical Guidelines",
        "Policy creator": [
          "Hungary"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This policy entry seems to concern the drawing up of ethical guidelines. No material was linked to the initiative. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25009",
        "Series #": 3,
        "Title": "Hungary: AI Ethical Guidelines",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-8-XEmkvnWQ",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-8-XEmkvnWQ",
      "name": "Hungary: AI Ethical Guidelines",
      "index": 96,
      "createdAt": "2024-05-29T02:56:17.613Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-8-XEmkvnWQ"
    },
    {
      "values": {
        "Policy Name": "AI Action Plan",
        "Policy creator": [
          "Hungary"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The documents linked do not go anywhere, but this does not look particularly education-focused. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26459",
        "Series #": 2,
        "Title": "Hungary: AI Action Plan",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-WMxHd-VBhN",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-WMxHd-VBhN",
      "name": "Hungary: AI Action Plan",
      "index": 95,
      "createdAt": "2024-05-29T02:52:48.181Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-WMxHd-VBhN"
    },
    {
      "values": {
        "Policy Name": "Hungary’s AI Strategy",
        "Policy creator": [
          "Hungary"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Locating this document was a bit of a nightmare. In any case, it’s out there and in English, which is convenient (for us). There is a fair bit of relevant content—including reference to “AI-supported education”. It is committed to: “intensive use of AI technologies in the developments associated with data management in higher education” (p 31). ",
        "File": [
          "Hungary’s Artificial Intelligence Strategy.pdf"
        ],
        "Year of Commencement or Creation": "2020",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Plans further action. It sets out a strategy on AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26765",
        "Series #": 1,
        "Title": "Hungary: Hungary’s AI Strategy",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "Under “Objectives by 2030 directly affecting citizens”, it notes that “2.5 million citizens benefit from AI-supported education” (p 20)\n“The aim is to collect, promote and make available Hungarian language versions of personalised learning support products available internationally for people at risk of falling behind (disabled, elderly, digital illiterates, those with a low level of education), using AI technologies, as well as to identify and provide priority development and support for talented people from an early age. • International collection and Hungarian translation of guidance material prepared for the groups at risk of falling behind in the labour market.\nContinuous dialogue on the development results and the special demands that may be formulated as the development goals.\nIntroducing games for improving high-level mathematical and logical skills from an early age and identifying talented children and teenagers. \nProvision of mentors and tutors; online and in-person training for recognised talents and providing support for them beyond the school system.” (p 31)\n\n“Intensive use of AI technologies in the developments associated with data management in higher education.” (p 30)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "“A general regulatory environment needs to be put in place for data assets with functions such as supporting the AIrelated use of public data assets and facilitating the process of turning data into assets (assetization), together with the development of the relevant financial and legal regulations – taking into account the various sectors’ specificities and responsibilities in terms of data processing, as well as the relevant fundamental rights and the international framework of data regulations. \nCreation of a framework law on data assets. \nIntroduction of a sector-specific regulatory environment to enable data to be turned into assets and their use for purposes of AI. \nDeveloping rules to govern the use of public data, along with a concept for and rules on their assetization.” (p 34)\n\n“The goal is to enable citizens to participate, as active and responsible actors, in the data economy where the secondary use of data takes place and to exercise their fundamental rights relating to the protection of personal data. To this end, they need to be enabled to dispose over data pertaining to them and to participate actively and securely in the secondary use of such data.” (p 43)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "“Inclusion and talent coaching for groups at risk of falling behind in the labour market The aim is to collect, promote and make available Hungarian language versions of personalised learning support products available internationally for people at risk of falling behind (disabled, elderly, digital illiterates, those with a low level of education), using AI technologies, as well as to identify and provide priority development and support for talented people from an early age.” (p 31)",
        "General principles on AI": [
          "Augmentation, not replacement. AI systems should augment, not displace, workers.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. "
        ],
        "Draft Analysis Complete": true,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": true,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i--PZ-g1Dix2",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i--PZ-g1Dix2",
      "name": "Hungary: Hungary’s AI Strategy",
      "index": 94,
      "createdAt": "2024-05-29T02:46:55.324Z",
      "updatedAt": "2024-06-03T00:01:55.281Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui--PZ-g1Dix2"
    },
    {
      "values": {
        "Policy Name": "Action Plan for Iceland in the Fourth Industrial Revolution",
        "Policy creator": [
          "Iceland"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Nothing listed, but found the document elsewhere. Does not say anything interesting about EdTech—it is focused on job training/skills. ",
        "File": [
          "Iceland&4thIndustrialRevolution-2019.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26846",
        "Series #": 2,
        "Title": "Iceland: Action Plan for Iceland in the Fourth Industrial Revolution",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-bb_wbORPQv",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-bb_wbORPQv",
      "name": "Iceland: Action Plan for Iceland in the Fourth Industrial Revolution",
      "index": 408,
      "createdAt": "2024-05-29T02:14:30.887Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-bb_wbORPQv"
    },
    {
      "values": {
        "Policy Name": "Iceland’s AI Strategy",
        "Policy creator": [
          "Iceland"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This policy was marked as “forthcoming” in 2021. Nothing seems to have benn added. Will check the separately-listed Action Plan. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26847",
        "Series #": 1,
        "Title": "Iceland: Iceland’s AI Strategy",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-LKY7zJDjLk",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-LKY7zJDjLk",
      "name": "Iceland: Iceland’s AI Strategy",
      "index": 97,
      "createdAt": "2024-05-29T02:14:24.968Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-LKY7zJDjLk"
    },
    {
      "values": {
        "Policy Name": "Mauririus AI Strategy",
        "Policy creator": [
          "Mauritius"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The relevant thing here is its summary of what other countries were doing in 2018 (it has a table of their AI strategies). I have saved this document elsewhere for that purpose. However, it says nothing about EdTech.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27393",
        "Series #": 1,
        "Title": "Mauritius: Mauririus AI Strategy",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-NLfhoHrLUG",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-NLfhoHrLUG",
      "name": "Mauritius: Mauririus AI Strategy",
      "index": 98,
      "createdAt": "2024-05-29T02:09:41.891Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-NLfhoHrLUG"
    },
    {
      "values": {
        "Policy Name": "Presidential Commission on Fourth Industrial Revolution",
        "Policy creator": [
          "South Africa"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a 2019 initiative outlining some vague intentions. It seems that South Africa is in the early stages of its AI journey, and that developing or deploying EdTech is not something that has happened yet. ",
        "File": [
          "42388gen209.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26873",
        "Series #": 1,
        "Title": "South Africa: Presidential Commission on Fourth Industrial Revolution",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "Non-OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-OwDQAylnHX",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-OwDQAylnHX",
      "name": "South Africa: Presidential Commission on Fourth Industrial Revolution",
      "index": 99,
      "createdAt": "2024-05-29T02:07:13.372Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-OwDQAylnHX"
    },
    {
      "values": {
        "Policy Name": "Work of upcoming Swedish Digitalisation Strategy including AI",
        "Policy creator": [
          "Sweden"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Ah, finally: the document that explains what Sweden is doing? No. There is nothing listed on the OECD page, and no links. I found some stuff on screen use in school, quantum computing, etc—but it’s all very thin. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27681",
        "Series #": 8,
        "Title": "Sweden: Work of upcoming Swedish Digitalisation Strategy including AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-VH4E1FQe9q",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-VH4E1FQe9q",
      "name": "Sweden: Work of upcoming Swedish Digitalisation Strategy including AI",
      "index": 107,
      "createdAt": "2024-05-29T02:00:56.498Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-VH4E1FQe9q"
    },
    {
      "values": {
        "Policy Name": "Swedish National Digitalisation Council",
        "Policy creator": [
          "Sweden"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is very little information about what this renewed Digitalisation Council will do. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24976",
        "Series #": 7,
        "Title": "Sweden: Swedish National Digitalisation Council",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-THGKTF6V2q",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-THGKTF6V2q",
      "name": "Sweden: Swedish National Digitalisation Council",
      "index": 106,
      "createdAt": "2024-05-29T01:58:29.685Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-THGKTF6V2q"
    },
    {
      "values": {
        "Policy Name": "Strategy for Increased Access to Data",
        "Policy creator": [
          "Sweden"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is focused on data-sharing. Tenuous connection to AI in education. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27331",
        "Series #": 6,
        "Title": "Sweden: Strategy for Increased Access to Data",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-dAqXybdHxM",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-dAqXybdHxM",
      "name": "Sweden: Strategy for Increased Access to Data",
      "index": 105,
      "createdAt": "2024-05-29T01:56:20.581Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-dAqXybdHxM"
    },
    {
      "values": {
        "Policy Name": "Government Assignment on SMEs and Data as a Strategic Resource",
        "Policy creator": [
          "Sweden"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is about governments promoting SMEs’ ability to use data as a strategic resource. Tenuous connection to AI in education. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26681",
        "Series #": 5,
        "Title": "Sweden: Government Assignment on SMEs and Data as a Strategic Resource",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-lP_EK8nXFo",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-lP_EK8nXFo",
      "name": "Sweden: Government Assignment on SMEs and Data as a Strategic Resource",
      "index": 104,
      "createdAt": "2024-05-29T01:55:27.815Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-lP_EK8nXFo"
    },
    {
      "values": {
        "Policy Name": "Digital Excellence",
        "Policy creator": [
          "Sweden"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This focuses on skill development for AI — with no special mention of using AI to do so — rather than EdTech. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26631",
        "Series #": 4,
        "Title": "Sweden: Digital Excellence",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-9Kc_EArn6U",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-9Kc_EArn6U",
      "name": "Sweden: Digital Excellence",
      "index": 103,
      "createdAt": "2024-05-29T01:54:08.134Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-9Kc_EArn6U"
    },
    {
      "values": {
        "Policy Name": "Big Data Analysis",
        "Policy creator": [
          "Sweden"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is about mapping ‘big data analysis’. Only very loosely relevant to AI in education. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26680",
        "Series #": 3,
        "Title": "Sweden: Big Data Analysis",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-_80G-6Wl-r",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-_80G-6Wl-r",
      "name": "Sweden: Big Data Analysis",
      "index": 102,
      "createdAt": "2024-05-29T01:52:14.502Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-_80G-6Wl-r"
    },
    {
      "values": {
        "Policy Name": "AI Commission",
        "Policy creator": [
          "Sweden"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This does not look especially relevant. The description is all about AI R&D and education for AI. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27679",
        "Series #": 2,
        "Title": "Sweden: AI Commission",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-p2fHhiHy0W",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-p2fHhiHy0W",
      "name": "Sweden: AI Commission",
      "index": 101,
      "createdAt": "2024-05-29T01:51:18.865Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-p2fHhiHy0W"
    },
    {
      "values": {
        "Policy Name": "National Approach to AI",
        "Policy creator": [
          "Sweden"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a very thin strategy that says nothing about EdTech. Note that it is quite old (2018) so perhaps before ‘AI in everything’ was all the rage. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24975",
        "Series #": 1,
        "Title": "Sweden: National Approach to AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-7xCxRXGt99",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-7xCxRXGt99",
      "name": "Sweden: National Approach to AI",
      "index": 100,
      "createdAt": "2024-05-29T01:50:25.116Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-7xCxRXGt99"
    },
    {
      "values": {
        "Policy Name": "Human-Centred AI for Human Resources",
        "Policy creator": [
          "Turkiye"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The policy initiative here was to produce guidance on AI in HR. Similar issues are raised in education (hiring, admissions, etc) so it is worth including this. Might need to add some new “AI in education principles”. Also note the “created from the Human-Centred Artificial Intelligence for Human Resources project.”",
        "File": [
          "WEF_Human_Centred_AI_for_HR_2021.pdf"
        ],
        "Year of Commencement or Creation": "2021",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Develops tools. It provides tools and place them in the hands of businesses or governments",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27318",
        "Series #": 10,
        "Title": "Turkiye: Human-Centred AI for Human Resources",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“In addition to being a target specifically for the regulation of AI, HR already operates in a highly regulated space. Most countries have numerous labour laws that would apply to AI-based HR tools. In some ways, this existing regulation may already be providing safeguards and even useful guidance. For instance, a number of countries already have anti-discrimination regulations on employment decisions and hiring tests, which include a recognition that such practices can have unintended discriminatory effects (known as adverse impact or indirect discrimination)” (p 15)",
        "General principles on AI": [
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "
        ],
        "Draft Analysis Complete": true,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": true,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-OX3xS8Y5MT",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-OX3xS8Y5MT",
      "name": "Turkiye: Human-Centred AI for Human Resources",
      "index": 108,
      "createdAt": "2024-05-29T01:42:21.376Z",
      "updatedAt": "2024-06-05T21:37:17.815Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-OX3xS8Y5MT"
    },
    {
      "values": {
        "Policy Name": "12th Development Plan",
        "Policy creator": [
          "Turkiye"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "I will need to update my DeepL account to translate this 253-page document. It likely provides the most authoritative statement of what Turkey is doing in this space. ",
        "File": [
          "On-Ikinci-Kalkinma-Plani_2024-2028_11122023.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27676",
        "Series #": 9,
        "Title": "Turkiye: 12th Development Plan",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-y5uMqxZAKs",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-y5uMqxZAKs",
      "name": "Turkiye: 12th Development Plan",
      "index": 113,
      "createdAt": "2024-05-29T01:38:08.256Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-y5uMqxZAKs"
    },
    {
      "values": {
        "Policy Name": "Medum Term Program (2024—2026)",
        "Policy creator": [
          "Turkiye"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is nothing in here about EdTech. Query whether references to it in the national strategy were long-term aspirations that never translated into action?",
        "File": [
          "Medium-Term-Program-2024-2026.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27677",
        "Series #": 8,
        "Title": "Turkiye: Medum Term Program (2024—2026)",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-TZge-4Hhb3",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-TZge-4Hhb3",
      "name": "Turkiye: Medum Term Program (2024—2026)",
      "index": 112,
      "createdAt": "2024-05-29T01:34:56.156Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-TZge-4Hhb3"
    },
    {
      "values": {
        "Policy Name": "The Digital Youth AI Ecosystem",
        "Policy creator": [
          "Turkiye"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This initiative was designed to provide a support network to students of AI. Not EdTech-focused. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27678",
        "Series #": 7,
        "Title": "Turkiye: The Digital Youth AI Ecosystem",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-d5ZiOWQuzQ",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-d5ZiOWQuzQ",
      "name": "Turkiye: The Digital Youth AI Ecosystem",
      "index": 111,
      "createdAt": "2024-05-29T01:33:55.104Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-d5ZiOWQuzQ"
    },
    {
      "values": {
        "Policy Name": "Priority Areas and the Upcoming Technology Roadmap in AI",
        "Policy creator": [
          "Turkiye"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is very little detail listed here, but no mention of EdTech/AI in education.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26202",
        "Series #": 6,
        "Title": "Turkiye: Priority Areas and the Upcoming Technology Roadmap in AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-YxqXchd1hp",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-YxqXchd1hp",
      "name": "Turkiye: Priority Areas and the Upcoming Technology Roadmap in AI",
      "index": 110,
      "createdAt": "2024-05-29T01:17:40.477Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-YxqXchd1hp"
    },
    {
      "values": {
        "Policy Name": "Eleventh Development Plan",
        "Policy creator": [
          "Turkiye"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This has been superseded by the 12th Development Plan.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26781",
        "Series #": 5,
        "Title": "Turkiye: Eleventh Development Plan",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-UMzE9GTz-B",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-UMzE9GTz-B",
      "name": "Turkiye: Eleventh Development Plan",
      "index": 109,
      "createdAt": "2024-05-29T01:16:54.307Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-UMzE9GTz-B"
    },
    {
      "values": {
        "Policy Name": "Digital Innovation Cooperation Platform",
        "Policy creator": [
          "Turkiye"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is very thin on details, regrettably; but there is no mention of EdTech in the material I can find. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "",
        "Series #": 4,
        "Title": "Turkiye: Digital Innovation Cooperation Platform",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-qYSz4CYaiU",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-qYSz4CYaiU",
      "name": "Turkiye: Digital Innovation Cooperation Platform",
      "index": 117,
      "createdAt": "2024-05-29T01:12:40.068Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-qYSz4CYaiU"
    },
    {
      "values": {
        "Policy Name": "Action Plan on Human Rights",
        "Policy creator": [
          "Turkiye"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is one page in this document (p 108) that I thought would be interesting. It is about the intersection between AI and human rights. However, the extent of the measure is just to consider a body to address the issue. If anything relevant came out of it, it would presumably have been included in Turkey’s (very large) policy repository on the OECD. The only other AI principles concerned the use of AI in the judiciary. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27321",
        "Series #": 3,
        "Title": "Turkiye: Action Plan on Human Rights",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-Cq4NjtGYP0",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Cq4NjtGYP0",
      "name": "Turkiye: Action Plan on Human Rights",
      "index": 116,
      "createdAt": "2024-05-29T01:09:05.211Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Cq4NjtGYP0"
    },
    {
      "values": {
        "Policy Name": "2023 Industry and Technology Strategy",
        "Policy creator": [
          "Turkiye"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is very R&D-focused, and not written with EdTech in mind. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25608",
        "Series #": 2,
        "Title": "Turkiye: 2023 Industry and Technology Strategy",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-lMMZHfB_0K",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-lMMZHfB_0K",
      "name": "Turkiye: 2023 Industry and Technology Strategy",
      "index": 115,
      "createdAt": "2024-05-29T01:07:06.806Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-lMMZHfB_0K"
    },
    {
      "values": {
        "Policy Name": "National AI Strategy",
        "Policy creator": [
          "Turkiye"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Most of this strategy is about “AI education”, but there is an initiative in here about education technology.",
        "File": [
          "TRNationalAIStrategy2021-2025.pdf"
        ],
        "Year of Commencement or Creation": "2021",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26590",
        "Series #": 1,
        "Title": "Turkiye: National AI Strategy",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "“The Education Technologies Incubation and Innovation Center will be implemented in 2021 by the Ministry of National Education, General Directorate of Innovation and Education Technologies, within the scope of the World Bank's “Safe Schooling and Distance Education Project”. The Center will operate in METU Technopolis and will work in cooperation with the public-private sector. Within the scope of the project, an innovation ecosystem in education will be developed, and through this ecosystem, new digital tools and pedagogical models will be developed and released, and blended education processes will be supported through the cooperation of various stakeholders. In this direction, working groups for AI education will be established, capacity building activities and R&D activities will be carried out for AI applications in education.” (p 54)\nThe rest of the content is about teaching AI as a discipline (quite different to using AI to teach). \nThis policy does not make it clear which principles will govern this specific EdTech initiative, so the broad principles expressed in this document will only be included below (under general principles). [CF my analysis of the Netherlands Strategy or the EU AI Act, where it is made clear that broad principles expressed extend to AI in education.]",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Expressed generally, but not specifically in relation to EdTech:\n“The implementation of AI technologies also raises privacy and national security concerns in many cases. In addition, the widespread use of AI-powered autonomous or semi-autonomous decision-making mechanisms raises ethical problems such as the protection of human rights and the prevention of discrimination. Therefore, building an effective AI ecosystem requires establishing an appropriate ethical and legal framework that takes into account the technological nature of AI” (p 15)\n“The OECD Council Recommendation on Artificial Intelligence, to which our country is also a party, was adopted on 22 May 2019 in order to strengthen the global AI policy ecosystem that respects human rights, democratic and ethical values.1 These principles, supported by the EU, were soon adopted by the G20 as well. The document also provides recommendations for international cooperation on trustworthy AI.”\n“Human dignity, human rights and fundamental freedoms must be essential throughout the lifecycle of AI systems. All AI technologies to be developed in our country should be designed in compliance with national ethical values and by prioritizing human rights, democratic values and the rule of law so that all members of society can benefit from such technologies. No human should be harmed physically, economically, socially, politically or psychologically at any stage in the lifecycle of AI systems. In interactions with AI systems throughout their lifecycle, people should never be objectified, their dignity should never be harmed, and human rights should never be violated or abused.” (p 59)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "This strategy uses the language of “fairness”. The concept is not specifically used in relation to AI in education, but generally:\n“Fairness AI systems should be designed to provide an equal and fair service to all stakeholders while adhering to the rule of law and fundamental rights and freedoms. The fairness of AI systems means that the benefits of AI technology are shared at local, national and international levels, while taking into account the specific needs of different age groups, different cultural systems, different language groups, people with disabilities, and disadvantaged, marginalized and vulnerable segments of the society. It should be ensured that decisions made based on algorithms do not give rise to discriminatory or unfair effects on different demographic populations. In order to prevent the emergence of unintentional discrimination in decision-making processes, monitoring and accountability mechanisms should be developed and those mechanisms should be included in the implementation process.” (p 60)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "“An impact analysis framework will be established to monitor and evaluate the level of implementation of AI values and principles” (p 73)\nOn collaborative development and interoperability:\n“The participation of different stakeholders throughout the lifecycle of AI systems is essential for inclusive and agile AI governance, the benefits of AI passing through society, and for AI to contribute to technological progress and development. Stakeholders of AI systems include public institutions, NGOs, international organizations, researchers, academia, media, educators, policy makers, the private sector, human rights institutions, and other bodies established for the youth and children. It is important to adopt open standards and interoperability to facilitate collaboration among AI stakeholders. Agile governance measures should be taken in line with technological developments and new sociotechnical needs.” (p 61)\nProcurement:\nIt makes reference to the WEF’s Procurement toolkit:\n“The WEF has developed and piloted common tools for governments to deliver AI solutions built with ethical principles in mind. The AI Procurement Toolkit for the Public and Private Sector prepared for this purpose includes concrete recommendations on purchasing, risk assessments, proposal drafting and evaluation.34 In addition, a toolkit for recruitment, performance evaluation and promotion is being developed with the contribution of public institutions and private sector organizations in our country in order to base the use of AI applications in human resources on human-centric and ethical values.”  (p 31)\nLater it expressly says:\n“The commercialization of developed AI solutions will be supported by prioritizing them in public procurement.” (p 69)\nCould we infer that it recognises the normative influence procurement exerts? Or is it simply saying that it will support R&D here, and not delving into ethics? I have assumed the latter. ",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "One of the more progressive strategies I have seen. Have these ideals been realised in practice?",
        "Record Entered By": ""
      },
      "id": "i-JGZxJmkxIv",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-JGZxJmkxIv",
      "name": "Turkiye: National AI Strategy",
      "index": 114,
      "createdAt": "2024-05-29T00:58:49.546Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-JGZxJmkxIv"
    },
    {
      "values": {
        "Policy Name": "AI Strategy",
        "Policy creator": [
          "Lithuania"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is a generally relevant collection of policies from p 8, but all of the education-related content concerns preparing people for a life with AI — education for AI — rather than AI in education. Including this on the basis of the broadly applicable principles. ",
        "File": [
          "Lithuania_Artificial_Intelligence_Strategy_2019.pdf"
        ],
        "Year of Commencement or Creation": "2019",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Plans further action. It sets out a strategy on AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24220",
        "Series #": 1,
        "Title": "Lithuania: AI Strategy",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "All of the education-related content concerns preparing people for a life with AI — education for AI — rather than AI in education.",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "“To ensure that we stay on the right track, a human-centric approach to AI is needed. Trustworthy AI has two components: (1) ethical purpose - it should respect fundamental rights, applicable regulation and core principles and values and (2) it should be technically robust and reliable since, even with good intentions, a lack of technological mastery can cause unintentional harm.” (p 8)\n\n“Principle 1: To advice the public sector on ethical AI regulation and implementation. Mechanism: Establish AI ethics committee that reviews impact of technology on fundamental rights.” (p 8)",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Opportunity. The opportunities of AI should be harnessed."
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": true,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-4u9qJ87NTG",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-4u9qJ87NTG",
      "name": "Lithuania: AI Strategy",
      "index": 118,
      "createdAt": "2024-05-29T00:52:23.424Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-4u9qJ87NTG"
    },
    {
      "values": {
        "Policy Name": "Action Plan for the Digital Transformation of Slovakia",
        "Policy creator": [
          "Slovakia"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This makes reference to support for AI-based tools in education, and — more generally — using “digital technologies for innovations and improvement of the quality of education” (p 21)",
        "File": [
          "AP-DT-English-Version-FINAL.pdf"
        ],
        "Year of Commencement or Creation": "2019",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25880",
        "Series #": 1,
        "Title": "Slovakia: Action Plan for the Digital Transformation of Slovakia",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "Opportunity\n“we will support the use of digital technologies in order to increase the success of the process of education” (p 20)\n“We will support innovation capacity and introduction of solutions built on artificial intelligence, in particular, at the level of SMEs. Therefore, we will set up a network of digital innovation centres and improve possibilities of cooperation with the academic sector in applied research in the field of artificial intelligence, which is significantly based on source data. At the same time, we will support new business models in the digital economy, in order to make conditions in Slovakia for the rise of platforms transforming standard sectors, such as transport, finance, health care and education. It means setting up “regulatory sandboxes”, introducing “future-proof regulations” and redesigning permits for the needs of the digital era.” (p 32)\n“Support increasing higher and specialised skills for IoT, data science, artificial intelligence, programming, for the needs of STEM studies (science, technology, engineering and mathematics), team work and collaborative and co-creative procedures, creative designing and trading as well as other fields of economy and public administration due to their digital transformation,” (p 27)\nDo not consider education holistically — no reference to privacy risks specifically in education, for instance. \n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "Two key references:\n“The intent of the Action Plan also encompasses building trust of persons using digital technologies, ensuring protection of shared data and setting conditions for creating responsible and adequate process of digital transformation. Specific attention in implementation of proposed measures of this Action Plan will be paid to protection of fundamental rights and freedoms of natural persons, in particular right to privacy in connection to personal data processing and compliance with requirements put on personal data protection in relevant European3 as well as national legislation4 .” (p 16)\n“It is necessary to make sure that selected methods are reliable, they are primarily not intended for activities aimed at damaging humans, their rights and freedoms,” (p 65)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "It speaks about:\n“Fair access to technologies for all groups of population (justice, non-discrimination)” (p 65)",
        "General principles on AI": [
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "“Principle of not causing harm – to assets, health, social status, etc.,” (p 65)\n“Transparency and controllability of system using AI, comprehensibility of basic principles of functioning for the general public (application of the informed consent principle),” (p 65)\nImpact assessment:\nThe intent of the Action Plan also encompasses building trust of persons using digital technologies, ensuring protection of shared data and setting conditions for creating responsible and adequate process of digital transformation. Specific attention in implementation of proposed measures of this Action Plan will be paid to protection of fundamental rights and freedoms of natural persons, in particular right to privacy in connection to personal data processing and compliance with requirements put on personal data protection in relevant European3 as well as national legislation4 . Before the process of implementation of those measures referred to in this Action Plan, when personal data is processed (in particular setting up and deployment of new information systems and technologies), the data protection impact assessment will be made in the sense of Art. 35 of the General Data Protection Regulation and prior consultation with the supervisory authority will be used in the sense of Art. 36 of the General Data Protection Regulation prior to the data processing, if the data protection impact assessment implies that such processing could lead to high risk unless the controller adopts measures to mitigate the risk. (p 16-17)\n(This is a narrow impact assessment)",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-Jzg5JOd1pY",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Jzg5JOd1pY",
      "name": "Slovakia: Action Plan for the Digital Transformation of Slovakia",
      "index": 119,
      "createdAt": "2024-05-29T00:39:04.985Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Jzg5JOd1pY"
    },
    {
      "values": {
        "Policy Name": "Greek National Strategy for AI",
        "Policy creator": [
          "Greece"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This strategy is (1) Greek, and (2) 400 pages, so unable to be translated with my DeepL subscription. I am going to have to upgrade it later. \nGiven what Greece has said in its (newer) GenAI strategy, this is not a super high-priority document to review, but it would be worth taking a look at it.  ",
        "File": [
          "digital_strategy.pdf"
        ],
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26788",
        "Series #": 2,
        "Title": "Greece: Greek National Strategy for AI",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "Translation Needed",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "Pending translation",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-Gzw5TXyORw",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-Gzw5TXyORw",
      "name": "Greece: Greek National Strategy for AI",
      "index": 120,
      "createdAt": "2024-05-28T23:29:30.202Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-Gzw5TXyORw"
    },
    {
      "values": {
        "Policy Name": "Generative AI Greece 20230 “Future of Generative AI in Greece”",
        "Policy creator": [
          "Greece"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This report is interesting and bold. It recognises that autonomous education applications could be hugely significant. This is definitely worth coming back to.",
        "File": [
          "Gen_AI_Greece_EN_s.pdf"
        ],
        "Year of Commencement or Creation": "2023",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary",
          "Vocational or Professional"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Seeks information. It gathers inputs on public sentiment about AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27603",
        "Series #": 1,
        "Title": "Greece: Generative AI Greece 20230 “Future of Generative AI in Greece”",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "Opportunity:\n“Focusing even at the classroom level, NLP has the potential to enhance the educational process in various ways. At the international level, in a recent report by the IE University Center for Governance1, in the section concerning education, among the scenarios discussed regarding the future of the educational process with the introduction of NLP, a scenario emerged with a significant margin, suggesting the existence of potential (virtual) classrooms where an AI tutor facilitator will play a significant role, while NLP will be utilized to facilitate the creation of potential virtual experiences outside the classroom environment, thus making the educational process more empirical in this specific sense. It is within its technological capabilities for NLP to operate as an assistant to teachers in the classroom, offering students a better understanding of subjects by creating notes, reports, diagrams, and lesson summaries. According to the estimation of Konstantinos Karpouzis, Associate Professor at the Department of Communication, Media and Culture of the Panteion University, \"the integration of NLP into the educational system through the production of personalized content, descriptive assessment, and the use of its tools for the education of students and teachers in new technologies\" is one of the greatest opportunities.” (p 45)\nThis is interesting too — lifelong learning:\n“An opportunity for the Greek reality could also be the enhancement of lifelong learning and adult education in general. One of the main benefits of NLP in lifelong learning is its ability to provide personalized educational experiences. Traditional education usually follows a \"one size fits all\" model, where students are expected to learn at the same pace and in the same way, which is incompatible with adult learners who have unique needs and learning preferences. NLP can analyze large amounts of data on the strengths, weaknesses, and learning styles of a student to create a personalized learning plan.” (p 45)\n\nNote that principles concerned with risks are not addressed at this lower level of abstraction (education-specific) — see below. ",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "“Through the establishment of proactive monitoring and control mechanisms, systematic and effective monitoring of the implementation of ethical guidelines and legislation will be feasible, ensuring that AI is used in a way that respects human rights and the demand for individual and social well-being. Overall, this approach concerns the preparedness of Greek society for the development of AI in a just and sustainable manner, while promoting innovation and growth in this sector. It also involves strengthening the necessary \"institutional triangle\" between digital governance, digital regulation, and digital ethics” (p 105)\n“There is a need to provide a framework of broader universal political guidelines and standards for developers and AI users to ensure that their systems are designed and used ethically. This includes principles such as transparency, justice, and the protection of privacy and human rights.” (p 27)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "Increasing equality\n“Furthermore, NLP capabilities can be particularly beneficial in special education, where it can be tailored to students' specific difficulties, creating real-time lessons tailored to their individual needs108. 109 Additionally, natural language learning and teaching systems can assess students' levels of knowledge, identify gaps in their understanding, and then address them through personalized learning materials and explanations.” (p 45)\n“The guidelines should reflect both societal values and general ethical principles, promoting excellence and safety, transparency and innovation, human benefit, and the fight against digital (or algorithmic) social discrimination and inequalities, as well as human control.” (p 104)\nAugmenting inequality\n“The tendency of AI systems to perpetuate or even exacerbate existing biases, prejudices, and inequalities poses a significant ethical challenge.” (p 82)",
        "General principles on AI": [
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Bias testing. AI systems should be tested for bias. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "Note that these are framed as “risks” rather than principles, but there are implicit normative ideas within the text. \n\nCyber security:\nThey speak of ‘adversarial attacks’\nAI models may be susceptible to adversarial attacks. Adversarial attacks are deliberate modifications to input data that attempt to compromise the performance of an AI model, and this can also affect AI models. Adversarial attacks can have unintended consequences, such as compromising image creation in an AI model by adding small modifications to input data, thus leading to undesirable outputs (such as misleading images or images containing unwanted information, e.g., reproduction of stereotypes, etc.) (p 65)",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "Before delving into specific possibilities of future application, it may be worth mentioning that in recent years there have already been examples of utilizing the capabilities of NLP and AI in the digital educational industry through metrics linking it to qualifications certification and the job market. The intersection of work capabilities and educational skills is now emerging as a privileged investment field98. It is worth noting that in the international educational industry, the development of platform economy models has favored an algorithmically oriented \"demand-driven education,\" competency-based education, using NLP to develop predictive talent analytics, to match students and graduates with potential career paths through matching tools. This technological capability is offered to them to integrate into the constantly evolving job market (between learning and earning). Based on mass-collected data from educational platforms, from reports on the completion of digital asynchronous educational programs and skills certification tests, the goal pursued is now to shape some algorithmic matching models of successful course completion cycles with professional performance indicators in the job market. (p 42)",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-JhOfOAT4Ya",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-JhOfOAT4Ya",
      "name": "Greece: Generative AI Greece 20230 “Future of Generative AI in Greece”",
      "index": 121,
      "createdAt": "2024-05-28T23:25:29.038Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-JhOfOAT4Ya"
    },
    {
      "values": {
        "Policy Name": "Policy for the Development of Artificial Intelligence in Poland from 2020",
        "Policy creator": [
          "Poland"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a super interesting policy. Poland is proud of its PISA results and sees AI as being an essential tool for “boosting” its strong position. The fourth pillar of its strategy is titled AI and Education (see p 42). Bold vision expressed — worth analysing further. ",
        "File": [
          "Poland_Policy_for_Artificial_Intelligence_Development_in_Poland_from_2020_2020.pdf"
        ],
        "Year of Commencement or Creation": "2020",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Trust. Organisations seeking to incorporate AI into educational settings must build trust.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24268",
        "Series #": 1,
        "Title": "Poland: Policy for the Development of Artificial Intelligence in Poland from 2020",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "Opportunities\n“The issues of AI-related skill development and the use of AI-based tools in educational processes are the key issues of the Integrated Skills Strategy 2030 in Poland, which is currently undergoing development.” (p 23)\n“ensuring high availability of educational tools in Poland, including online tools, enabling all people who want to get educated in the field of AI to gain knowledge, both theoretical and practical.” (p 42)\nTeacher training:\n“intensification of the use of tools and embedded systems in education, accompanied with training for teachers in their proper use in the teaching process;” (p 43)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“Analysis of the ethical ramifications of AI implementation and the impact of AI systems on the sphere of human rights” (p 25)\n“assessing the societal impact of AI-based systems (in particular the impact on human rights and freedoms) and developing methods for their independent auditing, according a predefined manner and scope;” (p 25)\n“Poland’s continued activity in the Council of Europe in the initiative to develop recommendations for AI with regard to the protection of human rights, the rule of law and democracy.” (p 25)\n“international activities that will support the promotion of Polish business in the field of AI and the development of AI technologies that respect human dignity and fundamental human rights, in accordance with EU and OECD standards, as well as digital diplomacy activities in the area of policies or regulations concerning artificial intelligence” (p 6)\nAdditional material on fundamental rights (see, eg, p 23)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "Fairness\n“diversity, non-discrimination and fairness” (p 63)\nEquality\n“Artificial intelligence is redefining many professions due to process optimisation and automation, and as a result machines replace humans in doing standard and repeatable tasks on an unprecedented scale. This risks aggravating problems in socially and economically excluded regions, increasing unemployment, as well as exacerbating various forms of inequality and discrimination.”",
        "General principles on AI": [
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,"
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "Note Poland’s aspiration: “Poland is the European leader in education in AI and other digital technologies at secondary school level” (p 45)",
        "Record Entered By": ""
      },
      "id": "i-z5-nxrhEvU",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-z5-nxrhEvU",
      "name": "Poland: Policy for the Development of Artificial Intelligence in Poland from 2020",
      "index": 122,
      "createdAt": "2024-05-28T23:21:18.902Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-z5-nxrhEvU"
    },
    {
      "values": {
        "Policy Name": "Spaceresources.lu",
        "Policy creator": [
          "Luxembourg"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Not relevant at all — about space companies.",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-1335",
        "Series #": 3,
        "Title": "Luxembourg: Spaceresources.lu",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-tZvURqdj0L",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-tZvURqdj0L",
      "name": "Luxembourg: Spaceresources.lu",
      "index": 125,
      "createdAt": "2024-05-28T23:18:35.944Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-tZvURqdj0L"
    },
    {
      "values": {
        "Policy Name": "Digital Luxembourg",
        "Policy creator": [
          "Luxembourg"
        ],
        "Relevant?": "No",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is an old, low-investment initiative that is not at all education-centred. ",
        "File": "",
        "Year of Commencement or Creation": "",
        "Relevance Type": "",
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": "",
        "Governance practices employed": "",
        "Analysis Complete": false,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-1337",
        "Series #": 2,
        "Title": "Luxembourg: Digital Luxembourg",
        "Opportunity and risk orientation": "",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": "",
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-vHzm5pUBfk",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-vHzm5pUBfk",
      "name": "Luxembourg: Digital Luxembourg",
      "index": 124,
      "createdAt": "2024-05-28T23:17:50.943Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-vHzm5pUBfk"
    },
    {
      "values": {
        "Policy Name": "AI: A Strategic Vision for Luxembourg",
        "Policy creator": [
          "Luxembourg"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Very little is said about education, but what is said is about the promise of EdTech: “In the domain of education, AI could help in defining and generating personalized teaching/learning methods and tools, especially in the field of differentiated education.” Worth noting. ",
        "File": [
          "AI_EN_0.pdf"
        ],
        "Year of Commencement or Creation": "2019",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24335",
        "Series #": 1,
        "Title": "Luxembourg: AI: A Strategic Vision for Luxembourg",
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "",
        "Key quotes on AI in education principles": "“While AI is not radically new, especially for Luxembourg’s researchers, it is on the threshold of being accessible and applicable across industries and throughout society: digital health, finance, mobility, logistics, clean technologies, space and beyond – not to mention education, environment and art” (p 8)\n“In the domain of education, AI could help in defining and generating personalized teaching/learning methods and tools, especially in the field of differentiated education” (p 14)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "“As a diverse, innovative nation, we will decide what impact this technology will have on human rights, on people’s lives and on our democratic values.” (p 4)",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "
        ],
        "Draft Analysis Complete": false,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": false,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-5t3qlI4mpu",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-5t3qlI4mpu",
      "name": "Luxembourg: AI: A Strategic Vision for Luxembourg",
      "index": 123,
      "createdAt": "2024-05-28T23:15:53.248Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-5t3qlI4mpu"
    },
    {
      "values": {
        "Policy Name": "Guidelines on AI",
        "Policy creator": [
          "Switzerland"
        ],
        "Relevant?": "Yes",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a pretty standard AI framework. Included in case of interest. Could be applied to AI in education. ",
        "File": [
          "_Artificial Intelligence_ – Adoption of Guidelines for the Federal Government.pdf"
        ],
        "Year of Commencement or Creation": "2020",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Analysis Complete": true,
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26987",
        "Series #": 5,
        "Title": "Switzerland: Guidelines on AI",
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "Category of creator": [
          "OECD"
        ],
        "Translation Comments": "N/A - English",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“Put people at the centre: The dignity and well-being of every individual, as well as the public interest, must be at the forefront of the development and use of AI systems. Particular attention is paid to the protection of fundamental rights in the use of AI.” (p 1)",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. "
        ],
        "Draft Analysis Complete": true,
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Weekend": true,
        "Key quotes on general AI principles": "",
        "WC Favourite": false,
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Record Entered By": ""
      },
      "id": "i-ptJWDz_6mV",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/rows/i-ptJWDz_6mV",
      "name": "Switzerland: Guidelines on AI",
      "index": 130,
      "createdAt": "2024-05-28T23:11:48.516Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-XCJGnAn3CE/_rui-ptJWDz_6mV"
    }
  ]
}
