{
  "columns": [
    {
      "id": "c-L3R0H6xpKL",
      "type": "column",
      "name": "Category of creator",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-L3R0H6xpKL",
      "calculated": true,
      "format": {
        "type": "select",
        "isArray": false
      },
      "formula": "[Policy creator].[OECD?].ListCombine()"
    },
    {
      "id": "c-JILGl3j9sD",
      "type": "column",
      "name": "Policy creator",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-JILGl3j9sD",
      "format": {
        "table": {
          "id": "grid-2iQy6VFcq_",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-2iQy6VFcq_",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-2iQy6VFcq_",
          "name": "Jurisdictions"
        },
        "type": "lookup",
        "isArray": true
      }
    },
    {
      "id": "c-5WWbiBHe9B",
      "type": "column",
      "name": "Policy Name",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-5WWbiBHe9B",
      "format": {
        "type": "text",
        "isArray": false
      }
    },
    {
      "id": "c-FlyVKlvCIx",
      "type": "column",
      "name": "Year of Commencement or Creation",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-FlyVKlvCIx",
      "format": {
        "type": "text",
        "isArray": false
      }
    },
    {
      "id": "c-iohuaEflSp",
      "type": "column",
      "name": "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-iohuaEflSp",
      "format": {
        "type": "text",
        "isArray": false
      }
    },
    {
      "id": "c-2pT34POxIT",
      "type": "column",
      "name": "Relevance Type",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-2pT34POxIT",
      "format": {
        "table": {
          "id": "grid-1ohiEKjQFc",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-1ohiEKjQFc",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-1ohiEKjQFc",
          "name": "Nature of relevance"
        },
        "type": "lookup",
        "isArray": true
      }
    },
    {
      "id": "c-fJvB8zmh-Y",
      "type": "column",
      "name": "What kinds of education, if any, are contemplated by the policy?",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-fJvB8zmh-Y",
      "format": {
        "table": {
          "id": "grid-0_3yg-Vkoy",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-0_3yg-Vkoy",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-0_3yg-Vkoy",
          "name": "Which kind of education does it expressly mention?"
        },
        "type": "lookup",
        "isArray": true
      }
    },
    {
      "id": "c-zdfmo_m_Tj",
      "type": "column",
      "name": "Principles on AI in education",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-zdfmo_m_Tj",
      "format": {
        "table": {
          "id": "grid-zXkG0jBLna",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-zXkG0jBLna",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-zXkG0jBLna",
          "name": "AI in education principles"
        },
        "type": "lookup",
        "isArray": true
      }
    },
    {
      "id": "c-5VlrDV5zWa",
      "type": "column",
      "name": "Governance practices employed",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-5VlrDV5zWa",
      "format": {
        "table": {
          "id": "grid-Xr9iAFDRZl",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-Xr9iAFDRZl",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-Xr9iAFDRZl",
          "name": "Type of policy initaitive"
        },
        "type": "lookup",
        "isArray": true
      }
    },
    {
      "id": "c-zAp89itebl",
      "type": "column",
      "name": "Opportunity and risk orientation",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-zAp89itebl",
      "format": {
        "table": {
          "id": "grid-P_wv2uo4M6",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-P_wv2uo4M6",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-P_wv2uo4M6",
          "name": "Considering both opportunities and risks?"
        },
        "type": "lookup",
        "isArray": false
      }
    },
    {
      "id": "c-84Ex4h0pTV",
      "type": "column",
      "name": "File",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-84Ex4h0pTV",
      "format": {
        "type": "attachments",
        "isArray": true
      }
    },
    {
      "id": "c-wPHcwhpe1X",
      "type": "column",
      "name": "Key quotes on AI in education principles",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-wPHcwhpe1X",
      "format": {
        "type": "canvas",
        "isArray": false
      }
    },
    {
      "id": "c-5hHdZ0sfu8",
      "type": "column",
      "name": "Does the policy reflect the principle of human rights compatibility?",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-5hHdZ0sfu8",
      "format": {
        "table": {
          "id": "grid-qlBRzb18gd",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-qlBRzb18gd",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-qlBRzb18gd",
          "name": "Does it make reference to human, fundamental, or inalienable rights?"
        },
        "type": "lookup",
        "isArray": false
      }
    },
    {
      "id": "c-Y854zWDfFY",
      "type": "column",
      "name": "Key quote on human rights",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-Y854zWDfFY",
      "format": {
        "type": "text",
        "isArray": false
      }
    },
    {
      "id": "c-LxM7tcl6OJ",
      "type": "column",
      "name": "Does the policy reflect the principle of equity/equality?",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-LxM7tcl6OJ",
      "format": {
        "table": {
          "id": "grid-OWGRQYLMAA",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-OWGRQYLMAA",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-OWGRQYLMAA",
          "name": "Does it make reference to equity?"
        },
        "type": "lookup",
        "isArray": false
      }
    },
    {
      "id": "c-U0fCdFgXTA",
      "type": "column",
      "name": "Key quote on equity/equality",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-U0fCdFgXTA",
      "format": {
        "type": "text",
        "isArray": false
      }
    },
    {
      "id": "c-tQrodNzumD",
      "type": "column",
      "name": "General principles on AI",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-tQrodNzumD",
      "format": {
        "table": {
          "id": "grid-Jef7egIzgb",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-Jef7egIzgb",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-Jef7egIzgb",
          "name": "General AI principles"
        },
        "type": "lookup",
        "isArray": true
      }
    },
    {
      "id": "c-Nq_phIQjPG",
      "type": "column",
      "name": "Link (OECD or Other)",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-Nq_phIQjPG",
      "format": {
        "display": "iconOnly",
        "type": "link",
        "isArray": false
      }
    },
    {
      "id": "c-r-XaOjk8Lk",
      "type": "column",
      "name": "Analysis Complete",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-r-XaOjk8Lk",
      "format": {
        "displayType": "check",
        "type": "checkbox",
        "isArray": false
      }
    },
    {
      "id": "c-81BAzxH2C6",
      "type": "column",
      "name": "Draft Analysis Complete",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-81BAzxH2C6",
      "format": {
        "displayType": "check",
        "type": "checkbox",
        "isArray": false
      }
    },
    {
      "id": "c-lgXRPxQGDm",
      "type": "column",
      "name": "Key quotes on general AI principles",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-lgXRPxQGDm",
      "format": {
        "type": "canvas",
        "isArray": false
      }
    },
    {
      "id": "c-OgsmPhUiK0",
      "type": "column",
      "name": "Notable Case Studes - Examples of AI in Education",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-OgsmPhUiK0",
      "format": {
        "type": "canvas",
        "isArray": false
      }
    },
    {
      "id": "c-O2MdT9sMx2",
      "type": "column",
      "name": "Other Points of Interest",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-O2MdT9sMx2",
      "format": {
        "type": "canvas",
        "isArray": false
      }
    },
    {
      "id": "c-erzTbcFItg",
      "type": "column",
      "name": "Reasons for non-inclusion (other than \"Irrelevant\")",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-erzTbcFItg",
      "format": {
        "type": "select",
        "isArray": false
      }
    },
    {
      "id": "c-LT8GCmk4tr",
      "type": "column",
      "name": "Record Entered By",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-LT8GCmk4tr",
      "format": {
        "table": {
          "id": "grid-vq4WMZ5Lm7",
          "type": "table",
          "tableType": "table",
          "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-vq4WMZ5Lm7",
          "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tugrid-vq4WMZ5Lm7",
          "name": "Record Entered By"
        },
        "type": "lookup",
        "isArray": true
      }
    },
    {
      "id": "c-V85VzcYUCM",
      "type": "column",
      "name": "Relevant?",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-V85VzcYUCM",
      "format": {
        "type": "select",
        "isArray": false
      }
    },
    {
      "id": "c-gdxdwF0OOx",
      "type": "column",
      "name": "Series #",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-gdxdwF0OOx",
      "format": {
        "precision": 22,
        "useThousandsSeparator": true,
        "type": "number",
        "isArray": false
      }
    },
    {
      "id": "c-Sm3wWbxOJ2",
      "type": "column",
      "name": "Title",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-Sm3wWbxOJ2",
      "display": true,
      "calculated": true,
      "format": {
        "type": "text",
        "isArray": false
      },
      "formula": "Concatenate([Policy creator],\": \",[Policy Name])"
    },
    {
      "id": "c-9Qm-26QJsu",
      "type": "column",
      "name": "Translation Comments",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/grid-XCJGnAn3CE/columns/c-9Qm-26QJsu",
      "format": {
        "type": "select",
        "isArray": false
      }
    }
  ],
  "rows": [
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "South Korea"
        ],
        "Policy Name": "Framework Act on Artificial Intelligence Development and Establishment of a Foundation for Trustworthiness ",
        "Year of Commencement or Creation": "2025",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "A general framework regulates high-impact AI including education",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Binds. It creates binding obligations in relation to AI",
          "Proposes law. It proposes a law or provides a draft law on AI",
          "Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)",
          "Tracks. It sets out to boost understanding specifically of where and how AI is being used",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122) ENGLISH.pdf",
          "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress."
        ],
        "Link (OECD or Other)": "https://www.law.go.kr/%25EB%25B2%2595%25EB%25A0%25B9/%25EC%259D%25B8%25EA%25B3%25B5%25EC%25A7%2580%25EB%258A%25A5%2520%25EB%25B0%259C%25EC%25A0%2584%25EA%25B3%25BC%2520%25EC%258B%25A0%25EB%25A2%25B0%2520%25EA%25B8%25B0%25EB%25B0%2598%2520%25EC%25A1%25B0%25EC%2584%25B1%2520%25EB%2593%25B1%25EC%2597%2590%2520%25EA%25B4%2580%25ED%2595%259C%2520%25EA%25B8%25B0%25EB%25B3%25B8%25EB%25B2%2595/(20676,20250121)",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "South Korea: Framework Act on Artificial Intelligence Development and Establishment of a Foundation for Trustworthiness ",
        "Translation Comments": "Translation Completed (DeepL)"
      },
      "id": "i-6vjnfILLDk",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-6vjnfILLDk",
      "name": "South Korea: Framework Act on Artificial Intelligence Development and Establishment of a Foundation for Trustworthiness ",
      "index": 494,
      "createdAt": "2025-04-30T01:49:31.178Z",
      "updatedAt": "2025-04-30T06:34:32.834Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-6vjnfILLDk"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United Kingdom"
        ],
        "Policy Name": "A pro-innovation approach  to AI regulation",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "A general regulation approach but can inform education",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI",
          "Plans further action. It sets out a strategy on AI",
          "Tracks. It sets out to boost understanding specifically of where and how AI is being used",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "a-pro-innovation-approach-to-ai-regulation-amended-web-ready.pdf"
        ],
        "Key quotes on AI in education principles": "We anticipate that regulators will need to:\n\n1. Interpret and articulate ‘fairness’ as relevant to their sector or domain,\n\n2. Decide in which contexts and specific instances fairness is important and relevant (which it may not always be).\n\n3. Design, implement and enforce appropriate governance requirements for ‘fairness’ as applicable to the entities that they regulate.\n\n4. Where a decision involving use of an AI system has a legal or similarly significant effect on an individual, regulators will need to consider the suitability of requiring AI system operators to provide an appropriate justification for that decision to affected parties.\n\n5. AI systems should comply with regulatory requirements relating to vulnerability of individuals within specific regulatory domains. Regulators will need to consider how use of AI systems may alter individuals’ vulnerability, pursuant to their existing powers and remits.\n\n6. Consider the role of available technical standards addressing AI fairness, bias mitigation and ethical considerations (for example, ISO/IEC TR 24027:2021, ISO/IEC 12791*, ISO/IEC TR 24368:2022) to clarify regulatory guidance and support the implementation of risk treatment measures.",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Inclusive development. AI systems should be developed inclusively. "
        ],
        "Link (OECD or Other)": "https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "United Kingdom: A pro-innovation approach  to AI regulation",
        "Translation Comments": "N/A - English"
      },
      "id": "i-mVcrtMCV1l",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-mVcrtMCV1l",
      "name": "United Kingdom: A pro-innovation approach  to AI regulation",
      "index": 493,
      "createdAt": "2025-04-30T01:12:12.328Z",
      "updatedAt": "2025-04-30T01:33:26.550Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-mVcrtMCV1l"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Mauritius"
        ],
        "Policy Name": "The National Artificial Intelligence Strategy of Mauritania for 2025–2029",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The strategy includes AI in education sector",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI",
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)",
          "Communicates a stance. It expresses a hope for the future of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "The National Artificial Intelligence Strategy of Mauritania for 2025–2029.pdf"
        ],
        "Key quotes on AI in education principles": "This strategy will integrate artificial intelligence technologies into the field of education through projects aimed at serving all stakeholders in the educational system. one the one hand , these projects will be used to enhance student learning by providing interactive tools and programs specifically designed to meet their needs, thereby boosting their academic success. On the other hand, teachers will benefit from these projects by creating innovative educational content, analyzing student performance, and tailoring instruction based on each student's individual progress.  At the institutional level, these projects will assist educational institutions in improving resource management, curriculum planning, and decision-making based on accurate data and in-depth analyses.  Additionally, this strategy includes a project for translating various national dialects, which aims to enhance social cohesion by facilitating linguistic communication and access to knowledge resources in the different dialects used in the country.",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,"
        ],
        "Link (OECD or Other)": "https://mtnima.gov.mr/wp-content/uploads/2024/07/strategie-EN-Final-26-07-2024-.pdf",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "This strategic priority focuses on ensure that the development and utilization of artificial intelligence complies with stringent ethical and legal standards. These standards encompass safeguarding personal data, ensuring data protection and privacy, respecting intellectual property rights, and adhering to pertinent regulations. Our commitment to upholding the ethical standards of the Arab League, the African Union and the United Nations is integral to accomplishing this strategy.",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "Mauritius: The National Artificial Intelligence Strategy of Mauritania for 2025–2029",
        "Translation Comments": "N/A - English"
      },
      "id": "i-0SqFdnPRIL",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-0SqFdnPRIL",
      "name": "Mauritius: The National Artificial Intelligence Strategy of Mauritania for 2025–2029",
      "index": 492,
      "createdAt": "2025-04-30T00:52:07.857Z",
      "updatedAt": "2025-04-30T01:08:56.524Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-0SqFdnPRIL"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United States"
        ],
        "Policy Name": "Driving U.S. Innovation in Artificial Intelligence: A Roadmap for Artificial Intelligence Policy in the United States Senate",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "A comprehensive framework aimed at addressing the multifaceted opportunities and risks presented by artificial intelligence (“AI”) technologies could inform the governance of AI in education",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Plans further action. It sets out a strategy on AI",
          "Proposes law. It proposes a law or provides a draft law on AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "Driving U.S. Innovation in Artificial Intelligence A Roadmap for Artificial Intelligence Policy in.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "United States: Driving U.S. Innovation in Artificial Intelligence: A Roadmap for Artificial Intelligence Policy in the United States Senate",
        "Translation Comments": "N/A - English"
      },
      "id": "i-j33OQcVixo",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-j33OQcVixo",
      "name": "United States: Driving U.S. Innovation in Artificial Intelligence: A Roadmap for Artificial Intelligence Policy in the United States Senate",
      "index": 491,
      "createdAt": "2025-04-30T00:26:12.572Z",
      "updatedAt": "2025-04-30T00:50:46.186Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-j33OQcVixo"
    },
    {
      "values": {
        "Category of creator": [
          ""
        ],
        "Policy creator": [
          "Sri Lanka"
        ],
        "Policy Name": "Sri Lanka's National Strategy on AI",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Mentions education as a high-impact area and a key governance domain",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "National AI strategy for Sri Lanka.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Human-centricity: AI systems should respect human-centred values and pursue benefits for society, including health, well-being, relationships, personhood, and individual dignity. They should not be used for malicious purposes or to sway or deceive users into making harmful decisions.",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "Fairness and Equity: AI systems should be designed and implemented with fairness in mind, minimizing bias and discrimination to ensure equitable treatment for all individuals. They must not undermine legal rights, discriminate unfairly, or create unfair market outcomes.",
        "General principles on AI": [
          "Augmentation, not replacement. AI systems should augment, not displace, workers.",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power.",
          "Freedom of speech and assembly [NEW]. AI systems should not abrogate freedom of speech or assembly. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. "
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "Sri Lanka: Sri Lanka's National Strategy on AI",
        "Translation Comments": ""
      },
      "id": "i-wycemXJq9G",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-wycemXJq9G",
      "name": "Sri Lanka: Sri Lanka's National Strategy on AI",
      "index": 490,
      "createdAt": "2025-04-29T08:07:44.766Z",
      "updatedAt": "2025-04-29T08:30:26.654Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-wycemXJq9G"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Spain"
        ],
        "Policy Name": "2024 Artificial Intelligence Strategy",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Although not focused on education, the strategy identifies education as one of the social domains for AI supervision and calls for developing flexible yet robust frameworks tailored to contexts such as education.",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)",
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "Spain’s 2024 Artificial Intelligence Strategy.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "R&D. Sufficient resources should be invested in AI R&D."
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "Spain: 2024 Artificial Intelligence Strategy",
        "Translation Comments": ""
      },
      "id": "i-b9L-R5YgBc",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-b9L-R5YgBc",
      "name": "Spain: 2024 Artificial Intelligence Strategy",
      "index": 489,
      "createdAt": "2025-04-29T07:44:44.345Z",
      "updatedAt": "2025-04-29T08:06:18.710Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-b9L-R5YgBc"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "India"
        ],
        "Policy Name": "National Programme on Artificial Intelligence (NPAI) Skilling Framework",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Addresses AI skilling across education and embeds responsible AI principles into educational governance.",
        "Relevance Type": [
          "Policy is about AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Secondary",
          "Tertiary",
          "Vocational or Professional"
        ],
        "Principles on AI in education": [
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Managing bias. The risk of bias should be managed with care. ",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ",
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Plans further action. It sets out a strategy on AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "5732498_Report-on-NPAI-Skilling-Framework.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "Ethical artificial intelligence (AI) refers to the development and use of AI systems in a responsible and morally acceptable manner. It involves ensuring that AI technologies align with ethical principles and values, protect human rights, and minimize potential harms.",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "Fairness and Bias: AI systems should be designed and trained to avoid bias and discrimination based on factors like race, gender, or ethnicity. Developers should carefully select training data, regularly evaluate, and address biases, and promote transparency in algorithmic decisionmaking.",
        "General principles on AI": [
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Augmentation, not replacement. AI systems should augment, not displace, workers.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. "
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "In summary, ethical AI requires a multidimensional approach that considers fairness, transparency, privacy, accountability, human oversight, social impact, testing, and continuous improvement.",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "India: National Programme on Artificial Intelligence (NPAI) Skilling Framework",
        "Translation Comments": "N/A - English"
      },
      "id": "i-KqWfv_mXvr",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-KqWfv_mXvr",
      "name": "India: National Programme on Artificial Intelligence (NPAI) Skilling Framework",
      "index": 483,
      "createdAt": "2025-04-29T06:33:28.411Z",
      "updatedAt": "2025-04-29T07:17:34.495Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-KqWfv_mXvr"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Malta"
        ],
        "Policy Name": "Visioning the Future by Transforming Education-National Education Strategy",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "It explicitly mentions professional training on AI for teachers​, AI literacy and digital citizenship skills for students​ and the use of AI for data analysis and education policy planning​.",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "
        ],
        "Governance practices employed": [
          "Communicates a stance. It expresses a hope for the future of AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "Maltese National Education Strategy 2024-2030.pdf"
        ],
        "Key quotes on AI in education principles": "Eventually, it is the Ministry’s plan to employ AI technologies for data analysis and forecasting, the results of which will serve as evidence for future policies and strategies.",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "Internationally, equity and inclusion have been set high on the agenda since there is a general understanding that social gaps have been exacerbated following the pandemic, a higher rate of migration and due to the digital divide28. The Ministry is committed to addressing social fragmentation and inequalities since it is our belief that education is a fundamental tool through which everyone is given the opportunity to reach their potential. To this end, one of the first steps to be taken to understand how different policies and decisions are impacting different groups of students, is employing a system-wide data disaggregation exercise29, which is also one of the SDG indicators for quality education. Eventually, it is the Ministry’s plan to employ AI technologies for data analysis and forecasting, the results of which will serve as evidence for future policies and strategies.",
        "General principles on AI": [
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. "
        ],
        "Link (OECD or Other)": "https://www.gov.mt/en/publicconsultation/Pages/2023/NL-0051-2023.aspx",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "Malta: Visioning the Future by Transforming Education-National Education Strategy",
        "Translation Comments": ""
      },
      "id": "i-SL_Hq9MiTY",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-SL_Hq9MiTY",
      "name": "Malta: Visioning the Future by Transforming Education-National Education Strategy",
      "index": 482,
      "createdAt": "2025-04-28T06:34:16.612Z",
      "updatedAt": "2025-04-28T07:13:32.996Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-SL_Hq9MiTY"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "France"
        ],
        "Policy Name": "Our AI: Our Ambition for France",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The policy discusses AI’s integration into public services including education",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Develops tools. It provides tools and place them in the hands of businesses or governments"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "France-Our AI Our Ambition for France.pdf"
        ],
        "Key quotes on AI in education principles": "Finally, AI systems should be used to improve the quality of public services. Artificial intelligence can improve public services, by helping to personalize education, give patients more time, better support and anticipate professional transitions, and reduce bureaucracy.\nWe also need to invest in training for everyone, at every age: young people in school and afterschool, specialized and non-specialized students, employees, the self-employed and publicsector workers, retirees This means preparing for tomorrow's professions, in particular by structuring a range of hybrid higher education courses, such as \"AI + biology\" and \"law + AI\", or by creating AI chairs in design schools We must also enable the use of AI in today's professions, for example by planning an AI awareness course for all civil servants\n",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "Today, it's up to us to take advantage of AI by putting it in its rightful place: that of a technological means at the service of an ambition for humanity, equality, solidarity, justice, prosperity and freedom.\nAlgorithms contribute to inequalities in work and employment The massification of uses is accompanied by a growing environmental impact.",
        "General principles on AI": [
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power."
        ],
        "Link (OECD or Other)": "https://www.info.gouv.fr/upload/media/content/0001/09/02cbcb40c3541390be391feb3d963a4126b12598.pdf",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "France: Our AI: Our Ambition for France",
        "Translation Comments": ""
      },
      "id": "i-H-8vLe7oN4",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-H-8vLe7oN4",
      "name": "France: Our AI: Our Ambition for France",
      "index": 481,
      "createdAt": "2025-04-28T06:14:24.710Z",
      "updatedAt": "2025-04-28T06:33:47.438Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-H-8vLe7oN4"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United Kingdom"
        ],
        "Policy Name": "AI Opportunity Action Plan",
        "Year of Commencement or Creation": "2025",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This policy is included because it explicitly proposes developing AI talent through education systems and anticipates AI being used as a tool for assessment within the education sector.",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Tertiary",
          "Vocational or Professional"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Communicates a stance. It expresses a hope for the future of AI",
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "UK-AI Opportunity Action Plan.pdf"
        ],
        "Key quotes on AI in education principles": "AI directly benefits working people by improving health care and education and how citizens interact with their government.",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "Increase the diversity of the talent pool. Only 22% of people working in AI and data science are women. Achieving parity would mean thousands of additional workers.",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "United Kingdom: AI Opportunity Action Plan",
        "Translation Comments": "N/A - English"
      },
      "id": "i-BlChGUymUq",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-BlChGUymUq",
      "name": "United Kingdom: AI Opportunity Action Plan",
      "index": 478,
      "createdAt": "2025-04-24T05:16:56.617Z",
      "updatedAt": "2025-04-24T05:30:58.621Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-BlChGUymUq"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United Kingdom"
        ],
        "Policy Name": "Introduction to AI Assurance",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "It illustrates a practical approach to AI governance through internal organisational processes. The use of structured ‘risk assessments’—including staff workshops, detailed questionnaires, and internal audits—demonstrates how educational technology providers can identify and mitigate potential harms (e.g. to user safety, institutional reputation, or learning outcomes).",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. "
        ],
        "Governance practices employed": [
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "UK-Introduction to AI Assurance.pdf"
        ],
        "Key quotes on AI in education principles": "Risk assessments are used to consider and identify a range of potential risks that might arise  from the development and/or deployment of an  AI product/systems.",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "Impact assessments are used to anticipate the wider  effects of a system/product on the environment,  equality, human rights, data protection, or other  outcomes.",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "Impact assessments are used to anticipate the wider  effects of a system/product on the environment,  equality, human rights, data protection, or other  outcomes.",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "United Kingdom: Introduction to AI Assurance",
        "Translation Comments": "N/A - English"
      },
      "id": "i-l6Q9QbdRI3",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-l6Q9QbdRI3",
      "name": "United Kingdom: Introduction to AI Assurance",
      "index": 477,
      "createdAt": "2025-04-24T05:02:50.459Z",
      "updatedAt": "2025-04-24T05:15:49.398Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-l6Q9QbdRI3"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Canada"
        ],
        "Policy Name": "Guide On The Use Of Generative AI",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Involved generative AI may not be suited for use in administrative [such as in the education field] decision-making at this stage.",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "[N/A]"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "BT48-37-2023-eng.pdf"
        ],
        "Key quotes on AI in education principles": "However, generative AI may not be suited for use in administrative  decision-making at this stage. The design and functioning of generative  models can limit federal institutions’ ability to ensure transparency,  8 accountability and fairness in decisions made by generative AI systems or  informed by their outputs. As well, the terms of use for the generative AI  products of many leading technology companies prohibit using their  products to make high-impact decisions. For example, OpenAI instructs  users not to employ ChatGPT in decisions about credit, employment,  educational institutions, or public assistance services; law enforcement and  criminal justice; and migration and asylum.",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Issue: generative AI poses risks to human rights, privacy, intellectual property protection, and procedural fairness",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "Risks could also arise from the opacity of generative AI models and their  potential for producing inaccurate, biased or inconsistent outputs. This  opacity makes it difficult to trace and understand how the AI system  produces outputs, which can undermine procedural fairness in instances  where a federal institution is obliged to provide clients with reasons for  administrative decisions, such as decisions to deny benefits. The quality of AI outputs can also impact individuals’ legal rights. For example, biased  outputs could lead to discrimination in services, potentially violating human  rights.\nTo maintain public trust and ensure the responsible use of generative AI  tools, federal institutions should align with the “FASTER” principles-Fair: ensure that content from these tools does not include or amplify  biases and that it complies with human rights, accessibility, and  procedural and substantive fairness obligations",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Augmentation, not replacement. AI systems should augment, not displace, workers.",
          "Bias testing. AI systems should be tested for bias. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Environmental wellbeing. The use of AI should not harm the environment. "
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "This guide also seeks to raise awareness and foster coordination among  federal institutions. It highlights the importance of engaging key  stakeholders before deploying generative AI tools for public use and before  using them for purposes such as service delivery.",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "Canada: Guide On The Use Of Generative AI",
        "Translation Comments": ""
      },
      "id": "i-7EwyhnaVd0",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-7EwyhnaVd0",
      "name": "Canada: Guide On The Use Of Generative AI",
      "index": 474,
      "createdAt": "2025-04-24T04:13:43.970Z",
      "updatedAt": "2025-04-24T04:47:33.413Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-7EwyhnaVd0"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": "Australia",
        "Policy Name": "National framework for the assurance of artificial intelligence in government",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Instead of focusing on technical detail, the framework sets foundations across all aspects of government, so including education.",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Human rights-centred. The technology must be consistent with human rights. ",
          "Information. Information about the technology in use should be readily available. ",
          "Managing bias. The risk of bias should be managed with care. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Trust. Organisations seeking to incorporate AI into educational settings must build trust.",
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. ",
          "Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology."
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "National framework for the assurance of artificial intelligence in government.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "AI systems should respect human rights, diversity and the autonomy of individuals.\nGovernments should involve people with different lived experiences, including marginalisation, throughout the lifecycles of a use case to gather informed perspectives,  remove preconceptions and avoid overlooking important considerations.",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "Governments should ensure high-quality data and algorithmic design. Audits of AI inputs and outputs for unfair biases, data quality statements and other data  governance and management practices may assist to understand and mitigate bias in AI systems.",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "Australia's 8 AI Ethics Principles, demonstrating how governments can practically apply them to their assurance of AI. \nHuman, societal and environmental wellbeing: Throughout their lifecycle, AI systems should benefit  individuals, society and the environment\nHuman-centred values: AI systems should respect human rights, diversity and the autonomy of individuals.\nFairness: AI systems should be inclusive and accessible, and should not involve or result in unfair discrimination against individuals, communities or groups.\nPrivacy protection and security: AI systems should respect and uphold privacy rights of individuals and ensure the protection of data.\nReliability and safety: Throughout their lifecycle, AI systems should reliably operate in accordance with their intended purpose.\nTransparency and explainability: There should be transparency and responsible disclosure so people can understand when they are being significantly impacted by AI, and can find out when an AI system is engaging with them.\nContestability: When an AI system significantly impacts a person, community,  group or environment, there should be a timely process to allow  people to challenge the use or outcomes of the AI system.\nAccountability: Those responsible for the different phases of the AI  system lifecycle should be identifiable and accountable for the outcomes of the AI systems, and human oversight of AI systems should be enabled.",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "Australia: National framework for the assurance of artificial intelligence in government",
        "Translation Comments": "N/A - English"
      },
      "id": "i-OCnVnwg791",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-OCnVnwg791",
      "name": "Australia: National framework for the assurance of artificial intelligence in government",
      "index": 472,
      "createdAt": "2025-03-03T02:22:23.278Z",
      "updatedAt": "2025-03-04T23:49:34.774Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-OCnVnwg791"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": "Italy",
        "Policy Name": "Italian Strategy for Artificial Intelligence 2024-2026",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Education as one of the four marco-area in the strategic actions",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Tertiary",
          "Primary",
          "Secondary"
        ],
        "Principles on AI in education": [
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ",
          "Critical thinking. Use of the tools should not come at the cost of critical thinking.  ",
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "Italian Strategy for Artificial Intelligence 2024-2026.pdf"
        ],
        "Key quotes on AI in education principles": "To harness the benefits of AI, however, high professional skills capable of developing and managing algorithms and AI systems are required...As a preliminary to any strategic action, it is therefore essential to address this structural problem by deploying a major plan to strengthen, integrate, and disseminate AI knowledge and related digital skills throughout the education system: from Higher Technical Institutes (ITS) to universities, with particular attention to research doctorates.\nThe development of a national strategy for Artificial Intelligence must be based on the premise that, in this exceptionally dynamic context, no worker can be left behind. In order for AI-derived applications to have positive effects on the whole society, reducing risks, it will be necessary to further expand the concept of “education” by aiming in Italy to implement an AI literacy process that involves schools, workers, and all citizens, with attention to the most vulnerable categories.\nObjectives: Promote widespread university education on AI; Implement educational pathways on AI in schools\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "(Design of Intalian large molecule models)Development should focus on specific applications contextualized in significant application domains for our country, for example in Public Administration or in the health sector, that fully comply with European values and regulations in terms of: (i) transparency of training data, to ensure compliance with non-discrimination laws, privacy (GDPR), human rights protection, providing reliable information on the sources from which content is generated;",
        "Does the policy reflect the principle of equity/equality?": "[N/A]",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. "
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "Italy: Italian Strategy for Artificial Intelligence 2024-2026",
        "Translation Comments": "N/A - English"
      },
      "id": "i-4zUYKmQq-a",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-4zUYKmQq-a",
      "name": "Italy: Italian Strategy for Artificial Intelligence 2024-2026",
      "index": 471,
      "createdAt": "2025-03-03T01:04:13.795Z",
      "updatedAt": "2025-03-03T02:18:41.052Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-4zUYKmQq-a"
    },
    {
      "values": {
        "Category of creator": [
          "IO"
        ],
        "Policy creator": "African Union",
        "Policy Name": "Continental Artificial Intelligence Strategy",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This includes a section on expanding AI adoption in the education sector in Africa with recommendation and associated actions",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "African Union-Continental Artificial Intelligence Strategy.pdf"
        ],
        "Key quotes on AI in education principles": "Despite the risks, AI has the potential to facilitate higher-order thinking if guided by proper instructional design and support formative assessment of basic skills.",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Human Rights and Human Dignity—The production, development, use and assessment of AI systems in Africa will always uphold human dignity, gender equality and respect and promote all the human rights set out under the African Charter on Human and Peoples’ Rights and its subsidiary instruments, as well as the Universal Declaration on Human Rights and related instruments of international human rights law.",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "Special efforts are needed from continental, regional and national agencies and governments to ensure that the development and adoption of AI are inclusive and benefit all Africans, empower women and girls, and underrepresented groups and respect Africa’s cultural and linguistic diversity.",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "African Union: Continental Artificial Intelligence Strategy",
        "Translation Comments": "N/A - English"
      },
      "id": "i-ViAANnebu8",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-ViAANnebu8",
      "name": "African Union: Continental Artificial Intelligence Strategy",
      "index": 470,
      "createdAt": "2025-03-03T00:55:02.832Z",
      "updatedAt": "2025-03-03T01:01:16.746Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-ViAANnebu8"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Australia"
        ],
        "Policy Name": "Inquiry into the Use of Generative Artificial Intelligence in the Australian Education System",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is directly on the topic. Lots of interesting submissions.\nSubmissions – Parliament of Australia (aph.gov.au)",
        "Relevance Type": [
          "Policy is about AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "[N/A: This is an inquiry, and does not presuppose the answer to questions]"
        ],
        "Governance practices employed": [
          "Seeks information. It gathers inputs on public sentiment about AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": "",
        "Key quotes on AI in education principles": "“The House of Representatives Standing Committee on Employment, Education and Training will inquire into the issues and opportunities presented by generative Artificial Intelligence (AI), and comprehensively explore current and future impacts on Australia’s early childhood education, schools, and higher education sectors.\n The inquiry will include consideration of:\nThe strengths and benefits of generative AI tools for children, students, educators and systems and the ways in which they can be used to improve education outcomes;\nThe future impact generative AI tools will have on teaching and assessment practices in all education sectors, the role of educators, and the education workforce generally;\nThe risks and challenges presented by generative AI tools, including in ensuring their safe and ethical use and in promoting ongoing academic and research integrity;\nHow cohorts of children, students and families experiencing disadvantage can access the benefits of AI;\nInternational and domestic practices and policies in response to the increased use of generative AI tools in education, including examples of best practice implementation, independent evaluation of outcomes, and lessons applicable to the Australian context; and\nRecommendations to manage the risks, seize the opportunities, and guide the potential development of generative AI tools including in the area of standards.”\n\nNote that the submissions might be interesting as secondary materials. ",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "The terms of reference do not use the language of “human rights”. ",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "The terms of reference do not use the language of “equity”. ",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "https://www.aph.gov.au/Parliamentary_Business/Committees/House/Employment_Education_and_Training/AIineducation/Terms_of_Reference",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 21,
        "Title": "Australia: Inquiry into the Use of Generative Artificial Intelligence in the Australian Education System",
        "Translation Comments": "N/A - English"
      },
      "id": "i-dsHz67wttW",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-dsHz67wttW",
      "name": "Australia: Inquiry into the Use of Generative Artificial Intelligence in the Australian Education System",
      "index": 18,
      "createdAt": "2024-06-01T06:56:56.730Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-dsHz67wttW"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Estonia"
        ],
        "Policy Name": "Estonia Education Strategy 2035",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is directly on point — part of their education strategy involves using technology to make progress. Note I have included some supplementary documents in addition to the actual strategy. The big focus is “digital pedagogy”. ",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "Estonia's Education Minister Kristina Kallas on the challenges and opportunities of AI in learning and empowerment [Q&A] - TNGlobal.pdf",
          "Estonia - Education Strategy 2021-2035 _ Digital Skills and Jobs Platform.pdf",
          "Estonia to unleash AI for personalisation of education.pdf",
          "The AI debate in Estonian education_ A balanced approach - Education Estonia.pdf",
          "estonia_education_strategy_2021-2023.pdf"
        ],
        "Key quotes on AI in education principles": "Digital pedagogy:\n“Educators are familiar with trends, opportunities, risks and methodologies related to new technologies, and apply the technologies in a purposeful way. Smart learning resources and methodology support captivating and effective learning and teaching, and help to give and receive immediate and substantial feedback.” (2035 Education Strategy (English), p 19)\nSmart learning resources:\n“Smart learning resources allow personalised and adaptive learning by means of technology. Smart learning resources enable the empowerment of learners and the addition of value to the learning process through the use of technology (learning analytics, AI, etc.).” (2035 Education Strategy (English), p 36)\nSummary \n“Educators are familiar with trends, opportunities, risks and methodologies related to new technologies, and apply the technologies in a purposeful way. Smart learning resources and methodology support captivating and effective learning and teaching, and help to give and receive immediate and substantial feedback. Essential action is personalisation and diversification of learning and supporting learning through digital solutions. It is necessary to: promote the development and implementation of diverse methods of learning and teaching (including digital pedagogy); develop and use digital solutions as tools for educational innovation that enable the diversification and personalisation of education, including assessment for learning; raise awareness among participants in the learning process of the opportunities and risks of the information society; adopt a systematic approach to the introduction of new solutions; improve access to Estonian – language education and learning of Estonian by introducing digital solutions.” (Education Strategy Summary Document, no pinpoint)\nInterview with the Minister leading this:\n“Minister Kallas acknowledges the challenges of teacher shortages and the need for curriculum adaptation in light of the rapid emergence of AI. However, she remains optimistic, emphasizing the importance of investing in teacher training, developing AI-enhanced learning tools, and fostering collaboration between the public and private sectors. Estonia’s groundbreaking initiatives, such as the AI-enabled infrastructure for personalized learning and the ProgeTiiger Program for teaching programming skills, have garnered international attention. Kallas envisions further collaboration with countries like Singapore, sharing insights and expertise to advance the field of EdTech innovation.” (Interview doc, no pinpoint)",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "N/A",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "N/A",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "https://technode.global/2024/05/17/estonias-education-minister-kristina-kallas-on-the-challenges-and-opportunities-of-ai-in-learning-and-empowerment-qa/",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 12,
        "Title": "Estonia: Estonia Education Strategy 2035",
        "Translation Comments": "N/A - English"
      },
      "id": "i-viyYHzDKAf",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-viyYHzDKAf",
      "name": "Estonia: Estonia Education Strategy 2035",
      "index": 16,
      "createdAt": "2024-06-01T06:29:39.281Z",
      "updatedAt": "2024-06-03T23:12:54.856Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-viyYHzDKAf"
    },
    {
      "values": {
        "Category of creator": [
          "IO"
        ],
        "Policy creator": [
          "UNESCO"
        ],
        "Policy Name": "Guidance for generative AI in education and research",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Highly relevant. ",
        "Relevance Type": [
          "Policy is about AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Academic integrity. Students should be supported to use AI tools ethically in their work, which extends to appropriate attribution.",
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Critical thinking. Use of the tools should not come at the cost of critical thinking.  ",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Human rights-centred. The technology must be consistent with human rights. ",
          "Information. Information about the technology in use should be readily available. ",
          "Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.",
          "Managing bias. The risk of bias should be managed with care. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.",
          "Promoting diversity. Technology should be used to expose users to diverse perspectives. ",
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "386693eng.pdf"
        ],
        "Key quotes on AI in education principles": "To properly understand where they are coming from, note the introduction:\n“However, a thematic set of guidance on GenAI for education should not be understood as a claim that GenAI is the solution to education’s fundamental challenges. Despite the media hyperbole, it is unlikely that GenAI alone will solve any of the problems facing education systems around the world. In responding to long-standing educational issues, it is key to uphold the idea that human capacity and collective action, and not technology, is the determining factor in effective solutions to fundamental challenges faced by societies.” (p 7)\nThere is so much in here that I suggest it is better to read pp 24 to 27\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“UNESCO’s 2021 Recommendation on the Ethics of Artificial Intelligence provides the requisite normative framework to start addressing the multiple controversies around generative AI, including those that pertain to education and research. It is based on a human-centred approach to AI which advocates that the use of AI should be at the service of the development of human capabilities for inclusive, just and sustainable futures. Such an approach must be guided by human rights principles, and the need to protect human dignity and the cultural diversity that defines the knowledge commons. In terms of governance, a human-centred approach requires proper regulation that can ensure human agency, transparency and public accountability.” (p 18)\n“EdGPT. Finally, there is also a need for robust research to ensure that EdGPT does not undermine students’ human rights nor disempower teachers.” (p 13)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "Data poverty: Kalervo Gulson \nAs noted earlier, GenAI relies upon huge amounts of data and massive computing power in addition to its iterative innovations in AI architectures and training methods, which are mostly only available to the largest international technology companies and a few economies (mostly the United States, People’s Republic of China, and to a lesser extent Europe). This means that the possibility to create and control GenAI is out of reach of most companies and most countries, especially those in the Global South. \nAs access to data becomes increasingly essential for the economic development of countries and for the digital opportunities of individuals, those countries and people who do not have access to or cannot afford enough data are left in a situation of ‘data poverty’ (Marwala, 2023). The situation is similar for access to computing power. The rapid pervasion of GenAI in technologically advanced countries and regions has accelerated exponentially the generation and processing of data, and has simultaneously intensified the concentration of AI wealth in the Global North. As an immediate consequence, the data-poor regions have been further excluded and put at long-term risk of being colonized by the standards embedded in the GPT models. The current ChatGPT models are trained on data from online users which reflect the values and norms of the Global North, making them inappropriate for locally relevant AI algorithms in data-poor communities in many parts of the Global South or in more disadvantaged communities in the Global North. (p 14)\nA few other references:\nA starting point for this is the 2022 AI and education: guidance for policy-makers (UNESCO, 2022b). It proposes a comprehensive set of recommendations to guide governments in the development and implementation of sector-wide policies on AI and education with a focus on promoting quality education, social equity and inclusion. Most of the recommendations remain applicable and can be further adapted to guide the formulation of specific policies on GenAI in education. The following eight specific measures for the planning of policies on GenAI in education and research are proposed here to complement this existing guidance. (p 24)\nAccess and equity: GenAI systems in education may exacerbate existing disparities in access to technology and educational resources, further deepening inequities. (p 36)",
        "General principles on AI": [
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Augmentation, not replacement. AI systems should augment, not displace, workers."
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "Note: It is hard to uncouple general and education-specific principles. It is clear that the general principles are intended to apply to education (indeed, they are expressly restated), but one can infer that the narrower principles are intended to apply more broadly. ",
        "Notable Case Studes - Examples of AI in Education": "See, for example, p 33 — “Socratic challenger” and “Advisor for project-based learning”",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 5,
        "Title": "UNESCO: Guidance for generative AI in education and research",
        "Translation Comments": ""
      },
      "id": "i-3KYj_XmjkW",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-3KYj_XmjkW",
      "name": "UNESCO: Guidance for generative AI in education and research",
      "index": 59,
      "createdAt": "2024-05-30T22:56:41.285Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-3KYj_XmjkW"
    },
    {
      "values": {
        "Category of creator": [
          "IO"
        ],
        "Policy creator": [
          "European Union"
        ],
        "Policy Name": "AI Act (Resolution on the text of the AI Act)",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Note that this regulation lists education as high-risk. ",
        "Relevance Type": [
          "Policy has an AI in education component",
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ",
          "Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.",
          "Human rights-centred. The technology must be consistent with human rights. ",
          "Managing bias. The risk of bias should be managed with care. ",
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Transparency (transparency to government). The extent to which AI is used in educational settings should be clear to the government. ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.",
          "Interoperability. AI systems deployed in educational settings should be able to work with other systems. "
        ],
        "Governance practices employed": [
          "Proposes law. It proposes a law or provides a draft law on AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "TA-9-2024-0138_EN.pdf"
        ],
        "Key quotes on AI in education principles": "Note: Given that the entire scheme for “high-risk” systems applies to AI in education, there is some duplication here. The norms that directly apply to AI in education are expressed generally, so both sets of boxes have been ticked. I have not spent a disproportionate amount of time thinking about whether the draft AI Act impliedly expresses particular norms. It would be worth getting Jose-Miguel to look over this record and tweak it using his working knowledge of the scheme. \nNote 2: No page numbers provided in text. \n\nSpecification of education as high-risk:\n“Education and vocational training: (a) AI systems intended to be used to determine access or admission or to assign natural persons to educational and vocational training institutions at all levels; (b) AI systems intended to be used to evaluate learning outcomes, including when those outcomes are used to steer the learning process of natural persons in educational and vocational training institutions at all levels; (c) AI systems intended to be used for the purpose of assessing the appropriate level of education that an individual will receive or will be able to access, in the context of or within educational and vocational training institutions; (d) AI systems intended to be used for monitoring and detecting prohibited behaviour of students during tests in the context of or within educational and vocational training institutions.” \nOpportunity:\n“By improving prediction, optimising operations and resource allocation, and personalising digital solutions available for individuals and organisations, the use of AI can provide key competitive advantages to undertakings and support socially and environmentally beneficial outcomes, for example in... education” \n“The deployment of AI systems in education is important to promote high-quality digital education and training and to allow all learners and teachers to acquire and share the necessary digital skills and competences, including media literacy, and critical thinking, to take an active part in the economy, society, and in democratic processes.” \nHarm:\n“Considering the imbalance of power in the context of work or education, combined with the intrusive nature of these systems, such systems could lead to detrimental or unfavourable treatment of certain natural persons or whole groups thereof. Therefore, the placing on the market, the putting into service, or the use of AI systems intended to be used to detect the emotional state of individuals in situations related to the workplace and education should be prohibited. That prohibition should not cover AI systems placed on the market strictly for medical or safety reasons, such as systems intended for therapeutical use.” \n“However, AI systems used in education or vocational training, in particular for determining access or admission, for assigning persons to educational and vocational training institutions or programmes at all levels, for evaluating learning outcomes of persons, for assessing the appropriate level of education for an individual and materially influencing the level of education and training that individuals will receive or will be able to access or for monitoring and detecting prohibited behaviour of students during tests should be classified as high-risk AI systems, since they may determine the educational and professional course of a person’s life and therefore affect that person’s ability to secure a livelihood. When improperly designed and used, such systems may be particularly intrusive and may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation.” \nImpact assessments:\n“In order to efficiently ensure that fundamental rights are protected, deployers of high-risk AI systems that are bodies governed by public law, or private operators providing public services and operators deploying certain high-risk AI systems listed in an annex to this Regulation, such as banking or insurance entities, should carry out a fundamental rights impact assessment prior to putting it into use. Services important for individuals that are of public nature may also be provided by private entities. Private operators providing such services of public nature are linked to tasks in the public interest such as in the area of education, healthcare, social services, housing, administration of justice. The aim of the fundamental rights impact assessment is for the deployer to identify the specific risks to the rights of individuals or groups of individuals likely to be affected, identify measures to be taken in the case of a materialisation of those risk. The impact assessment should apply to the first use of the high-risk AI system, and should be updated when the deployer considers that any of the relevant factors have changed. The impact assessment should identify the deployer’s relevant processes in which the high-risk AI system will be used in line with its intended purpose, and should include a description of the period of time and frequency in which the system is intended to be used as well as of specific categories of natural persons and groups who are likely to be affected in the specific context of use.” ",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "The whole regime is built around rights protections. Examples can be found everywhere. Just one example:\n“In order to efficiently ensure that fundamental rights are protected, deployers of high-risk AI systems that are bodies governed by public law, or private operators providing public services and operators deploying certain high-risk AI systems listed in an annex to this Regulation, such as banking or insurance entities, should carry out a fundamental rights impact assessment prior to putting it into use. Services important for individuals that are of public nature may also be provided by private entities. Private operators providing such services of public nature are linked to tasks in the public interest such as in the area of education, healthcare, social services, housing, administration of justice. The aim of the fundamental rights impact assessment is for the deployer to identify the specific risks to the rights of individuals or groups of individuals likely to be affected, identify measures to be taken in the case of a materialisation of those risk. The impact assessment should apply to the first use of the high-risk AI system, and should be updated when the deployer considers that any of the relevant factors have changed. The impact assessment should identify the deployer’s relevant processes in which the high-risk AI system will be used in line with its intended purpose, and should include a description of the period of time and frequency in which the system is intended to be used as well as of specific categories of natural persons and groups who are likely to be affected in the specific context of use.” ",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "One of the key concerns specific to education is the perpetuation of discrimination:  \n“However, AI systems used in education or vocational training, in particular for determining access or admission, for assigning persons to educational and vocational training institutions or programmes at all levels, for evaluating learning outcomes of persons, for assessing the appropriate level of education for an individual and materially influencing the level of education and training that individuals will receive or will be able to access or for monitoring and detecting prohibited behaviour of students during tests should be classified as high-risk AI systems, since they may determine the educational and professional course of a person’s life and therefore affect that person’s ability to secure a livelihood. When improperly designed and used, such systems may be particularly intrusive and may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation.” \n",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "
        ],
        "Link (OECD or Other)": "https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "Lots to say on this — JM already an expert in this Act, so will defer spending a lot of time extracting quotations. ",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 3,
        "Title": "European Union: AI Act (Resolution on the text of the AI Act)",
        "Translation Comments": ""
      },
      "id": "i-eCAcTesvI4",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-eCAcTesvI4",
      "name": "European Union: AI Act (Resolution on the text of the AI Act)",
      "index": 171,
      "createdAt": "2024-05-30T22:45:59.556Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-eCAcTesvI4"
    },
    {
      "values": {
        "Category of creator": [
          "IO"
        ],
        "Policy creator": [
          "European Union"
        ],
        "Policy Name": "European Parliament resolution of 19 May 2021 on artificial intelligence in education, culture and the audiovisual sector (2020/2017(INI))",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is directly relevant—and very broad. It covers (almost) as many principles as one could think of. ",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ",
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. ",
          "Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Human rights-centred. The technology must be consistent with human rights. ",
          "Managing bias. The risk of bias should be managed with care. ",
          "Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.",
          "Competition. There should be sufficient competition in the market to ensure that one AI edtech provider does not have excessive market power. ",
          "Interoperability. AI systems deployed in educational settings should be able to work with other systems. ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Transparency (transparency to government). The extent to which AI is used in educational settings should be clear to the government. "
        ],
        "Governance practices employed": [
          "Communicates a stance. It expresses a hope for the future of AI"
        ],
        "Opportunity and risk orientation": "",
        "File": [
          "TA-9-2021-0238_EN (2).pdf"
        ],
        "Key quotes on AI in education principles": "Opportunities:\n“whereas AI has particular potential to offer solutions for the day-to-day challenges of the education sector, such as the personalisation of learning, monitoring learning difficulties, the automation of subject-specific content/knowledge, providing better professional training and supporting the transition to a digital society” (paragraph X)\n“whereas AI could have practical applications in terms of reducing the administrative work of educators and educational institutions, freeing up time for their core teaching and learning activities” (paragraph Y)\n“whereas AI-enabled personalised learning experiences can not only help to increase students’ motivation and enable them to reach their full potential, but also reduce drop-out rates” (paragraph AA)\n“Highlights that the use of AI in education systems brings a wide range of possibilities, opportunities and tools for making it more innovative, inclusive, efficient and increasingly effective by introducing new high-quality learning methods that are quick, personalised and student-centric; stresses, however, that as it will impact education and social inclusion, the availability of such tools must be ensured for all social groups by establishing equal access to education and learning and leaving no one behind, especially people with disabilities;” (paragraph 31)\n“Stresses that the real objective of AI in education systems should be to make education as individualised as possible, offering students personalised academic paths in line with their strengths and weaknesses and didactic material tailored to their characteristics, while maintaining educational quality and the integrating principle of our education systems” (paragraph 33)\nOpportunities to understand:\n“whereas it is essential to ensure that all people in the Union acquire the necessary skills from an early age in order to better understand the capabilities and limitations of AI” (paragraph U)\nHarm:\n“whereas the application of AI in education raises concerns around the ethical use of data, learners’ rights, data access and protection of personal data, and therefore entails risks to fundamental rights such as the creation of stereotyped models of learners’ profiles and behaviour that could lead to discrimination or risks of doing harm by the scaling-up of bad pedagogical practices;” (paragraph AD)\nAugmentation not replacement:\n“AI technologies cannot be used to the detriment or at the expense of in-person education, as teachers must not be replaced by any AI or AI-related technologies” (paragraph 34)\nProcurement:\n“encourages public authorities, in this regard, to incentivise the development and deployment of AI technologies through public funding and public procurement” (paragraph 46)\nCooperation and inclusion:\n“Stresses that the learning benefits of using AI in education will depend not only on AI itself, but on how teachers use AI in the digital learning environment to meet the needs of pupils, students and teachers; points out, therefore, the need for AI programmers to involve teaching communities in the development, deployment and use of AI technologies where possible, creating a nexus environment to form connections and cooperation between AI programmers, developers, companies, schools, teachers and other public and private stakeholders in order to create AI technologies that are suitable for real-life educational environments, reflect the age and developmental readiness of each learner and meet the highest ethical standards; highlights that educational institutions should only deploy trustworthy, ethical, human-centred technologies which are auditable at every stage of their lifecycle by public authorities and civil society; emphasises the advantages of free and open-source solutions in this regard; calls for schools and other educational establishments to be provided with the financial and logistical support as well as the expertise required to introduce solutions for the learning of the future;” (paragraph 35)\nTeacher training:\n“Highlights, moreover, the need to continuously train teachers so they can adapt to the realities of AI-powered education and acquire the necessary knowledge and skills to use AI technologies in a pedagogical and meaningful way, enabling them to fully embrace the possibilities offered by AI and to understand its limitations” (paragraph 36)\nInteroperability:\n“calls for the data used and produced by AI applications in education to be accessible, interoperable and of high quality, and to be shared with the relevant public authorities in an accessible way and with respect for copyright and trade secrets legislation; recalls that children constitute a vulnerable group who deserve particular attention and protection” (paragraph 43)\nSo much more could be included, but suffice it to say that all of the boxes ticked reflect clear statements by the European Parliament. ",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Human rights are built into this document—although they are not the only end pursued. Given acknowledged underinvestment in AI, there are also economic considerations at play. \n\nPerhaps the strongest statement:\n“Underlines the strategic importance of AI and related technologies for the Union; stresses that the approach to AI and its related technologies must be human-centred and anchored in human rights and ethics, so that AI genuinely becomes an instrument that serves people, the common good and the general interest of citizens;” (paragraph 1)\nMore education-specific: \n“Asserts that education, culture and the audiovisual sector are sensitive areas as far as the use of AI and related technologies is concerned, as they have the potential to impact on the cornerstones of the fundamental rights and values of our society” (paragraph 3)\n",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "There are many, many examples. Education-specific ones include: \n“whereas education and educational opportunities are a fundamental right; whereas the development, deployment and use of AI technologies in the education sector should be classified as high risk and subject to stricter requirements on safety, transparency, fairness and accountability;” (paragraph R)\n“whereas AI and related technologies can be used to improve learning and teaching methods, notably by helping education systems to use fair data to improve educational equity and quality, while promoting tailor-made curricula and better access to education and improving and automating certain administrative tasks; whereas equal and fair access to digital technologies and high-speed connectivity are required in order to make the use of AI beneficial to the whole of society; whereas it is of the utmost importance to ensure that digital education is accessible to all, including those from disadvantaged backgrounds and people with disabilities; whereas learning outcomes do not depend on technology per se, but on how teachers can use technology in pedagogically meaningful ways;” (paragraph W)",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress."
        ],
        "Link (OECD or Other)": "https://www.europarl.europa.eu/doceo/document/TA-9-2021-0238_EN.html",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "These general principles are referred to as background (”Whereas...”). \n\nSome of the principles absent here are stated more specifically (e.g., the ‘augmentation not replacement’ is not expressed generally, but is expressed specifically with regard to teachers. ",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "“Calls on the Commission to include education in the regulatory framework for high-risk AI applications, given the importance of ensuring that education continues to contribute to the public good, as well as the high sensitivity of data on pupils, students and other learners;” — this happened",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "European Union: European Parliament resolution of 19 May 2021 on artificial intelligence in education, culture and the audiovisual sector (2020/2017(INI))",
        "Translation Comments": ""
      },
      "id": "i-wfPuoK3OXV",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-wfPuoK3OXV",
      "name": "European Union: European Parliament resolution of 19 May 2021 on artificial intelligence in education, culture and the audiovisual sector (2020/2017(INI))",
      "index": 19,
      "createdAt": "2024-05-30T22:41:18.325Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-wfPuoK3OXV"
    },
    {
      "values": {
        "Category of creator": [
          "IO"
        ],
        "Policy creator": [
          "OECD"
        ],
        "Policy Name": "AI Principles",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "These are important principles that apply to EdTech. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "AI Principles Overview - OECD.AI.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“AI actors should respect the rule of law, human rights, democratic and human-centred values throughout the AI system lifecycle. These include non-discrimination and equality, freedom, dignity, autonomy of individuals, privacy and data protection, diversity, fairness, social justice, and internationally recognised labour rights. This also includes addressing misinformation and disinformation amplified by AI, while respecting freedom of expression and other rights and freedoms protected by applicable international law.\nTo this end, AI actors should implement mechanisms and safeguards, such as capacity for human agency and oversight, including to address risks arising from uses outside of intended purpose, intentional misuse, or unintentional misuse in a manner appropriate to the context and consistent with the state of the art.” (https://oecd.ai/en/dashboards/ai-principles/P6)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“Stakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for people and the planet, such as augmenting human capabilities and enhancing creativity, advancing inclusion of underrepresented populations, reducing economic, social, gender and other inequalities, and protecting natural environments, thus invigorating inclusive growth, well-being, sustainable development and environmental sustainability.”  (https://oecd.ai/en/dashboards/ai-principles/P5)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "OECD: AI Principles",
        "Translation Comments": "N/A - English"
      },
      "id": "i-7fKHs4fMnK",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-7fKHs4fMnK",
      "name": "OECD: AI Principles",
      "index": 60,
      "createdAt": "2024-05-30T09:47:57.293Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-7fKHs4fMnK"
    },
    {
      "values": {
        "Category of creator": [
          "IO"
        ],
        "Policy creator": [
          "UNESCO"
        ],
        "Policy Name": "Recommendation on Ethics in Artificial Intelligence",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This document provides a general summary of artificial intelligence principles, but has a dedicated section on education and research (see Area 8). This document is also very human rights oriented. ",
        "Relevance Type": [
          "Policy has an AI in education component",
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": [
          "Human rights-centred. The technology must be consistent with human rights. ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology.",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. ",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "381137eng (1) (1).pdf"
        ],
        "Key quotes on AI in education principles": "“Member States should promote general awareness programmes about AI developments, including on data and the opportunities and challenges brought about by AI technologies, the impact of AI systems on human rights and their implications, including children’s rights. These programmes should be accessible to nontechnical as well as technical groups.” (p 34)\n“AI systems used in learning should be subject to strict requirements when it comes to the monitoring, assessment of abilities, or prediction of the learners’ behaviours. AI should support the learning process without reducing cognitive abilities and without extracting sensitive information, in compliance with relevant personal data protection standards.” (p 34)\n“Member States should promote the participation and leadership of girls and women, diverse ethnicities and cultures, persons with disabilities, marginalized and vulnerable people or people in vulnerable situations, minorities and all persons not enjoying the full benefits of digital inclusion, in AI education programmes at all levels, as well as the monitoring and sharing of best practices in this regard with other Member States.” (p 34)\n“Member States should ensure that AI researchers are trained in research ethics and require them to include ethical considerations in their designs, products and publications, especially in the analyses of the datasets they use, how they are annotated, and the quality and scope of the results with possible applications.” (p 35)\n\n“Member States should develop guidelines for humanrobot interactions and their impact on human-human relationships, based on research and directed at the future development of robots, and with special attention to the mental and physical health of human beings. Particular attention should be given to the use of robots in health care and the care for older persons and persons with disabilities, in education, and robots for use by children, toy robots, chatbots and companion robots for children and adults. Furthermore, assistance of AI technologies should be applied to increase the safety and ergonomic use of robots, including in a human-robot working environment. Special attention should be paid to the possibility of using AI to manipulate and abuse human cognitive biases.” (p 37)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“AI systems raise new types of ethical issues that include, but are not limited to, their impact on decision-making, employment and labour, social interaction, health care, education, media, access to information, digital divide, personal data and consumer protection, environment, democracy, rule of law, security and policing, dual use, and human rights and fundamental freedoms, including freedom of expression, privacy and nondiscrimination.” (p 10)\n\n“From a socio-technical lens, greater transparency contributes to more peaceful, just, democratic and inclusive societies. It allows for public scrutiny that can decrease corruption and discrimination, and can also help detect and prevent negative impacts on human rights.” (p 22)\n\n“Recalling that, by the terms of its Constitution, UNESCO seeks to contribute to peace and security by promoting collaboration among nations through education, the sciences, culture, and communication and information, in order to further universal respect for justice, for the rule of law and for the human rights and fundamental freedoms which are affirmed for the peoples of the world” (p 5)\n\n“Convinced that the Recommendation presented here, as a standard-setting instrument developed through a global approach, based on international law, focusing on human dignity and human rights, as well as gender equality, social and economic justice and development, physical and mental well-being, diversity, interconnectedness, inclusiveness, and environmental and ecosystem protection can guide AI technologies in a responsible direction” (p 5)\n\n“Considering that AI technologies can be of great service to humanity and all countries can benefit from them, but also raise fundamental ethical concerns, for instance regarding the biases they can embed and exacerbate, potentially resulting in discrimination, inequality, digital divides, exclusion and a threat to cultural, social and biological diversity and social or economic divides; the need for transparency and understandability of the workings of algorithms and the data with which they have been trained; and their potential impact on, including but not limited to, human dignity, human rights and fundamental freedoms, gender equality, democracy, social, economic, political and cultural processes, scientific and engineering practices, animal welfare, and the environment and ecosystems” (p 5)\n\n“The objectives of this Recommendations are (c) to protect, promote and respect human rights and fundamental freedoms, human dignity and equality, including gender equality; to safeguard the interests of present and future generations; to preserve the environment, biodiversity and ecosystems; and to respect cultural diversity in all stages of the AI system life cycle.” (p 15) \n\n“In all cases, any possible limitations on human rights and fundamental freedoms must have a lawful basis, and be reasonable, necessary and proportionate, and consistent with States’ obligations under international law.” (p 18)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“AI actors should promote social justice and safeguard fairness and non-discrimination of any kind in compliance with international law. This implies an inclusive approach to ensuring that the benefits of AI technologies are available and accessible to all, taking into consideration the specific needs of different age groups, cultural systems, different language groups, persons with disabilities, girls and women, and disadvantaged, marginalized and vulnerable people or people in vulnerable situations.” (p 20)\n“Member States should work to promote inclusive access for all, including local communities, to AI systems with locally relevant content and services, and with respect for multilingualism and cultural diversity.” (p 20)\n“Member States should work to tackle digital divides and ensure inclusive access to and participation in the development of AI” (p 20)\n“At the national level, Member States should promote equity between rural and urban areas, and among all persons regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds, in terms of access to and participation in the AI system life cycle.” (p 20)\n\n“At the international level, the most technologically advanced countries have a responsibility of solidarity with the least advanced to ensure that the benefits of AI technologies are shared such that access to and participation in the AI system life cycle for the latter contributes to a fairer world order with regard to information, communication, culture, education, research and socio-economic and political stability.” (p 20)\n\n“Furthermore, new ethical challenges are created by the potential of AI algorithms to reproduce and reinforce existing biases, and thus to exacerbate already existing forms of discrimination, prejudice and stereotyping.” (p 10)\n\n“AI actors should make all reasonable efforts to minimize and avoid reinforcing or perpetuating discriminatory or biased applications and outcomes throughout the life cycle of the AI system to ensure fairness of such systems. Effective remedy should be available against discrimination and biased algorithmic determination.” (p 20)\n\n“Respect, protection and promotion of diversity and inclusiveness should be ensured throughout the life cycle of AI systems, consistent with international law, including human rights law. This may be done by promoting active participation of all individuals or groups regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds.” (p 19)\n\n“Learning about the impact of AI systems should include learning about, through and for human rights and fundamental freedoms, meaning that the approach and understanding of AI systems should be grounded by their impact on human rights and access to rights, as well as on the environment and ecosystems.” (p 23) ",
        "General principles on AI": [
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 3,
        "Title": "UNESCO: Recommendation on Ethics in Artificial Intelligence",
        "Translation Comments": "N/A - English"
      },
      "id": "i-eIePcoMdFY",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-eIePcoMdFY",
      "name": "UNESCO: Recommendation on Ethics in Artificial Intelligence",
      "index": 57,
      "createdAt": "2024-05-30T09:45:24.008Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-eIePcoMdFY"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "India"
        ],
        "Policy Name": "Approach Document for India — Operationalizing Principles for Responsible AI",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is about mechanisms for operationalising principles set out in the first of this two-part series. This is all broadly relevant. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Develops tools. It provides tools and place them in the hands of businesses or governments"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Part2-Responsible-AI-12082021.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Implication of “security risks” - “Real-world deployments may lead to malfunctioning and potentially impact the fundamental rights if underlying AI models are manipulated” (p 3)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“The diversity, scale, digital divide, lack of awareness and inequality serves a fertile ground for the negative effects of AI to amplify. Creating a trusted AI ecosystem is important to realise both the economic and social potential of AI.” (p 7)\n\n“Social research must be aimed at understanding the interaction of AI systems with the local and marginalised communities. This includes understanding how different communities are impacted by the deployment of AI technologies for the delivery of benefits and services, and if benefits are reaching the population as intended, ramifications of risks and considerations such as discrimination, inclusivity, privacy, etc on local and marginalised communities, and identify any other concerns, both in the short term and long term, shaped by the introduction of Artificial Intelligence.” (p 15)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27226",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 3,
        "Title": "India: Approach Document for India — Operationalizing Principles for Responsible AI",
        "Translation Comments": "N/A - English"
      },
      "id": "i-Zc3haNaboY",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-Zc3haNaboY",
      "name": "India: Approach Document for India — Operationalizing Principles for Responsible AI",
      "index": 24,
      "createdAt": "2024-05-30T04:34:33.796Z",
      "updatedAt": "2024-06-03T07:19:30.253Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-Zc3haNaboY"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "India"
        ],
        "Policy Name": "Approach Document for India — Principles for Responsible AI",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is an interesting little paragraph here on positive discrimination — helping certain persons access education (which, in context, is to be achieved through AI). These principles are not framed in terms of EdTech, but could be applied.",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Proposes law. It proposes a law or provides a draft law on AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Responsible-AI-22022021.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Under “Systems Consideration 4: Incorrect decisions leading to exclusion from access to services or benefits”, it notes that: \n“In a beneficiary identification system, an incorrect decision could lead to exclusion of services and benefits guaranteed by the State and in criminal identification systems, it could lead to loss of fundamental rights. When the AI systems are used, particularly for critical services by the Government, it is important to have processes and systems in place for raising an objection.” (p 25)\n\nSee also Appendix 2 (p 59) for the review of global regulatory landscape (some mentions of human rights in the context of EU). ",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "Note that both formal equality and substantive equality are captured. \n\n“Principle of Inclusivity and Non-discrimination: AI systems should not deny opportunity to a qualified person on the basis of their identity. It should not deepen the harmful historic and social divisions based on religion, race, caste, sex, descent, place of birth or residence in matters of education, employment, access to public spaces, etc. It should also strive to ensure that unfair exclusion of services or benefits does not happen. In case of an adverse decision, appropriate grievance redressal mechanism should be designed in a manner affordable and accessible to everyone irrespective of their background.” (p 50)\n\n“Safety and robustness of AI systems can pose serious challenges especially in high risk prone applications; unequal access to AI powered applications for marginalized populations can further accentuate digital divide.” (p 17)\n\n“The ‘systematic’ exclusion from access to services and benefits could undermine trust in the system.” (p 16)",
        "General principles on AI": [
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Opportunity. The opportunities of AI should be harnessed."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27225",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 2,
        "Title": "India: Approach Document for India — Principles for Responsible AI",
        "Translation Comments": "N/A - English"
      },
      "id": "i-gW1QzUap3c",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-gW1QzUap3c",
      "name": "India: Approach Document for India — Principles for Responsible AI",
      "index": 26,
      "createdAt": "2024-05-30T04:30:01.440Z",
      "updatedAt": "2024-06-03T07:19:52.294Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-gW1QzUap3c"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "India"
        ],
        "Policy Name": "National Strategy on AI",
        "Year of Commencement or Creation": "2018",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is super important: India is a very linguistically diverse place. So it’s national strategy envisaged leveraging AI technologies to help with education. Education is one of the five areas that AI will be applied to. ",
        "Relevance Type": [
          "Policy has an AI in education component",
          "Policy contains case studies on AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary",
          "Vocational or Professional"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "National-Strategy-for-Artificial-Intelligence.pdf"
        ],
        "Key quotes on AI in education principles": "The key story here is: India is experiencing low retention rates and poor learning outcomes, and one of the problems is a lack of technology. \n“AI can potentially solve for quality and access issues observed in the Indian education sector. Potential use cases include augmenting and enhancing the learning experience through personalised learning, automating and expediting administrative tasks, and predicting the need for student intervention to reduce dropouts or recommend vocational training.” (p 20)\n“AI has the potential to bring about changes in the sector by supplementing pedagogy and establishing systems to inform and support decision making across stakeholders and administrative levels. However, implementation of AI must be preceded by efforts to digitise records of teacher performance, student performance, and curriculum. Several AI tools are being successfully used in other parts of the world, and they can be adapted to the Indian context to target specific challenges.”\nWhat they are interested in: see use cases below. \nTeacher training:\nA recent survey found that level of adoption of technology in schools is lacking, and can be largely attributed to lack of teacher training, despite provision of the ICT infrastructure. (p 36)\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "“Address and implement data protection framework, which protects human rights and privacy without stifling innovation in India.” (p 93) — only reference",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "There are a few references to discrimination, but this plan is not really framed in the language of equality/equity. Even the opportunity here is framed as an opportunity to improve education (rather than, for example, decrease educational inequality — cf Indonesia). ",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24951",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "Note — education is considered in an “opportunity-only” way. The content on ethics is addressed in broad terms. ",
        "Notable Case Studes - Examples of AI in Education": "a) Adaptive learning tools for customised learning: While AI may not completely replace a teacher, it has the potential to greatly assist teachers in efficiently and effectively managing multi-level / multi?grade classrooms, by judging learning levels of individual students, and allowing automated development of customised educational content adapted to each child’s class and learning level. Assessing time spent by a student on each part / page of the learning material, for example, would allow real-time feedback on student performance to help the teacher appropriately tailor her guidance to the child. This concept can be extended to automatic grading of tests, as well. \nb) Intelligent and interactive tutoring systems: Intelligent Tutoring Systems can provide great benefit to students through delivery of learning materials adapted to the child’s proficiency level, learning style, and pace of learning. In-built pop-up questions tailored to students, for example, can help increase interactivity, and catch student’s attention and interest. It can also help in assessment of student’s level of attention or comprehension to appropriately design remedial instruction. GradeGuardian, for example, uses predictive models and visualisations for student performance with an interactive dashboard showing anticipated effect of policy changes. Submission includes 3 components packaged as a single web app – a Chatbot that inputs student information, an Advisor Console that shows students at risk, and a prediction module for policymakers.\nc) Predictive tools to inform pre-emptive action for students predicted to drop out of school: Analysis of test results and attendance records using AI can be used to predict probable student activities and inform pre-emptive action. For instance, in a recent preliminary experiment conducted in Andhra Pradesh, AI applications processed data on all students based on parameters such as gender, socio?economic factors, academic performance, school infrastructure, teacher skills, etc., with the objective of helping the government identify students likely to drop out. Test results could inform suggestions to enroll students in vocational studies. Additionally, redressal mechanisms could be put in place to identify students whose performance can be improved by focus of existing schemes to their family.\n(d)) Automated rationalisation of teachers: AI tools can be used to develop automated teacher posting and transfer systems, using analytics based on demand – supply gaps across schools in the State, candidate’s prior postings, candidate preferences, etc. This would help in plugging of gaps in teacher distribution more effectively. \ne) Customised professional development courses: To tackle issues of poorly designed professional development courses with poor coverage, adaptive AI tools can be used to design automated, customised professional development training content for the teacher based on their performance, identification of their knowledge and skill gaps. This could then be continuously adapted as teacher’s skills and concepts improve.\n (p 37-38 — read this section, noting the pop-out boxes with concrete case studies)\n",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "India: National Strategy on AI",
        "Translation Comments": ""
      },
      "id": "i-F0cUMbalq-",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-F0cUMbalq-",
      "name": "India: National Strategy on AI",
      "index": 25,
      "createdAt": "2024-05-30T04:29:45.240Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-F0cUMbalq-"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Malta"
        ],
        "Policy Name": "Technology Assessment Recognition Framework",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is an interesting model that could definitely be applied to EdTech. TARF - Technology Assessment Recognition Framework - Malta Digital Innovation Authority (gov.mt)",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI",
          "Develops tools. It provides tools and place them in the hands of businesses or governments"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27583",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 2,
        "Title": "Malta: Technology Assessment Recognition Framework",
        "Translation Comments": "N/A - English"
      },
      "id": "i-noNor4BMYA",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-noNor4BMYA",
      "name": "Malta: Technology Assessment Recognition Framework",
      "index": 28,
      "createdAt": "2024-05-30T04:22:26.071Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-noNor4BMYA"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Malta"
        ],
        "Policy Name": "Towards Trustworthy AI: Malta’s Ethical AI Framework",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a nuanced framework for AI. It talks authorities through precisely what should be done (rather than merely expressing broad norms). Focus on its “governance practices” table. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "Malta_Towards_Ethical_and_Trustworthy_AI_vFINAL.pdf"
        ],
        "Key quotes on AI in education principles": "N/A",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "It stresses: “Respect for all applicable laws and regulations, human rights and democratic values;” — this theme keeps coming back. \n“Conduct human rights impact assessment, identifying and documenting potential trade-offs between different principles and rights.”",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“Equality, non-discrimination and solidarity — AI operations can not generate unfairly biased outcomes, and the benefits and opportunities of AI should be equitably available to all.” (p 9)",
        "General principles on AI": [
          "Respect for laws [NEW]. AI should respect existing law.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24993",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "Note: These principles are inferred from governance control. ",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "This is interesting for its “governance practices” table. Worth paying attention to. \n\nNote that this has been characterised as being equally interested in risks and opportunities. Why? The primary justification is that it sees ETHICS as being one of the central tools for being the “ultimate launchpad” for AI. This is an important point—it is not merely seeing ethics as belonging to the domain of risk mitigation. ",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Malta: Towards Trustworthy AI: Malta’s Ethical AI Framework",
        "Translation Comments": ""
      },
      "id": "i-KzUPzwvpZR",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-KzUPzwvpZR",
      "name": "Malta: Towards Trustworthy AI: Malta’s Ethical AI Framework",
      "index": 27,
      "createdAt": "2024-05-30T04:11:49.801Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-KzUPzwvpZR"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Peru"
        ],
        "Policy Name": "National AI Strategy (2021-2026)",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is directly relevant to AI in education (particularly individualisation of education for each student)",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Secondary",
          "Primary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": "",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "Peru_National_Artificial_Intelligence_Strategy_2021-2026.pdf"
        ],
        "Key quotes on AI in education principles": "“Use case in education:\nAI adapted to the needs of each student\nFrom school to college, AI could individualize the learning needs of each student. \nThe system could respond to the needs of the student, placing greater emphasis on certain topics, repeating things until the student masters it. \nIn general, helping the student to learn at her own pace, whatever this could be. \nAI could give feedback to students and teachers \nAI could give feedback to teachers and students about the results of the course itself. \nSome AI systems are used to monitor student progress and alert teachers when there might be a problem with student performance. \nThese systems could give the support to the students who need it, and to the teacher, to find the areas where he can improve the instructions to the student so that he does not fail with the subject of the course.” (p 19)\n \n“Through the National Center for Innovation and Artificial Intelligence, prioritize the development of use cases where Artificial Intelligence can generate concrete solutions such as those proposed in various investigations aligned to the United Nations 2030 sustainable development goals, such as the elimination of poverty, zero hunger, quality education, clean and accessible energy, clean water and sustainable cities, good health, better qualified jobs, the reduction of social gaps and others.” (p 67)",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“A.5.1.7. In the public sector, in all cases of use of AI to classify people (to provide benefits, opportunities or sanctions to citizens), they must have a socioeconomic impact study to guarantee equity.” (p 79)",
        "General principles on AI": [
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities."
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "image.png",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Peru: National AI Strategy (2021-2026)",
        "Translation Comments": ""
      },
      "id": "i-4zem25qHQm",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-4zem25qHQm",
      "name": "Peru: National AI Strategy (2021-2026)",
      "index": 31,
      "createdAt": "2024-05-30T04:01:52.887Z",
      "updatedAt": "2024-06-06T03:04:13.416Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-4zem25qHQm"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Kenya"
        ],
        "Policy Name": "Kenya’s Digital Economy Strategy",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is a hugely important case study on digital inequality here:\nThe same assumption was extended to the basic education too where it turned out that only less than 25% of learners could participate in remote/online learning. Similarly, the Kenyan labour force are largely in the informal sector where working remotely was not a solution. Unfortunately, the measures that were put in place to address the digital inequalities during the pandemic were seen more as a necessity and not as priorities.\nI am including this for the purpose or asking: How do we roll out AI if the basic infrastructure is not there?",
        "Relevance Type": [
          "Policy contains case studies on AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A Other]"
        ],
        "Governance practices employed": [
          "[N/A]"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "10TH-JULY-FINAL-COPY-DIGITAL-ECONOMY-STRATEGY-DRAFT-ONE.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "[N/A]",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27138",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "This is a case study in the failure to get AI in education projects off the ground. \nThe key point is as follows:\n\nThe same assumption was extended to the basic education too where it turned out that only less than 25% of learners could participate in remote/online learning. Similarly, the Kenyan labour force are largely in the informal sector where working remotely was not a solution. Unfortunately, the measures that were put in place to address the digital inequalities during the pandemic were seen more as a necessity and not as priorities.\n\nThis should be read together with Kenya’s other policies, which deal expressly with AI and blockchain. ",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 4,
        "Title": "Kenya: Kenya’s Digital Economy Strategy",
        "Translation Comments": ""
      },
      "id": "i-TkXOJxaGiN",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-TkXOJxaGiN",
      "name": "Kenya: Kenya’s Digital Economy Strategy",
      "index": 46,
      "createdAt": "2024-05-30T03:06:58.553Z",
      "updatedAt": "2024-06-04T23:03:49.690Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-TkXOJxaGiN"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Kenya"
        ],
        "Policy Name": "Emerging Digital Technologies for Kenya — Exploration and Analysis",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This work was undertaken by the government’s Blockchain and AI Taskforce, and is “AI for development” focused. There is broad awareness that this technology could be used to deliver personalised virtual lessons. They also point to systems already in place — including an SMS-based learning platform. This is a really interesting research paper. ",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "KenEcon_30.pdf"
        ],
        "Key quotes on AI in education principles": "Opportunity\n“In the education sector, AI exhibits the potential to improve learning outcomes by supporting the delivery of personalised virtual lessons. A good example here is M-Shule, an SMS-based learning platform in Kenya, which uses AI to track and analyse student performance and to deliver lessons that satisfy their needs and increase their competency. The platform reduces the fear of failure that is inherent in several learning environments, allowing students to advance at their own pace and to ultimately improve their learning outcomes.” (p 10)\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "“The technology will enable the constitutional rights of the citizens and is expected to continually ensure transparent elections in the country. Elected officials will also be held accountable relative to the use of public resources and effective delivery of government services.” (p 87)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“Essentially, the sharing economy is expected to transition to the next level, where the middleman is not extracting maximum value at the expense of the other participants. Instead, depending on the specific use case or design, the created value will be distributed more equitably” (p 107)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Bias testing. AI systems should be tested for bias. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27135",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "“In the education sector, AI has the potential to improve learning outcomes through more personalised, virtual lessons. For example, M-Shule, an SMS-based learning platform in Kenya, uses AI to track and analyse student performance and to deliver lessons that meet their individual needs and thereby grow their competency. The M-Shule platform reduces the fear of failure inherent in many learning environments. Students can advance at their own pace and ultimately improve their learning outcomes.” (p 39)\n\n(p 40)",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Kenya: Emerging Digital Technologies for Kenya — Exploration and Analysis",
        "Translation Comments": ""
      },
      "id": "i-6wgFj6IDsa",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-6wgFj6IDsa",
      "name": "Kenya: Emerging Digital Technologies for Kenya — Exploration and Analysis",
      "index": 44,
      "createdAt": "2024-05-30T03:02:11.353Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-6wgFj6IDsa"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Romania"
        ],
        "Policy Name": "Romania’s National Strategy",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Romania has a clear intention to use AI in education—specifically: \nPersonalised content presentation, evaluation and feedback \nClasses augmented with AR & VR technologies\nRecommendations for further studying and curation of content\nEnhanced blended learning through AI \nGamification concepts implemented through AI technology\n",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "Romania-2019.pdf"
        ],
        "Key quotes on AI in education principles": "“Romania’s future depends on the education system available to young generations. The obsolete methods used in teaching combined with the poor training of teachers lead to concerning percentages of functional analphabetism in Romania, especially in rural areas. \nAI technologies have the potential to revolutionise the education system through projects such as:\nPersonalised content presentation, evaluation and feedback\nClasses augmented with AR & VR technologies\nRecommendations for further studying and curation of content \nEnhanced blended learning through AI \nGamification concepts implemented through AI technology” (p 9)\n\nAnother initiative concerning training (p 15):\n",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Opportunity. The opportunities of AI should be harnessed."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24849",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "Very little of interest in this strategy — very “carpe diem”, but not a lot of detail or discussion of risk. ",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Romania: Romania’s National Strategy",
        "Translation Comments": ""
      },
      "id": "i-AkCFVNxew3",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-AkCFVNxew3",
      "name": "Romania: Romania’s National Strategy",
      "index": 468,
      "createdAt": "2024-05-30T02:23:12.056Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-AkCFVNxew3"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Egypt"
        ],
        "Policy Name": "Egypt National AI Strategy",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The focus here is on AI education, but it is recognised that EdTech could help Egypt achieve its development goals.",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "Publications_672021000_Egypt-National-AI-Strategy-English.pdf"
        ],
        "Key quotes on AI in education principles": "The key reference to EdTech is as follows:\n\n“Applying AI to areas such as education or healthcare can facilitate access, overcome staff shortages, and reduce risks and costs. On the other hand, concerns are growing about increasingly automated and autonomous AI systems widening the technological, economic, and social gaps due to the lack of basic infrastructure and human capacity capable of exploiting this technology, especially in countries with a large proportion of low-skilled or unskilled labor.” [8]\nIt shows that Egypt is curious but recognises the practical difficulties of harnessing the technology. ",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "N/A",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“The National AI Strategy is a key priority for helping Egypt achieve relevant UN Sustainable Development Goals as they pertain to Egypt (in numerical order 4, 5, 8, 9, 10, 11). The relevant SDGs address inclusive and equitable education” (p 24)\n",
        "General principles on AI": [
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Bias testing. AI systems should be tested for bias. ",
          "Augmentation, not replacement. AI systems should augment, not displace, workers.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,"
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26476",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Egypt: Egypt National AI Strategy",
        "Translation Comments": "Official Translation Obtained"
      },
      "id": "i-dELwsp5J0Y",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-dELwsp5J0Y",
      "name": "Egypt: Egypt National AI Strategy",
      "index": 54,
      "createdAt": "2024-05-30T02:11:00.927Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-dELwsp5J0Y"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "China"
        ],
        "Policy Name": "White Paper on Trustworthy AI",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is generally relevant material here. Also, interesting commentary surrounding China’s AI governance:\nChina’s New AI Governance Initiatives Shouldn’t Be Ignored - Carnegie Endowment for International Peace",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "t0390_trustworthy_AI_EN.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "“(4) AI fairness technology With the widespread application of AI systems, such systems have exhibited unfair decision-making behaviors and discrimination against certain groups. Academia holds that the main reasons for such decision-making biases are as follows: limited by data collection conditions, the weights of different groups in the data are unbalanced; the AI model trained on the unbalanced dataset may then be applied to the overall data, and while performance is sacrificed on a small amount of data, the model's decision-making becomes unfair. In order to ensure the fairness of decision-making in AI systems, relevant researchers have mainly constructed completely heterogeneous datasets to minimize inherent discrimination and bias in the data; datasets are then checked periodically to ensure the high quality of the data. In addition, there are also algorithms that use fair decision-making quantitative indicators to reduce or eliminate decision-making bias and potential discrimination. Such existing fairness indicators can be divided into two categories: individual fairness and group fairness. Specifically, individual fairness measures the degree of prejudice of intelligent decision-making toward different individuals, and group fairness measures the degree of prejudice of intelligent decision-making toward different groups.” (p 11)\n\n“The number of AI applications in sensitive fields continues to grow, such as in hiring, criminal justice, and healthcare, and its fairness has also been the subject of widespread concern. Fairness technology can balance data from a technical perspective, thereby further guiding the model to give fair results, which is of great significance for improving the fairness of decision-making in AI systems.” (p 11)\n\n“In terms of diversity and tolerance, attention should be paid to the fairness and diversity of training datasets to avoid lack of trust caused by data bias. The performance of an AI system depends on the quality of the training data. The dataset may contain implicit race, gender, or ideological bias (Table 1), which may cause the AI system’s decision-making to be inaccurate or biased and discriminatory. Enterprises should focus on improving the diversity and fairness of training data to meet the requirements of diversity and inclusion. On the one hand, attention must be paid to the inherent discrimination and prejudice that may appear in the data and proactive measures should be taken to weaken the impact of such prejudice; on the other hand, the dataset should be reviewed periodically to ensure the high quality of the data. Also, the testing process should use quantitative indicators based on fair decision-making capabilities to test the AI system.” (p 15)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27294",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "China: White Paper on Trustworthy AI",
        "Translation Comments": "N/A - English"
      },
      "id": "i-88Rbwn15L0",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-88Rbwn15L0",
      "name": "China: White Paper on Trustworthy AI",
      "index": 464,
      "createdAt": "2024-05-30T01:18:25.206Z",
      "updatedAt": "2024-06-05T21:37:17.815Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-88Rbwn15L0"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "China"
        ],
        "Policy Name": "Governance Principles for New Generation AI",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "These are broadly relevant.",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Governance Principles for the New Generation Artificial Intelligence--Developing Responsible Artificial Intelligence - Chinadaily.com.cn.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“The development of AI should be based on the premise of ensuring social security and respecting human rights, and should prevent misuse, abuse and evil use of AI technology by all means.” (p 1)\n“AI development should respect and protect the privacy of individuals and fully protect an individual’s rights to know and to choose.” (p 2)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“The development of AI should promote fairness and justice, protect the rights and interests of all stakeholders, and promote equal opportunities.” (p 2)\n\nCould also be interpreted as formal (rather than substantive) equality: \n“Through technology advancement and management improvement, prejudices and discriminations should be eliminated as much as possible in the process of data acquisition, algorithm design, technology development, and product development and application.” (p 2)",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24427",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 5,
        "Title": "China: Governance Principles for New Generation AI",
        "Translation Comments": "N/A - English"
      },
      "id": "i-VbWA0f4jSi",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-VbWA0f4jSi",
      "name": "China: Governance Principles for New Generation AI",
      "index": 458,
      "createdAt": "2024-05-30T01:17:03.342Z",
      "updatedAt": "2024-06-04T22:34:36.295Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-VbWA0f4jSi"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "China"
        ],
        "Policy Name": "National New Generation AI Plan",
        "Year of Commencement or Creation": "2017",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "“Intelligent education” is built into China’s plan. \nNote that far more detailed information about its educational intentions are built into its subsequent education policy (included in our policy tool). ",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "P020210628714286134479.pdf"
        ],
        "Key quotes on AI in education principles": "(p 7)\n\nVery minimal commentary on risks. This is it: “While robustly developing AI, we must highlight the potential safety risks, enhance early prevention and guidance, reduce risks to a maximum degree and ensure the safe, reliable and manageable development of AI.”\n\nThe main usage of “governance” relates to “intelligent social governance” (by which it means “public administration”). \n",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "N/A",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24274",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 3,
        "Title": "China: National New Generation AI Plan",
        "Translation Comments": "Official Translation Obtained"
      },
      "id": "i-5nkZlHdSBx",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-5nkZlHdSBx",
      "name": "China: National New Generation AI Plan",
      "index": 456,
      "createdAt": "2024-05-30T01:16:33.257Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-5nkZlHdSBx"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "China"
        ],
        "Policy Name": "AI Innovation Action Plan for Institutions of Higher Education",
        "Year of Commencement or Creation": "2018",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This has a section on “intelligent education” that is directly relevant—and really interesting. As far back as 2018, it was looking into the following: “Accelerate and promote the deep integration and innovative development of AI in education.” See details below. \nNote, however, that this strategy is broader in scope than “EdTech governance” — it considers the role of educational institutions in developing a robust AI sector. ",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Communicates a stance. It expresses a hope for the future of AI",
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "Notice-of-the-Ministry-of-Education-on-Issuing-the-Artificial-Intelligence-Innovation-Action-Plan-for-Institutes-of-Higher-Education.pdf"
        ],
        "Key quotes on AI in education principles": "There is significant appetite here:\n“Using smart technology to innovate new ways to provide training, revolutionize teaching methods, improve academic administration, and build an intelligentized, networked, personalized, lifelong education system are important measures for promoting the development of balanced education, educational equity, and increased education quality. It is an indispensable driver of and support for educational modernization.” (p 2)\n\nWhat does it want to do with AI in education?\n“Promote the development of intelligent education. Promote educational and teaching reform. Move towards a smart campus model based on digital campuses. Create a technology-enabled teaching environment. Explore new AI-based teaching models. Reconstruct how teachers teach, using AI to monitor the teaching process, analyze students, and assess attainment levels. Set up comprehensive, multi-dimensional, big data-based smart assessments. Accurately evaluate both teacher and student performance. Institute individualized aptitude-based curricula. Promote academic administration reform. Support schools’ use of AI technology to modify their organizational structures and management systems and optimize how they operate and serve their students. Implement delicacy management and personalized service on campuses to completely upgrade schools’ administrative levels. Promote lifelong online learning, encourage the development of student-centric intelligentized learning platforms, provide a rich variety of personalized learning resources, innovate how services are provided, and tailor lifelong learning.” (p 10)\n“Demonstrating the application of AI in intelligent education. Accelerate and promote the deep integration and innovative development of AI in education. Research strategies, standards, and specifications for developing intelligent education. Explore channels and methods for integrating AI technology into the educational environment, teaching models, curricula, teaching methods, academic administration, educational assessment, and educational research. Develop an intelligentized, cloud-based education platform and encourage new ways of teaching that are supported by AI to modernize education from the ground up.” (p 11)",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "N/A",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“Using smart technology to innovate new ways to provide training, revolutionize teaching methods, improve academic administration, and build an intelligentized, networked, personalized, lifelong education system are important measures for promoting the development of balanced education, educational equity, and increased education quality. It is an indispensable driver of and support for educational modernization” (p 2)",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26851",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 2,
        "Title": "China: AI Innovation Action Plan for Institutions of Higher Education",
        "Translation Comments": "Official Translation Obtained"
      },
      "id": "i-SE9pMo8wjZ",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-SE9pMo8wjZ",
      "name": "China: AI Innovation Action Plan for Institutions of Higher Education",
      "index": 61,
      "createdAt": "2024-05-30T01:15:57.142Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-SE9pMo8wjZ"
    },
    {
      "values": {
        "Category of creator": [
          "IO"
        ],
        "Policy creator": [
          "UNESCO"
        ],
        "Policy Name": "Beijing Consensus on AI and Education",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "It is difficult to think of a more relevant document than this. It is all about AI empowering teachers, helping manage schools, and so on. ",
        "Relevance Type": [
          "Policy is about AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Managing bias. The risk of bias should be managed with care. "
        ],
        "Governance practices employed": "",
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "W020190828311234688933.pdf"
        ],
        "Key quotes on AI in education principles": "Opportunities:\n“We are committed to leading appropriate policy responses aimed at the systematic integration of AI and education to innovate education, teaching and learning, and at leveraging AI to accelerate the delivery of open and flexible education systems that enable equitable, relevant and quality lifelong learning opportunities for all that will contribute to achieving the SDGs and the shared future for mankind.” (p 3)\nTalks about AI for education management and delivery\n“10. Be cognizant of the breakthrough in the use of data in transforming evidence-based policy planning processes. Consider integrating or developing AI technologies and tools that are relevant for upgrading education management information systems (EMIS) in order to enhance data collection and processing, making education management and provision more equitable, inclusive, open and personalized. “\n“11. Consider also introducing new models for delivering education and training in different learning institutions and settings that can be enabled by the use of AI, in order to serve different actors such as students, teaching staff, parents and communities” (p 5)\nTalks about AI to empower teaching and teachers\n“Be mindful that while AI provides opportunities to support teachers in their educational and pedagogical responsibilities, human interaction and collaboration between teachers and learners must remain at the core of education...” (p 5)\n“Dynamically review and define teachers’ roles and required competencies in the context of teacher policies, strengthen teacher training institutions, and develop appropriate capacity-building programmes to prepare teachers to work effectively in AI-rich education settings.” (p 5)\nTalks about AI for learning and assessment\n“Be cognizant of trends regarding the potential of AI to support learning and learning assessments”... (p 5)\nAugmentation not replacement\n“Be aware that teachers cannot be displaced by machines, and ensure that their rights and working conditions are protected” (p 5)\nEthical, transparent, and auditable\nSee p 8\n\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Starts with a background statement:\n“We also recognize the distinctive features of human intelligence. Recalling the principles set forth in the Universal Declaration of Human Rights, we reaffirm UNESCO’s humanistic approach to the use of AI with a view towards protecting human rights and preparing all people with the appropriate values and skills needed for effective human–machine collaboration in life, learning and work, and for sustainable development.” (p 4)\nMoves on to more significant propositions:\n“Coordinate collective actions to promote the equitable use of AI in education in the context of the global and regional Education 2030 architecture, including through sharing AI technology, programmes and resources for capacity-building, with due respect for human rights and gender equality” (p 9)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "“Recalling the Qingdao Declaration adopted in 2015 on leveraging information and communication technology (ICT) to achieve SDG 4, which stated that emerging technologies must be harnessed to strengthen education systems, access to education for all, quality and effective learning, and equitable and more efficient service provision, we are cognizant of the urgency of reaffirming and renewing this commitment as we move towards an era characterized by the widespread application of AI.” (p 3)\nThe main section on equity comes later:\n“22. Reaffirm that ensuring inclusion and equity in and through education, and offering lifelong learning opportunities to all, are the cornerstones of achieving SDG 4 – Education 2030. Reaffirm that technological breakthroughs in the field of AI in education are an opportunity to improve access to education for the most vulnerable groups.” (p 7)\n“23. Ensure that AI promotes high-quality education and learning opportunities for all, irrespective of gender, disability, social or economic status, ethnic or cultural background, or geographic location. The development and use of AI in education should not deepen the digital divide and must not display bias against any minority or vulnerable groups.” (p 7)\n“24. Ensure that AI tools in teaching and learning enable the effective inclusion of students with learning impairments or disabilities and those studying in a language other than their mother tongue.” (p 7)\nEtc",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27218",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "UNESCO: Beijing Consensus on AI and Education",
        "Translation Comments": ""
      },
      "id": "i-0pzKRyXc_Y",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-0pzKRyXc_Y",
      "name": "UNESCO: Beijing Consensus on AI and Education",
      "index": 56,
      "createdAt": "2024-05-30T01:15:43.255Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-0pzKRyXc_Y"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Bulgaria"
        ],
        "Policy Name": "Concept for the Development of AI in Bulgaria until 2030",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is broad acknowledgment that AI will contribute to modernisation of schools, but also generally relevant governance norms. ",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education",
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. ",
          "Human rights-centred. The technology must be consistent with human rights. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Communicates a stance. It expresses a hope for the future of AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "conceptforthedevelopmentofaiinbulgariauntil2030.pdf"
        ],
        "Key quotes on AI in education principles": "The document makes some general remarks regarding the importance of AI education (curriculum) in primary and secondary schools in meeting skills requirements, as well as development of AI-focused university programs (including for noting, but not relevant to current project):\n“A key role for the development and implementation of AI is the availability of human potential: specialists who are familiar with the latest discoveries and trends in the field, to master methods and tools for scientific research, implementation in practice and teaching, or to be able explain the benefits of adopting intelligent systems for widespread use.\nMore relevant content — \nGeneral governance norm: \n“Special attention to the study of the impact of AI on society, as well as to the standards for building reliable AI. This suggests, on the one hand, the inclusion in the university educational programmes in informatics and technical specialties of academic disciplines focused on the legal, ethical and social aspects of AI, and on the other hand, the inclusion of disciplines for researching the impact of AI in the schools of social sciences, legal sciences and humanities.” (p 37)\nOther norms include preparing students to understand the risks of the technology, which is relevant:\n“Increasing students' competencies in the field of ethical issues related to the use of information technology and their rights in the digital world in which they live.” (p 36)\nRelevant to opportunity: \n“Applying AI tools in education to increase the quality, attractiveness and efficiency of the educational process, while strictly observing the protection of fundamental rights and proper consideration of the vulnerable situation of children.” (p 36)\n“Implementing AI in university management. Given the breakthrough in the use of data to transform planning processes, to develop and integrate AI technologies and tools that are important for improving education management information systems (EMIS) to optimize data collection and processing to achieve a fairer, more inclusive, open and personalized education.” (p 37)\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "“It must create a unique \"trust ecosystem\" by ensuring compliance with EU rules, including those for the protection of fundamental human rights and consumer rights, especially in relation to high-risk AI systems.” (p 31)\n“Reliable AI presupposes the development of a legal framework to ensure that the fundamental rights of citizens are preserved, including ensuring product safety and determining legal liability.” (p 16)\n“The principles of respect for fundamental rights, non-discrimination and the protection of personal data should be seen as an integral part of the requirements that ensure the safety of AI technologies.” (p 40)\n“To provide the necessary conditions for ensuring the development of reliable AI technologies in Bulgaria, an assessment of the applicability and effectiveness of the existing regulations on guaranteeing the fundamental rights of citizens and the safety of new products, including AI technologies, as well as the methodology for licensing these products and putting them into operation.” (p 41)",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26500",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Bulgaria: Concept for the Development of AI in Bulgaria until 2030",
        "Translation Comments": "N/A - English"
      },
      "id": "i-ks1e65Ehoi",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-ks1e65Ehoi",
      "name": "Bulgaria: Concept for the Development of AI in Bulgaria until 2030",
      "index": 62,
      "createdAt": "2024-05-30T01:05:01.550Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-ks1e65Ehoi"
    },
    {
      "values": {
        "Category of creator": [
          "OECD",
          "OECD",
          "OECD",
          "OECD",
          "OECD"
        ],
        "Policy creator": [
          "France",
          "Italy",
          "Ireland",
          "Luxembourg",
          "Slovenia"
        ],
        "Policy Name": "AI4T",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is highly relevant — about preparing teachers to embrace AI in education / ensuring that have the skills to manage it. Note that it is France and others. \nAI4T - Artificial Intelligence for and by teachers | France Education international (france-education-international.fr)\n\nHere is a link to the textbook, which I have included as a secondary source:\nAI for Teachers — Textbook",
        "Relevance Type": [
          "Policy is about AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary"
        ],
        "Principles on AI in education": [
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Develops tools. It provides tools and place them in the hands of businesses or governments"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "AI4T - Artificial Intelligence for and by teachers _ France Education international.pdf"
        ],
        "Key quotes on AI in education principles": "“At the end of the project, the aim is that teachers will become more confident and aware users of AI-based resources, which will help them to improve their practice. In addition, AI4T is contributing to the implementation of new teaching methods in the classroom and to the informed use of AI as a decision-making aid. A European network is being set up to share experience and best practice.” (no pinpoint)\n\nNote that they actually built a textbook:\nTextbook – AI4T project",
        "Does the policy reflect the principle of human rights compatibility?": "",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 13,
        "Title": "FranceItalyIrelandLuxembourgSlovenia: AI4T",
        "Translation Comments": "Translation Completed (Google Translate)"
      },
      "id": "i-NzS1c7nWDB",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-NzS1c7nWDB",
      "name": "FranceItalyIrelandLuxembourgSlovenia: AI4T",
      "index": 441,
      "createdAt": "2024-05-29T08:20:33.114Z",
      "updatedAt": "2024-06-04T22:38:02.206Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-NzS1c7nWDB"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Chile"
        ],
        "Policy Name": "Smart Job Retraining",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is more promising — it is about providing “tools that help [citizens] in the process of job retraining’. IDB | Smart Job Retraining (iadb.org)\nIt is not entirely clear what the ‘machine learnin’ component is. ",
        "Relevance Type": [
          "Policy contains case studies on AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Vocational or Professional"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Develops tools. It provides tools and place them in the hands of businesses or governments"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27049",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "TC “aims at designing a technological platform called \"Intelligent Labor Retraining\" or RELINT (in Spanish), based on a data intelligence model that allows companies and individuals to be guided in the process of retraining. On the one hand, supporting companies in a digital transformation process by introducing reskilling, upskilling and outplacement mechanisms and, on the other hand, allowing workers to improve their skills for a new type of company or to start a new labor route. This is done by linking interests, experience and employability potential with the demand that the market is requesting for new skills derived from the ongoing digital transformation.”\n",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 10,
        "Title": "Chile: Smart Job Retraining",
        "Translation Comments": ""
      },
      "id": "i-H3DXVgh09v",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-H3DXVgh09v",
      "name": "Chile: Smart Job Retraining",
      "index": 77,
      "createdAt": "2024-05-29T04:38:15.161Z",
      "updatedAt": "2024-06-06T03:05:20.882Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-H3DXVgh09v"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Belgium"
        ],
        "Policy Name": "AI 4 Belgium",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "These guidelines have a section of “AI as an education tool”. Definitely translate the broader policy document to check for relevant content—but if not, you can firmly say that, in principle, the Belgium government supports two use cases:\nDeploy AI as a tool for individualised training adapted to each individual student \nApply AI as a tool for teachers to enhance their teaching",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "report_en.pdf"
        ],
        "Key quotes on AI in education principles": "Note — the existence of risk is recognised, but this is a predominantly “seize the day” policy. ",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "N/A",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“Finally, AI can also be a tool in education. It can drastically improve quality and equity in many cases.”",
        "General principles on AI": [
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24234",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 3,
        "Title": "Belgium: AI 4 Belgium",
        "Translation Comments": "Translation Needed"
      },
      "id": "i-zLeK3YsXOk",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-zLeK3YsXOk",
      "name": "Belgium: AI 4 Belgium",
      "index": 88,
      "createdAt": "2024-05-29T03:41:10.073Z",
      "updatedAt": "2024-06-03T02:37:13.450Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-zLeK3YsXOk"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Mexico"
        ],
        "Policy Name": "Website for Personal Data Protection Impact Assessments",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a really cool, interactive impact assessment tool worth noting (though not for AI per se — focuses on data protection). A version of this could be developed for EdTech, whether the data protection aspect or otherwise. Am I required to file a DPIA? – EIPDP (inai.org.mx) ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27479",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "This kind of system could be useful — an impact assessment tool of sorts. \nimage.png",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 10,
        "Title": "Mexico: Website for Personal Data Protection Impact Assessments",
        "Translation Comments": "Translation Needed"
      },
      "id": "i-1xjaXeD9Ml",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-1xjaXeD9Ml",
      "name": "Mexico: Website for Personal Data Protection Impact Assessments",
      "index": 417,
      "createdAt": "2024-05-29T03:06:42.064Z",
      "updatedAt": "2024-06-03T04:55:12.590Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-1xjaXeD9Ml"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Hungary"
        ],
        "Policy Name": "Hungary’s AI Strategy",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Locating this document was a bit of a nightmare. In any case, it’s out there and in English, which is convenient (for us). There is a fair bit of relevant content—including reference to “AI-supported education”. It is committed to: “intensive use of AI technologies in the developments associated with data management in higher education” (p 31). ",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Plans further action. It sets out a strategy on AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "Hungary’s Artificial Intelligence Strategy.pdf"
        ],
        "Key quotes on AI in education principles": "Under “Objectives by 2030 directly affecting citizens”, it notes that “2.5 million citizens benefit from AI-supported education” (p 20)\n“The aim is to collect, promote and make available Hungarian language versions of personalised learning support products available internationally for people at risk of falling behind (disabled, elderly, digital illiterates, those with a low level of education), using AI technologies, as well as to identify and provide priority development and support for talented people from an early age. • International collection and Hungarian translation of guidance material prepared for the groups at risk of falling behind in the labour market.\nContinuous dialogue on the development results and the special demands that may be formulated as the development goals.\nIntroducing games for improving high-level mathematical and logical skills from an early age and identifying talented children and teenagers. \nProvision of mentors and tutors; online and in-person training for recognised talents and providing support for them beyond the school system.” (p 31)\n\n“Intensive use of AI technologies in the developments associated with data management in higher education.” (p 30)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "“A general regulatory environment needs to be put in place for data assets with functions such as supporting the AIrelated use of public data assets and facilitating the process of turning data into assets (assetization), together with the development of the relevant financial and legal regulations – taking into account the various sectors’ specificities and responsibilities in terms of data processing, as well as the relevant fundamental rights and the international framework of data regulations. \nCreation of a framework law on data assets. \nIntroduction of a sector-specific regulatory environment to enable data to be turned into assets and their use for purposes of AI. \nDeveloping rules to govern the use of public data, along with a concept for and rules on their assetization.” (p 34)\n\n“The goal is to enable citizens to participate, as active and responsible actors, in the data economy where the secondary use of data takes place and to exercise their fundamental rights relating to the protection of personal data. To this end, they need to be enabled to dispose over data pertaining to them and to participate actively and securely in the secondary use of such data.” (p 43)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "“Inclusion and talent coaching for groups at risk of falling behind in the labour market The aim is to collect, promote and make available Hungarian language versions of personalised learning support products available internationally for people at risk of falling behind (disabled, elderly, digital illiterates, those with a low level of education), using AI technologies, as well as to identify and provide priority development and support for talented people from an early age.” (p 31)",
        "General principles on AI": [
          "Augmentation, not replacement. AI systems should augment, not displace, workers.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26765",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Hungary: Hungary’s AI Strategy",
        "Translation Comments": "N/A - English"
      },
      "id": "i--PZ-g1Dix2",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i--PZ-g1Dix2",
      "name": "Hungary: Hungary’s AI Strategy",
      "index": 94,
      "createdAt": "2024-05-29T02:46:55.324Z",
      "updatedAt": "2024-06-03T00:01:55.281Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui--PZ-g1Dix2"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Turkiye"
        ],
        "Policy Name": "Human-Centred AI for Human Resources",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The policy initiative here was to produce guidance on AI in HR. Similar issues are raised in education (hiring, admissions, etc) so it is worth including this. Might need to add some new “AI in education principles”. Also note the “created from the Human-Centred Artificial Intelligence for Human Resources project.”",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Develops tools. It provides tools and place them in the hands of businesses or governments",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "WEF_Human_Centred_AI_for_HR_2021.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“In addition to being a target specifically for the regulation of AI, HR already operates in a highly regulated space. Most countries have numerous labour laws that would apply to AI-based HR tools. In some ways, this existing regulation may already be providing safeguards and even useful guidance. For instance, a number of countries already have anti-discrimination regulations on employment decisions and hiring tests, which include a recognition that such practices can have unintended discriminatory effects (known as adverse impact or indirect discrimination)” (p 15)",
        "General principles on AI": [
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27318",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 10,
        "Title": "Turkiye: Human-Centred AI for Human Resources",
        "Translation Comments": "N/A - English"
      },
      "id": "i-OX3xS8Y5MT",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-OX3xS8Y5MT",
      "name": "Turkiye: Human-Centred AI for Human Resources",
      "index": 108,
      "createdAt": "2024-05-29T01:42:21.376Z",
      "updatedAt": "2024-06-05T21:37:17.815Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-OX3xS8Y5MT"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Turkiye"
        ],
        "Policy Name": "National AI Strategy",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Most of this strategy is about “AI education”, but there is an initiative in here about education technology.",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "TRNationalAIStrategy2021-2025.pdf"
        ],
        "Key quotes on AI in education principles": "“The Education Technologies Incubation and Innovation Center will be implemented in 2021 by the Ministry of National Education, General Directorate of Innovation and Education Technologies, within the scope of the World Bank's “Safe Schooling and Distance Education Project”. The Center will operate in METU Technopolis and will work in cooperation with the public-private sector. Within the scope of the project, an innovation ecosystem in education will be developed, and through this ecosystem, new digital tools and pedagogical models will be developed and released, and blended education processes will be supported through the cooperation of various stakeholders. In this direction, working groups for AI education will be established, capacity building activities and R&D activities will be carried out for AI applications in education.” (p 54)\nThe rest of the content is about teaching AI as a discipline (quite different to using AI to teach). \nThis policy does not make it clear which principles will govern this specific EdTech initiative, so the broad principles expressed in this document will only be included below (under general principles). [CF my analysis of the Netherlands Strategy or the EU AI Act, where it is made clear that broad principles expressed extend to AI in education.]",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Expressed generally, but not specifically in relation to EdTech:\n“The implementation of AI technologies also raises privacy and national security concerns in many cases. In addition, the widespread use of AI-powered autonomous or semi-autonomous decision-making mechanisms raises ethical problems such as the protection of human rights and the prevention of discrimination. Therefore, building an effective AI ecosystem requires establishing an appropriate ethical and legal framework that takes into account the technological nature of AI” (p 15)\n“The OECD Council Recommendation on Artificial Intelligence, to which our country is also a party, was adopted on 22 May 2019 in order to strengthen the global AI policy ecosystem that respects human rights, democratic and ethical values.1 These principles, supported by the EU, were soon adopted by the G20 as well. The document also provides recommendations for international cooperation on trustworthy AI.”\n“Human dignity, human rights and fundamental freedoms must be essential throughout the lifecycle of AI systems. All AI technologies to be developed in our country should be designed in compliance with national ethical values and by prioritizing human rights, democratic values and the rule of law so that all members of society can benefit from such technologies. No human should be harmed physically, economically, socially, politically or psychologically at any stage in the lifecycle of AI systems. In interactions with AI systems throughout their lifecycle, people should never be objectified, their dignity should never be harmed, and human rights should never be violated or abused.” (p 59)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "This strategy uses the language of “fairness”. The concept is not specifically used in relation to AI in education, but generally:\n“Fairness AI systems should be designed to provide an equal and fair service to all stakeholders while adhering to the rule of law and fundamental rights and freedoms. The fairness of AI systems means that the benefits of AI technology are shared at local, national and international levels, while taking into account the specific needs of different age groups, different cultural systems, different language groups, people with disabilities, and disadvantaged, marginalized and vulnerable segments of the society. It should be ensured that decisions made based on algorithms do not give rise to discriminatory or unfair effects on different demographic populations. In order to prevent the emergence of unintentional discrimination in decision-making processes, monitoring and accountability mechanisms should be developed and those mechanisms should be included in the implementation process.” (p 60)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26590",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "“An impact analysis framework will be established to monitor and evaluate the level of implementation of AI values and principles” (p 73)\nOn collaborative development and interoperability:\n“The participation of different stakeholders throughout the lifecycle of AI systems is essential for inclusive and agile AI governance, the benefits of AI passing through society, and for AI to contribute to technological progress and development. Stakeholders of AI systems include public institutions, NGOs, international organizations, researchers, academia, media, educators, policy makers, the private sector, human rights institutions, and other bodies established for the youth and children. It is important to adopt open standards and interoperability to facilitate collaboration among AI stakeholders. Agile governance measures should be taken in line with technological developments and new sociotechnical needs.” (p 61)\nProcurement:\nIt makes reference to the WEF’s Procurement toolkit:\n“The WEF has developed and piloted common tools for governments to deliver AI solutions built with ethical principles in mind. The AI Procurement Toolkit for the Public and Private Sector prepared for this purpose includes concrete recommendations on purchasing, risk assessments, proposal drafting and evaluation.34 In addition, a toolkit for recruitment, performance evaluation and promotion is being developed with the contribution of public institutions and private sector organizations in our country in order to base the use of AI applications in human resources on human-centric and ethical values.”  (p 31)\nLater it expressly says:\n“The commercialization of developed AI solutions will be supported by prioritizing them in public procurement.” (p 69)\nCould we infer that it recognises the normative influence procurement exerts? Or is it simply saying that it will support R&D here, and not delving into ethics? I have assumed the latter. ",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "One of the more progressive strategies I have seen. Have these ideals been realised in practice?",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Turkiye: National AI Strategy",
        "Translation Comments": ""
      },
      "id": "i-JGZxJmkxIv",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-JGZxJmkxIv",
      "name": "Turkiye: National AI Strategy",
      "index": 114,
      "createdAt": "2024-05-29T00:58:49.546Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-JGZxJmkxIv"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Lithuania"
        ],
        "Policy Name": "AI Strategy",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is a generally relevant collection of policies from p 8, but all of the education-related content concerns preparing people for a life with AI — education for AI — rather than AI in education. Including this on the basis of the broadly applicable principles. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Plans further action. It sets out a strategy on AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "Lithuania_Artificial_Intelligence_Strategy_2019.pdf"
        ],
        "Key quotes on AI in education principles": "All of the education-related content concerns preparing people for a life with AI — education for AI — rather than AI in education.",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "“To ensure that we stay on the right track, a human-centric approach to AI is needed. Trustworthy AI has two components: (1) ethical purpose - it should respect fundamental rights, applicable regulation and core principles and values and (2) it should be technically robust and reliable since, even with good intentions, a lack of technological mastery can cause unintentional harm.” (p 8)\n\n“Principle 1: To advice the public sector on ethical AI regulation and implementation. Mechanism: Establish AI ethics committee that reviews impact of technology on fundamental rights.” (p 8)",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Opportunity. The opportunities of AI should be harnessed."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24220",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Lithuania: AI Strategy",
        "Translation Comments": ""
      },
      "id": "i-4u9qJ87NTG",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-4u9qJ87NTG",
      "name": "Lithuania: AI Strategy",
      "index": 118,
      "createdAt": "2024-05-29T00:52:23.424Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-4u9qJ87NTG"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Slovakia"
        ],
        "Policy Name": "Action Plan for the Digital Transformation of Slovakia",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This makes reference to support for AI-based tools in education, and — more generally — using “digital technologies for innovations and improvement of the quality of education” (p 21)",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "AP-DT-English-Version-FINAL.pdf"
        ],
        "Key quotes on AI in education principles": "Opportunity\n“we will support the use of digital technologies in order to increase the success of the process of education” (p 20)\n“We will support innovation capacity and introduction of solutions built on artificial intelligence, in particular, at the level of SMEs. Therefore, we will set up a network of digital innovation centres and improve possibilities of cooperation with the academic sector in applied research in the field of artificial intelligence, which is significantly based on source data. At the same time, we will support new business models in the digital economy, in order to make conditions in Slovakia for the rise of platforms transforming standard sectors, such as transport, finance, health care and education. It means setting up “regulatory sandboxes”, introducing “future-proof regulations” and redesigning permits for the needs of the digital era.” (p 32)\n“Support increasing higher and specialised skills for IoT, data science, artificial intelligence, programming, for the needs of STEM studies (science, technology, engineering and mathematics), team work and collaborative and co-creative procedures, creative designing and trading as well as other fields of economy and public administration due to their digital transformation,” (p 27)\nDo not consider education holistically — no reference to privacy risks specifically in education, for instance. \n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "Two key references:\n“The intent of the Action Plan also encompasses building trust of persons using digital technologies, ensuring protection of shared data and setting conditions for creating responsible and adequate process of digital transformation. Specific attention in implementation of proposed measures of this Action Plan will be paid to protection of fundamental rights and freedoms of natural persons, in particular right to privacy in connection to personal data processing and compliance with requirements put on personal data protection in relevant European3 as well as national legislation4 .” (p 16)\n“It is necessary to make sure that selected methods are reliable, they are primarily not intended for activities aimed at damaging humans, their rights and freedoms,” (p 65)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "It speaks about:\n“Fair access to technologies for all groups of population (justice, non-discrimination)” (p 65)",
        "General principles on AI": [
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25880",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "“Principle of not causing harm – to assets, health, social status, etc.,” (p 65)\n“Transparency and controllability of system using AI, comprehensibility of basic principles of functioning for the general public (application of the informed consent principle),” (p 65)\nImpact assessment:\nThe intent of the Action Plan also encompasses building trust of persons using digital technologies, ensuring protection of shared data and setting conditions for creating responsible and adequate process of digital transformation. Specific attention in implementation of proposed measures of this Action Plan will be paid to protection of fundamental rights and freedoms of natural persons, in particular right to privacy in connection to personal data processing and compliance with requirements put on personal data protection in relevant European3 as well as national legislation4 . Before the process of implementation of those measures referred to in this Action Plan, when personal data is processed (in particular setting up and deployment of new information systems and technologies), the data protection impact assessment will be made in the sense of Art. 35 of the General Data Protection Regulation and prior consultation with the supervisory authority will be used in the sense of Art. 36 of the General Data Protection Regulation prior to the data processing, if the data protection impact assessment implies that such processing could lead to high risk unless the controller adopts measures to mitigate the risk. (p 16-17)\n(This is a narrow impact assessment)",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Slovakia: Action Plan for the Digital Transformation of Slovakia",
        "Translation Comments": ""
      },
      "id": "i-Jzg5JOd1pY",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-Jzg5JOd1pY",
      "name": "Slovakia: Action Plan for the Digital Transformation of Slovakia",
      "index": 119,
      "createdAt": "2024-05-29T00:39:04.985Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-Jzg5JOd1pY"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Greece"
        ],
        "Policy Name": "Generative AI Greece 20230 “Future of Generative AI in Greece”",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This report is interesting and bold. It recognises that autonomous education applications could be hugely significant. This is definitely worth coming back to.",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary",
          "Vocational or Professional"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Seeks information. It gathers inputs on public sentiment about AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "Gen_AI_Greece_EN_s.pdf"
        ],
        "Key quotes on AI in education principles": "Opportunity:\n“Focusing even at the classroom level, NLP has the potential to enhance the educational process in various ways. At the international level, in a recent report by the IE University Center for Governance1, in the section concerning education, among the scenarios discussed regarding the future of the educational process with the introduction of NLP, a scenario emerged with a significant margin, suggesting the existence of potential (virtual) classrooms where an AI tutor facilitator will play a significant role, while NLP will be utilized to facilitate the creation of potential virtual experiences outside the classroom environment, thus making the educational process more empirical in this specific sense. It is within its technological capabilities for NLP to operate as an assistant to teachers in the classroom, offering students a better understanding of subjects by creating notes, reports, diagrams, and lesson summaries. According to the estimation of Konstantinos Karpouzis, Associate Professor at the Department of Communication, Media and Culture of the Panteion University, \"the integration of NLP into the educational system through the production of personalized content, descriptive assessment, and the use of its tools for the education of students and teachers in new technologies\" is one of the greatest opportunities.” (p 45)\nThis is interesting too — lifelong learning:\n“An opportunity for the Greek reality could also be the enhancement of lifelong learning and adult education in general. One of the main benefits of NLP in lifelong learning is its ability to provide personalized educational experiences. Traditional education usually follows a \"one size fits all\" model, where students are expected to learn at the same pace and in the same way, which is incompatible with adult learners who have unique needs and learning preferences. NLP can analyze large amounts of data on the strengths, weaknesses, and learning styles of a student to create a personalized learning plan.” (p 45)\n\nNote that principles concerned with risks are not addressed at this lower level of abstraction (education-specific) — see below. ",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "“Through the establishment of proactive monitoring and control mechanisms, systematic and effective monitoring of the implementation of ethical guidelines and legislation will be feasible, ensuring that AI is used in a way that respects human rights and the demand for individual and social well-being. Overall, this approach concerns the preparedness of Greek society for the development of AI in a just and sustainable manner, while promoting innovation and growth in this sector. It also involves strengthening the necessary \"institutional triangle\" between digital governance, digital regulation, and digital ethics” (p 105)\n“There is a need to provide a framework of broader universal political guidelines and standards for developers and AI users to ensure that their systems are designed and used ethically. This includes principles such as transparency, justice, and the protection of privacy and human rights.” (p 27)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "Increasing equality\n“Furthermore, NLP capabilities can be particularly beneficial in special education, where it can be tailored to students' specific difficulties, creating real-time lessons tailored to their individual needs108. 109 Additionally, natural language learning and teaching systems can assess students' levels of knowledge, identify gaps in their understanding, and then address them through personalized learning materials and explanations.” (p 45)\n“The guidelines should reflect both societal values and general ethical principles, promoting excellence and safety, transparency and innovation, human benefit, and the fight against digital (or algorithmic) social discrimination and inequalities, as well as human control.” (p 104)\nAugmenting inequality\n“The tendency of AI systems to perpetuate or even exacerbate existing biases, prejudices, and inequalities poses a significant ethical challenge.” (p 82)",
        "General principles on AI": [
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Bias testing. AI systems should be tested for bias. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27603",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "Note that these are framed as “risks” rather than principles, but there are implicit normative ideas within the text. \n\nCyber security:\nThey speak of ‘adversarial attacks’\nAI models may be susceptible to adversarial attacks. Adversarial attacks are deliberate modifications to input data that attempt to compromise the performance of an AI model, and this can also affect AI models. Adversarial attacks can have unintended consequences, such as compromising image creation in an AI model by adding small modifications to input data, thus leading to undesirable outputs (such as misleading images or images containing unwanted information, e.g., reproduction of stereotypes, etc.) (p 65)",
        "Notable Case Studes - Examples of AI in Education": "Before delving into specific possibilities of future application, it may be worth mentioning that in recent years there have already been examples of utilizing the capabilities of NLP and AI in the digital educational industry through metrics linking it to qualifications certification and the job market. The intersection of work capabilities and educational skills is now emerging as a privileged investment field98. It is worth noting that in the international educational industry, the development of platform economy models has favored an algorithmically oriented \"demand-driven education,\" competency-based education, using NLP to develop predictive talent analytics, to match students and graduates with potential career paths through matching tools. This technological capability is offered to them to integrate into the constantly evolving job market (between learning and earning). Based on mass-collected data from educational platforms, from reports on the completion of digital asynchronous educational programs and skills certification tests, the goal pursued is now to shape some algorithmic matching models of successful course completion cycles with professional performance indicators in the job market. (p 42)",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Greece: Generative AI Greece 20230 “Future of Generative AI in Greece”",
        "Translation Comments": ""
      },
      "id": "i-JhOfOAT4Ya",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-JhOfOAT4Ya",
      "name": "Greece: Generative AI Greece 20230 “Future of Generative AI in Greece”",
      "index": 121,
      "createdAt": "2024-05-28T23:25:29.038Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-JhOfOAT4Ya"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Poland"
        ],
        "Policy Name": "Policy for the Development of Artificial Intelligence in Poland from 2020",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a super interesting policy. Poland is proud of its PISA results and sees AI as being an essential tool for “boosting” its strong position. The fourth pillar of its strategy is titled AI and Education (see p 42). Bold vision expressed — worth analysing further. ",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Trust. Organisations seeking to incorporate AI into educational settings must build trust.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "Poland_Policy_for_Artificial_Intelligence_Development_in_Poland_from_2020_2020.pdf"
        ],
        "Key quotes on AI in education principles": "Opportunities\n“The issues of AI-related skill development and the use of AI-based tools in educational processes are the key issues of the Integrated Skills Strategy 2030 in Poland, which is currently undergoing development.” (p 23)\n“ensuring high availability of educational tools in Poland, including online tools, enabling all people who want to get educated in the field of AI to gain knowledge, both theoretical and practical.” (p 42)\nTeacher training:\n“intensification of the use of tools and embedded systems in education, accompanied with training for teachers in their proper use in the teaching process;” (p 43)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“Analysis of the ethical ramifications of AI implementation and the impact of AI systems on the sphere of human rights” (p 25)\n“assessing the societal impact of AI-based systems (in particular the impact on human rights and freedoms) and developing methods for their independent auditing, according a predefined manner and scope;” (p 25)\n“Poland’s continued activity in the Council of Europe in the initiative to develop recommendations for AI with regard to the protection of human rights, the rule of law and democracy.” (p 25)\n“international activities that will support the promotion of Polish business in the field of AI and the development of AI technologies that respect human dignity and fundamental human rights, in accordance with EU and OECD standards, as well as digital diplomacy activities in the area of policies or regulations concerning artificial intelligence” (p 6)\nAdditional material on fundamental rights (see, eg, p 23)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "Fairness\n“diversity, non-discrimination and fairness” (p 63)\nEquality\n“Artificial intelligence is redefining many professions due to process optimisation and automation, and as a result machines replace humans in doing standard and repeatable tasks on an unprecedented scale. This risks aggravating problems in socially and economically excluded regions, increasing unemployment, as well as exacerbating various forms of inequality and discrimination.”",
        "General principles on AI": [
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,"
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24268",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "Note Poland’s aspiration: “Poland is the European leader in education in AI and other digital technologies at secondary school level” (p 45)",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Poland: Policy for the Development of Artificial Intelligence in Poland from 2020",
        "Translation Comments": ""
      },
      "id": "i-z5-nxrhEvU",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-z5-nxrhEvU",
      "name": "Poland: Policy for the Development of Artificial Intelligence in Poland from 2020",
      "index": 122,
      "createdAt": "2024-05-28T23:21:18.902Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-z5-nxrhEvU"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Luxembourg"
        ],
        "Policy Name": "AI: A Strategic Vision for Luxembourg",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Very little is said about education, but what is said is about the promise of EdTech: “In the domain of education, AI could help in defining and generating personalized teaching/learning methods and tools, especially in the field of differentiated education.” Worth noting. ",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "AI_EN_0.pdf"
        ],
        "Key quotes on AI in education principles": "“While AI is not radically new, especially for Luxembourg’s researchers, it is on the threshold of being accessible and applicable across industries and throughout society: digital health, finance, mobility, logistics, clean technologies, space and beyond – not to mention education, environment and art” (p 8)\n“In the domain of education, AI could help in defining and generating personalized teaching/learning methods and tools, especially in the field of differentiated education” (p 14)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "“As a diverse, innovative nation, we will decide what impact this technology will have on human rights, on people’s lives and on our democratic values.” (p 4)",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24335",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Luxembourg: AI: A Strategic Vision for Luxembourg",
        "Translation Comments": ""
      },
      "id": "i-5t3qlI4mpu",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-5t3qlI4mpu",
      "name": "Luxembourg: AI: A Strategic Vision for Luxembourg",
      "index": 123,
      "createdAt": "2024-05-28T23:15:53.248Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-5t3qlI4mpu"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Switzerland"
        ],
        "Policy Name": "Guidelines on AI",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a pretty standard AI framework. Included in case of interest. Could be applied to AI in education. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "_Artificial Intelligence_ – Adoption of Guidelines for the Federal Government.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“Put people at the centre: The dignity and well-being of every individual, as well as the public interest, must be at the forefront of the development and use of AI systems. Particular attention is paid to the protection of fundamental rights in the use of AI.” (p 1)",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26987",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 5,
        "Title": "Switzerland: Guidelines on AI",
        "Translation Comments": "N/A - English"
      },
      "id": "i-ptJWDz_6mV",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-ptJWDz_6mV",
      "name": "Switzerland: Guidelines on AI",
      "index": 130,
      "createdAt": "2024-05-28T23:11:48.516Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-ptJWDz_6mV"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Czech Republic"
        ],
        "Policy Name": "National AI Strategy of the Czech Republic",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is one of the most EdTech-oriented strategies I have seen so far. See extracts below. \n",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "NAIS_eng_web.pdf"
        ],
        "Key quotes on AI in education principles": "Its strategic goals relating to AI in education are very opportunity-oriented:\n“recommend universities to use AI for university management”; (p 26)\n“Implementation of pilot projects for the management of higher education institutions and teaching methods at all levels of education using the principles of management of complex systems using AI” (p 26)\n“Financially support pilot projects for the management of higher education institutions and teaching methods at all levels of education using the principles of management of complex systems using AI”. (p 27)\n“Completing the transformation of education, including fully functional AI teaching in English in most relevant schools and the transformation of content and form of teaching with regard to the ongoing changes in the labour market and society” (p 27)\nOne of the really interesting concrete initiatives for implementation:\n“Support programme for the implementation of AI in education, including the use of tools for managing the transformation of education based on artificial intelligence” (p 28)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "Long-term objective (until 2035):\n“We are going to prevent discrimination, manipulation and misuse of AI, we are going to set the rules for decision-making of algorithms about people in everyday life. We want artificial intelligence to serve all the people of Europe.” (p 3)\n“A significant role in development will also be played by clear legislation, ensuring the protection of fundamental rights and security as well as legal certainty for investors (Chapter 6).” (p 7)\n“Securing standards primarily in the areas of security, personal data protection and the protection of fundamental rights in research, development and use of AI.” (p 36)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“Ensuring equal opportunities and benefits brought about by economic development for the entire society ... the creation of an administrative and legislative framework for AI that avoids any form of discrimination or disadvantage, with a strong emphasis on rights and privacy;” (p 8)\nAssuming that by avoiding disadvantage, they mean ensuring substantive equality — i.e., the law is acting to ensure that people are equal (which is an outcome — i.e., within the province of equity)\n“Potential threats include deepening the problems in socially excluded regions, temporarily increasing structural and frictional unemployment, or deepening the various forms of inequality and discrimination” (p 30)",
        "General principles on AI": [
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24171",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "Note: for procurement, it is actually doing the opposite to using procurement to drive compliance with standards. It talks about: “Removing legal barriers to AI development, including public law and, for example, public procurement.” (p 36)",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Czech Republic: National AI Strategy of the Czech Republic",
        "Translation Comments": "N/A - English"
      },
      "id": "i-Qau2vIXd3P",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-Qau2vIXd3P",
      "name": "Czech Republic: National AI Strategy of the Czech Republic",
      "index": 131,
      "createdAt": "2024-05-28T21:30:35.552Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-Qau2vIXd3P"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "South Korea"
        ],
        "Policy Name": "Human-Centred National Guidelines for AI Ethics",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a good general framework that could easily be applied to EdTech. Attached. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "The National Guidelines for AI Ethics _ The National Guidelines for AI Ethics _ INTRODUCTION _ 인공지능 윤리 소통채널.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Under Principle 1 - Safeguarding Human Right\n“AI should be developed and utilized in a way that respects equal human rights and guarantees diverse democratic values and rights stipulated in international human rights laws and similar standards. \n\nAI should not be developed or utilized in a way that violates human rights and freedom” (p 2)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "Under Principle 6 - Solidarity\n“Diverse stakeholders should be provided with equitable participation opportunities throughout the entire AI system lifecycle” (p 3)\nUnder Principle 3 - Respect for Diversity\n“The socially disadvantaged and vulnerable should be guaranteed access to AI technologies and services Efforts should be made to ensure equal distribution of AI benefits to all people rather than to certain groups” (p 3) \n“Throughout every stage of AI development and utilization the diversity and representativeness of the AI users should be ensured and bias and discrimination based on personal characteristics such as gender age disability region race religion and nationality should be minimized Commercialized AI systems should be generally applicable to all individuals” (p 3)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27065",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 5,
        "Title": "South Korea: Human-Centred National Guidelines for AI Ethics",
        "Translation Comments": "N/A - English"
      },
      "id": "i-RIW2LAshak",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-RIW2LAshak",
      "name": "South Korea: Human-Centred National Guidelines for AI Ethics",
      "index": 404,
      "createdAt": "2024-05-28T21:06:14.668Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-RIW2LAshak"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "South Korea"
        ],
        "Policy Name": "National Strategy for AI",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is very little here about EdTech — just a few fleeting references. But in addition to these references, there is a general governance framework. This just scrapes through. ",
        "Relevance Type": [
          "Policy contains case studies on AI in education",
          "Policy makes fleeting reference to AI in education",
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "Korea_National_Strategy_for_Artificial_Intelligence_2019.pdf"
        ],
        "Key quotes on AI in education principles": "The key opportunities identified:\n‘AI-powered English assistant teacher’.\nAlso talks about ‘[e]xpanding practical educational platforms for better accessibility to vocational training and providing various contents through a smart training platform (opened in Oct. 2019)’ (p 46). \nHowever, I am not sure what it means by ‘smart training platform’ — thin on details",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "image.png",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26497",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "There is not much to say — it is just outlining the kinds of values it intends to explore. Up to this point, it had not built a robust AI ethics framework. ",
        "Notable Case Studes - Examples of AI in Education": "‘AI-powered English assistant teacher’ using technology assists English teacher classes through conversations and quizzes in English (checking speaking ability by students’ (p 13)",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "South Korea: National Strategy for AI",
        "Translation Comments": ""
      },
      "id": "i-LVovi9GBwR",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-LVovi9GBwR",
      "name": "South Korea: National Strategy for AI",
      "index": 136,
      "createdAt": "2024-05-28T21:05:37.383Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-LVovi9GBwR"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Japan"
        ],
        "Policy Name": "Governance Guidelines for Implementation of AI Principles",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Note that this document is an official translation. It was prepared by the Expert Group. As it happens, there is some really useful material in here. Could be applied to EdTech. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "20210709_9.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "A few questions asked in “Practical Examples for Gap Analysis between AI Governance Goals and Current State: \nDid the AI developer give due consideration when designing the data set so that it would not entrench/impair any unfair discrimination based on certain social attributes?\nExample: Did the AI system developer consider the possibility that unfair discrimination based on certain social attributes may be reproduced as a result of prioritizing the reproducibility of the real world?\nExample: Did the AI developer ensure not to use any data set that could entrench/impair unfair discrimination based on certain social attributes, even at the cost of the reproducibility of the real world?” (p 70)",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27170",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 2,
        "Title": "Japan: Governance Guidelines for Implementation of AI Principles",
        "Translation Comments": ""
      },
      "id": "i-cdhpUfOZAa",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-cdhpUfOZAa",
      "name": "Japan: Governance Guidelines for Implementation of AI Principles",
      "index": 144,
      "createdAt": "2024-05-28T02:41:31.068Z",
      "updatedAt": "2024-06-03T07:24:49.496Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-cdhpUfOZAa"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Japan"
        ],
        "Policy Name": "Integrated Innovation Strategy Promotion Council",
        "Year of Commencement or Creation": "2022",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Note that the document is translated with DeepL. There is some recognition that AI could be used to enhance education (although the focus is on how to educate Japan for AI). ",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education",
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "AI Japan en.pdf"
        ],
        "Key quotes on AI in education principles": "“There are high expectations for AI in many areas, including telemedicine and A I diagnostic support for improved access to medical care and personalized medicine, expanded access to education and personalized support, flood and other disaster forecasting, including for use in developing countries, and technology to enable resource recycling throughout economic activities.” (p 29)",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“There are high expectations for AI in many areas, including telemedicine and A I diagnostic support for improved access to medical care and personalized medicine, expanded access to education and personalized support, flood and other disaster forecasting, including for use in developing countries, and technology to enable resource recycling throughout economic activities.” (p 29)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25312",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "Interoperability:\n“For example, establishing interoperability of Japan's digital data platform with data platforms such as India Stack can help them access and scale their operations in larger markets” (p 25)\nProcurement:\nA little vague — details lost in translation — but this could be relevant: “It is essential to establish a trust infrastructure for government procurement in the United States and a common trust infrastructure in the EU. The U.S. has already established a trust infrastructure in the field of government procurement and the EU has established a common trust infrastructure, and Japan has also started related studies.” (p 64)",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Japan: Integrated Innovation Strategy Promotion Council",
        "Translation Comments": "Translation Completed (DeepL)"
      },
      "id": "i-kCIhlFwLkT",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-kCIhlFwLkT",
      "name": "Japan: Integrated Innovation Strategy Promotion Council",
      "index": 145,
      "createdAt": "2024-05-28T02:34:17.490Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-kCIhlFwLkT"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United States"
        ],
        "Policy Name": "AI Bill of Rights Blueprint",
        "Year of Commencement or Creation": "2022",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There are some interesting and broadly relevant ideas in this blueprint for an AI Bill of Rights. https://www.whitehouse.gov/ostp/ai-bill-of-rights/\n",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education",
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "Managing bias. The risk of bias should be managed with care. ",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Human rights-centred. The technology must be consistent with human rights. ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities."
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Blueprint-for-an-AI-Bill-of-Rights.pdf"
        ],
        "Key quotes on AI in education principles": "“But there is much more work to do to protect the public from algorithmic discrimination to use and design automated systems in an equitable way... Ensuring equity should also go beyond existing guardrails to consider the holistic impact that automated systems make on underserved communities and to institute proactive protections that support these communities.\nA predictive model marketed as being able to predict whether students are likely to drop out of school was used by more than 500 universities across the country. The model was found to use race directly as a predictor, and also shown to have large disparities by race; Black students were as many as four times as likely as their otherwise similar white peers to be deemed at high risk of dropping out. These risk scores are used by advisors to guide students towards or away from majors, and some worry that they are being used to guide Black students away from math and science subjects.” (p 24)\n“The National Disabled Law Students Association expressed concerns that individuals with disabilities were more likely to be flagged as potentially suspicious by remote proctoring AI systems because of their disability-specific access needs such as needing longer breaks or using screen readers or dictation software.” (p 25) \n“Companies collect student data such as demographic information, free or reduced lunch status, whether they've used drugs, or whether they've expressed interest in LGBTQI+ groups, and then use that data to forecast student success.76 Parents and education experts have expressed concern about collection of such sensitive data without express parental consent, the lack of transparency in how such data is being used, and the potential for resulting discriminatory impacts.” (p 37)\n\n“A school board’s attempt to surveil public school students—undertaken without adequate community input—sparked a state-wide biometrics moratorium.79 Reacting to a plan in the city of Lockport, New York, the state’s legislature banned the use of facial recognition systems and other “biometric identifying technology” in schools until July 1, 2022.80 The law additionally requires that a report on the privacy, civil rights, and civil liberties implications of the use of such technologies be issued before biometric identification technologies can be used in New York schools.” (p 39)\n“Education-related concerning uses included the increased use of remote proctoring systems, student location and facial recognition tracking, teacher evaluation systems, robot teachers, and more... Various panelists raised the limitations of existing privacy law as a key concern, pointing out that students should be able to reinvent themselves and require privacy of their student records and education-related data in order to do so. The overarching concerns of surveillance in these domains included concerns about the chilling effects of surveillance on student expression...” (p 57)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as the objective or justification of the policy (the primary objective or justification)",
        "Key quote on human rights": "“Civil liberties and civil rights must not be limited by the threat of surveillance or harassment facilitated or aided by an automated system.” (p 34)\n\n“School audio surveillance systems monitor student conversations to detect potential \"stress indicators\" as a warning of potential violence. Online proctoring systems claim to detect if a student is cheating on an exam using biometric markers. These systems have the potential to limit student freedom to express a range of emotions at school and may inappropriately flag students with disabilities who need accommodations or use screen readers or dictation software as cheating.” (p 37)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "“You should not face discrimination by algorithms and systems should be used and designed in an equitable way.” (p 5)\n“Proactive assessment of equity in design. Those responsible for the development, use, or oversight of automated systems should conduct proactive equity assessments in the design phase of the technology research and development or during its acquisition to review potential input data, associated historical context, accessibility for people with disabilities, and societal goals to identify potential discrimination and effects on equity resulting from the introduction of the technology.” (p 26)",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society."
        ],
        "Link (OECD or Other)": "https://www.whitehouse.gov/ostp/ai-bill-of-rights/",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 27,
        "Title": "United States: AI Bill of Rights Blueprint",
        "Translation Comments": "N/A - English"
      },
      "id": "i-ibWXq2I11E",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-ibWXq2I11E",
      "name": "United States: AI Bill of Rights Blueprint",
      "index": 400,
      "createdAt": "2024-05-27T10:35:27.349Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-ibWXq2I11E"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United States"
        ],
        "Policy Name": "State Department Guidance on Products or Services with Surveillance Capabilities",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is an initiative that could (and should) be considered when developing EdTech for schools. One could imagine numerous surveillance technologies (e.g., attendance monitoring) that should be screened by reference to these principles — or something like them — prior to deployment. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A Other]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI",
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "DRL-Industry-Guidance-Project-FINAL-1-pager-508-1.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as the objective or justification of the policy (the primary objective or justification)",
        "Key quote on human rights": "This is all about “Human Rights Due Diligence”:\nThe U.S. Department of State is committed to the promotion and protection of human rights. In that spirit, U.S. businesses should carefully review this voluntary guidance and consider whether to participate in, or continue to participate in, transactions if they identify a risk that the end-user will likely misuse the product or service to carry out human rights violations or abuses. (p 1)\nHuman Rights Due Diligence (hereinafer “due diligence”): For the purpose of this document, “due diligence” is defined as the process by which a business  works to  identify,  anticipate,  prevent, mitigate,  and account for how it addresses actual or potential adverse impacts on the human rights of individuals. This includes impacts that it may cause or contribute to, or to which it is otherwise directly linked.  In accordance with the UN Guiding Principles, among the factors that should be considered where impacts are directly linked include the business’s leverage over the entity concerned, how crucial the relationship is to the business, the severity of the abuse, and whether terminating the relationship with the entity would have adverse human rights consequences. (p 5)",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "N/A",
        "General principles on AI": [
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Respect for laws [NEW]. AI should respect existing law.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Freedom of speech and assembly [NEW]. AI systems should not abrogate freedom of speech or assembly. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26986",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "Procurement — “In sales where the ultimate end use may not be known but the product or service in question presents a human rights risk, require end-user license agreement with human rights safeguards language, and require re-sellers to conduct their own human rights due diligence in cases of resale” (11)",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": [
          "Will Cesta"
        ],
        "Relevant?": "Yes",
        "Series #": 41,
        "Title": "United States: State Department Guidance on Products or Services with Surveillance Capabilities",
        "Translation Comments": ""
      },
      "id": "i-ronKCeda9b",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-ronKCeda9b",
      "name": "United States: State Department Guidance on Products or Services with Surveillance Capabilities",
      "index": 398,
      "createdAt": "2024-05-27T09:32:13.420Z",
      "updatedAt": "2024-06-05T22:45:06.600Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-ronKCeda9b"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United States"
        ],
        "Policy Name": "Government by Algorithm: AI in Federal Administrative Agencies",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a brilliant report—David Engstrom as lead. It is included for its broad principles, but there is very little on education in here. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Government by Algorithm.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "This is not really focused on civil/human rights. It talks about other legal rights, but there are only a handful of fleeting references to the others. ",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "Uses the languages of discrimination throughout — eg:\n\n“Second, the rise of AI decision tools will increasingly challenge conventional principles of antidiscrimination law”\n“Formal blindness can be functional discrimination.”\n“The administrative state’s growing adoption of AI tools risks compounding biases against vulnerable groups. If biases go unchecked, agency tools will only deepen existing inequities and also likely run afoul of antidiscrimination law”",
        "General principles on AI": [
          "Respect for laws [NEW]. AI should respect existing law.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Opportunity. The opportunities of AI should be harnessed."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26961",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "The content on procurement is not clear-cut — not “yep, sets standards to influence development”. It explores interesting related ideas, though:\n\n“In sum, usability may militate in favor of internal capacity building. Privately produced, procurement-generated tools may boast the most cutting-edge analytics, but may also be less tailored to the task at hand, be less attuned to legal requirements and an agency’s bureaucratic realities, and do not necessarily come with ongoing and regular engagement between technologists and agency enforcement staff. In contrast, in-house production may strain agency budgets, but will yield governance tools that are, on average, better tailored to subtle governance tasks, more law- and policy?compliant, more attuned to complex organizational dynamics, and less subject to information leakage and conflicts of interest that can reduce a tool’s efficacy and raise significant distributive concerns”",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": [
          "Will Cesta"
        ],
        "Relevant?": "Yes",
        "Series #": 14,
        "Title": "United States: Government by Algorithm: AI in Federal Administrative Agencies",
        "Translation Comments": ""
      },
      "id": "i-Wliu2lS19z",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-Wliu2lS19z",
      "name": "United States: Government by Algorithm: AI in Federal Administrative Agencies",
      "index": 373,
      "createdAt": "2024-05-27T09:25:44.010Z",
      "updatedAt": "2024-06-06T00:01:48.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-Wliu2lS19z"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United States"
        ],
        "Policy Name": "Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is important to our project because it joins the links between ‘racial equity’/’support for underserved communities’ with AI: “promote equity in science and root out bias in the design and use of new technologies, such as artificial intelligence”. See also: “(b) When designing, developing, acquiring, and using artificial intelligence and automated systems in the Federal Government, agencies shall do so, consistent with applicable law, in a manner that advances equity.” These are short statements, but hugely important given that they are coming from the global leader in AI and apply — as executive law — to the public service in the US. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [],
        "Governance practices employed": [
          "[N/A]"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government _ The White House.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“and promote equity and human rights around the world through our foreign policy and foreign assistance.”\n\nAlso speaks a lot about human rights. ",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“; promote equity in science and root out bias in the design and use of new technologies, such as artificial intelligence”\n“When designing, developing, acquiring, and using artificial intelligence and automated systems in the Federal Government, agencies shall do so, consistent with applicable law, in a manner that advances equity.”",
        "General principles on AI": [
          "Respect for laws [NEW]. AI should respect existing law.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27439",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": [
          "Will Cesta"
        ],
        "Relevant?": "Yes",
        "Series #": 3,
        "Title": "United States: Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government",
        "Translation Comments": ""
      },
      "id": "i-d8BRcO2fJK",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-d8BRcO2fJK",
      "name": "United States: Executive Order on Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government",
      "index": 161,
      "createdAt": "2024-05-27T09:12:44.160Z",
      "updatedAt": "2024-06-05T23:47:42.455Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-d8BRcO2fJK"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United States"
        ],
        "Policy Name": "Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The US expressly deals with AI in education in its recent Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. It makes reference to important imminent developments (such as a toolkit). \n\n  (d)  To help ensure the responsible development and deployment of AI in the education sector, the Secretary of Education shall, within 365 days of the date of this order, develop resources, policies, and guidance regarding AI.  These resources shall address safe, responsible, and nondiscriminatory uses of AI in education, including the impact AI systems have on vulnerable and underserved communities, and shall be developed in consultation with stakeholders as appropriate.  They shall also include the development of an “AI toolkit” for education leaders implementing recommendations from the Department of Education’s AI and the Future of Teaching and Learning report, including appropriate human review of AI decisions, designing AI systems to enhance trust and safety and align with privacy-related laws and regulations in the educational context, and developing education-specific guardrails.",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": [
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Trust. Organisations seeking to incorporate AI into educational settings must build trust."
        ],
        "Governance practices employed": [
          "Binds. It creates binding obligations in relation to AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence _ The White House.pdf"
        ],
        "Key quotes on AI in education principles": "Avoidance of harm in education:\n“Such protections are especially important in critical fields like healthcare, financial services, education, housing, law, and transportation, where mistakes by or misuse of AI could harm patients, cost consumers or small businesses, or jeopardize safety or rights.”\nThe key extract is as follows:\n“To help ensure the responsible development and deployment of AI in the education sector, the Secretary of Education shall, within 365 days of the date of this order, develop resources, policies, and guidance regarding AI. These resources shall address safe, responsible, and nondiscriminatory uses of AI in education, including the impact AI systems have on vulnerable and underserved communities, and shall be developed in consultation with stakeholders as appropriate. They shall also include the development of an “AI toolkit” for education leaders implementing recommendations from the Department of Education’s AI and the Future of Teaching and Learning report, including appropriate human review of AI decisions, designing AI systems to enhance trust and safety and align with privacy-related laws and regulations in the educational context, and developing education-specific guardrails.”",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“Americans’ privacy and civil liberties must be protected as AI continues advancing.”\n“(d) Artificial Intelligence policies must be consistent with my Administration’s dedication to advancing equity and civil rights.”\nNote also the AI Bill of Rights blueprint",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "“(d) Artificial Intelligence policies must be consistent with my Administration’s dedication to advancing equity and civil rights. My Administration cannot — and will not — tolerate the use of AI to disadvantage those who are already too often denied equal opportunity and justice. From hiring to housing to healthcare, we have seen what happens when AI use deepens discrimination and bias, rather than improving quality of life. Artificial Intelligence systems deployed irresponsibly have reproduced and intensified existing inequities, caused new types of harmful discrimination, and exacerbated online and physical harms. My Administration will build on the important steps that have already been taken — such as issuing the Blueprint for an AI Bill of Rights, the AI Risk Management Framework, and Executive Order 14091 of February 16, 2023 (Further Advancing Racial Equity and Support for Underserved Communities Through the Federal Government) — in seeking to ensure that AI complies with all Federal laws and to promote robust technical evaluations, careful oversight, engagement with affected communities, and rigorous regulation.” (p 2-3)\nNote also the comments specific to education:\n“To help ensure the responsible development and deployment of AI in the education sector, the Secretary of Education shall, within 365 days of the date of this order, develop resources, policies, and guidance regarding AI. These resources shall address safe, responsible, and nondiscriminatory uses of AI in education, including the impact AI systems have on vulnerable and underserved communities, and shall be developed in consultation with stakeholders as appropriate. They shall also include the development of an “AI toolkit” for education leaders implementing recommendations from the Department of Education’s AI and the Future of Teaching and Learning report, including appropriate human review of AI decisions, designing AI systems to enhance trust and safety and align with privacy-related laws and regulations in the educational context, and developing education-specific guardrails.”",
        "General principles on AI": [
          "Augmentation, not replacement. AI systems should augment, not displace, workers.",
          "Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power.",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Environmental wellbeing. The use of AI should not harm the environment. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27577",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "There is so much here that it is worth reading the policy attached — focus on the opening principles (especially p 1-4, leading up to the definitions)",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "Memorable point: “In the end, AI reflects the principles of the people who build it, the people who use it, and the data upon which it is built. I firmly believe that the power of our ideals; the foundations of our society; and the creativity, diversity, and decency of our people are the reasons that America thrived in past eras of rapid change. They are the reasons we will succeed again in this moment. We are more than capable of harnessing AI for justice, security, and opportunity for all.”",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 2,
        "Title": "United States: Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence",
        "Translation Comments": ""
      },
      "id": "i-qEBK7OMRGa",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-qEBK7OMRGa",
      "name": "United States: Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence",
      "index": 160,
      "createdAt": "2024-05-27T09:07:40.068Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-qEBK7OMRGa"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Singapore"
        ],
        "Policy Name": "Proposed Model AI Governance Framework for Generative AI",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This framework builds on the general Model AI Governance Framework released in 2019-2020. It is built on 9 core principles. It is easy to see how this could be adapted to educational contexts, particularly as the emerging EdTech is (largely) driven by genAI. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Proposed_MGF_Gen_AI_2024.pdf"
        ],
        "Key quotes on AI in education principles": "“AI should serve the public in impactful ways. Today, AI powers many public services, such as adaptive learning systems in schools and health management systems in hospitals. This unlocks new value propositions, creates efficiencies and improves user experience.” (p 20)",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“The aim is to establish a global Digital Commons – a place with common rules-of-the-road and equal opportunities for all citizens to flourish, regardless of their geographical location.” (p 20) ",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Bias testing. AI systems should be tested for bias. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27638",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 33,
        "Title": "Singapore: Proposed Model AI Governance Framework for Generative AI",
        "Translation Comments": "N/A - English"
      },
      "id": "i-cEsc8uQgVt",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-cEsc8uQgVt",
      "name": "Singapore: Proposed Model AI Governance Framework for Generative AI",
      "index": 365,
      "createdAt": "2024-05-27T01:40:32.338Z",
      "updatedAt": "2024-06-05T21:37:17.815Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-cEsc8uQgVt"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Singapore"
        ],
        "Policy Name": "Model AI Governance Framework",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a solid governance framework for AI generally. Some parts of it could be applied to educational settings. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "SGModelAIGovFramework2.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“Human rights alignment: Ensure that the design, development and implementation of technologies do not infringe internationally recognised human rights.” (p 65)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "Under “6. Human Centricity and Well-being”\n“a. To aim for an equitable distribution of the benefits of data practices and avoid data practices that disproportionately disadvantage vulnerable groups.” (p 65)\n\nUnder “Different datasets for training, testing, and validation”\n“Where applicable, the model could also be checked for systematic bias by testing it on different demographic groups to observe whether any groups are being systematically advantaged or disadvantaged.” (p 40)\n\n“Ensure that algorithmic decisions do not create discriminatory or unjust impacts across different demographic lines (e.g. race, sex, etc.).” (p 64)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24428",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 32,
        "Title": "Singapore: Model AI Governance Framework",
        "Translation Comments": "N/A - English"
      },
      "id": "i-eQMFUuu1hw",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-eQMFUuu1hw",
      "name": "Singapore: Model AI Governance Framework",
      "index": 364,
      "createdAt": "2024-05-27T01:40:13.108Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-eQMFUuu1hw"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Singapore"
        ],
        "Policy Name": "ASEAN Guide on AI Governance and Ethics",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a highly relevant framework that could — in part — be applied to educational settings. It offers a concrete guide (sort of like the UK and Canada) from p 17 (i.e., impact assessment). See also Annex A: AI Risk Impact Assessment template (p 60). ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "ASEAN-Guide-on-AI-Governance-and-Ethics_beautified_201223_v2.pdf"
        ],
        "Key quotes on AI in education principles": "“To mitigate discrimination, it is important that the design, development, and deployment of AI systems align with fairness and equity principles. In addition, the datasets used to train the AI systems should be diverse and representative. Appropriate measures should be taken to mitigate potential biases during data collection and pre-processing, training, and inference. For example, the ASEAN Guide on AI Governance and Ethics 12 training and test dataset for an AI system used in the education sector should be adequately representative of the student population by including students of different genders and ethnicities.” (p 12)",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“Deployers should have safeguards in place to ensure that algorithmic decisions do not further exacerbate or amplify existing discriminatory or unjust impacts across different demographics and the design, development, and deployment of AI systems should not result in unfair biasness or discrimination. An example of such safeguards would include human interventions and checks on the algorithms and its outputs. Deployers of AI systems should conduct regular testing of such systems to confirm if there is bias and where bias is confirmed, make the necessary adjustments to rectify imbalances to ensure equity.” (p 12)\n\n“If not properly managed, an AI system’s outputs used to make decisions with significant impact on individuals could perpetuate existing discriminatory or unjust impacts to specific demographics. To mitigate discrimination, it is important that the design, development, and deployment of AI systems align with fairness and equity principles.” (p 12)\n\n“Propagation of embedded biases: Generative AI systems have the ability to capture and reflect the biases present in the training dataset. If not properly addressed, these biases can be inherited and result in biased or toxic output that reinforces biased or discriminatory stereotypes. For example, image generation systems prompted with “African worker” may generate images of individuals in tattered clothing and rudimentary tools, while simultaneously generating images of wealthy individuals when prompted with “European worker”28 . This highlights the risk of propagation of biases from foundation models to downstream models trained from them, which perpetuates such biases and stereotypes.” (p 56)\n\n“When designing and developing AI systems, deployers and developers also need to bear in mind the principles of human-centricity, fairness and equity, transparency and explainability, safety and security, robustness and reliability, accountability and integrity, and privacy and data governance.” (p 29)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Augmentation, not replacement. AI systems should augment, not displace, workers.",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27645",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 26,
        "Title": "Singapore: ASEAN Guide on AI Governance and Ethics",
        "Translation Comments": "N/A - English"
      },
      "id": "i-FgCTrbGUmb",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-FgCTrbGUmb",
      "name": "Singapore: ASEAN Guide on AI Governance and Ethics",
      "index": 361,
      "createdAt": "2024-05-27T01:38:48.336Z",
      "updatedAt": "2025-04-24T03:57:09.712Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-FgCTrbGUmb"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Singapore"
        ],
        "Policy Name": "Transforming education through technology masterplan 2030",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is one of the most relevant documents encountered yet. It is a dedicated EdTech plan. Worth reading here:\nEdTech Masterplan 2030 | MOE\nAlso attached as a PDF, but it’s worth following the links. ",
        "Relevance Type": [
          "Policy is about AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. "
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "EdTech Masterplan 2030 _ MOE.pdf"
        ],
        "Key quotes on AI in education principles": "Opportunities:\nProvide AI-enabled, resource-rich Singapore Student Learning Space (SLS) for greater customisation of learning\nAI-enabled features in SLS to customise learning pathways to individual student’s needs, for example, the Adaptive Learning System.\nRicher variety of learning resources in the SLS to enable finer customisation and to support self-directed learning.\nProvide digital tools and platforms to enhance feedback and assessment\nAI-enabled tools to provide immediate and customised feedback to students, for example, through Learning Feedback Assistants.\nTraining:\nGreater emphasis on e-Pedagogy and use of EdTech in both NIE pre-service teacher training and in-service teacher professional development\nProvide resources and professional development opportunities for teachers on data literacy and cyber wellness.\nPartner Centre of Teaching and Learning Excellence (CTLE) to study and share effective and innovative use of EdTech\n",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27663",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "Singapore Student Learning Space (SLS) Info-Site (moe.edu.sg) — AI-enabled Student Learning Space ",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 21,
        "Title": "Singapore: Transforming education through technology masterplan 2030",
        "Translation Comments": ""
      },
      "id": "i-cYzSrNlIt4",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-cYzSrNlIt4",
      "name": "Singapore: Transforming education through technology masterplan 2030",
      "index": 356,
      "createdAt": "2024-05-27T01:37:05.956Z",
      "updatedAt": "2024-06-03T23:13:10.878Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-cYzSrNlIt4"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Singapore"
        ],
        "Policy Name": "Public Sector AI Playbook",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is an interesting document—could something like this be handed out to users of these systems? Lots of examples / case studies. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Develops tools. It provides tools and place them in the hands of businesses or governments",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "public-sector-ai-playbook.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27660",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 16,
        "Title": "Singapore: Public Sector AI Playbook",
        "Translation Comments": "N/A - English"
      },
      "id": "i-eofU-tnKpc",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-eofU-tnKpc",
      "name": "Singapore: Public Sector AI Playbook",
      "index": 351,
      "createdAt": "2024-05-27T01:36:11.891Z",
      "updatedAt": "2024-06-06T03:10:26.217Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-eofU-tnKpc"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Singapore"
        ],
        "Policy Name": "National AI Strategy 2.0",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is one of very few national strategies that sees the relationship between AI and education as being more about educating people to ‘do AI’. It sees AI as a tool to be deployed in many domains, including education. There is not a lot of detail in this report—that is broken out in its dedicated education policy. ",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "nais2023.pdf"
        ],
        "Key quotes on AI in education principles": "“Smart Nation Priorities, where AI assists our national development, and unlocks new value propositions for social impact. These include Healthcare, Education & Manpower, Trust & Safety, and Public Service Delivery” (p 18)",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "N/A",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "N/A",
        "General principles on AI": [
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Opportunity. The opportunities of AI should be harnessed."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27628",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 2,
        "Title": "Singapore: National AI Strategy 2.0",
        "Translation Comments": "Official Translation Obtained"
      },
      "id": "i-XSShfibeDy",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-XSShfibeDy",
      "name": "Singapore: National AI Strategy 2.0",
      "index": 348,
      "createdAt": "2024-05-27T01:35:50.952Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-XSShfibeDy"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Austria"
        ],
        "Policy Name": "AI Mission Austria 2030",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is a brief line here about AI in education: ‘AI can help learners and educators to make learning more effective and exciting.’ The other content about education concerns education for AI. However, there are some broadly relevant governance ideas here. This is not a high-priority plan, but worth noting. ",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education",
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": "",
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Communicates a stance. It expresses a hope for the future of AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "aimat_ua (1).pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24233",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Austria: AI Mission Austria 2030",
        "Translation Comments": "N/A - English"
      },
      "id": "i-il2x7bQckP",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-il2x7bQckP",
      "name": "Austria: AI Mission Austria 2030",
      "index": 163,
      "createdAt": "2024-05-27T01:14:37.198Z",
      "updatedAt": "2024-06-02T23:37:28.020Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-il2x7bQckP"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Norway"
        ],
        "Policy Name": "Report No 22 ",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "I have translated this report on data as a resource. I had low expectations, but there is actually some interesting stuff on data sharing in primary and secondary education that could be adapted to data collected by AI applications. I have translated a copy of the report. See 5.2.3.",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education",
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary"
        ],
        "Principles on AI in education": [
          "Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations."
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "request.pdf"
        ],
        "Key quotes on AI in education principles": "5.2.3 Research and education data\n“Disclosure must take place within the framework of a good level of privacy and with the necessary considerations for security, intellectual property rights and trade secrets. In order to achieve the main goal of more sharing and reuse of data, the appropriate use of licences on the data is of great importance. On behalf of the Ministry of Education and Research, the Research Council of Norway has therefore appointed a committee to investigate rights and licensing issues in connection with the sharing of research data, with the aim of ensuring that the results of publicly funded research contribute to value creation and benefit the general public. The results of the committee's work will be presented in the summer of 2021. \nOn behalf of the Ministry of Education and Research, Unit (the Norwegian Directorate for ICT and Joint Services in Higher Education and Research) is carrying out a pilot project on the sharing of data on education, research and integration. Examples of education data are data from primary and secondary education. The goal is to establish an infrastructure for making data available in the knowledge sector that facilitates both efficient information management (\"order in one's own house\") and an infrastructure for reuse. The pilot project is based on the concept study Future sharing of data in the knowledge sector, which was carried out in the period January 2019 to January 2020.38 The pre-project will detail and possibly adjust the recommended concept, and it will form the basis for deciding on a possible realisation of the concept through a main project or a programme consisting of several projects.”",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "“Data must be shared and used in such a way that fundamental rights and freedoms are respected, and Norwegian societal values are preserved.” (1.2) \n\n“The Digital Services Act (DSA) can be seen as a revision of the E-Commerce Directive. Since the E-Commerce Directive came into force in 2000, the digital landscape has changed significantly through the emergence of new digital platforms. The DSA will improve the ability to remove illegal content online and better protect users' fundamental rights, including freedom of expression.” 7.1.2\n\n“The Government's policy will also promote a balanced data economy that safeguards Norwegian societal values and respects the fundamental rights and freedoms of the individual” (8)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“Risk of discrimination and erroneous conclusions \nThe use of profiling based on algorithms and artificial intelligence can provide better and more personalised services, but it can also increase the risk of unlawful discrimination. When services are more individualised, consumers are at risk of being subjected to price discrimination. Algorithm-based advertising systems can also be designed in such a way that, for example, housing rental and job ads are only shown to certain groups of people, so that others are effectively excluded and potentially discriminated against.” (7.2.1)\n\n“An important issue is the work to promote a level playing field between multinational companies and Norwegian players.” (2) \n\nUnder “Boks 5.9 Open Data Licenses” in 5.3 \n“Open Standard Data Licences is a general agreement between a data provider and those who will use the data. The agreement contains very few restrictions and ensures a level playing field for all users. The licences facilitate the combination of data from multiple sources and room for manoeuvre to process data and offer services and new data products in the market. Examples of open data licenses are Creative Commons Attribution 4.0 (CC BY 4.0) and Norwegian License for Public Data (NLOD).” (5.3)\n\n“In December 2020, the European Commission presented the Digital Services Act and the Digital Markets Act. These are intended to fulfil two main objectives: To create a secure digital area where the rights of all users of digital services are protected, and to ensure a level playing field for promoting innovation, growth and competition both in the EU/EEA and globally.” (7.1.2)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27303",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 5,
        "Title": "Norway: Report No 22 ",
        "Translation Comments": "Translation Completed (Google Translate)"
      },
      "id": "i-RecXqYep6s",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-RecXqYep6s",
      "name": "Norway: Report No 22 ",
      "index": 333,
      "createdAt": "2024-05-27T00:52:42.234Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-RecXqYep6s"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Norway"
        ],
        "Policy Name": "National Strategy for AI",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "For the most part, this strategy talks about education for AI rather than AI in education. However, it also talks about the deployment of AI for training purposes (see p 45). This is a great case study, and led to a concrete recommendation: “consider a digital platform for continuing and further education programs’. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education",
          "Policy makes fleeting reference to AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI",
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Communicates a stance. It expresses a hope for the future of AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "Norway_National_Strategy_for_Artificial_Intelligence_2020.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "“Norwegian society is characterised by trust and respect for fundamental values such as human rights and privacy. This is something we perhaps take for granted in Norway, but leading the way in developing human-friendly and trustworthy artificial intelligence may prove a key advantage in today's global competition.” (p2) \n\n“Norwegian society is characterised by trust and respect for fundamental values such as human rights and privacy. The Government wants Norway to lead the way in 6 developing and using AI with respect for individual rights and freedoms. This can become a key advantage in today's global competition.” (p 5-6)\n\n“The Government will encourage development and use of artificial intelligence in Norway to be based on ethical principles and to respect human rights and democracy” (p 61)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“AI systems must facilitate inclusion, diversity and equal treatment When developing and using AI, it is especially important to ensure that AI contribute to inclusion and equality, and that discrimination be avoided. Datasets that are used to train AI systems can contain historical bias, be incomplete or incorrect. Identifiable and discriminatory bias should, if possible, be removed in the collection phase. Bias can be counteracted by putting in place oversight processes to analyse and correct the system’s decisions in light of the purpose.” (p 59)\n\n“Ethical considerations should be built into algorithms during development. Among other things, it will be important to assess whether an algorithm may lead to discrimination and whether it is sufficiently robust to withstand manipulation. Ethical evaluations may also call for considering potential environmental impacts and whether a system contributes to achieving the UN Sustainable Development Goals.” (p 60)\n\n“Automated administrative proceedings can also enhance implementation of rights and obligations; for example, by automatically making decisions that grant benefits when the conditions are met. This can particularly benefit the most disadvantaged in society.” (p 27)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality)."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26464",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Norway: National Strategy for AI",
        "Translation Comments": "N/A - English"
      },
      "id": "i-TH30MMf_2H",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-TH30MMf_2H",
      "name": "Norway: National Strategy for AI",
      "index": 164,
      "createdAt": "2024-05-27T00:51:22.656Z",
      "updatedAt": "2024-06-03T07:18:00.486Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-TH30MMf_2H"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United States"
        ],
        "Policy Name": "Artificial Intelligence and the Future of Teaching and Learning: Insights and Recommendations",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This document was prepared by the Office of Educational Technology to ‘share knowledge’ about artificial intelligence. It pursues the answers to two overarching questions: (1) ‘What is our collective vision of a desirable and achievable educational system that leverages automation to advance learning while protecting and centering human agency?’; and (2) How and on what timeline will we be ready with necessary guidelines and guardrails, as well as convincing evidence of positive impacts, so that constituents can ethically and equitably implement this vision widely?’ It advances a handful of interesting and relevant principles. ",
        "Relevance Type": [
          "Policy is about AI in education",
          "Policy contains case studies on AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary"
        ],
        "Principles on AI in education": [
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Managing bias. The risk of bias should be managed with care. ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.",
          "Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Transparency (transparency to government). The extent to which AI is used in educational settings should be clear to the government. ",
          "Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.",
          "Trust. Organisations seeking to incorporate AI into educational settings must build trust.",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "Artificial Intelligence and the Future of Teaching and Learning (1).pdf"
        ],
        "Key quotes on AI in education principles": "\nContestability:\n“The Blueprint for an AI Bill of Rights similarly calls for “access to timely human consideration and remedy by a fallback and escalation process if an automated system fails, it produces an error, or you would like to appeal or contest its impacts…” Building on this consensus, we call upon all constituents to adopt “humans in the loop” as a key criterion for educational use of AI.” (53)\nReplacement:\n“Some teachers worry that they may be replaced—to the contrary, the Department firmly rejects the idea that AI could replace teachers.” (p 3)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "“Policies should not hinder innovation and improvement, nor should they be burdensome to implement. Society needs an education-focused AI policy that protects civil rights and promotes democratic values in the building, deployment, and governance of automated systems to be used across the many decentralized levels of the American educational system.”\nEndorses the AI Bill of Rights blueprint numerous times",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "Risk of inequity:\n“Yet, the broad equity challenges of avoiding algorithmic discrimination while increasing community and cultural responsiveness must be approached within the four foundations we earlier outlined: human in the loop, equity, safety and effectiveness, and evaluation of AI models. We cannot expect AI models to respect cultural responsiveness. The Department is particularly concerned that equity is something that engaged educators and other responsive adults are in the best position to address and something that is never solely addressable as a computational problem.” (p 34)\n“To what extent are teachers able to exercise voice and decision-making to improve equity, reduce bias, and increase cultural responsiveness in the use of AI-enabled tools and systems?” (p 34)\n“Our call for attending to equity considerations as we evaluate AI models requires information about how discriminatory bias may arise in particular AI systems and what developers have done to address it. This can only be achieved with transparency for how the tools use datasets to achieve outcomes and what data they have available or that a teacher could include in her judgement but are not available to the system (IEP status is offered as an example above).” (p 35)\nIncreasing equity:\n“From neurotypical to neurodiverse learners. AI models could help in including neurodiverse learners (students who access, process, and interact with the world in less common ways than “neurotypical” students) who could benefit from different learning paths and from forms of display and input that fit their strengths. Constituents want AI models that can support learning for neurodiverse learners and learners with disabilities. Thus, they want AI models that can work with multiple paths to learning and multiple modalities of interaction. Such models should be tested for efficacy, to guard against the possibility that some students could be assigned a “personalized” but inadequate learning resource. In addition, some systems for neurodiverse students are presently underutilized, so designs that support intended use will also be important.” (p 21)\n“In support of equitable learning, especially for those most affected by the pandemic, AI could shift edtech from a current deficit-based model to a strengths-based alternative. In addition to finding student weaknesses and assigning fixes, edtech could make recommendations based on strengths that students bring to learning and how adapting to the whole student—a cognitive, social, and self-regulating person—could enable more powerful learning. Adapting to the whole student should include supporting students with disabilities as well as English learners. With regard to equity, we must remain highly attuned to the challenges of bias (which are inherent to how AI systems are developed) and take firm action to ensure fairness.” (p 52)\nMonitoring:\n“How strong are the processes or systems for monitoring student use of AI for barriers, bias, or other undesirable consequences of AI use by learners? How are emergent issues addressed?” (p 23)\nPedagogical optimisation:\n“Thus, our key recommendation is to tease out the strengths and limitations of AI models inside forthcoming edtech products and to focus on AI models that align closely to desired visions of learning. AI is now advancing rapidly, and we should differentiate between products that have simple AI-like features inside and products that have more sophisticated AI models.” (p 24)\nTeacher training:\n“We anticipate teachers will need training and support to understand how and when they will need to exercise human judgement.” (p 32)\nUnderstanding:\n“In education, decision makers will need more than notice—they will need to understand how AI models work in a range of general educational use cases, so they can better anticipate limitations, problems, and risks. AI models in edtech will be approximations of reality and, thus, constituents can always ask these questions: How precise are the AI models? Do they accurately capture what is most important? How well do the recommendations made by an AI model fit educational goals? What are the broader implications of using AI models at scale in educational processes?”\nEtc — lots of information in here",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "This is very EdTech-focused. Broad principles are mostly linked specifically to the educational context. ",
        "Notable Case Studes - Examples of AI in Education": "“Examples of AI supporting learning principles in this section include the following: AI-based tutoring for students as they solve math problems (based on cognitive learning theories), adapting to learners with special needs (based on the Universal Design for Learning framework and related theories), and AI support for effective student teamwork (based on theories in the field called “Computer Supported Collaborative Learning”).” (p 18) — more to be found\n",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "United States: Artificial Intelligence and the Future of Teaching and Learning: Insights and Recommendations",
        "Translation Comments": ""
      },
      "id": "i-RitrSNR6M4",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-RitrSNR6M4",
      "name": "United States: Artificial Intelligence and the Future of Teaching and Learning: Insights and Recommendations",
      "index": 169,
      "createdAt": "2024-05-26T22:24:56.599Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-RitrSNR6M4"
    },
    {
      "values": {
        "Category of creator": [
          "IO"
        ],
        "Policy creator": [
          "European Union"
        ],
        "Policy Name": "European Commission, Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and learning for Educators",
        "Year of Commencement or Creation": "2022",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This document, taking into account the EU regulatory framework on AI generally, endeavours to ‘provide awareness and practical guidance for educators who are increasingly confronted with the use of AI in their teaching and practice’. \nThe document is principally concerned with school environments, though much of what it says is relevant to education generally. This is one of the most directly relevant policy initiatives. \nFocus on Action 6. ",
        "Relevance Type": [
          "Policy is about AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Managing bias. The risk of bias should be managed with care. ",
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ",
          "Student overreliance. Examination and testing should seek to reduce the risk of overreliance by students on this technology.",
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Academic integrity. Students should be supported to use AI tools ethically in their work, which extends to appropriate attribution.",
          "Information. Information about the technology in use should be readily available. ",
          "Trust. Organisations seeking to incorporate AI into educational settings must build trust.",
          "Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems.",
          "Human rights-centred. The technology must be consistent with human rights. "
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "European Commission (1).pdf"
        ],
        "Key quotes on AI in education principles": "Summary of ethical considerations:\n“Human agency relates to an individual’s capability to become a competent member of society. A person with agency can determine their life choices and be responsible for their actions. Agency underpins widely used concepts such as autonomy, self-determination, and responsibility. \nFairness relates to everyone being treated fairly in the social organisation. Clear processes are required so that all users have equal access to opportunity. These include equity, inclusion, non-discrimination, and fair distribution of rights and responsibilities. \nHumanity addresses consideration for the people, their identity, integrity, and dignity. We need to consider the well-being, safety, social cohesion, meaningful contact, and respect that is necessary for a meaningful human connection. That connection implies, for example, that we approach people with respect of their intrinsic value and not as a data object or a means-to-an-end. It is at the essence of the human-centric approach to AI. \nJustified choice relates to the use of knowledge, facts, and data to justify necessary or appropriate collective choices by multiple stakeholders in the school environment. It requires transparency and is based on participatory and collaborative models of decision-making as well as explainability. These ethical considerations are intrinsically valuable and worth striving for in education. They guide educators and school leaders in their decisions about the use of AI systems in education. The key ethical requirements introduced below can help ensure that AI systems used in education and training are trustworthy and address relevant concerns.” (p 18)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "“We shall also strongly benefit from the views and experience of our pupils, their families, and all stakeholders in the field of education about the use and impact of AI in their daily work and how to make it further beneficial while avoiding risks and negative effects to human rights and our fundamental EU values.” (p 7)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "\n“Fairness relates to everyone being treated fairly in the social organisation. Clear processes are required so that all users have equal access to opportunity. These include equity, inclusion, non-discrimination, and fair distribution of rights and responsibilities.” (p 18)\n\nThe two aspects:\n“AI can result in new forms of inequalities or discrimination and exacerbate existing ones. However, if properly designed and used, it can also offer opportunities to improve access and inclusion - in everyday life, in work, and in education. There is also significant potential for AI to provide educational resources for young people with disabilities and special needs. For example, AI-based solutions such as real-time live captioning can assist those with impaired hearing, while audio description can make access easier and more effective for people with low levels of vision” (p 12)\nNote their case study on “providing individualised interventions for special needs”:\n“A school is considering how AI systems can help reduce barriers for students with special educational needs. The school is currently trialling an AI system to detect student support demands early on and provide tailored instructional support. By detecting patterns of corresponding characteristics from measures such as learning performance, standardised tests attention span or reading speed, the system suggests probabilities of specific diagnoses and related recommendations for interventions.” (p 23)\nNote that it focuses on the language of “fairness”. Its guidance questions on using AI in education ethically are:\nIs the system accessible by everyone in the same way without any barriers? \nDoes the system provide appropriate interaction modes for learners with disabilities or special education needs? Is the AI system designed to treat learners respectfully adapting to their individual needs? \nIs the user interface appropriate and accessible for the age level of the learners? Has the usability and user-experience been tested for the target age group? \nAre there procedures in place to ensure that AI use will not lead to discrimination or unfair behaviour for all users? \nDoes the AI system documentation or its training process provide insight into potential bias in the data? \nAre procedures in place to detect and deal with bias or perceived inequalities that may arise? (p 20)",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26885",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "This is education-focused. ",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 2,
        "Title": "European Union: European Commission, Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and learning for Educators",
        "Translation Comments": "N/A - English"
      },
      "id": "i-BzC3TE7vsZ",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-BzC3TE7vsZ",
      "name": "European Union: European Commission, Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and learning for Educators",
      "index": 170,
      "createdAt": "2024-05-26T22:20:47.390Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-BzC3TE7vsZ"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "New Zealand"
        ],
        "Policy Name": "Algorithm Charter for Aotearoa New Zealand",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is effectively a broad framework for classifying risk and thinking about governance of algorithms generally. It is not education-focused, but this kind of document — optimised for educational contexts — could be given to schools by the Department of Education. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Algorithm-Charter-2020_Final-English-1 (1).pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“Ensure that privacy, ethics and human rights are safeguarded by: Regularly peer reviewing algorithms to assess for unintended consequences and act on this information.” (p 3)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“Simple algorithms can be used to standardise business processes to ensure scarce resources are distributed equitably.” (p 1)\nConsideration for Māori persons under “Partnership” - “Deliver clear public benefit through Treaty commitments by: Embedding a Te Ao Māori perspective in the development and use of algorithms consistent with the principles of the Treaty of Waitangi.” (p 3)",
        "General principles on AI": [
          "Bias testing. AI systems should be tested for bias. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25730",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "New Zealand: Algorithm Charter for Aotearoa New Zealand",
        "Translation Comments": ""
      },
      "id": "i-0TFl3ja1DB",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-0TFl3ja1DB",
      "name": "New Zealand: Algorithm Charter for Aotearoa New Zealand",
      "index": 173,
      "createdAt": "2024-05-26T22:03:43.964Z",
      "updatedAt": "2024-06-04T22:38:42.129Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-0TFl3ja1DB"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Estonia"
        ],
        "Policy Name": "Estonian Catalogue of Public Sector Information Systems",
        "Year of Commencement or Creation": "2018",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This policy is not education-oriented, but is a good example of the kind of database that could be built for EdTech. Note: Will need to translate before using. \nInfosüsteemid - Riigi infosüsteemi haldussüsteem RIHA",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A Other]"
        ],
        "Governance practices employed": [
          "[N/A]"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26751",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "The reason for including this policy is that it provides a good example of a system that could be used to highlight which AI systems are in use, particularly in government schools. ",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 8,
        "Title": "Estonia: Estonian Catalogue of Public Sector Information Systems",
        "Translation Comments": "Translation Needed"
      },
      "id": "i-8iMFNRIMnV",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-8iMFNRIMnV",
      "name": "Estonia: Estonian Catalogue of Public Sector Information Systems",
      "index": 305,
      "createdAt": "2024-05-26T10:02:45.078Z",
      "updatedAt": "2024-06-04T23:04:30.755Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-8iMFNRIMnV"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Estonia"
        ],
        "Policy Name": "AI Use Cases in the Public Sector",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The policy here is logging instances in which this technology is used. It seems like something that could be applied to EdTech — specifically, we are talking about the principle of “monitoring”. \n\nSee Original source. Translated examples:\n\nSchool Kratt\nThe aim of the project was to investigate the feasibility of applying logs for the use of digital learning assets to automatically create models for measuring learning outcomes using machine learning methods. Such models make it possible to collect more systematic information about the learner's development automatically, without interfering with the study, and thus provide input for better planning and automatic personalization of further learning. As part of the project: a visual prototype was created to demonstrate the results of measuring learning outcomes, the first models were trained using machine learning, and a primary methodology for data science was created.\n\nText-to-speech in language exams and tests\nAudio files of instructions for the listening parts of language exams are usually recorded in the studio. However, in recent years, language technology has developed so rapidly, and speech synthesis at such a good level that instead of reading instructions, they can be quickly and easily created using a computer program. This saves time and money, and examiners do not even realize that the instructions are actually read by a machine instead of a human.\n\nMarakratt\nAs part of the project, a proof-of-concept solution for the student was created for a kratt supporting individual learning paths. The project experimented with the use of machine learning to create models for recommending learning material. Prototype-like models were also created to help automate the personalisation of learning assets and activities used in learning, based on the interests, knowledge and abilities of the learners.\n\nPersonal learning path\nIn the case of personalised learning, there is a transition from a teacher-centred learning process to a learner-centred one, and the learner can make choices based on his or her goals, pace that suits him or her, tools and interests. Based on the available data, the aim is to develop solutions that would make it possible to give feedback to the Estonian learner and teacher about the learning process and go further: to show what the learner has done, as well as why he or she did it and what are the possible gaps in his or her knowledge or skills.",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Tracks. It sets out to boost understanding specifically of where and how AI is being used"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "AI Usage Cases Estonia.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "N/A",
        "Does the policy reflect the principle of equity/equality?": "N/A",
        "Key quote on equity/equality": "N/A",
        "General principles on AI": [
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26828",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 3,
        "Title": "Estonia: AI Use Cases in the Public Sector",
        "Translation Comments": "Translation Completed (Google Translate)"
      },
      "id": "i-BvDC6gzHEo",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-BvDC6gzHEo",
      "name": "Estonia: AI Use Cases in the Public Sector",
      "index": 300,
      "createdAt": "2024-05-26T10:02:12.522Z",
      "updatedAt": "2024-06-04T23:03:11.475Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-BvDC6gzHEo"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Italy"
        ],
        "Policy Name": "AI Strategic Programme",
        "Year of Commencement or Creation": "2022",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Like most national AI strategies, Italy talks about education in the context of AI skill. But it also recognises that AI ‘can constitute a powerful instrument for a fruitful transformation of the national education system to develop personalized learning plans while ensuring fairness and trustworthiness’ (p 17). There are also some useful general governance ideas expressed. ",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education",
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "Italy_Artificial_Intelligence_Strategic_Programme_2022-2024.pdf"
        ],
        "Key quotes on AI in education principles": "Education-specific comments\n“Education system. As artificial intelligence is transforming every aspect of our lives we need to educate all people to this technology through a new education and training plan to understand, reinforce, integrate and disseminate AI technology. AI should be an important topic at all education levels. At the same time, it can constitute a powerful instrument for a fruitful transformation of the national education system to develop personalized learning plans while ensuring fairness and trustworthiness.” (p 17).\n\nGeneral guiding principles:\nItaly’s AI is a European AI. In line with the EU Coordinated Plan on Artificial Intelligence, the Italian Strategic Programme stems from the awareness that only through common and coordinated actions Europe will be able to compete globally and work towards strategic autonomy. Therefore, this programme reflects the four sets of proposals put forward by the 2021 EU Coordinated Plan on AI. First, it sets enabling conditions for AI’s development and uptake by focusing on cooperation, data and computing infrastructure. Second, it leverages on existing Italian HPC and data-management infrastructure. Third, it aims at nurturing talents and adheres to the joint effort for improving and adopting the harmonised set of rules for AI proposed by the AI ACT. Fourth, it identifies priority sectors where to build strategic leadership. \nItaly will be a global research and innovation hub of AI. To guarantee future economic growth and strategic autonomy, it is essential for Italy to boost its AI research and development ecosystem and leapfrog at the forefront of AI developments. Accordingly, this strategic programme will invest in frontier research and applications to develop AI methodologies and techniques of tomorrow. \nItaly’s AI will be human-centred, trustworthy and sustainable. Technologies must not promote economic growth per se, but inclusive and sustainable growth, in line with the principles contained in Article 3 of the Italian Constitution and the United Nations Sustainable Development Goals. This means that AI development must be centred around economic and social inclusion, human rights as well as environ?mental sustainability. AI must be designed and implemented in a responsible and transparent manner, based on trust and robustness so that it can be safely adopted in every sector and be capable of respon?ding to societal challenges. To this aim, Italy adheres to the “Ethics Guidelines for trustworthy AI- Guidance and implementation program” defined by the High Level Expert Group on AI. \nItalian companies will become leaders of AI-based research, development and innovation. The digital transformation of our entrepreneurial ecosystem is a must, if Italy wants to keep up with the most deve?loped and innovative nations. To that end, this programme fosters the development, implementation and adoption of AI solutions. Public-private partnerships will be instrumental in finding appropriate synergies between research bodies and enterprises with the aim of increasing Italy’s technology transfer capabilities and thus competitiveness. \nItaly’s public administrations will govern with AI and will govern AI. The use and impact of AI in the public sector revolves around the dual dimensions of governance ‘with and of’ AI. On the one hand, Italy’s Government will improve its internal processes and policies thanks to a responsible use of data and AI technology. On the other hand, the Government is committed to governing AI and mitigating its potential risks, especially to safeguard human rights and ensure an ethical deployment of AI.\nNote: The “general principles” identified are from a crude summary.",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“The use and impact of AI in the public sector revolves around the dual dimensions of governance ‘with and of’ AI. On the one hand, Italy’s Government will improve its internal processes and policies thanks to a responsible use of data and AI technology. On the other hand, the Government is committed to governing AI and mitigating its potential risks, especially to safeguard human rights and ensure an ethical deployment of AI.” (p 14)\n“Technologies must not promote economic growth per se, but inclusive and sustainable growth, in line with the principles contained in Article 3 of the Italian Constitution and the United Nations Sustainable Development Goals. This means that AI development must be centred around economic and social inclusion, human rights as well as environmental sustainability. AI must be designed and implemented in a responsible and transparent manner, based on trust and robustness so that it can be safely adopted in every sector and be capable of responding to societal challenges. To this aim, Italy adheres to the “Ethics Guidelines for trustworthy AI- Guidance and implementation program” defined by the High Level Expert Group on AI.” (p 14)",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "N/A",
        "General principles on AI": [
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Interoperability. AI systems should be able to work with other systems. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27222",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Italy: AI Strategic Programme",
        "Translation Comments": "Official Translation Obtained"
      },
      "id": "i-s-WMQjjj_P",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-s-WMQjjj_P",
      "name": "Italy: AI Strategic Programme",
      "index": 176,
      "createdAt": "2024-05-24T04:29:45.220Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-s-WMQjjj_P"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Netherlands"
        ],
        "Policy Name": "Non-Discrimination by Design",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "These guidelines could be useful in educational settings.  It’s a practical checklist of sorts. \nNew guidelines aim to correct discriminatory algorithms | Vrije Universiteit Brussel (vub.be)",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Non-discriminatie by design.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as the objective or justification of the policy (the primary objective or justification)",
        "Key quote on human rights": "“The guideline is a result of the Dutch government’s commitment to human rights as a starting point for the use of AI and is in line with the recently adopted motion by politicians Jesse Klaver and Lilianne Ploumen on the new governance culture, in which the country’s parliament stated that “racism must be ended as soon as possible, not least by stopping the use of discriminatory algorithms”.” ",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“Algorithms work with data, but the data that organisations hold is often incomplete and biased. An algorithm that learns from today’s world will learn that men are more likely to be invited for an interview for a managerial position than women; an algorithm trained on the police database, which has an overrepresentation of data from neighbourhoods with many residents with an immigrant background, will conclude that crime is concentrated in those neighbourhoods. Organisations should therefore always check the data is balanced, complete and up to date.” (no pinpoint — website)\n\n“The control of algorithms should not only be about whether the system explicitly makes decisions based on discriminatory grounds such as race, orientation, beliefs or age. Even if automatic decision-making systems do not take these factors into account directly, they may do so indirectly. If a predictive policing system uses postcode areas, for example, it can lead to indirect discrimination, because it can advise the police to do a lot of surveillance in particular areas. The risk of self-fulfilling prophecies is high. “",
        "General principles on AI": [
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Bias testing. AI systems should be tested for bias. ",
          "Human rights-centred. AI systems should be compatible with human rights. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27116",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 11,
        "Title": "Netherlands: Non-Discrimination by Design",
        "Translation Comments": "Translation Needed"
      },
      "id": "i-oeQINs-uuL",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-oeQINs-uuL",
      "name": "Netherlands: Non-Discrimination by Design",
      "index": 181,
      "createdAt": "2024-05-24T00:14:03.083Z",
      "updatedAt": "2024-06-03T07:20:22.021Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-oeQINs-uuL"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United Kingdom"
        ],
        "Policy Name": "AI Procurement-In-A-Box",
        "Year of Commencement or Creation": "2018",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is another useful ‘tool’ intended to drive norms and standards. It does this at the procurement level. It could be applied to EdTech. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "WEF_AI_Procurement_in_a_Box_AI_Government_Procurement_Guidelines_2020.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information in reference to AI in general",
        "Key quote on human rights": "Under “example of human rights assessment from Google Cloud”\n“Google Cloud launched a Celebrity Recognition tool to a select set of media and entertainment customers to help them identify and label celebrities in professionally produced content, such as movies and sporting events. From the beginning of the product development process, they engaged in a human rights impact assessment (HRIA) and internal AI principles reviews. In partnership with BSR, a human rights non-profit organization, and using the UN’s Guiding Principles on Business and Human Rights as a framework, the team considered potential impacts throughout numerous dimensions including privacy, discrimination, freedom of expression and many others. Aspects such as consultation with potentially affected stakeholders, dialogue with independent expert resources and paying particular attention to those at heightened risk of vulnerability or marginalization were part of the methodology” (p 16)\n\n“Assemble multidisciplinary teams that specialize in designing, procuring, evaluating and operationalizing AI systems. These multidisciplinary teams should include expertise in: policy from the domain (e.g. justice) in which the AI solution will be applied, machine learning/ data science, data engineering, technology (software and hardware), procurement, ethics and human rights.” (p 21) ",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“Employment decisions have high stakes with critical consequences for individuals, organizations and society. Algorithms can make predictions in ways that disadvantage certain groups. Hence, concerns about AI algorithms bias and discrimination are particularly heightened, further complicated by labour and anti-discrimination laws.” (p 8)",
        "General principles on AI": [
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27022",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "Guidelines - What are the key considerations when starting a procurement process? (p 11-12) \nUse procurement processes that focus not on prescribing a specific solution but rather on outlining problems and opportunities, and allow room for iteration.\nDefine the public benefit of using AI while assessing risks.\nAlign your procurement with relevant existing governmental strategies and contribute to their further improvement.\nIncorporate potentially relevant legislation and codes of practice in your RFP.\nArticulate the technical and administrative feasibility of accessing relevant data.\nHighlight the technical and ethical limitations of intended uses of data to avoid issues such as historical data bias.\nWork with a diverse, multidisciplinary team\nFocus throughout the procurement process on mechanisms of algorithmic accountability and of transparency norms.\nImplement a process for the continued engagement of the AI provider with the acquiring entity for knowledge transfer and long-term risk assessment.\nCreate the conditions for a level and fair playing field among AI solution providers.",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 27,
        "Title": "United Kingdom: AI Procurement-In-A-Box",
        "Translation Comments": "N/A - English"
      },
      "id": "i-wH9XyF1SnK",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-wH9XyF1SnK",
      "name": "United Kingdom: AI Procurement-In-A-Box",
      "index": 299,
      "createdAt": "2024-05-24T00:08:54.179Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-wH9XyF1SnK"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United Kingdom"
        ],
        "Policy Name": "Welsh Language Technology Action Plan",
        "Year of Commencement or Creation": "2018",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a very good example of an optimistic vision for education — an example of how technology can help students. ",
        "Relevance Type": [
          "Policy contains case studies on AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": "",
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "welsh-language-technology-and-digital-media-action-plan.pdf"
        ],
        "Key quotes on AI in education principles": "“The Welsh language to be the user interface (UI) language of devices in Welsh-medium education and for Welsh-speaking students and staff in colleges and universities in Wales.” (p 13)",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Opportunity. The opportunities of AI should be harnessed."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26880",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "The initiative is using AI to enable greater use of the Welsh language, including in educational settings. ",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 25,
        "Title": "United Kingdom: Welsh Language Technology Action Plan",
        "Translation Comments": ""
      },
      "id": "i-0oQBY0gmWD",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-0oQBY0gmWD",
      "name": "United Kingdom: Welsh Language Technology Action Plan",
      "index": 297,
      "createdAt": "2024-05-24T00:08:34.228Z",
      "updatedAt": "2024-06-03T03:55:15.425Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-0oQBY0gmWD"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United Kingdom"
        ],
        "Policy Name": "UK Government’s Guidelines for AI Procurement",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This extends on the Procurement-In-A-Box content dealt with earlier. This is the specific document that emerged out of a project with the World Economic Forum. Could definitely be applied to EdTech procurement, at least in government schools. \nGuidelines for AI procurement - GOV.UK (www.gov.uk)\n",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Incentivises. It encourages compliance with non-binding standards on AI (eg, through procurement norms)",
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically",
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Guidelines for AI procurement - GOV.UK.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "“Explain in your procurement documentation that the public benefit is a main driver of your decision-making process when assessing proposals. Consider the human and socio-economic impact and benefits of your AI system in line with Social Value guidance. Public benefit goals must be relevant to what you are procuring (and not generic in nature) and must comply with the principles of non-discrimination, equal treatment and proportionality.” (p 8-9)\n\n“Have suppliers highlighted and/or addressed any issues of bias within the data? Do they clearly explain why their strategies are appropriate and proportionate? Do they have a plan for addressing any issues that you may have missed and underline the importance of an agile project delivery?” (p 11)\n\n“As part of the evaluation process, also review the specialist skills, qualifications and diversity of the team that will develop and deploy the AI system. This can also help to anticipate or detect unfair bias in the system.” (p 20)",
        "General principles on AI": [
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24808",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 23,
        "Title": "United Kingdom: UK Government’s Guidelines for AI Procurement",
        "Translation Comments": "N/A - English"
      },
      "id": "i-gEpPiSpPhW",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-gEpPiSpPhW",
      "name": "United Kingdom: UK Government’s Guidelines for AI Procurement",
      "index": 295,
      "createdAt": "2024-05-24T00:08:08.619Z",
      "updatedAt": "2024-06-05T21:37:17.815Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-gEpPiSpPhW"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United Kingdom"
        ],
        "Policy Name": "Foundation Model Taskforce",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is a hugely relevant project on the “opportunity” side. As the UK government argued, building a government-owned foundation model could, in education, ‘transform teachers’ day-to-day work, freeing up their time to focus on delivering excellent teaching’.\nInitial £100 million for expert taskforce to help UK build and adopt next generation of safe AI - GOV.UK (www.gov.uk)",
        "Relevance Type": [
          "Policy makes fleeting reference to AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "To build capacity — to en",
          "Develops tools. It provides tools and place them in the hands of businesses or governments"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": "",
        "Key quotes on AI in education principles": "“In education it could transform teachers’ day-to-day work, freeing up their time to focus on delivering excellent teaching.”",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27548",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "Opportunity\n“This technology is also predicted to raise global GDP by 7 percent over a decade, making its adoption a vital opportunity to grow the UK economy.”\n“Developed responsibly, cutting-edge AI can have a transformative impact in nearly every industry. It can revolutionise the way we develop new medical treatments, tackle climate change and improve our public services, all while growing and future-proofing our economy.”\nEtc\nTrust\n“To support businesses and public trust in these systems and drive their adoption, the Taskforce will work with the sector towards developing the safety and reliability of foundation models, both at a scientific and commercial level.”",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 13,
        "Title": "United Kingdom: Foundation Model Taskforce",
        "Translation Comments": ""
      },
      "id": "i-xGK8RQmKFx",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-xGK8RQmKFx",
      "name": "United Kingdom: Foundation Model Taskforce",
      "index": 285,
      "createdAt": "2024-05-24T00:07:26.088Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-xGK8RQmKFx"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "United Kingdom"
        ],
        "Policy Name": "National AI Strategy",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Like most national strategies reviewed, this focuses on AI education rather than EdTech governance. However, it does express some general governance norms (see p 50) that could be applied to EdTech.",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": "",
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "National_AI_Strategy_-_PDF_version.pdf"
        ],
        "Key quotes on AI in education principles": "This is not focused on ‘EdTech’ — more focused on building capacity for education, like most national strategies. ",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information in reference to AI in general",
        "Key quote on human rights": "“We will collaborate with key actors and partners on the global stage to promote the responsible development and deployment of AI. The UK will act to protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. Through our science partnerships and wider development and diplomacy work, we will seek to engage early with countries on AI governance, to promote open society values and defend human rights” (p 50)\n“This is not to say that AI is currently unregulated. The UK already regulates many aspects of the development and use of AI through ‘cross-sector’ legislation and different regulators. For example, there is coverage in areas like data protection (Information Commissioner’s Office), competition (Competition & Markets Authority), human rights and equality (Equality & Human Rights Commission). As well as through ‘sector-specific’ legislation and regulators, for example financial services (Financial Conduct Authority) and medical products (Medicines and Healthcare products Regulatory Agency).” (p 51)\n“The UK is already working with like-minded partners to ensure that shared values on human rights, democratic principles and the rule of law shape AI regulation and governance frameworks, whether binding or non-binding, and that an inclusive multi-stakeholder approach is taken throughout these processes.” (p 55)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“For example, concerns around fairness relate to algorithmic bias and discrimination issues under the Equality Act, the use of personal data (including sensitive personal data) and sector-specific notions of fairness such as the Financial Conduct Authority’s Fair Treatment of Customers guidance.” (p 55)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27177",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "There are lots of fleeting references. \n\nInteroperability (extracted because many do not mention it):\n“Growing the UK’s contribution to the development of global AI technical standards, to translate UK R&D for trustworthy AI into robust, technical specifications and processes that can support our AI governance model, ensure global interoperability and minimise the costs of regulatory compliance;” (p 50)\n“UK Defence has a strong record of collaboration with international partners and allies. Key collaborations include engagement with NATO allies to lead AI integration and interoperability across the Alliance, and supporting the AI Partnership for Defence, a 14-nation coalition providing values based global leadership for defence AI.” (p 55)\n“We want global technical standards for AI to benefit UK citizens, businesses, and the economy by: • Supporting R&D and Innovation. Technical standards should provide clear definitions and processes for innovators and businesses, lowering costs and project complexity and improving product consistency and interoperability, supporting market uptake.” (p 57)\nOn procurement:\n“Public Sector as exemplar for AI procurement & ethics” (p 14)\nThen they note:\n“National Statistics Data Science Campus; the Crown Commercial Service’s public sector AI procurement portal; and support for the Department for International Trade attracting AI related Foreign Direct Investment into the UK.”\nArtificial Intelligence (AI) - CCS (crowncommercial.gov.uk)\n",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "United Kingdom: National AI Strategy",
        "Translation Comments": ""
      },
      "id": "i-M57ryB1BR9",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-M57ryB1BR9",
      "name": "United Kingdom: National AI Strategy",
      "index": 182,
      "createdAt": "2024-05-24T00:06:30.998Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-M57ryB1BR9"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Ireland"
        ],
        "Policy Name": "National AI Strategy",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is a focus here on ‘AI education’, but that is not the only thing. They also recognise that AI can advance Ireland’s objectives in areas including education—that it can be a force for good in this space. \n\nThis is an excellent document—both for its general guidance on AI governance and commentary on the opportunities at hand (including increasing access to education). ",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "national-ai-strategy.pdf"
        ],
        "Key quotes on AI in education principles": "Preparedness to embrace AI in education\n“Consider how AI can be incorporated into future policy for digital learning” (p 11)\n“For example, AI applications can advance our objectives in areas such as climate action, public health, education, housing, urban development, preservation of cultural heritage, food security, human rights, crisis response and disaster management, amongst others” (p 7)\nAI for social inclusion: \n“AI FOR SOCIAL INCLUSION While there is a risk that AI could result in new forms of inequalities, it may also offer opportunities to improve access and inclusion - in work, in education, in everyday life, and in making human connections. For example, robots incorporating AI and smart home assistants are being used to assist in providing health and social care.13 There is also significant potential for AI to provide educational resources for people with disabilities and special needs.14 The development of AI-based semantic technologies to extract digital content can render navigation and access easier and more effective for people with low levels of vision. In addition, AI-based innovations like real-time live captioning can assist those with impaired hearing.” (p 18)\nTranslation in learning:\n“researchers at Lero, the SFI Research Centre for Software, are working with Microsoft to develop AI-based “chatbots” to provide opportunities for young refugees to access and avail of high-quality educational resources in their own languages” (p 18)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "“A human rights-based approach to AI is increasingly supported by multilateral standard-setting organisations, such as the United Nations (UN), the UN Educational, Scientific and Cultural Organisation (UNESCO), the Organisation for Economic Cooperation and Development (OECD) and the Council of Europe.23 Human rights are protected by law and as such should underpin ethics guidance for AI.” (p 25)\n“Deploying AI in certain public service areas - for example policing - will require particular attention from an ethical and human rights perspective. In driving public service adoption of AI, the GovTech Delivery Board will consider appropriate safeguards – including the potential use of impact assessments - to ensure that the use of AI within the Public Service is consistent with ethical principles and with human rights obligations.” (p 25)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "Risk of AI augmenting/being a source of inequity:\n“While AI will lead to some displacement, as with other previous disruptive technological advances, it will also lead to the creation of new jobs and higher productivity and incomes. The policy challenge is to ensure that these gains are shared equitably.” (p 11)\n“AI-based systems have the potential to exacerbate existing structural inequities and marginalisation of vulnerable groups. For instance, AI-based facial recognition technology that has been trained disproportionately on lighter skin tones may be significantly less accurate in relation to people of colour and can thus exhibit higher false positive rates for this population.” (p 21)\n“Beneficial AI innovation also relies on strong data governance, which ensures privacy, equity, transparency, and inclusivity. The proposal for an EU Data Governance Act is an important initiative in this respect.” (p 61)\nSocial inclusion:\n“While there is a risk that AI could result in new forms of inequalities, it may also offer opportunities to improve access and inclusion - in work, in education, in everyday life, and in making human connections. For example, robots incorporating AI and smart home assistants are being used to assist in providing health and social care.1” (p 18)\nThis sounds like substantive equality to me\n“There is also significant potential for AI to provide educational resources for people with disabilities and special needs.14 The development of AI-based semantic technologies to extract digital content can render navigation and access easier and more effective for people with low levels of vision. In addition, AI-based innovations like real-time live captioning can assist those with impaired hearing.” (p 18)",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Bias testing. AI systems should be tested for bias. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Inclusive development. AI systems should be developed inclusively. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27106S",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "On the principle that impact assessments should be undertaken:\n“Impact assessments are an important tool to identify and mitigate any potential risks of adverse impacts of AI. These impact assessments can be carried out voluntarily under an ethics-based approach, but they can also be incorporated under a binding legal framework. EU law already requires Impact Assessments in specific sectors, such as Data Protection Impact Assessments (DPIAs) under the GDPR. The Assessment List for Trustworthy AI (ALTAI), specifically refers to the need to perform a fundamental rights impact assessment for AI systems and provides examples of relevant questions for this purpose.25 The Council of Europe also recommends that Governments should conduct human rights impact assessments in the area of AI.” (p 25)\n“Certification schemes or codes of conduct (whether voluntary or mandatory) are another way of building trust in AI systems and providing a pathway to compliance. Certification can provide independent and effective assurance that the protection and security of personal data involved in the training, testing, and application of AI algorithms, models and systems accords with international and Irish standards. This can be used to drive efficient, responsible, accountable and ethical AI data processing of personal data. For example, the Code of Conduct and Certification mechanisms under the General Data Protection Regulation (GDPR) are a means by which compliance with that Regulation can be verified.” (p 27)\n“This can be especially helpful and advantageous where the outcomes of AI usage in data processing operations may lead to decisions that have impact or a risk to individuals. It is possible these risks can be significant in some cases and that this could lead to bias, discrimination or a limitation of rights. The Top Team on Standards will examine ways to support the development of certification schemes and codes of conduct to address particular aspects of AI processing or different stages of AI development and operations in areas such as:\nexplainability and transparency \ndetermination or demonstration of fairness \nestimations of bias in training data \nmechanisms to effectively audit AI systems \nsecuring AI datastores and training sets \ndata minimisation and anonymisation techniques that provide for effective outputs or AI “decisions” \neffective support for GDPR rights in AI systems \ndesign principles for AI systems that ensure effective data protection”  (p 27)",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Ireland: National AI Strategy",
        "Translation Comments": "N/A - English"
      },
      "id": "i-F_yviDxDMK",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-F_yviDxDMK",
      "name": "Ireland: National AI Strategy",
      "index": 184,
      "createdAt": "2024-05-23T22:28:41.075Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-F_yviDxDMK"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Netherlands"
        ],
        "Policy Name": "Vision on Generative AI",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This vision statement / issues paper deals expressly with education. \n\nThere are some interesting comments on unequal access to technology — “Smaller companies, educational institutions, teachers, students, and socio-economically vulnerable groups may be disadvantaged, which can increase social inequalities within a society as well as between societies worldwide” (p 14). Also note strong intention to regulate: “It is important that the government facilitates a support structure that manages the development of AI for education” (p 20). ",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Collaboration. AI programmers, developers, companies, schools, teachers, and other stakeholders should cooperate to develop technology. ",
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Trust. Organisations seeking to incorporate AI into educational settings must build trust.",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Information. Information about the technology in use should be readily available. ",
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. ",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ",
          "Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ",
          "Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.",
          "Human rights-centred. The technology must be consistent with human rights. ",
          "Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Transparency (transparency to government). The extent to which AI is used in educational settings should be clear to the government. ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "Government-wide+vision+on+generative+AI+of+the+Netherlands.pdf"
        ],
        "Key quotes on AI in education principles": "Note on above — the general principles it discusses are intended to apply to education (among other things), so there is some overlap between “education principles” and “general principles”. However, quotes are placed in the “general” box if general, and “education” box if education-specific. \n\nInvestment\n“It is important that the government facilitates a support structure that manages the development of AI for education. With funding from the National Growth Fund, the Ministries of Economic Affairs and Climate Policy and Education, Culture and Science are investing substantially in the National Education Lab AI (NOLAI) for a period of ten years. Teachers, scientists, and companies collaborate to responsibly develop and evaluate advanced digital innovations, such as AI, in primary education.7 For instance, AI is being utilised to develop a centralised teacher dashboard and to offer customised assistance to students in their learning” (p 20)\nSection titled “Generative AI as a learning tool”\n“Generative AI models can be used to analyse huge amounts of data quickly. Generative AI can therefore be used, for example, to explain complex texts, interpret key topics and draw conclusions. Users can therefore also use generative AI as a learning tool. \nWe see this role, for example, in the field of language and translation, Generative AI models are capable of translating large amounts of text with high accuracy. The technology can be used to translate content, making relevant information available to a wider audience. This can be helpful for language learning and for translating websites or educational materials, including those related to government. \nGenerative AI can therefore play an important role as a learning tool in education. For instance, this technology can assist students in generating summaries, clarifying learning material, and composing practice questions. Generative AI models can create personalised feedback, recommendations, and interventions by analysing users’ learning patterns to tailor teaching to personal learning needs.11 \nTeachers can use generative AI to design teaching methods or improve teaching materials. \nFurthermore, generative AI enables the prediction of future student performance based on past student data, which can help identify students who may require additional support.12 \nThe function of a learning tool is exemplified by the use of digital search engines, which are utilised by the majority of individuals in their daily lives. Generative AI has already been integrated into search engines by companies like Google and Microsoft, significantly improving their functionality. \nFinally, generative AI applications like ChatGPT are capable of explaining concepts in a variety of ways. The tool can be utilised for academic or professional purposes, as well as for everyday topics such as explaining the operation of a fuse box or how to save energy. Due to the interactive nature of applications like ChatGPT, users can request customised or more detailed explanations.” (p 10)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "The key passage is as follows (on p 20):\n“ii Laws and regulations in the Netherlands and the EU\nDifferent legal frameworks apply to the development and application of generative AI. The following discusses how the development of generative AI relates to fundamental rights with a particular focus on the European AI Act.\nFundamental rights \nThe use and development of generative AI could potentially affect the realisation of fundamental rights. The fundamental rights affected by generative AI are the prohibition of discrimination and the right to privacy and data protection. \nThe prohibition of discrimination and the principle of equality are included in Article 1 of the Constitution. The prohibition of discrimination is enshrined in Article 14 of the European Convention on Human Rights (ECHR) and Article 26 of the International Covenant on Civil and Political Rights (ICCPR). As previously noted in chapter 3b, generative AI can inadvertently perpetuate bias or discrimination. Bias can enter generative AI systems in various ways, including through developer and training data. As only a handful of AI developers shape generative AI and applications, (unconscious) bias may inadvertently be introduced into the models. In addition, training data may contain bias and enter the model, spreading and amplifying this bias widely.8 \nThe use and development of generative AI may raise concerns regarding the protection of privacy and data. The right to privacy is set out in Article 10 of the Constitution. In addition, the right to privacy is protected by Article 8 of the European Convention on Human Rights (Right to respect private and family life) and Article 17 of the International Covenant on Civil and Political Rights.”",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "Concerns about concentrations of power and related access concerns: \n“The development of generative AI depends on a handful of large companies. This can result in unequal access to technology and disproportionate opportunities to take advantage of it. Smaller companies, educational institutions, teachers, students, and socio-economically vulnerable groups may be disadvantaged, which can increase social inequalities within a society as well as between societies worldwide. Finally, market power is often the prelude to exerting social and political influence.” (p 14)\n“Generative AI for greater equality”\n“Generative AI should help promote equality and bridge (socio-economic) gaps, both within and between countries. This is in line with several of the Sustainable Development Goals (SDGs).\nThis requires, firstly, monitoring the impact of automation on wage and employment trends, especially where increasing income and wealth inequality. AI may cause wages for different jobs to diverge more, as was the case with previous automation.34 \nSecondly, policies and initiatives that promote economic equality, such as education and retraining programmes, social safety nets, and inclusive AI development that ensures a more balanced distribution of opportunities, can help counter economic inequality and reduce the digital divide. It is important to ensure that our social safety net is well-equipped for the socio-economic transitions that generative AI is expected to trigger in the mid to long term. \nFinally, equity requires fair conditions for all parties involved in model development and training. It is important to note that human ‘labellers’ who assist in improving AI models should receive fair compensation and working conditions. Unfortunately, this is not always the case.” (p 26)\n",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Augmentation, not replacement. AI systems should augment, not displace, workers.",
          "Bias testing. AI systems should be tested for bias. ",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27627",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "Procurement:\n“Contracted generative AI applications should also comply with the General Government Terms and Conditions for IT Contracts 2022 and departmental procurement conditions (if they prevail).” (p 40)\n“Drafting, developing or refining (intergovernmental) procurement conditions with a view to generative AI.” (p 42)\n“It encourages the use of open source by applying the ‘open source unless’ principle in procurement and development.” (p 25)\n“The Dutch government has a commendable role in the responsible and safe development, procurement, and deployment of generative AI.” (p 40)\nAugmentation:\n“It may be undesirable to replace certain forms of human contact with AI-driven processes” (p 26)\nImpact assessment content”:\n“Government leading by example \nThe government is actively promoting the acquisition of knowledge and skills. This allows us to take full advantage of the opportunities provided by generative AI. Adequate commitment to knowledge and skills also benefits one’s grasp of technology, promotes social equity, and encourages participation. As a government, we will set a positive example. ...\nAs a government, we recognise the importance of innovation and experimentation in harnessing generative AI for public values. All generative AI applications must comply with relevant laws and regulations.22 To determine whether a specific form of generative AI deployment is feasible, a risk analysis should be conducted for each unique case before use. These are a Data Protection Impact Assessment (DPIA) and an algorithm impact assessment (such as an Impact Assessment Fundamental Rights and Algorithms (IAMA)), which identifies risks and mitigation measures. The results of this should be submitted to the (departmental) Chief Information Officer and the Data Protection Officer for advice before deployment. The above points apply when using or (re)developing an open-source generative AI application. In the context of the ‘Wet open overheid’ (Open Government Act) (Woo) and encouraging transparency, the policy guideline “open (source), unless” applies.23 Non-contracted generative AI applications” (p 40)",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "It seems to have built “Dutch open language models”\n“Dutch open language models \n“We encourage the development of Dutch and European LLM’s compliant to public values. Financing GPT NL is one example. We are also exploring the possibility of joining the Alliance for Languages Technologies European Digital Infrastructure Consortium (ALT-EDIC), among others”; (p 14)",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 10,
        "Title": "Netherlands: Vision on Generative AI",
        "Translation Comments": ""
      },
      "id": "i-SxcvRiVWW4",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-SxcvRiVWW4",
      "name": "Netherlands: Vision on Generative AI",
      "index": 195,
      "createdAt": "2024-05-23T10:22:00.655Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-SxcvRiVWW4"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Netherlands"
        ],
        "Policy Name": "Amsterdam’s Register",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The idea of an AI register could be applied to educational settings (which is one of the transparency norms).\nAlgorithm Register",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Tracks. It sets out to boost understanding specifically of where and how AI is being used"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": "",
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information in reference to AI in general",
        "Key quote on human rights": "“Algorithms used in public services must adhere to the same rules and principles as all other public services provided by the municipality. That means they must treat people equally, not limit their freedom, be transparent and open to democratic control and be at the service of the people of Amsterdam; not the other way around.” (https://algoritmeregister.amsterdam.nl/en/more-information/) ",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Inclusive development. AI systems should be developed inclusively. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26889",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "The Algorithm Register encourages users to: \naccess the published algorithms for their own interests; and\nprovide feedback and participate in “building human-centered algorithms in Amsterdam”. \nIt also provides open access to some of the algorithms used by the City of Amsterdam. ",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 4,
        "Title": "Netherlands: Amsterdam’s Register",
        "Translation Comments": "N/A - English"
      },
      "id": "i-5BdsrZQR69",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-5BdsrZQR69",
      "name": "Netherlands: Amsterdam’s Register",
      "index": 189,
      "createdAt": "2024-05-23T10:20:52.902Z",
      "updatedAt": "2024-06-06T03:10:06.114Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-5BdsrZQR69"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Netherlands"
        ],
        "Policy Name": "Algorithm Supervision Body",
        "Year of Commencement or Creation": "2022",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Translated with DeepL. This is highly relevant in a general sense — it is about approaches to regulating algorithms. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A Other]"
        ],
        "Governance practices employed": [
          "To help officials anticipate the impact of AI by offering them systematic frameworks and tools",
          "[N/A]"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "advies-privacy-company-inrichting-algoritmetoezicht en.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "Numerous references to human rights, including requirement of a “mandatory human rights impact assessment” by the ministry. ",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about the risk of AI augmenting inequities/inequalities",
        "Key quote on equity/equality": "Talks about “non-discrimination” throughout",
        "General principles on AI": [
          "Ex-ante impact assessment. Before an AI system is deployed, its properties and likely impact should be considered. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27438",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": [
          "Will Cesta"
        ],
        "Relevant?": "Yes",
        "Series #": 3,
        "Title": "Netherlands: Algorithm Supervision Body",
        "Translation Comments": "Translation Completed (DeepL)"
      },
      "id": "i-dwqYhbrrRP",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-dwqYhbrrRP",
      "name": "Netherlands: Algorithm Supervision Body",
      "index": 188,
      "createdAt": "2024-05-23T10:20:45.245Z",
      "updatedAt": "2024-06-05T23:05:44.633Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-dwqYhbrrRP"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Canada"
        ],
        "Policy Name": "Canada’s Digital Charter",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is not ‘about’ AI in education, but the norms it expresses could be applied to AI in education. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Seeks information. It gathers inputs on public sentiment about AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Canada Charter.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "Mentions concepts related to human rights in its 10 principles: \n“Free from Hate and Violent Extremism” (Principle 9) \n“Safety and Security” (Principle 2) ",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "Mentions a concept related to equity in its 10 principles: \n“A Level Playing Field” (Principle 6) ",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress."
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24508",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 5,
        "Title": "Canada: Canada’s Digital Charter",
        "Translation Comments": "N/A - English"
      },
      "id": "i-npZS-xFGnW",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-npZS-xFGnW",
      "name": "Canada: Canada’s Digital Charter",
      "index": 201,
      "createdAt": "2024-05-23T08:40:26.962Z",
      "updatedAt": "2024-06-03T07:18:49.846Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-npZS-xFGnW"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Canada"
        ],
        "Policy Name": "Algorithmic Impact Assessment",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This is one of the most important and interesting initiatives, and one that could definitely be applied to AI in education. It is a concrete tool designed to help officials assess and mitigate risk. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Guides impact assessment. It helps officials anticipate or evaluate the impact of AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Algorithmic Impact Assessment Tool - Canada.ca.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“The impacts of automating an administrative decision are classified into 4 levels, ranging from Level I (little impact) to Level IV (very high impact). The AIA is intended to identify risks and assess impacts in a broad range of areas, including: \nthe rights of individuals or communities \nthe health or well-being of individuals or communities \nthe economic interests of individuals, entities, or communities \nthe ongoing sustainability of an ecosystem” (p 5-6)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“A broad range of information about an automation project is required to fully answer the questions in the risk and mitigation areas of the AIA. Prior to starting the AIA, it is useful to have information about: \nthe administrative decision that the automated decision system will inform, contribute to, or make, the context in which the system will be used, and the way the system will assist or replace the judgement of a human decision-maker \nthe clients subject to the decision, including evidence of any vulnerability (for example, socioeconomic, demographic, geographic)” (p8-9)",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Bias testing. AI systems should be tested for bias. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Procurement as a regulatory force. Governments seeking to procure the use of AI systems should ensure that the terms of procurement filter out unsafe products, thereby incentivising the creation of safe systems. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-24387",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 3,
        "Title": "Canada: Algorithmic Impact Assessment",
        "Translation Comments": "N/A - English"
      },
      "id": "i-d273os6Vd3",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-d273os6Vd3",
      "name": "Canada: Algorithmic Impact Assessment",
      "index": 199,
      "createdAt": "2024-05-23T08:40:00.447Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-d273os6Vd3"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Indonesia"
        ],
        "Policy Name": "National AI Strategy",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "Note: Translated using DeepL. There is a fair bit of content worth looking into here, including an application map in education (p 127). \nThere is a governance section, but my feeling is that this is very opportunity-oriented. Nothing is said about risk in the education context, but some general AI risk principles are included. ",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "Indonesia en.pdf"
        ],
        "Key quotes on AI in education principles": "The big picture here is that: (a) results in schools are bad, (b) university is inaccessible, but: \nArtificial Intelligence can be utilized to increase the scale and reach of quality education services with special attention to rural communities, people with disabilities, and children with special needs. Artificial Intelligence can be applied to personalize content and learning experiences that take into account various modes of interaction according to learner characteristics. Artificial Intelligence can also help manage information on learning outcomes and their scaling up as feedback to the system in order to produce adaptive and automated delivery of learning experiences (p 97-98)\nArtificial Intelligence can be utilized to improve the efficiency of teachers' administrative tasks beyond the preparation and delivery of learning content. This includes preparing general teaching plans, evaluating learning outcomes, ensuring academic integrity, and evaluating educator performance. Automation of these administrative tasks can help teachers focus more on preparing and delivering quality learning content. (p 98)\nThere are three (3) perspectives in the application of Artificial Intelligence for education, namely student/learner-facing (learning-facing), teacher/teaching (teacher-facing) and managers and administrators at all levels (system-facing) as users [Zawacki-Richter et al. 2019].\nThey go on to say:\nEducation services that are currently class-based will shift to learner-based education. Furthermore, education can lead to Precision Learning which takes the term from the health field. In Precision Learning, learning in addition to taking into account the cognitive, affective, and psycho-motor aspects of students, also takes into account the behavior or daily habits of students. Then with the amount of data that can be taken from students through gadgets, computers and students' digital footprints, there will be a lot of information obtained from individual students. Formal learning in schools will slowly shift from school to out of school which is currently recognized by the government with the existence of home schooling with a standardized evaluation system. Artificial Intelligence will play a major role in the changes in education in the future. Various applications of Artificial Intelligence in Education are shown in Figure 7-4, including Intelligent Online Education, Smart Course Content with AR/VR, Virtual Laboratory, Adaptive Learning System, Adaptive Assessment System, Adaptive Classification System, Serious Game in Education, and Precision Learning System. (p 126)\nWhat can be done?\nDevelopment of various multimedia content, educational games, and adaptive assessment for learning as a fun experience rather than learning as a burden.\n The development of integrated education data, coordinated learning materials, integrated question banks and the use of smart evaluation methods to realize an open education system (stakeholders working together) rather than a closed education system (stakeholders acting individually). \nDevelopment of an adaptive assessment system and an intelligent student classification system to make teachers a facilitator of learning rather than a transmitter of knowledge. \nDevelopment of a precision learning system to realize a learner-centered and personalized approach rather than a one-size fits all pedagogical approach (p 127)\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "“Artificial Intelligence that is intended to generate public trust and be accountable must fulfil the element of safety, meaning that the Artificial Intelligence developed can be tested and is suitable for use without threatening the safety and protection of human rights.” (p 41)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "“Artificial Intelligence can be utilized to increase the scale and reach of quality education services with special attention to rural communities, people with disabilities, and children with special needs. Artificial Intelligence can be applied to personalize content and learning experiences that take into account various modes of interaction according to learner characteristics. Artificial Intelligence can also help manage information on learning outcomes and their scaling. (p 97)”\nMore general comments:\nTo achieve trustworthy Artificial Intelligence, there must be a focus on inclusion and diversity throughout the lifecycle of the Artificial Intelligence system, which must be user-centered and designed in a way that allows everyone to use the Artificial Intelligence product or service. (p 40)",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Competition. There should be sufficient diversity in the AI market to ensure that providers do not have excessive market power.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Equity/equality (increasing equity/equality). AI should be used as a means of achieving equity/equality (or decreasing inequity/inequality).",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Intellectual property compatibility. Education organisations should ensure that AI systems are compatible with intellectual property rights,",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26968",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "Note: Indonesia is not signing up to the “augmentation, not replacement” team:\nDuring a Kompas100 CEO Forum event in Jakarta on Thursday (28/11/2019), the President of the Republic of Indonesia, Joko Widodo, ordered government agencies to eliminate two ranks of civil servants by 2020 and replace their roles with Artificial Intelligence, in an effort to cut bureaucracy that hampers investment. President Jokowi's statement was reinforced by an analysis by an international organization (Deloitte, 2019) that sheds light on how Artificial Intelligence can benefit the government (p 122)\nProcurement:\nNot sure whether this is a dodgy translation...?\nCreate a policy that prioritizes products made by the nation's children in government procurement to reduce dependence on imported products and at the same time to increase TKDN. (p 27)\nSets “public trust” as one of the goals (p 39)",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Indonesia: National AI Strategy",
        "Translation Comments": "Translation Completed (DeepL)"
      },
      "id": "i-r3DyNRPcd4",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-r3DyNRPcd4",
      "name": "Indonesia: National AI Strategy",
      "index": 206,
      "createdAt": "2024-05-23T02:26:03.418Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-r3DyNRPcd4"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Latvia"
        ],
        "Policy Name": "Latvia’s National AI Strategy",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This policy recognises that AI has a role to play in education, and refers to some general regulatory principles that could be applied to education.",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary",
          "Tertiary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "Latvia (translated).pdf"
        ],
        "Key quotes on AI in education principles": "The main section on AI in education — as distinct from AI education — is:\nAI as a tool can be used to improve general education. Basically, three educational support functions that AI can perform can be highlighted88: \n1. Smart content – A technology that can create a synopsis from the contents of a book or prepare a test for testing knowledge. For example, Cram10189 or Netex learning90 tools. \n2. Smart training systems (virtual learning assistant) – personalized electronic training tailored to the needs, learning style, preferences of the pupil or student. For example, the Carnegie Lerning91 tool. \n3. Virtual learning environment as an aid to learning information. For example, the Victoryxr92 tool. AI systems could also be used as a virtual teaching assistant to test and aggregate learners' knowledge. Analysts at Technavio predict that between 2018 and 2022, the size of the AI market in the U.S. education sector will grow by 48%.93 (p 22)\nIt does not go much further. ",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "It talks about human rights a fair bit in the context of its governance ambitions, for example:\nAI systems should be designed in a way that respects the rule of law, human rights, democratic values and diversity and should include appropriate safeguards, such as ensuring human intervention where necessary, to ensure fairness. (p 22)\nAs set out in the Charter, CEPEJ believes that the application of AI in the area of justice can help improve efficiency and quality and must be implemented responsibly, with respect for fundamental rights, as guaranteed in particular by the European Convention on Human Rights and the Council of Europe Convention for the Protection of Personal Data with regard to Automatic Processing of Personal Data. (p 41)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "Nothing education-specific.\nThe closest thing I can find — noting that this is a DeepL translation — is:\nthe main requirements for AI-systems are sustainable and inclusive development, human orientation and fairness, transparency and explainability of actions, security, responsibility. (p 22)\n",
        "General principles on AI": [
          "Bias testing. AI systems should be tested for bias. ",
          "Disinformation. AI - particularly GenAI - should not be used as an instrument of disinformation. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Interoperability. AI systems should be able to work with other systems. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26933",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "“As set out in the Charter, CEPEJ believes that the application of AI in the area of justice can help improve efficiency and quality and must be implemented responsibly, with respect for fundamental rights, as guaranteed in particular by the European Convention on Human Rights and the Council of Europe Convention for the Protection of Personal Data with regard to Automatic Processing of Personal Data.” (p 22) \nEtc, etc [cites a range of principles developed]\nIt seems to implicitly accept these principles (although notes that “explainability” is complex):\n“It is these basic principles that must also be taken into account when developing AI solutions in Latvia and planning their further development.” (p 24)",
        "Notable Case Studes - Examples of AI in Education": "They mention a few use cases:\n1. Smart content – A technology that can create a synopsis from the contents of a book or prepare a test for testing knowledge. For example, Cram10189 or Netex learning90 tools. \n2. Smart training systems (virtual learning assistant) – personalized electronic training tailored to the needs, learning style, preferences of the pupil or student. For example, the Carnegie Lerning91 tool. \n3. Virtual learning environment as an aid to learning information. For example, the Victoryxr92 tool. AI systems could also be used as a virtual teaching assistant to test and aggregate learners' knowledge. Analysts at Technavio predict that between 2018 and 2022, the size of the AI market in the U.S. education sector will grow by 48%.93 (p 22)\n",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Latvia: Latvia’s National AI Strategy",
        "Translation Comments": ""
      },
      "id": "i-YejprgjJnB",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-YejprgjJnB",
      "name": "Latvia: Latvia’s National AI Strategy",
      "index": 211,
      "createdAt": "2024-05-23T01:16:13.693Z",
      "updatedAt": "2024-06-05T21:39:18.055Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-YejprgjJnB"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Slovenia"
        ],
        "Policy Name": "National AI Programme of Slovenia",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This policy seems to be on the robust end of the spectrum. The document attached addresses numerous relevant areas, particularly “Ensuring an appropriate legal and ethical framework”, which may prove generally relevant (see p 58 of the document attached). Note that the document attached was translated with DeepL— this is not an official translation. Definitely worth further investigation. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education",
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ",
          "Teacher training. Teachers should be trained to ensure that AI is used well in educational settings. ",
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "Slovenia.pdf"
        ],
        "Key quotes on AI in education principles": "“The use of AI in education will enable fairer access to education for more vulnerable groups and people with special needs, as the use of AI solutions allows educational resources and methods to be adapted to each individual according to their needs and preferences. It is particularly important that teachers at all levels of education know and understand AI solutions so well that they actively use them as a tool to facilitate their work by bringing them closer to students' needs, making the necessary analyses, facilitating assessment and, ultimately, upgrading their own professional development.” (p 31)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "“Slovenia stands for AI, which as a tool must primarily serve a person to ensure the quality of his life, thus joining EU countries with a vision of human-centric development and introduction of AI for his good and for the benefit of society. Ensuring public acceptance of AI is key to this, and this must be based on the confidence that AI deployment will actually produce positive impacts on individuals' lives. To do this, we must provide an appropriate legal and ethical framework that preserves and guarantees the acquisition and continued respect of human rights and fundamental freedoms, thereby guaranteeing the civil, political, economic, social and cultural rights of every individual, regardless of the level of introduction of new solutions.” (p 8)\n\n“The development and introduction of AI into society must be based on respect for human rights and fundamental freedoms as enshrined in the Constitution of the Republic of Slovenia, the EU Charter of Fundamental Rights, the Universal Declaration of Human Rights and other fundamental international instruments in the field of human rights. It must respect the fundamental values of Slovenian society, the rule of law and democracy and ensure economic and political stability” (p 13)\n\n“Slovenia's efforts are also in line with the OECD Principles on Artificial Intelligence, which promote artificial intelligence that is innovative and trustworthy and respects human rights and democratic values.” (p 13)\n“Taking into account the basic direction of the Programme for the development and deployment of trustworthy and human-centric AI, it is necessary to provide public and private sector actors with appropriate education and awareness raising on the ethical and legal aspects of the development and use of AI, including a focus on different human rights risks.” (p 41)\n\n“Safety authorities shall only introduce AIs in the performance of their duties if this is necessary from the point of view of effectiveness and efficiency and the solutions do not endanger human rights and fundamental freedoms, are ethical, lawful and proportionate. In the area of freedom, security and justice, as in some other areas (e.g. procedures and decisions in healthcare), humans must have control over the use of AI and must therefore be given the right and be able to request review and review of decisions taken using AI. Responsibility for final decisions must lie with a clearly identifiable decision-maker. Systems operating in this field must be transparent and offer not only assessments or proposals but also their explanations wherever AI techniques allow it (the issue of transparency and explainability of AI methods).” (p 52) \n\n“The speed of AI deployment and its impacts on society largely depend on people's trust that solutions are safe, robust and actually help improve their lives and ensure freedom, human rights and democratic processes.” (p 55) \n\n“Ethical principles should therefore be reflected in the relevant legal regime of IMs. Although there is no legal vacuum in the field of AI with regard to the protection of human rights, regulation is necessary for the effective enforcement of already applicable sectoral norms, for example, anti-discrimination (international, EU and national) law.” (p 58)\n\n“Slovenia will strengthen cooperation at the international level in the field of research, development and innovation; Education; scientific and economic diplomacy; regulation and regulation of the development, implementation and use of AI in accordance with respect for human rights and fundamental freedoms; developing an appropriate legal and ethical framework; international development cooperation and strengthening North-South cooperation and supporting sustainable development and achieving the SDGs.” (p 61)\n\n“Support education and awareness raising among businesses and the public sector on providing a legal and ethical framework for the development, deployment and use of AI, including human rights compliance issues.” (p 64)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "“AI shall pay particular attention to the protection of privacy and personal data and non-discrimination, and generally to ensure that the development and use of AI is based on ethical guidelines68 and criteria that ensure this, such as human performance and control, technical robustness and security, privacy and data management, transparency, diversity, non-discrimination and equity, social and environmental well-being and clear accountability.” (p 58)\n\n“The use of AI in education will enable fairer access to education for more vulnerable groups and people with special needs, as the use of AI solutions allows educational resources and methods to be adapted to each individual according to their needs and preferences. It is particularly important that teachers at all levels of education know and understand AI solutions so well that they actively use them as a tool to facilitate their work by bringing them closer to students' needs, making the necessary analyses, facilitating assessment and, ultimately, upgrading their own professional development.” (p 31)\n\n“Support digital training and literacy programmes for the widest population, including vulnerable groups, and in particular people with special needs, for the acquisition of digital competences and user skills in the field of AI (general lifelong learning, adult computer literacy).” (p 51)\n\n“Support lifelong education to AI also for more vulnerable groups and people with special needs 45 will help reduce the risk of social and digital exclusion, which could be exacerbated by the uptake of AI in certain areas of society” (p 31)\n",
        "General principles on AI": [
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Bias testing. AI systems should be tested for bias. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Inclusive development. AI systems should be developed inclusively. ",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-14677",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Slovenia: National AI Programme of Slovenia",
        "Translation Comments": "Translation Completed (DeepL)"
      },
      "id": "i-Xg_AS09rrG",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-Xg_AS09rrG",
      "name": "Slovenia: National AI Programme of Slovenia",
      "index": 215,
      "createdAt": "2024-05-22T23:45:56.061Z",
      "updatedAt": "2024-06-06T02:14:24.932Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-Xg_AS09rrG"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "United Arab Emirates"
        ],
        "Policy Name": "UAE National Strategy for AI",
        "Year of Commencement or Creation": "2018",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "As with many of the AI strategies reviewed, this one is focused on AI as a tool for economic growth, and sees education principally as a method of learning to ‘do’ AI — its focus on the safe and effective use of AI in education is less pronounced. However, there are a few areas of potential relevance — see Objective 4 (Adopt AI Across Customer Service to Improve Lives and Government) and Objective 8 (Ensure Strong Governance and Effective Regulation). ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "United_Arab_Emirates_National_Strategy_for_Artificial_Intelligence_2017-2031.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "No",
        "Key quote on human rights": "",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "“The UAE also faces significant social and economic challenges, where the outcomes for the population are poor compared to other countries. For example, high rates of obesity and heart disease, high rates of traffic fatalities, poor air quality and poor education outcomes. Using AI to better respond to these challenges has huge potential benefits. There is a role for Government in supercharging this – providing the focus, resources and drive to solve these challenges.” (p 30)",
        "General principles on AI": [
          "Opportunity. The opportunities of AI should be harnessed.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-25387",
        "Analysis Complete": true,
        "Draft Analysis Complete": true,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": "",
        "Title": "United Arab Emirates: UAE National Strategy for AI",
        "Translation Comments": "N/A - English"
      },
      "id": "i-hGDvWnUmlp",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-hGDvWnUmlp",
      "name": "United Arab Emirates: UAE National Strategy for AI",
      "index": 219,
      "createdAt": "2024-05-22T23:30:52.519Z",
      "updatedAt": "2024-06-05T21:37:17.815Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-hGDvWnUmlp"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Serbia"
        ],
        "Policy Name": "Strategy for the Development of AI in the Republic of Serbia for the Period 2020-2025",
        "Year of Commencement or Creation": "2020",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This plan discusses the “development of education geared to the needs of modern society and economy conditioned by the advancement of artificial intelligence” — education for AI — but does not actually deal with AI in education directly. However, it is concerned with general principles that are applicable to education. Specifically, Objective 5 (from page 41) focuses on ‘Ethical and safe application of artificial intelligence’. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Divides focus relatively evenly between risk and opportunity",
        "File": [
          "Serbia_Strategy_for_Development_of_Artificial_Intelligence_in_Republic_of_Serbia_2020-2025.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“. In this sense, the development of an ethical framework should enable the protection of basic human rights and common values,” (p 43)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "There is an entire section on: “Protection from discrimination in the implementation of artificial intelligence” (p 42)\n\n“The data used for training algorithms can be based on past discrimination (e.g. women have been higher risk taxpayers in the past and the algorithm forecasts the same situation in the future), there can be unbalanced data (e.g. significantly more data for men than for women causing the algorithm to favor men afterwards), or the responsible person fails at including all relevant data sources in the training. In addition, individuals who are subject to the decisions made by the AI model must have the right to an explanation and the right to transparency in connection with the algorithm. That is why it is necessary to enable: prevention of discrimination, enable early understanding and interpretation of the model and enable explanation of the decision.”",
        "General principles on AI": [
          "Inclusive development. AI systems should be developed inclusively. ",
          "Human rights-centred. AI systems should be compatible with human rights. ",
          "Harm Avoidance. AI systems should not harm the wellbeing or safety of members of society.",
          "Respect for laws [NEW]. AI should respect existing law.",
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Bias testing. AI systems should be tested for bias. ",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Opportunity. The opportunities of AI should be harnessed.",
          "Interoperability. AI systems should be able to work with other systems. ",
          "Trust. AI systems should not be used so as to undermine society’s trust. ",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. "
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26466",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": [
          "Will Cesta"
        ],
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Serbia: Strategy for the Development of AI in the Republic of Serbia for the Period 2020-2025",
        "Translation Comments": ""
      },
      "id": "i-XFPq4O1wP8",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-XFPq4O1wP8",
      "name": "Serbia: Strategy for the Development of AI in the Republic of Serbia for the Period 2020-2025",
      "index": 230,
      "createdAt": "2024-05-22T21:36:10.291Z",
      "updatedAt": "2024-06-05T23:35:51.831Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-XFPq4O1wP8"
    },
    {
      "values": {
        "Category of creator": [
          "Non-OECD"
        ],
        "Policy creator": [
          "Vietnam"
        ],
        "Policy Name": "National Strategy on R&D and Application of AI",
        "Year of Commencement or Creation": "2021",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "There is a clear intention here for the government of Viet Nam to drive the adoption of AI in education. The policy is very ‘opportunity-oriented’—very little is said about risk management. Still, there is clearly a governmental intervention concerned with AI in education — not merely education for AI capacity — so it is worth including this. ",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Does Not Specify"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Plans further action. It sets out a strategy on AI"
        ],
        "Opportunity and risk orientation": "Opportunity-focused (says significantly more about opportunities than risks)",
        "File": [
          "National Strategy On R&D and Application of Artificial Intelligence.pdf"
        ],
        "Key quotes on AI in education principles": "“Promote and carry out AI applications in the education sector: predict the work demand of the market; identify the student assessment criteria, support students to identify their job strengths upon graduation; automate the professional process of teachers; identify the criteria for achieving learning goals; personalize learning, improve learning efficiency with the help of teachers and virtual tutors to support students' awareness.” (p 18)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — One or two fleeting references, but not significant to the policy",
        "Key quote on human rights": "“Develop and supplement additional legal documents on privacy protection, human rights, security related to the development and application of AI and on ensuring network security for AI-related activities.” (p 5)",
        "Does the policy reflect the principle of equity/equality?": "No",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "R&D. Sufficient resources should be invested in AI R&D.",
          "Opportunity. The opportunities of AI should be harnessed."
        ],
        "Link (OECD or Other)": "https://en.baochinhphu.vn/national-strategy-on-rd-and-application-of-artificial-intelligence-11140663.htm",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 1,
        "Title": "Vietnam: National Strategy on R&D and Application of AI",
        "Translation Comments": "Translation Needed"
      },
      "id": "i-hVLihd7Ntd",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-hVLihd7Ntd",
      "name": "Vietnam: National Strategy on R&D and Application of AI",
      "index": 13,
      "createdAt": "2024-05-22T21:13:42.079Z",
      "updatedAt": "2024-06-05T21:38:16.468Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-hVLihd7Ntd"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Australia"
        ],
        "Policy Name": "Humans rights and technology discussion paper",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This paper certainly engages with the topic of education, but it is not exclusively focused on the safe and effective use of AI in education—it is identifying human rights risks. However, the content is broadly relevant, so it is worth including.",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. "
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "techrights_2019_discussionpaper_0.pdf"
        ],
        "Key quotes on AI in education principles": "“New technologies can improve the availability and accessibility of education. Lack of access to technology can exacerbate inequality, based on factors such as age, disability, Indigenous status, and rural or remote location.” (p 18)\n",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as the objective or justification of the policy (the primary objective or justification)",
        "Key quote on human rights": "“But we also saw how artificial intelligence (AI) and other new technologies can threaten our human rights. Time and again people told us, ‘I’m starting to realise that my personal information can be used against me’.” (p 7)\n\nAlso note its reference to the Convention on the Rights of Persons with Disabilities, which provides for: \n“equality in education, including taking appropriate measures facilitating and delivering education in the most appropriate modes and means of communication” (quoted on p 150)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "“The ultimate goal should be AI that benefits humanity by contributing to a more responsible and equitable society. By inviting multi-stakeholder input, considering risks, and setting rights-respecting standards, Australia has the opportunity to be among the norm-setters on the world stage.”\n\n(Another source quoted on p 133)",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26833",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 9,
        "Title": "Australia: Humans rights and technology discussion paper",
        "Translation Comments": "N/A - English"
      },
      "id": "i-0I94x5PNst",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-0I94x5PNst",
      "name": "Australia: Humans rights and technology discussion paper",
      "index": 237,
      "createdAt": "2024-05-21T09:52:27.091Z",
      "updatedAt": "2024-06-04T22:33:52.017Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-0I94x5PNst"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Australia"
        ],
        "Policy Name": "AI Ethics Framework ",
        "Year of Commencement or Creation": "2019",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "In principle, these principles apply to any form of AI deployed in Australia, including AI in education. ",
        "Relevance Type": [
          "Policy expresses principles or ideas that could inform the governance of AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "[N/A: Expressed at a high level of abstraction and does not specifically engage with AI in education]"
        ],
        "Governance practices employed": [
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Australia’s AI Ethics Principles _ Australia’s Artificial Intelligence Ethics Framework _ Department of Industry Science and Resources.pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“Human rights risks need to be carefully considered, as AI systems can equally enable and hamper such fundamental rights. It’s permissible to interfere with certain human rights where it’s reasonable, necessary and proportionate.” (no pinpoint)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "“This principle aims to ensure that AI systems are fair and that they enable inclusion throughout their entire lifecycle. AI systems should be user-centric and designed in a way that allows all people interacting with it to access the related products or services. This includes both appropriate consultation with stakeholders, who may be affected by the AI system throughout its lifecycle, and ensuring people receive equitable access and treatment. This is particularly important given concerns about the potential for AI to perpetuate societal injustices and have a disparate impact on vulnerable and underrepresented groups including, but not limited to, groups relating to age, disability, race, sex, intersex status, gender identity and sexual orientation. Measures should be taken to ensure the AI produced decisions are compliant with anti-discrimination laws.”",
        "General principles on AI": [
          "Transparency (explainability). AI systems should be sufficiently explainable.",
          "Transparency (transparency to user). It should be clear to the user of an AI system that they are using an AI system. ",
          "Transparency (transparency to government). The extent to which AI is used in a given settings should be clear to the government. ",
          "Ex-post impact assessment / monitoring. AI systems must be subject to monitoring, including independent audits, once deployed. ",
          "Equity/equality (non-augmentation of inequity/inequality). AI systems should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Privacy and data protection. AI systems should not create privacy or data security vulnerabilities.",
          "Accountability. It should always be clear who is accountable for the use of AI, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress.",
          "Technical robustness. AI systems should be technically robust, meaning that they can be relied on to work as intended. ",
          "Cyber-security and rogue actors. AI systems should be resilient to cyber-attacks from rogue actors. ",
          "Contestability. Users of AI systems should have the opportunity to contest outputs. ",
          "Environmental wellbeing. The use of AI should not harm the environment. ",
          "Inclusive development. AI systems should be developed inclusively. "
        ],
        "Link (OECD or Other)": "https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics-principles",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 6,
        "Title": "Australia: AI Ethics Framework ",
        "Translation Comments": "N/A - English"
      },
      "id": "i-X2pIeYByF8",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-X2pIeYByF8",
      "name": "Australia: AI Ethics Framework ",
      "index": 5,
      "createdAt": "2024-05-18T00:05:19.692Z",
      "updatedAt": "2024-06-02T22:43:23.722Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-X2pIeYByF8"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Australia"
        ],
        "Policy Name": "Australian Framework for Generative AI in Schools",
        "Year of Commencement or Creation": "2023",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "The Australian Framework for Generative AI in Schools is the most relevant Australian policy to the topic of ‘governance of AI in education’.",
        "Relevance Type": [
          "Policy is about AI in education"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "Primary",
          "Secondary"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric.",
          "Augmentation, not replacement. AI systems should not be used in educational settings as a replacement for teachers.",
          "Critical thinking. Use of the tools should not come at the cost of critical thinking.  ",
          "Academic integrity. Students should be supported to use AI tools ethically in their work, which extends to appropriate attribution.",
          "Understanding of strengths and limitations. Schools deploying AI should — through systematic instruction — teach students about the technology’s strengths and limitations. ",
          "Harm avoidance. AI systems used in schools should not harm the wellbeing or safety of any member of the school community. ",
          "Managing bias. The risk of bias should be managed with care. ",
          "Promoting diversity. Technology should be used to expose users to diverse perspectives. ",
          "Human rights-centred. The technology must be consistent with human rights. ",
          "Transparency (transparency to user). It should be clear to users — including students and schools — of an AI system in educational settings that they are using an AI system. ",
          "Information. Information about the technology in use should be readily available. ",
          "Equity/Inequality (non-augmentation on inequity/inequality, non-augmentation of discrimination). AI systems used in educational settings should not augment inequity/inequality throughout societies (for example, by being unevenly distributed). ",
          "Equity/equality (increasing equity/equality). This technology should be used as a means of reducing existing educational inequities/inequalities. ",
          "Intellectual property compliance. Education organisations should ensure that AI systems used in educational settings are compliant with intellectual property obligations.",
          "Accountability. It should always be clear who is accountable for the use of AI in educational settings, which entails clarity about who must report negative impacts, who must reduce negative impacts, and who must provide redress. ",
          "Robustness (technically robust). AI systems used in educational settings should be technically robust, meaning that they are reliable.",
          "Monitoring. AI systems used in educational settings must be subject to monitoring, including independent audits.",
          "Contestability. Users of AI systems in educational settings should have the opportunity to contest outputs. ",
          "Privacy and data protection. AI systems used in educational settings should not create privacy or data security vulnerabilities.",
          "Transparency (explainability of method). AI systems used in education should be sufficiently explainable, meaning that the methods of tools are broadly understandable.  ",
          "Cyber-security and rogue actors. AI systems used in educational settings should be resilient to cyber-attacks from rogue actors. ",
          "Pedagogical optimisation. Generative AI models used in pedagogy should be specifically optimised for pedagogy. ",
          "Privacy disclosure. School communities are made aware how data is being collected and used by developers of AI systems."
        ],
        "Governance practices employed": [
          "Educates. It helps officials or others understand the opportunities and risks of AI",
          "Offers guidance. It provides high-level guidance to organisations on how to use AI ethically"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "Australian Framework for Generative AI in Schools (2).pdf"
        ],
        "Key quotes on AI in education principles": "",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as an objective or justification of the policy (one of several objectives or justifications)",
        "Key quote on human rights": "“generative AI tools are used in ways that respect human and worker rights, including individual autonomy and dignity.” (p 6)",
        "Does the policy reflect the principle of equity/equality?": "Yes — it talks about both (a) the risk of AI augmenting inequities/inequalities AND (b) AI as a tool for promoting equitable/equal access",
        "Key quote on equity/equality": "4.1 Accessibility and inclusivity: generative AI tools are used in ways that enhance opportunities, and are inclusive, accessible, and equitable for people with disability and from diverse backgrounds. 4.2 Equity and access: regional, rural and remote communities are considered when implementing generative AI.(p 7)\n\nThe Framework aims to ensure that generative AI tools are used in ways that are fair, accessible and inclusive of all Australian school communities. (p 4)",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27568",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 8,
        "Title": "Australia: Australian Framework for Generative AI in Schools",
        "Translation Comments": "N/A - English"
      },
      "id": "i-kTVWc1qdJN",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-kTVWc1qdJN",
      "name": "Australia: Australian Framework for Generative AI in Schools",
      "index": 6,
      "createdAt": "2024-05-18T00:05:19.692Z",
      "updatedAt": "2024-06-04T22:34:11.566Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-kTVWc1qdJN"
    },
    {
      "values": {
        "Category of creator": [
          "OECD"
        ],
        "Policy creator": [
          "Australia"
        ],
        "Policy Name": "Safe and Responsible AI in Australia: Interim Response",
        "Year of Commencement or Creation": "2024",
        "Reasons for inclusion in / exclusion from our \"Approaches to Governing AI in Education\" table": "This consultation process yielded some relevant material and expresses norms concerned with opportunities (eg, ‘offering personalised learning experiences’).",
        "Relevance Type": [
          "Policy has an AI in education component"
        ],
        "What kinds of education, if any, are contemplated by the policy?": [
          "[N/A]"
        ],
        "Principles on AI in education": [
          "Opportunity-harnessing. Obligations surrounding the use of AI systems in educational settings are not only negative—educators, education leaders, and educational organisations should harness the opportunities to make education more innovative, inclusive, efficient and student-centric."
        ],
        "Governance practices employed": [
          "Seeks information. It gathers inputs on public sentiment about AI"
        ],
        "Opportunity and risk orientation": "Risk-focused (says significantly more about risk than opportunities)",
        "File": [
          "safe-and-responsible-ai-in-australia-governments-interim-response (1).pdf"
        ],
        "Key quotes on AI in education principles": "“AI has the potential to improve educational outcomes for children. It can offer personalised learning experiences which address their unique needs or help them to collaborate and develop critical thinking and problem-solving skills” (p 9)\n\nNote that they pointed out that AI in education is considered “high-risk” (p 14)",
        "Does the policy reflect the principle of human rights compatibility?": "Yes — as background information directly linked to the policy’s goals/aims/purpose",
        "Key quote on human rights": "“But harms may also manifest at a systemic level, with outputs potentially compromising political and social cohesion, stability of labour markets and human rights.” (p 10)",
        "Does the policy reflect the principle of equity/equality?": "One or two fleeting references, but not significant to the policy",
        "Key quote on equity/equality": "",
        "General principles on AI": [
          "[N/A]"
        ],
        "Link (OECD or Other)": "https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-27593",
        "Analysis Complete": true,
        "Draft Analysis Complete": false,
        "Key quotes on general AI principles": "",
        "Notable Case Studes - Examples of AI in Education": "",
        "Other Points of Interest": "",
        "Reasons for non-inclusion (other than \"Irrelevant\")": "",
        "Record Entered By": "",
        "Relevant?": "Yes",
        "Series #": 16,
        "Title": "Australia: Safe and Responsible AI in Australia: Interim Response",
        "Translation Comments": "N/A - English"
      },
      "id": "i-IPrCsM4tqD",
      "href": "https://coda.io/apis/v1/docs/84zKD-l2wx/tables/table-CMAV206Hzq/rows/i-IPrCsM4tqD",
      "name": "Australia: Safe and Responsible AI in Australia: Interim Response",
      "index": 9,
      "createdAt": "2024-05-18T00:05:19.692Z",
      "updatedAt": "2024-06-04T22:34:03.751Z",
      "browserLink": "https://coda.io/d/_d84zKD-l2wx#_tutable-CMAV206Hzq/_rui-IPrCsM4tqD"
    }
  ]
}